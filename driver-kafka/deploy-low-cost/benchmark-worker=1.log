13:47:15.621 [main] INFO log - Logging initialized @3718ms to org.eclipse.jetty.util.log.Slf4jLog
13:47:15.702 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
13:47:15.732 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@323e8306{/,null,AVAILABLE}
13:47:15.748 [main] INFO AbstractConnector - Started ServerConnector@733c423e{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
13:47:15.748 [main] INFO Server - Started @3848ms
13:47:15.750 [main] INFO PrometheusMetricsProvider - Started Prometheus stats endpoint at 0.0.0.0:8081
13:47:15.787 [main] INFO BenchmarkWorker - Starting benchmark with config: {
  "httpPort" : 8080,
  "statsPort" : 8081
}
13:47:15.831 [main] INFO Javalin - 
 _________________________________________
|        _                  _ _           |
|       | | __ ___   ____ _| (_)_ __      |
|    _  | |/ _` \ \ / / _` | | | '_ \     |
|   | |_| | (_| |\ V / (_| | | | | | |    |
|    \___/ \__,_| \_/ \__,_|_|_|_| |_|    |
|_________________________________________|
|                                         |
|    https://javalin.io/documentation     |
|_________________________________________|
13:47:15.834 [main] INFO Javalin - Starting Javalin ...
13:47:15.841 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
13:47:15.853 [main] INFO session - DefaultSessionIdManager workerName=node0
13:47:15.854 [main] INFO session - No SessionScavenger set, using defaults
13:47:15.855 [main] INFO session - node0 Scavenging every 660000ms
13:47:15.856 [main] INFO ContextHandler - Started i.j.e.j.@69b2f8e5{/,null,AVAILABLE}
13:47:15.856 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@a10c1b5{/,null,AVAILABLE}
13:47:15.858 [main] INFO AbstractConnector - Started ServerConnector@c3c4c1c{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
13:47:15.858 [main] INFO Server - Started @3957ms
13:47:15.858 [main] INFO EmbeddedServer - Jetty is listening on: [http://localhost:8080]
13:47:15.858 [main] INFO Javalin - Javalin has started \o/
13:47:15.928 [main] INFO InstanceWorkerStats - Instance worker stats initialized.
13:47:20.909 [qtp435803541-24] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
13:47:20.935 [qtp435803541-24] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

13:47:20.991 [qtp435803541-24] INFO AppInfoParser - Kafka version: 3.6.1
13:47:20.991 [qtp435803541-24] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:20.991 [qtp435803541-24] INFO AppInfoParser - Kafka startTimeMs: 1717336040989
13:47:23.734 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-002-6pJt9n8-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-002-6pJt9n8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.774 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.774 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.774 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043774
13:47:23.775 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Subscribed to topic(s): test-topic-0000002-AnoRVV8
13:47:23.781 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-005-28wZdjg-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-005-28wZdjg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.791 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.791 [pool-5-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.791 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.792 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043791
13:47:23.792 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Subscribed to topic(s): test-topic-0000005-z0C2FwA
13:47:23.792 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.793 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-008-5QZvSRw-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-008-5QZvSRw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.794 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] (Re-)joining group
13:47:23.797 [pool-6-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.798 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:23.798 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] (Re-)joining group
13:47:23.803 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.803 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.803 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043803
13:47:23.804 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Subscribed to topic(s): test-topic-0000008-0nz4Z_4
13:47:23.808 [pool-7-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.805 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-011-vfzfH9A-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-011-vfzfH9A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.811 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.811 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] (Re-)joining group
13:47:23.812 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Request joining group due to: need to re-join with the given member-id: consumer-sub-002-6pJt9n8-1-8f788499-14a2-4388-a193-c64fc8e13a09
13:47:23.812 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Request joining group due to: need to re-join with the given member-id: consumer-sub-005-28wZdjg-2-f9a6918c-9f67-4719-84a9-d58993c8a686
13:47:23.812 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.812 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.812 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] (Re-)joining group
13:47:23.812 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] (Re-)joining group
13:47:23.814 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Request joining group due to: need to re-join with the given member-id: consumer-sub-008-5QZvSRw-3-809c9842-8f62-49bb-8c73-55c3e140cdfa
13:47:23.815 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.815 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] (Re-)joining group
13:47:23.819 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.819 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.819 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043819
13:47:23.820 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Subscribed to topic(s): test-topic-0000011-zxqm4Mw
13:47:23.821 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-014-h9wlUsU-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-014-h9wlUsU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.823 [pool-8-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.823 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.824 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] (Re-)joining group
13:47:23.827 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Request joining group due to: need to re-join with the given member-id: consumer-sub-011-vfzfH9A-4-731f88af-6d6e-4dc9-95e0-8ba82b799454
13:47:23.828 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.828 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] (Re-)joining group
13:47:23.831 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.831 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.831 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043831
13:47:23.832 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Subscribed to topic(s): test-topic-0000014-CFLlGHs
13:47:23.833 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-017-jJK44Wo-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-017-jJK44Wo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.837 [pool-9-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.837 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.838 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] (Re-)joining group
13:47:23.841 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.841 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.841 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043841
13:47:23.841 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Subscribed to topic(s): test-topic-0000017--qoxjPU
13:47:23.842 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Request joining group due to: need to re-join with the given member-id: consumer-sub-014-h9wlUsU-5-3d5358a1-edfd-41bc-aee9-8883790397c3
13:47:23.842 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.842 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] (Re-)joining group
13:47:23.843 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-020-KL6yeeg-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-020-KL6yeeg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.846 [pool-10-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.847 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.847 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] (Re-)joining group
13:47:23.850 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.850 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.850 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043850
13:47:23.850 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Subscribed to topic(s): test-topic-0000020-M_uOt0w
13:47:23.851 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Request joining group due to: need to re-join with the given member-id: consumer-sub-017-jJK44Wo-6-93ab2526-0b00-482f-8c38-ca651f8ccf3f
13:47:23.851 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.851 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-023-Sc7rr-s-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-023-Sc7rr-s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.851 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] (Re-)joining group
13:47:23.855 [pool-11-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.855 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.856 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] (Re-)joining group
13:47:23.858 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.858 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.858 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043858
13:47:23.859 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Subscribed to topic(s): test-topic-0000023-UFWJKKU
13:47:23.860 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Request joining group due to: need to re-join with the given member-id: consumer-sub-020-KL6yeeg-7-13ca6c0b-0792-40c1-bef6-77351eed41fc
13:47:23.860 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-026-DpHAoCo-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-026-DpHAoCo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.860 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.860 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] (Re-)joining group
13:47:23.863 [pool-12-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.864 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.864 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.864 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.864 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043864
13:47:23.864 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] (Re-)joining group
13:47:23.864 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Subscribed to topic(s): test-topic-0000026-PbTraa0
13:47:23.865 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-029-YeUzVKw-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-029-YeUzVKw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.867 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Request joining group due to: need to re-join with the given member-id: consumer-sub-023-Sc7rr-s-8-072fd039-3829-4bc4-8c10-0019c42e1cd7
13:47:23.868 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.868 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] (Re-)joining group
13:47:23.869 [pool-13-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.869 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.870 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] (Re-)joining group
13:47:23.871 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.871 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.871 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043871
13:47:23.872 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Subscribed to topic(s): test-topic-0000029-Sq99nJQ
13:47:23.873 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-032-r4YZhPU-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-032-r4YZhPU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.873 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Request joining group due to: need to re-join with the given member-id: consumer-sub-026-DpHAoCo-9-fdc1aea6-c633-422d-a7be-c6cac19b7539
13:47:23.874 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.874 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] (Re-)joining group
13:47:23.876 [pool-14-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.876 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:23.877 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] (Re-)joining group
13:47:23.878 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.878 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.878 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043878
13:47:23.879 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Subscribed to topic(s): test-topic-0000032-uNikqf8
13:47:23.879 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Request joining group due to: need to re-join with the given member-id: consumer-sub-029-YeUzVKw-10-5fd7da0d-6907-4a33-aa28-10a04f45587d
13:47:23.880 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.880 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-035-AuoUT6k-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-035-AuoUT6k
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.880 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] (Re-)joining group
13:47:23.883 [pool-15-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.884 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:23.884 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] (Re-)joining group
13:47:23.885 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.885 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.885 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043885
13:47:23.885 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Subscribed to topic(s): test-topic-0000035-xhp6_oA
13:47:23.886 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-038-KClQAEM-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-038-KClQAEM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.887 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Request joining group due to: need to re-join with the given member-id: consumer-sub-032-r4YZhPU-11-c3c26292-31ca-412e-b76b-f5f492eecee7
13:47:23.887 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.887 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] (Re-)joining group
13:47:23.889 [pool-16-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.889 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.890 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] (Re-)joining group
13:47:23.891 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.891 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.891 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043891
13:47:23.892 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Subscribed to topic(s): test-topic-0000038-aoczOmE
13:47:23.893 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Request joining group due to: need to re-join with the given member-id: consumer-sub-035-AuoUT6k-12-6346eb87-995b-4970-a3c2-17bf0a4c3d3a
13:47:23.893 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-041-t9PKIe0-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-041-t9PKIe0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.894 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.894 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] (Re-)joining group
13:47:23.895 [pool-17-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.896 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:23.898 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.898 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.898 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043898
13:47:23.898 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] (Re-)joining group
13:47:23.898 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Subscribed to topic(s): test-topic-0000041-Ni38W-8
13:47:23.899 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-044-_n5fOqk-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-044-_n5fOqk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.901 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Request joining group due to: need to re-join with the given member-id: consumer-sub-038-KClQAEM-13-1cbadd5a-4333-4704-b9f2-c05078138e7f
13:47:23.901 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.901 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] (Re-)joining group
13:47:23.905 [pool-18-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.906 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:23.907 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] (Re-)joining group
13:47:23.908 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.908 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.908 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043908
13:47:23.908 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Subscribed to topic(s): test-topic-0000044-HLDd740
13:47:23.909 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-047-S-X33T4-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-047-S-X33T4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.910 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Request joining group due to: need to re-join with the given member-id: consumer-sub-041-t9PKIe0-14-2be82650-082f-41d9-8cb2-1cd13812d3d0
13:47:23.910 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.910 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] (Re-)joining group
13:47:23.912 [pool-19-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.912 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.913 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] (Re-)joining group
13:47:23.915 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Request joining group due to: need to re-join with the given member-id: consumer-sub-044-_n5fOqk-15-e4c285eb-9dac-4772-9716-7e4c269a2559
13:47:23.915 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.915 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.915 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.915 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043915
13:47:23.916 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] (Re-)joining group
13:47:23.916 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Subscribed to topic(s): test-topic-0000047-Ci_iHCk
13:47:23.917 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-050-FKJ6dKc-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-050-FKJ6dKc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.919 [pool-20-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.919 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.920 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] (Re-)joining group
13:47:23.921 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.921 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.921 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043921
13:47:23.922 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Subscribed to topic(s): test-topic-0000050-n3f7BfU
13:47:23.923 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Request joining group due to: need to re-join with the given member-id: consumer-sub-047-S-X33T4-16-723b0863-9428-4ed3-80d4-3cc4aaac66dc
13:47:23.923 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.923 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] (Re-)joining group
13:47:23.923 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-053-3OvowAU-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-053-3OvowAU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.925 [pool-21-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.926 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.926 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] (Re-)joining group
13:47:23.927 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.927 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.927 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043927
13:47:23.928 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Subscribed to topic(s): test-topic-0000053-Wz-ZTHE
13:47:23.929 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-056-7GWVmy8-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-056-7GWVmy8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.929 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Request joining group due to: need to re-join with the given member-id: consumer-sub-050-FKJ6dKc-17-f4444449-c6cc-41fd-b2f7-d8d9cb807620
13:47:23.929 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.930 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] (Re-)joining group
13:47:23.931 [pool-22-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.931 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.932 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] (Re-)joining group
13:47:23.933 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.933 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.933 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043933
13:47:23.933 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Subscribed to topic(s): test-topic-0000056-Hx4phh4
13:47:23.934 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-059-PRMMTYA-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-059-PRMMTYA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.935 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Request joining group due to: need to re-join with the given member-id: consumer-sub-053-3OvowAU-18-cef1be47-bebe-4fce-94ff-75e10c0e7f5e
13:47:23.935 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.935 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] (Re-)joining group
13:47:23.937 [pool-23-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.937 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.939 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.939 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.939 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043938
13:47:23.939 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Subscribed to topic(s): test-topic-0000059-2eeNhoM
13:47:23.940 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] (Re-)joining group
13:47:23.942 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Request joining group due to: need to re-join with the given member-id: consumer-sub-056-7GWVmy8-19-a1266d37-a0a5-48b8-99c4-d5f7ff3095cf
13:47:23.942 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.942 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] (Re-)joining group
13:47:23.946 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-062-Ium84nQ-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-062-Ium84nQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.949 [pool-24-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.949 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:23.950 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] (Re-)joining group
13:47:23.950 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.950 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.950 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043950
13:47:23.951 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Subscribed to topic(s): test-topic-0000062-rNORlD0
13:47:23.952 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Request joining group due to: need to re-join with the given member-id: consumer-sub-059-PRMMTYA-20-db584db0-06e0-4522-9aa3-90642c798f3a
13:47:23.953 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.953 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] (Re-)joining group
13:47:23.953 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-065-kktaSis-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-065-kktaSis
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.955 [pool-25-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.956 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:23.956 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] (Re-)joining group
13:47:23.957 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.957 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.958 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043957
13:47:23.958 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Subscribed to topic(s): test-topic-0000065-9yyIq1M
13:47:23.959 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-062-Ium84nQ-21-6139ed74-9428-4e7e-9b2c-76f7bdf47a35
13:47:23.959 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.959 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] (Re-)joining group
13:47:23.959 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-068-Ji5gaPU-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-068-Ji5gaPU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.961 [pool-26-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.962 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.962 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] (Re-)joining group
13:47:23.963 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.963 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.963 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043963
13:47:23.963 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Subscribed to topic(s): test-topic-0000068-BieU9RA
13:47:23.965 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Request joining group due to: need to re-join with the given member-id: consumer-sub-065-kktaSis-22-bf46199c-0624-40e1-a557-7e63612e30a6
13:47:23.965 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.965 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] (Re-)joining group
13:47:23.965 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-071-J3wy12s-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-071-J3wy12s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.968 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.968 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.968 [pool-27-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.968 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043968
13:47:23.969 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Subscribed to topic(s): test-topic-0000071-VWYOjwM
13:47:23.969 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.969 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] (Re-)joining group
13:47:23.970 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-074-OhduXsk-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-074-OhduXsk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.972 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Request joining group due to: need to re-join with the given member-id: consumer-sub-068-Ji5gaPU-23-19cd400e-e86e-4a31-ad36-22d481df0eac
13:47:23.972 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.972 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] (Re-)joining group
13:47:23.972 [pool-28-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.973 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.973 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] (Re-)joining group
13:47:23.974 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.974 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.974 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043974
13:47:23.974 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Subscribed to topic(s): test-topic-0000074-qfrgGP4
13:47:23.976 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Request joining group due to: need to re-join with the given member-id: consumer-sub-071-J3wy12s-24-7063b7cc-7c03-4b1d-93b0-1b5c40bc9d8e
13:47:23.976 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.976 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] (Re-)joining group
13:47:23.978 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-077-kf_A-30-26
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-077-kf_A-30
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.981 [pool-29-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.981 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.981 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:23.981 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.981 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043981
13:47:23.981 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Subscribed to topic(s): test-topic-0000077-bmvIbiY
13:47:23.982 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] (Re-)joining group
13:47:23.983 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-080-rGHvUyw-27
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-080-rGHvUyw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.984 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Request joining group due to: need to re-join with the given member-id: consumer-sub-074-OhduXsk-25-0ec884a4-c0d6-470e-a80f-c7c42181c0b4
13:47:23.984 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.984 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] (Re-)joining group
13:47:23.986 [pool-30-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.986 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.987 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.987 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.987 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043987
13:47:23.987 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Subscribed to topic(s): test-topic-0000080-GSwinHI
13:47:23.991 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] (Re-)joining group
13:47:23.993 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-083-CCXFO58-28
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-083-CCXFO58
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.993 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Request joining group due to: need to re-join with the given member-id: consumer-sub-077-kf_A-30-26-7c2873bc-089a-4612-9357-4f122b95e2d0
13:47:23.993 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.993 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] (Re-)joining group
13:47:23.994 [pool-31-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:23.995 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:23.995 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] (Re-)joining group
13:47:23.996 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:23.996 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:23.997 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336043996
13:47:23.997 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Subscribed to topic(s): test-topic-0000083-g-BmxjQ
13:47:23.998 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Request joining group due to: need to re-join with the given member-id: consumer-sub-080-rGHvUyw-27-80ee91b0-74cf-4c1f-ba30-2e6c9b800f73
13:47:23.998 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-086-VXzAfEs-29
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-086-VXzAfEs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:23.999 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:23.999 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] (Re-)joining group
13:47:24.002 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.002 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.002 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044002
13:47:24.002 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Subscribed to topic(s): test-topic-0000086-cFlu7XU
13:47:24.005 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-089-BLOZYn0-30
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-089-BLOZYn0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.007 [pool-33-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.011 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.007 [pool-32-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.012 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.013 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] (Re-)joining group
13:47:24.014 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] (Re-)joining group
13:47:24.014 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.014 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.015 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044014
13:47:24.015 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Subscribed to topic(s): test-topic-0000089-x68IQU4
13:47:24.016 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-092-UVWIdU0-31
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-092-UVWIdU0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.019 [pool-34-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.021 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.016 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Request joining group due to: need to re-join with the given member-id: consumer-sub-083-CCXFO58-28-16613d5f-0adf-481e-995f-9841136adfa5
13:47:24.022 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.022 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] (Re-)joining group
13:47:24.023 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] (Re-)joining group
13:47:24.023 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Request joining group due to: need to re-join with the given member-id: consumer-sub-086-VXzAfEs-29-21ccb2df-6890-4b1f-8ecf-95c6c7f03772
13:47:24.023 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.023 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] (Re-)joining group
13:47:24.024 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.025 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.025 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044024
13:47:24.025 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Subscribed to topic(s): test-topic-0000092-JXGTSos
13:47:24.025 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Request joining group due to: need to re-join with the given member-id: consumer-sub-089-BLOZYn0-30-628fc7ff-ba8d-442d-bb54-bac762ec10a1
13:47:24.026 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.026 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] (Re-)joining group
13:47:24.027 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-095-FqcULd4-32
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-095-FqcULd4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.029 [pool-35-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.030 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.030 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.030 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.031 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044030
13:47:24.031 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Subscribed to topic(s): test-topic-0000095-zPq6gTM
13:47:24.032 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] (Re-)joining group
13:47:24.033 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-098-AHs-bqI-33
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-098-AHs-bqI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.034 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Request joining group due to: need to re-join with the given member-id: consumer-sub-092-UVWIdU0-31-39ff6be8-3057-40db-afdf-b7c99526be9a
13:47:24.034 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.035 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] (Re-)joining group
13:47:24.037 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.039 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.039 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044037
13:47:24.039 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Subscribed to topic(s): test-topic-0000098-H_jRR9A
13:47:24.041 [pool-36-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.041 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-101-Ca9dsZA-34
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-101-Ca9dsZA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.044 [pool-37-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.044 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.044 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.044 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.045 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044044
13:47:24.045 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Subscribed to topic(s): test-topic-0000101-LhC-54M
13:47:24.046 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.046 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] (Re-)joining group
13:47:24.048 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Request joining group due to: need to re-join with the given member-id: consumer-sub-098-AHs-bqI-33-3b030e93-85a1-46d0-a58e-3fce11ac3238
13:47:24.048 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.049 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] (Re-)joining group
13:47:24.051 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] (Re-)joining group
13:47:24.051 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-104-PSzEn5A-35
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-104-PSzEn5A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.053 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Request joining group due to: need to re-join with the given member-id: consumer-sub-095-FqcULd4-32-6cf9ce82-713e-4e5b-b159-6e9ff299756c
13:47:24.056 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.056 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] (Re-)joining group
13:47:24.054 [pool-38-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.057 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.058 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] (Re-)joining group
13:47:24.059 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.060 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.060 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044059
13:47:24.060 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Subscribed to topic(s): test-topic-0000104--zE_tVI
13:47:24.060 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Request joining group due to: need to re-join with the given member-id: consumer-sub-101-Ca9dsZA-34-319a2c18-4700-4fd8-b1e7-9952abeb1a4b
13:47:24.060 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.060 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] (Re-)joining group
13:47:24.061 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-107-OReCH5E-36
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-107-OReCH5E
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.064 [pool-39-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.064 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.064 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.064 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.064 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044064
13:47:24.065 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Subscribed to topic(s): test-topic-0000107-fjH0hDM
13:47:24.065 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] (Re-)joining group
13:47:24.066 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-110-3jOB2Ps-37
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-110-3jOB2Ps
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.067 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Request joining group due to: need to re-join with the given member-id: consumer-sub-104-PSzEn5A-35-4ddc1bd5-2afa-4041-b3cd-239498bf00fb
13:47:24.067 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.067 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] (Re-)joining group
13:47:24.068 [pool-40-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.069 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.069 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] (Re-)joining group
13:47:24.070 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.070 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.070 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044070
13:47:24.070 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Subscribed to topic(s): test-topic-0000110-mZfst7E
13:47:24.071 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-113-MyqQE38-38
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-113-MyqQE38
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.071 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Request joining group due to: need to re-join with the given member-id: consumer-sub-107-OReCH5E-36-78174b04-0b27-4c6c-a36a-4b456601473b
13:47:24.072 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.072 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] (Re-)joining group
13:47:24.075 [pool-41-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.075 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.075 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.075 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044075
13:47:24.075 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.075 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Subscribed to topic(s): test-topic-0000113-cTWFNVA
13:47:24.076 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] (Re-)joining group
13:47:24.076 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-116-bave-3U-39
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-116-bave-3U
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.078 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Request joining group due to: need to re-join with the given member-id: consumer-sub-110-3jOB2Ps-37-a740afbb-54f1-46aa-897a-32d65be0d2f4
13:47:24.078 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.078 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] (Re-)joining group
13:47:24.080 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.080 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.080 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044080
13:47:24.080 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Subscribed to topic(s): test-topic-0000116-7UdnOfU
13:47:24.081 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-119-jj2jlEI-40
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-119-jj2jlEI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.084 [pool-42-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.084 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.084 [pool-43-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.085 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.085 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] (Re-)joining group
13:47:24.084 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.085 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.085 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044085
13:47:24.085 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Subscribed to topic(s): test-topic-0000119-SlKUM_g
13:47:24.085 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] (Re-)joining group
13:47:24.087 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Request joining group due to: need to re-join with the given member-id: consumer-sub-116-bave-3U-39-389ee98d-15fd-4d14-9a24-36b4bc348953
13:47:24.088 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.088 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] (Re-)joining group
13:47:24.088 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Request joining group due to: need to re-join with the given member-id: consumer-sub-113-MyqQE38-38-922ede0f-3a7d-43fe-93cf-af271a39dd2d
13:47:24.088 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.088 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] (Re-)joining group
13:47:24.088 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-122-JQEf4IY-41
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-122-JQEf4IY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.091 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.091 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.091 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044091
13:47:24.091 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Subscribed to topic(s): test-topic-0000122-BF9iF7A
13:47:24.092 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-125-CejEoPg-42
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-125-CejEoPg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.095 [pool-45-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.095 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.095 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.096 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044095
13:47:24.096 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.096 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Subscribed to topic(s): test-topic-0000125-hZwj-ZY
13:47:24.096 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] (Re-)joining group
13:47:24.097 [pool-44-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.097 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.097 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-128-L92zuD0-43
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-128-L92zuD0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.098 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] (Re-)joining group
13:47:24.098 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Request joining group due to: need to re-join with the given member-id: consumer-sub-122-JQEf4IY-41-673716fc-9927-4a2d-a9fc-627c20dcfb2b
13:47:24.099 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.099 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] (Re-)joining group
13:47:24.100 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Request joining group due to: need to re-join with the given member-id: consumer-sub-119-jj2jlEI-40-db96ff6d-39a0-4e82-a6c6-04d3498245f7
13:47:24.100 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.100 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] (Re-)joining group
13:47:24.101 [pool-46-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.101 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.102 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] (Re-)joining group
13:47:24.103 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.103 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.103 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044102
13:47:24.103 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Subscribed to topic(s): test-topic-0000128-VV-rVFU
13:47:24.104 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-131-5hwf5SE-44
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-131-5hwf5SE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.104 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Request joining group due to: need to re-join with the given member-id: consumer-sub-125-CejEoPg-42-e6df77de-ca5e-4b40-8460-43fa11700289
13:47:24.105 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.105 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] (Re-)joining group
13:47:24.106 [pool-47-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.106 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.107 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] (Re-)joining group
13:47:24.107 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.107 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.107 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044107
13:47:24.108 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Subscribed to topic(s): test-topic-0000131-xgUrqV0
13:47:24.108 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Request joining group due to: need to re-join with the given member-id: consumer-sub-128-L92zuD0-43-44e6a727-4814-4e57-8964-8235c6c350b3
13:47:24.109 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.109 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-134-HsIPgPc-45
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-134-HsIPgPc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.109 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] (Re-)joining group
13:47:24.110 [pool-48-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.111 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.111 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] (Re-)joining group
13:47:24.111 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.112 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.112 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044111
13:47:24.112 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Subscribed to topic(s): test-topic-0000134-Sxkgttc
13:47:24.113 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Request joining group due to: need to re-join with the given member-id: consumer-sub-131-5hwf5SE-44-d52a39e7-2ebc-4f98-8b13-c3ac565899fc
13:47:24.113 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-137-hiju0Qw-46
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-137-hiju0Qw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.113 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.113 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] (Re-)joining group
13:47:24.116 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.116 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.116 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044116
13:47:24.116 [pool-49-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.116 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Subscribed to topic(s): test-topic-0000137-Aei-Pwg
13:47:24.117 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.117 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-140-qIRKxm8-47
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-140-qIRKxm8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.117 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] (Re-)joining group
13:47:24.120 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Request joining group due to: need to re-join with the given member-id: consumer-sub-134-HsIPgPc-45-70543c7a-2485-4284-94d5-eb2810941f9c
13:47:24.120 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.120 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] (Re-)joining group
13:47:24.120 [pool-50-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.120 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.121 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] (Re-)joining group
13:47:24.122 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.122 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.122 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044122
13:47:24.122 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Subscribed to topic(s): test-topic-0000140-EL2B4IY
13:47:24.123 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Request joining group due to: need to re-join with the given member-id: consumer-sub-137-hiju0Qw-46-c26342d1-6083-4e1a-ad06-6f7410e30293
13:47:24.123 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-143-Rsowa4I-48
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-143-Rsowa4I
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.123 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.124 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] (Re-)joining group
13:47:24.126 [pool-51-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.127 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.127 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.127 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.127 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044127
13:47:24.127 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Subscribed to topic(s): test-topic-0000143-6mgkLNE
13:47:24.128 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] (Re-)joining group
13:47:24.129 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-146-p_YEMQg-49
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-146-p_YEMQg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.129 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Request joining group due to: need to re-join with the given member-id: consumer-sub-140-qIRKxm8-47-d61af1ec-0fd2-414d-afe7-297891c24b00
13:47:24.130 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.130 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] (Re-)joining group
13:47:24.132 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.133 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.133 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044132
13:47:24.133 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Subscribed to topic(s): test-topic-0000146-mwLxECY
13:47:24.134 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-149-mud_F7E-50
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-149-mud_F7E
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.134 [pool-52-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.134 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.134 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] (Re-)joining group
13:47:24.136 [pool-53-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.136 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.136 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.137 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Request joining group due to: need to re-join with the given member-id: consumer-sub-143-Rsowa4I-48-39396204-ecec-420a-b644-6fe87e0c6487
13:47:24.137 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.137 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044136
13:47:24.137 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.137 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] (Re-)joining group
13:47:24.137 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Subscribed to topic(s): test-topic-0000149-oEEgv68
13:47:24.138 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-152-UGEJeFY-51
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-152-UGEJeFY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.147 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] (Re-)joining group
13:47:24.148 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.148 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.148 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044148
13:47:24.149 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Subscribed to topic(s): test-topic-0000152-_ZPbr1E
13:47:24.149 [pool-54-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.149 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Request joining group due to: need to re-join with the given member-id: consumer-sub-146-p_YEMQg-49-da5769b1-13ee-4316-bd7e-bb154dfc9c26
13:47:24.149 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.149 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.149 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-155-Z5T-xls-52
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-155-Z5T-xls
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.149 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] (Re-)joining group
13:47:24.150 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] (Re-)joining group
13:47:24.153 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Request joining group due to: need to re-join with the given member-id: consumer-sub-149-mud_F7E-50-7c2787b0-357d-4277-a61f-d4cfce3c452d
13:47:24.153 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.153 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] (Re-)joining group
13:47:24.154 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.154 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.154 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044154
13:47:24.154 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Subscribed to topic(s): test-topic-0000155-lbbml9M
13:47:24.155 [pool-55-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.155 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.155 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-158-s6pzAPM-53
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-158-s6pzAPM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.156 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] (Re-)joining group
13:47:24.158 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Request joining group due to: need to re-join with the given member-id: consumer-sub-152-UGEJeFY-51-3df85ea4-6179-4dc7-bb22-db8612f9f3c6
13:47:24.158 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.158 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] (Re-)joining group
13:47:24.158 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.158 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.158 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044158
13:47:24.158 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Subscribed to topic(s): test-topic-0000158-6CVrNxA
13:47:24.159 [pool-56-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.160 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.160 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-161-pmw2YkA-54
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-161-pmw2YkA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.160 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] (Re-)joining group
13:47:24.162 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Request joining group due to: need to re-join with the given member-id: consumer-sub-155-Z5T-xls-52-6dc893dd-254f-48d5-aeae-bc0005b0b42f
13:47:24.162 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.162 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] (Re-)joining group
13:47:24.163 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.163 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.163 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044163
13:47:24.163 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Subscribed to topic(s): test-topic-0000161-wcsZU2U
13:47:24.163 [pool-57-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.164 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.164 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-164-c0L1gIA-55
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-164-c0L1gIA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.166 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] (Re-)joining group
13:47:24.167 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.167 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.167 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044167
13:47:24.167 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Subscribed to topic(s): test-topic-0000164-gepakbQ
13:47:24.169 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Request joining group due to: need to re-join with the given member-id: consumer-sub-158-s6pzAPM-53-0533c59c-51b8-4937-9784-971ceb6b5e59
13:47:24.169 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.169 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] (Re-)joining group
13:47:24.169 [pool-58-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.169 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.170 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-167-Nnszxcg-56
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-167-Nnszxcg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.172 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] (Re-)joining group
13:47:24.172 [pool-59-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.173 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.173 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.173 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.173 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044173
13:47:24.173 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Subscribed to topic(s): test-topic-0000167-BwF1nXw
13:47:24.174 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Request joining group due to: need to re-join with the given member-id: consumer-sub-161-pmw2YkA-54-fd20b23f-0a5d-49bd-9ff0-4a047515e44c
13:47:24.174 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.174 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] (Re-)joining group
13:47:24.178 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] (Re-)joining group
13:47:24.178 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-170-xjFOjPo-57
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-170-xjFOjPo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.180 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Request joining group due to: need to re-join with the given member-id: consumer-sub-164-c0L1gIA-55-d5a425e6-bdb4-4509-9bc2-a67746302f98
13:47:24.180 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.180 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] (Re-)joining group
13:47:24.180 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.180 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.180 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044180
13:47:24.180 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Subscribed to topic(s): test-topic-0000170-Z0q4Nvo
13:47:24.181 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-173-ASqOG_U-58
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-173-ASqOG_U
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.182 [pool-60-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.183 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.183 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] (Re-)joining group
13:47:24.184 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.185 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.185 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044184
13:47:24.185 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Subscribed to topic(s): test-topic-0000173-6CJkJ1w
13:47:24.185 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Request joining group due to: need to re-join with the given member-id: consumer-sub-167-Nnszxcg-56-b311d82e-730b-436c-9d5e-a7491a9ea67b
13:47:24.185 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.185 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] (Re-)joining group
13:47:24.186 [pool-61-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.186 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.186 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-176-sOqVDj8-59
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-176-sOqVDj8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.188 [pool-62-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.189 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.189 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.189 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.189 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044189
13:47:24.189 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Subscribed to topic(s): test-topic-0000176-BBDA9F8
13:47:24.194 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] (Re-)joining group
13:47:24.195 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Request joining group due to: need to re-join with the given member-id: consumer-sub-170-xjFOjPo-57-5ed4f893-e88a-4d4e-a1de-cb9cd90b0942
13:47:24.196 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.196 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] (Re-)joining group
13:47:24.196 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-179-U_eIN4k-60
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-179-U_eIN4k
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.196 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] (Re-)joining group
13:47:24.198 [pool-63-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.198 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Request joining group due to: need to re-join with the given member-id: consumer-sub-173-ASqOG_U-58-f9c8d3f4-ba89-4237-8f1c-95d3a7485c57
13:47:24.199 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.199 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.199 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] (Re-)joining group
13:47:24.199 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] (Re-)joining group
13:47:24.199 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.199 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.200 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044199
13:47:24.200 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Subscribed to topic(s): test-topic-0000179-Z_sMFPQ
13:47:24.201 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-182-fLKr5eA-61
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-182-fLKr5eA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.201 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Request joining group due to: need to re-join with the given member-id: consumer-sub-176-sOqVDj8-59-436da102-43ab-405b-a630-dd0c924cae1b
13:47:24.201 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.201 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] (Re-)joining group
13:47:24.202 [pool-64-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.202 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.203 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.203 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.203 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044203
13:47:24.204 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Subscribed to topic(s): test-topic-0000182-FHEBZ8A
13:47:24.204 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] (Re-)joining group
13:47:24.205 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-185-eOw6LnQ-62
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-185-eOw6LnQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.206 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Request joining group due to: need to re-join with the given member-id: consumer-sub-179-U_eIN4k-60-724feec0-f178-4288-b258-4ed680e535d1
13:47:24.206 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.206 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] (Re-)joining group
13:47:24.207 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.207 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.207 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044207
13:47:24.207 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Subscribed to topic(s): test-topic-0000185-PO-JbZY
13:47:24.208 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-188-e8Nf0Co-63
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-188-e8Nf0Co
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.211 [pool-66-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.211 [pool-65-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.211 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.211 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.212 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.212 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.212 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044212
13:47:24.212 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Subscribed to topic(s): test-topic-0000188-c6J0hjY
13:47:24.213 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] (Re-)joining group
13:47:24.214 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-191-lBEvzoE-64
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-191-lBEvzoE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.214 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] (Re-)joining group
13:47:24.214 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-185-eOw6LnQ-62-49dc2a3e-a7ea-473a-a7fc-7fa5d1622c72
13:47:24.215 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.215 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] (Re-)joining group
13:47:24.216 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Request joining group due to: need to re-join with the given member-id: consumer-sub-182-fLKr5eA-61-db8a0173-669e-40e6-9d6e-d633d97c8c45
13:47:24.216 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.216 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] (Re-)joining group
13:47:24.216 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.216 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.216 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044216
13:47:24.216 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Subscribed to topic(s): test-topic-0000191-PNN1Bfk
13:47:24.218 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-194-AYLbIW8-65
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-194-AYLbIW8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.220 [pool-68-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.220 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.220 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.220 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.220 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044220
13:47:24.221 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Subscribed to topic(s): test-topic-0000194-K-KCWTE
13:47:24.222 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] (Re-)joining group
13:47:24.223 [pool-67-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.223 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.223 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-197-x1osWkA-66
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-197-x1osWkA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.223 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] (Re-)joining group
13:47:24.224 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Request joining group due to: need to re-join with the given member-id: consumer-sub-191-lBEvzoE-64-07ce3648-0081-473d-b2ea-d4ccf96c2585
13:47:24.225 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.225 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] (Re-)joining group
13:47:24.225 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Request joining group due to: need to re-join with the given member-id: consumer-sub-188-e8Nf0Co-63-6b993404-0e53-4668-980c-17f02a2c84de
13:47:24.225 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.225 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] (Re-)joining group
13:47:24.226 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.226 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.226 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044225
13:47:24.226 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Subscribed to topic(s): test-topic-0000197-CIa3XGw
13:47:24.227 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-200-nWDAepo-67
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-200-nWDAepo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.228 [pool-69-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.228 [pool-70-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.229 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.229 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.229 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] (Re-)joining group
13:47:24.229 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] (Re-)joining group
13:47:24.231 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Request joining group due to: need to re-join with the given member-id: consumer-sub-194-AYLbIW8-65-55a7fc23-7467-43f9-aff7-e16bda169da2
13:47:24.231 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.231 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.231 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Request joining group due to: need to re-join with the given member-id: consumer-sub-197-x1osWkA-66-125bf17f-3127-464f-996a-e488cfde02c2
13:47:24.231 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.231 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044231
13:47:24.231 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] (Re-)joining group
13:47:24.231 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.231 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] (Re-)joining group
13:47:24.232 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Subscribed to topic(s): test-topic-0000200-viNaANQ
13:47:24.232 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-203-gcpAuDY-68
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-203-gcpAuDY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.234 [pool-71-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.234 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.235 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.235 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.235 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044235
13:47:24.235 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] (Re-)joining group
13:47:24.235 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Subscribed to topic(s): test-topic-0000203-9hn2q10
13:47:24.236 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-206-mE-iXvM-69
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-206-mE-iXvM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.237 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Request joining group due to: need to re-join with the given member-id: consumer-sub-200-nWDAepo-67-b6982a80-b4a1-4cb5-a10c-74aa106a449c
13:47:24.237 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.237 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] (Re-)joining group
13:47:24.237 [pool-72-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.238 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.238 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] (Re-)joining group
13:47:24.240 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.240 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.240 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044239
13:47:24.240 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Subscribed to topic(s): test-topic-0000206-sMqOXZA
13:47:24.240 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Request joining group due to: need to re-join with the given member-id: consumer-sub-203-gcpAuDY-68-c51441f3-60df-45e8-9ade-33367f9bf177
13:47:24.240 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.240 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] (Re-)joining group
13:47:24.242 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-209-I8XtIkQ-70
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-209-I8XtIkQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.243 [pool-73-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.244 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.244 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.244 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] (Re-)joining group
13:47:24.244 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.244 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044244
13:47:24.245 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Subscribed to topic(s): test-topic-0000209-PZuErwo
13:47:24.246 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-212-sdMrzi8-71
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-212-sdMrzi8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.246 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Request joining group due to: need to re-join with the given member-id: consumer-sub-206-mE-iXvM-69-2b34de5a-4e9e-4736-89aa-dda572617c74
13:47:24.246 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.246 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] (Re-)joining group
13:47:24.248 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.248 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.248 [pool-74-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.248 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044248
13:47:24.249 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.249 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Subscribed to topic(s): test-topic-0000212-WR9CMwQ
13:47:24.251 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-215-2NGygFY-72
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-215-2NGygFY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.252 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] (Re-)joining group
13:47:24.253 [pool-75-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.254 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.254 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.254 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.254 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044254
13:47:24.254 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Subscribed to topic(s): test-topic-0000215-Zb4mOoY
13:47:24.255 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] (Re-)joining group
13:47:24.257 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Request joining group due to: need to re-join with the given member-id: consumer-sub-212-sdMrzi8-71-89bf0721-7e72-42a8-a30c-5b8fa00fb21f
13:47:24.257 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-218-FyCfM7w-73
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-218-FyCfM7w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.257 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.257 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] (Re-)joining group
13:47:24.259 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.259 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.259 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044259
13:47:24.260 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Subscribed to topic(s): test-topic-0000218-6mkEIxQ
13:47:24.260 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-209-I8XtIkQ-70-2c0b0aa5-c9aa-4875-b72d-b11841d5c582
13:47:24.260 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.260 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] (Re-)joining group
13:47:24.262 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-221-skRvMk0-74
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-221-skRvMk0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.263 [pool-76-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.264 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.265 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.265 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.265 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044265
13:47:24.265 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Subscribed to topic(s): test-topic-0000221-7QIO4vA
13:47:24.266 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] (Re-)joining group
13:47:24.268 [pool-77-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.268 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.268 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Request joining group due to: need to re-join with the given member-id: consumer-sub-215-2NGygFY-72-b56164dd-3cd6-4a2f-af3a-b916b189ebf8
13:47:24.268 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.268 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] (Re-)joining group
13:47:24.269 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-224-ps_IW0s-75
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-224-ps_IW0s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.271 [pool-78-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.272 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.272 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.272 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.272 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044272
13:47:24.272 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Subscribed to topic(s): test-topic-0000224-vd-16Eg
13:47:24.275 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] (Re-)joining group
13:47:24.276 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Request joining group due to: need to re-join with the given member-id: consumer-sub-218-FyCfM7w-73-33e9ffd8-c160-4741-8ecd-83a9e45136f3
13:47:24.277 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.277 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] (Re-)joining group
13:47:24.279 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-227-CI5qRC4-76
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-227-CI5qRC4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.279 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] (Re-)joining group
13:47:24.281 [pool-79-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.281 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Request joining group due to: need to re-join with the given member-id: consumer-sub-221-skRvMk0-74-88754948-7f56-495d-b124-ef92717f3337
13:47:24.281 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.281 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.281 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] (Re-)joining group
13:47:24.282 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] (Re-)joining group
13:47:24.282 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.282 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.282 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044282
13:47:24.283 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Subscribed to topic(s): test-topic-0000227-PhYZ_-4
13:47:24.284 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Request joining group due to: need to re-join with the given member-id: consumer-sub-224-ps_IW0s-75-6e427e3a-b9d3-4390-863e-25730d787b37
13:47:24.284 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.284 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] (Re-)joining group
13:47:24.285 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-230-ZxkW-J4-77
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-230-ZxkW-J4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.287 [pool-80-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.287 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.288 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] (Re-)joining group
13:47:24.288 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.288 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.288 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044288
13:47:24.289 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Subscribed to topic(s): test-topic-0000230-4s4B6Wc
13:47:24.289 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Request joining group due to: need to re-join with the given member-id: consumer-sub-227-CI5qRC4-76-34fb7dfa-ecb1-471c-a761-58343d43796e
13:47:24.289 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.290 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] (Re-)joining group
13:47:24.290 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-233-DyuGDYs-78
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-233-DyuGDYs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.291 [pool-81-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.292 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.292 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] (Re-)joining group
13:47:24.293 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.293 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.293 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044293
13:47:24.293 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Subscribed to topic(s): test-topic-0000233-0IL1GHA
13:47:24.294 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Request joining group due to: need to re-join with the given member-id: consumer-sub-230-ZxkW-J4-77-f0042df0-bf7e-4878-9141-f9c256290032
13:47:24.294 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.294 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] (Re-)joining group
13:47:24.294 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-236-QpyZKpQ-79
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-236-QpyZKpQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.296 [pool-82-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.297 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.297 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.297 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.297 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044297
13:47:24.298 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Subscribed to topic(s): test-topic-0000236-5rPzsFQ
13:47:24.298 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] (Re-)joining group
13:47:24.299 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Request joining group due to: need to re-join with the given member-id: consumer-sub-233-DyuGDYs-78-2f4c5f13-564f-49a9-82b0-bc171d219570
13:47:24.299 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.299 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] (Re-)joining group
13:47:24.301 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-239-t3Nr_TI-80
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-239-t3Nr_TI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.303 [pool-83-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.303 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.304 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.304 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.304 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044304
13:47:24.305 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Subscribed to topic(s): test-topic-0000239-m_eFS6M
13:47:24.305 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] (Re-)joining group
13:47:24.307 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-236-QpyZKpQ-79-4ec37d98-d77f-4fdd-8e94-c0ff00e1c11f
13:47:24.307 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.307 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] (Re-)joining group
13:47:24.308 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-242-Bh6f6XI-81
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-242-Bh6f6XI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.310 [pool-84-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.311 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.311 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.311 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.312 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044311
13:47:24.312 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] (Re-)joining group
13:47:24.312 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Subscribed to topic(s): test-topic-0000242-5iXW5yk
13:47:24.313 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-245-ycGychY-82
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-245-ycGychY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.313 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Request joining group due to: need to re-join with the given member-id: consumer-sub-239-t3Nr_TI-80-43c0b98d-b35e-404e-aec1-bc42d9b58964
13:47:24.313 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.313 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] (Re-)joining group
13:47:24.316 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.316 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.316 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044316
13:47:24.316 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Subscribed to topic(s): test-topic-0000245-wLMd2DQ
13:47:24.318 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-248-m9k_AXQ-83
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-248-m9k_AXQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.321 [pool-86-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.321 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.321 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.321 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044321
13:47:24.321 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.321 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Subscribed to topic(s): test-topic-0000248-1cRH_ZI
13:47:24.321 [pool-85-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.322 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.322 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] (Re-)joining group
13:47:24.323 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] (Re-)joining group
13:47:24.324 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Request joining group due to: need to re-join with the given member-id: consumer-sub-245-ycGychY-82-0d6623f4-b061-415e-9823-d00a159cb2a9
13:47:24.324 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.324 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] (Re-)joining group
13:47:24.324 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-251-P61INns-84
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-251-P61INns
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.324 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Request joining group due to: need to re-join with the given member-id: consumer-sub-242-Bh6f6XI-81-b78f5f0a-8447-40ca-ae30-269937985336
13:47:24.324 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.324 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] (Re-)joining group
13:47:24.327 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.327 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.327 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044327
13:47:24.327 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Subscribed to topic(s): test-topic-0000251-eeL7Zsc
13:47:24.327 [pool-87-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.327 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.333 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-254-hjh2HZQ-85
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-254-hjh2HZQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.335 [pool-88-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.335 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.336 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.336 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.336 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044336
13:47:24.336 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Subscribed to topic(s): test-topic-0000254-CpZ6PWw
13:47:24.339 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] (Re-)joining group
13:47:24.339 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-257-41n5rmU-86
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-257-41n5rmU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.340 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-248-m9k_AXQ-83-d4d79b69-896c-4649-a3b5-07c46abd4313
13:47:24.341 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.341 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] (Re-)joining group
13:47:24.342 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.342 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.342 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044342
13:47:24.342 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Subscribed to topic(s): test-topic-0000257-P_M3hrc
13:47:24.343 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-260-nhO5cZo-87
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-260-nhO5cZo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.346 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.346 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.346 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044346
13:47:24.346 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Subscribed to topic(s): test-topic-0000260-DnsmC54
13:47:24.346 [pool-89-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.347 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.348 [pool-90-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.348 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.350 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] (Re-)joining group
13:47:24.351 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Request joining group due to: need to re-join with the given member-id: consumer-sub-251-P61INns-84-8bfb76cc-8a4c-4ce2-ad8f-556da26dbfeb
13:47:24.352 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.352 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] (Re-)joining group
13:47:24.358 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] (Re-)joining group
13:47:24.358 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] (Re-)joining group
13:47:24.360 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Request joining group due to: need to re-join with the given member-id: consumer-sub-257-41n5rmU-86-acf2952e-2f77-4a29-a1d3-1af4a2f5ef3d
13:47:24.360 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-254-hjh2HZQ-85-62b8c060-c57d-47e3-8222-0e648f538fc8
13:47:24.361 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.361 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.361 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] (Re-)joining group
13:47:24.361 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] (Re-)joining group
13:47:24.365 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-263-KhJJCEI-88
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-263-KhJJCEI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.367 [pool-91-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.367 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.368 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] (Re-)joining group
13:47:24.368 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.368 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.368 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044368
13:47:24.368 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Subscribed to topic(s): test-topic-0000263-OjpC5g8
13:47:24.369 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-266-DtdrO2U-89
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-266-DtdrO2U
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.370 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Request joining group due to: need to re-join with the given member-id: consumer-sub-260-nhO5cZo-87-63d0a23d-5298-4552-baed-0926cf2041bb
13:47:24.370 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.370 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] (Re-)joining group
13:47:24.372 [pool-92-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.372 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.373 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.373 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.373 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044372
13:47:24.373 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Subscribed to topic(s): test-topic-0000266-pK4XlDY
13:47:24.374 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] (Re-)joining group
13:47:24.375 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-269-U6vcn9Y-90
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-269-U6vcn9Y
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.375 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Request joining group due to: need to re-join with the given member-id: consumer-sub-263-KhJJCEI-88-2ac8fb2c-b847-4127-ae15-feeda7bcdf75
13:47:24.375 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.375 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] (Re-)joining group
13:47:24.376 [pool-93-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.376 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.377 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] (Re-)joining group
13:47:24.378 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.378 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.378 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044378
13:47:24.378 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Request joining group due to: need to re-join with the given member-id: consumer-sub-266-DtdrO2U-89-1ab97276-4051-49c6-aba8-3079d6a7855f
13:47:24.378 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Subscribed to topic(s): test-topic-0000269-7mR6KMk
13:47:24.378 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.378 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] (Re-)joining group
13:47:24.379 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-272-iyWy1Xg-91
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-272-iyWy1Xg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.381 [pool-94-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.381 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.382 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] (Re-)joining group
13:47:24.382 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.382 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.382 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044382
13:47:24.382 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Subscribed to topic(s): test-topic-0000272-GXSuIMg
13:47:24.383 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-275-vG7rzWg-92
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-275-vG7rzWg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.383 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Request joining group due to: need to re-join with the given member-id: consumer-sub-269-U6vcn9Y-90-3a4c7166-fd6e-439c-b21a-27ce71062056
13:47:24.384 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.384 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] (Re-)joining group
13:47:24.386 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.386 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.386 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044386
13:47:24.386 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Subscribed to topic(s): test-topic-0000275-I49nzkY
13:47:24.386 [pool-95-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.387 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.387 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-278-1tayTsg-93
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-278-1tayTsg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.389 [pool-96-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.389 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.390 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.390 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.390 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044390
13:47:24.390 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Subscribed to topic(s): test-topic-0000278-zWRdAgQ
13:47:24.392 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] (Re-)joining group
13:47:24.393 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Request joining group due to: need to re-join with the given member-id: consumer-sub-272-iyWy1Xg-91-f901542b-a75c-4b24-ba5f-aa75c244dda9
13:47:24.393 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.393 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] (Re-)joining group
13:47:24.399 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] (Re-)joining group
13:47:24.399 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-281-hYTH_Cs-94
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-281-hYTH_Cs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.401 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Request joining group due to: need to re-join with the given member-id: consumer-sub-275-vG7rzWg-92-dfc5386c-a02d-45d5-b108-eb13809f0668
13:47:24.401 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.402 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] (Re-)joining group
13:47:24.402 [pool-97-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.402 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.402 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.402 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] (Re-)joining group
13:47:24.402 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.402 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044402
13:47:24.403 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Subscribed to topic(s): test-topic-0000281-FQQUyA4
13:47:24.404 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-284-dW1PM8U-95
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-284-dW1PM8U
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.404 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Request joining group due to: need to re-join with the given member-id: consumer-sub-278-1tayTsg-93-9719dd9c-a1b2-4e6c-bdd2-38587dd39e14
13:47:24.404 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.404 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] (Re-)joining group
13:47:24.405 [pool-98-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.405 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.407 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.407 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.407 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044407
13:47:24.407 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Subscribed to topic(s): test-topic-0000284-Agh4b5c
13:47:24.408 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] (Re-)joining group
13:47:24.409 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-287-aBu5cu8-96
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-287-aBu5cu8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.409 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Request joining group due to: need to re-join with the given member-id: consumer-sub-281-hYTH_Cs-94-d9399126-343d-45ae-b38e-23e476b54076
13:47:24.409 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.409 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] (Re-)joining group
13:47:24.410 [pool-99-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.411 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.412 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.412 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.412 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044412
13:47:24.412 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Subscribed to topic(s): test-topic-0000287-3fcwIsk
13:47:24.416 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] (Re-)joining group
13:47:24.417 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-290-rV8Kfqc-97
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-290-rV8Kfqc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.417 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Request joining group due to: need to re-join with the given member-id: consumer-sub-284-dW1PM8U-95-4e0129aa-9bb4-4d3a-b013-8c1ce8497112
13:47:24.417 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.417 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] (Re-)joining group
13:47:24.419 [pool-100-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.419 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.419 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] (Re-)joining group
13:47:24.420 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.420 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.420 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044420
13:47:24.420 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Subscribed to topic(s): test-topic-0000290-5aCzRUQ
13:47:24.421 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Request joining group due to: need to re-join with the given member-id: consumer-sub-287-aBu5cu8-96-37b37836-68f5-4438-91dd-c0e08d44b894
13:47:24.421 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.421 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] (Re-)joining group
13:47:24.422 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-293-18lz3Qk-98
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-293-18lz3Qk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.424 [pool-101-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.424 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.424 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.424 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.424 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044424
13:47:24.425 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Subscribed to topic(s): test-topic-0000293-H8U0kX0
13:47:24.426 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] (Re-)joining group
13:47:24.427 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Request joining group due to: need to re-join with the given member-id: consumer-sub-290-rV8Kfqc-97-53c49796-0afa-47cf-9369-f3ca05edc678
13:47:24.427 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.427 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] (Re-)joining group
13:47:24.435 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-296-xM-Hg_s-99
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-296-xM-Hg_s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.436 [pool-102-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.437 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.437 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] (Re-)joining group
13:47:24.438 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.438 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.438 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044438
13:47:24.438 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Subscribed to topic(s): test-topic-0000296-217YnkM
13:47:24.439 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Request joining group due to: need to re-join with the given member-id: consumer-sub-293-18lz3Qk-98-e6565a8c-7697-47ac-af75-63e9b82da44a
13:47:24.439 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.439 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] (Re-)joining group
13:47:24.439 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-299-V-SUwIA-100
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-299-V-SUwIA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.441 [pool-103-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.441 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.441 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] (Re-)joining group
13:47:24.442 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.442 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.442 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044442
13:47:24.443 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Subscribed to topic(s): test-topic-0000299-9nrgwQo
13:47:24.443 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Request joining group due to: need to re-join with the given member-id: consumer-sub-296-xM-Hg_s-99-5adeaa4d-572d-4292-adb3-7617b3530861
13:47:24.443 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.443 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] (Re-)joining group
13:47:24.444 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-302-dY8BOm4-101
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-302-dY8BOm4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.445 [pool-104-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.446 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.446 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] (Re-)joining group
13:47:24.447 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.447 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.447 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044447
13:47:24.447 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Subscribed to topic(s): test-topic-0000302-DlyJbtk
13:47:24.448 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Request joining group due to: need to re-join with the given member-id: consumer-sub-299-V-SUwIA-100-42a09731-826b-449b-99e1-6ec6b010bae9
13:47:24.448 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.448 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] (Re-)joining group
13:47:24.450 [pool-105-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.451 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.451 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] (Re-)joining group
13:47:24.452 [qtp435803541-29] INFO LocalWorker - Created 101 consumers in 732.166798 ms
13:47:24.452 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Request joining group due to: need to re-join with the given member-id: consumer-sub-302-dY8BOm4-101-a930c212-dabf-4459-9347-fc4ed8820195
13:47:24.452 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.453 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] (Re-)joining group
13:47:25.254 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.257 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.265 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
13:47:25.275 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.276 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.276 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.276 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045276
13:47:25.277 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.277 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-2] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.277 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
13:47:25.279 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.279 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.279 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.279 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045279
13:47:25.280 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.280 [kafka-producer-network-thread | producer-1] INFO Metadata - [Producer clientId=producer-1] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.280 [kafka-producer-network-thread | producer-1] INFO TransactionManager - [Producer clientId=producer-1] ProducerId set to 12202 with epoch 0
13:47:25.280 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-3] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.281 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
13:47:25.282 [kafka-producer-network-thread | producer-2] INFO Metadata - [Producer clientId=producer-2] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.282 [kafka-producer-network-thread | producer-2] INFO TransactionManager - [Producer clientId=producer-2] ProducerId set to 13201 with epoch 0
13:47:25.282 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.282 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.282 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.282 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045282
13:47:25.283 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.283 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-4] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.283 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-4] Instantiated an idempotent producer.
13:47:25.284 [kafka-producer-network-thread | producer-3] INFO Metadata - [Producer clientId=producer-3] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.284 [kafka-producer-network-thread | producer-3] INFO TransactionManager - [Producer clientId=producer-3] ProducerId set to 12204 with epoch 0
13:47:25.285 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.285 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.285 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.285 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045285
13:47:25.285 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.286 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-5] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.286 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-5] Instantiated an idempotent producer.
13:47:25.287 [kafka-producer-network-thread | producer-4] INFO Metadata - [Producer clientId=producer-4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.287 [kafka-producer-network-thread | producer-4] INFO TransactionManager - [Producer clientId=producer-4] ProducerId set to 14105 with epoch 0
13:47:25.288 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.288 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.288 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.288 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045288
13:47:25.288 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.289 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-6] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.289 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-6] Instantiated an idempotent producer.
13:47:25.290 [kafka-producer-network-thread | producer-5] INFO Metadata - [Producer clientId=producer-5] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.290 [kafka-producer-network-thread | producer-5] INFO TransactionManager - [Producer clientId=producer-5] ProducerId set to 13204 with epoch 0
13:47:25.291 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.291 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.291 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.291 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045291
13:47:25.292 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.292 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-7] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.292 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-7] Instantiated an idempotent producer.
13:47:25.293 [kafka-producer-network-thread | producer-6] INFO Metadata - [Producer clientId=producer-6] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.293 [kafka-producer-network-thread | producer-6] INFO TransactionManager - [Producer clientId=producer-6] ProducerId set to 14106 with epoch 0
13:47:25.294 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.294 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.294 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.294 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045294
13:47:25.295 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.295 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-8] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.295 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-8] Instantiated an idempotent producer.
13:47:25.296 [kafka-producer-network-thread | producer-7] INFO Metadata - [Producer clientId=producer-7] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.296 [kafka-producer-network-thread | producer-7] INFO TransactionManager - [Producer clientId=producer-7] ProducerId set to 13206 with epoch 0
13:47:25.297 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.297 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.297 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.297 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045297
13:47:25.298 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.298 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-9] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.299 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-9] Instantiated an idempotent producer.
13:47:25.299 [kafka-producer-network-thread | producer-8] INFO Metadata - [Producer clientId=producer-8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.299 [kafka-producer-network-thread | producer-8] INFO TransactionManager - [Producer clientId=producer-8] ProducerId set to 12207 with epoch 0
13:47:25.301 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.301 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.301 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.301 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045301
13:47:25.301 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.302 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-10] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.302 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-10] Instantiated an idempotent producer.
13:47:25.303 [kafka-producer-network-thread | producer-9] INFO Metadata - [Producer clientId=producer-9] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.303 [kafka-producer-network-thread | producer-9] INFO TransactionManager - [Producer clientId=producer-9] ProducerId set to 14110 with epoch 0
13:47:25.304 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.304 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.304 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.304 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045304
13:47:25.304 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.305 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-11] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.305 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-11] Instantiated an idempotent producer.
13:47:25.306 [kafka-producer-network-thread | producer-10] INFO Metadata - [Producer clientId=producer-10] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.306 [kafka-producer-network-thread | producer-10] INFO TransactionManager - [Producer clientId=producer-10] ProducerId set to 14111 with epoch 0
13:47:25.307 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.307 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.307 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.307 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045307
13:47:25.307 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.308 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-12] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.308 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-12] Instantiated an idempotent producer.
13:47:25.309 [kafka-producer-network-thread | producer-11] INFO Metadata - [Producer clientId=producer-11] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.309 [kafka-producer-network-thread | producer-11] INFO TransactionManager - [Producer clientId=producer-11] ProducerId set to 14112 with epoch 0
13:47:25.311 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.311 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.311 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.311 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045311
13:47:25.311 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.312 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-13] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.312 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-13] Instantiated an idempotent producer.
13:47:25.312 [kafka-producer-network-thread | producer-12] INFO Metadata - [Producer clientId=producer-12] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.312 [kafka-producer-network-thread | producer-12] INFO TransactionManager - [Producer clientId=producer-12] ProducerId set to 14113 with epoch 0
13:47:25.314 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.314 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.314 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.314 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045314
13:47:25.314 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.315 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-14] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.315 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-14] Instantiated an idempotent producer.
13:47:25.315 [kafka-producer-network-thread | producer-13] INFO Metadata - [Producer clientId=producer-13] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.315 [kafka-producer-network-thread | producer-13] INFO TransactionManager - [Producer clientId=producer-13] ProducerId set to 14114 with epoch 0
13:47:25.317 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.317 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.317 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.317 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045317
13:47:25.318 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.318 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-15] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.318 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-15] Instantiated an idempotent producer.
13:47:25.319 [kafka-producer-network-thread | producer-14] INFO Metadata - [Producer clientId=producer-14] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.319 [kafka-producer-network-thread | producer-14] INFO TransactionManager - [Producer clientId=producer-14] ProducerId set to 13212 with epoch 0
13:47:25.320 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.320 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.320 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.320 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045320
13:47:25.321 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.322 [kafka-producer-network-thread | producer-15] INFO Metadata - [Producer clientId=producer-15] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.322 [kafka-producer-network-thread | producer-15] INFO TransactionManager - [Producer clientId=producer-15] ProducerId set to 13214 with epoch 0
13:47:25.322 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-16] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.322 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-16] Instantiated an idempotent producer.
13:47:25.324 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.324 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.324 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.324 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045324
13:47:25.325 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.326 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-17] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.326 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-17] Instantiated an idempotent producer.
13:47:25.326 [kafka-producer-network-thread | producer-16] INFO Metadata - [Producer clientId=producer-16] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.327 [kafka-producer-network-thread | producer-16] INFO TransactionManager - [Producer clientId=producer-16] ProducerId set to 12213 with epoch 0
13:47:25.327 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.328 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.328 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.328 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045328
13:47:25.328 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.329 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-18] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.329 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-18] Instantiated an idempotent producer.
13:47:25.329 [kafka-producer-network-thread | producer-17] INFO Metadata - [Producer clientId=producer-17] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.330 [kafka-producer-network-thread | producer-17] INFO TransactionManager - [Producer clientId=producer-17] ProducerId set to 14117 with epoch 0
13:47:25.330 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.331 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.331 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.331 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045331
13:47:25.331 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.332 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-19] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.332 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-19] Instantiated an idempotent producer.
13:47:25.332 [kafka-producer-network-thread | producer-18] INFO Metadata - [Producer clientId=producer-18] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.333 [kafka-producer-network-thread | producer-18] INFO TransactionManager - [Producer clientId=producer-18] ProducerId set to 12215 with epoch 0
13:47:25.333 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.333 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.333 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.333 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045333
13:47:25.333 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.334 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-20] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.334 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-20] Instantiated an idempotent producer.
13:47:25.335 [kafka-producer-network-thread | producer-19] INFO Metadata - [Producer clientId=producer-19] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.335 [kafka-producer-network-thread | producer-19] INFO TransactionManager - [Producer clientId=producer-19] ProducerId set to 14119 with epoch 0
13:47:25.335 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.335 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.335 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.335 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045335
13:47:25.336 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.336 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-21] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.336 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-21] Instantiated an idempotent producer.
13:47:25.337 [kafka-producer-network-thread | producer-20] INFO Metadata - [Producer clientId=producer-20] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.337 [kafka-producer-network-thread | producer-20] INFO TransactionManager - [Producer clientId=producer-20] ProducerId set to 13218 with epoch 0
13:47:25.338 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.338 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.338 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.338 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045338
13:47:25.339 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.339 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-22] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.339 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-22] Instantiated an idempotent producer.
13:47:25.340 [kafka-producer-network-thread | producer-21] INFO Metadata - [Producer clientId=producer-21] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.340 [kafka-producer-network-thread | producer-21] INFO TransactionManager - [Producer clientId=producer-21] ProducerId set to 13221 with epoch 0
13:47:25.341 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.341 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.341 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.341 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045341
13:47:25.342 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.342 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-23] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.342 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-23] Instantiated an idempotent producer.
13:47:25.343 [kafka-producer-network-thread | producer-22] INFO Metadata - [Producer clientId=producer-22] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.343 [kafka-producer-network-thread | producer-22] INFO TransactionManager - [Producer clientId=producer-22] ProducerId set to 14122 with epoch 0
13:47:25.346 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.346 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.346 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.346 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045346
13:47:25.346 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.347 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-24] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.347 [kafka-producer-network-thread | producer-23] INFO Metadata - [Producer clientId=producer-23] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.347 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-24] Instantiated an idempotent producer.
13:47:25.347 [kafka-producer-network-thread | producer-23] INFO TransactionManager - [Producer clientId=producer-23] ProducerId set to 13224 with epoch 0
13:47:25.349 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.349 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.349 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.349 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045349
13:47:25.349 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-25
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.350 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-25] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.350 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-25] Instantiated an idempotent producer.
13:47:25.351 [kafka-producer-network-thread | producer-24] INFO Metadata - [Producer clientId=producer-24] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.351 [kafka-producer-network-thread | producer-24] INFO TransactionManager - [Producer clientId=producer-24] ProducerId set to 13225 with epoch 0
13:47:25.352 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.352 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.352 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.352 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045352
13:47:25.352 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-26
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.353 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-26] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.353 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-26] Instantiated an idempotent producer.
13:47:25.353 [kafka-producer-network-thread | producer-25] INFO Metadata - [Producer clientId=producer-25] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.353 [kafka-producer-network-thread | producer-25] INFO TransactionManager - [Producer clientId=producer-25] ProducerId set to 13227 with epoch 0
13:47:25.355 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.355 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.355 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.355 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045355
13:47:25.355 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-27
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.356 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-27] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.356 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-27] Instantiated an idempotent producer.
13:47:25.356 [kafka-producer-network-thread | producer-26] INFO Metadata - [Producer clientId=producer-26] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.357 [kafka-producer-network-thread | producer-26] INFO TransactionManager - [Producer clientId=producer-26] ProducerId set to 13230 with epoch 0
13:47:25.358 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.358 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.358 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.358 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045358
13:47:25.359 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-28
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.359 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-28] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.359 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-28] Instantiated an idempotent producer.
13:47:25.360 [kafka-producer-network-thread | producer-27] INFO Metadata - [Producer clientId=producer-27] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.360 [kafka-producer-network-thread | producer-27] INFO TransactionManager - [Producer clientId=producer-27] ProducerId set to 12218 with epoch 0
13:47:25.361 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.361 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.361 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.361 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045361
13:47:25.362 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-29
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.362 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-29] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.362 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-29] Instantiated an idempotent producer.
13:47:25.363 [kafka-producer-network-thread | producer-28] INFO Metadata - [Producer clientId=producer-28] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.363 [kafka-producer-network-thread | producer-28] INFO TransactionManager - [Producer clientId=producer-28] ProducerId set to 14127 with epoch 0
13:47:25.364 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.364 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.364 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.364 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045364
13:47:25.365 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-30
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.365 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-30] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.365 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-30] Instantiated an idempotent producer.
13:47:25.366 [kafka-producer-network-thread | producer-29] INFO Metadata - [Producer clientId=producer-29] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.366 [kafka-producer-network-thread | producer-29] INFO TransactionManager - [Producer clientId=producer-29] ProducerId set to 14128 with epoch 0
13:47:25.367 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.368 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.368 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.368 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045368
13:47:25.368 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-31
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.369 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-31] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.369 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-31] Instantiated an idempotent producer.
13:47:25.369 [kafka-producer-network-thread | producer-30] INFO Metadata - [Producer clientId=producer-30] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.369 [kafka-producer-network-thread | producer-30] INFO TransactionManager - [Producer clientId=producer-30] ProducerId set to 13234 with epoch 0
13:47:25.371 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.371 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.371 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.371 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045371
13:47:25.371 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-32
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.372 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-32] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.372 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-32] Instantiated an idempotent producer.
13:47:25.372 [kafka-producer-network-thread | producer-31] INFO Metadata - [Producer clientId=producer-31] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.372 [kafka-producer-network-thread | producer-31] INFO TransactionManager - [Producer clientId=producer-31] ProducerId set to 14130 with epoch 0
13:47:25.374 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.374 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.374 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.374 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045374
13:47:25.374 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-33
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.375 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-33] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.375 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-33] Instantiated an idempotent producer.
13:47:25.375 [kafka-producer-network-thread | producer-32] INFO Metadata - [Producer clientId=producer-32] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.376 [kafka-producer-network-thread | producer-32] INFO TransactionManager - [Producer clientId=producer-32] ProducerId set to 12224 with epoch 0
13:47:25.377 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.377 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.377 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.377 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045377
13:47:25.377 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-34
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.378 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-34] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.378 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-34] Instantiated an idempotent producer.
13:47:25.378 [kafka-producer-network-thread | producer-33] INFO Metadata - [Producer clientId=producer-33] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.378 [kafka-producer-network-thread | producer-33] INFO TransactionManager - [Producer clientId=producer-33] ProducerId set to 12225 with epoch 0
13:47:25.380 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.380 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.380 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.380 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045380
13:47:25.380 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-35
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.381 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-35] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.381 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-35] Instantiated an idempotent producer.
13:47:25.382 [kafka-producer-network-thread | producer-34] INFO Metadata - [Producer clientId=producer-34] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.382 [kafka-producer-network-thread | producer-34] INFO TransactionManager - [Producer clientId=producer-34] ProducerId set to 14134 with epoch 0
13:47:25.383 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.383 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.383 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.383 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045383
13:47:25.383 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-36
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.384 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-36] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.384 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-36] Instantiated an idempotent producer.
13:47:25.385 [kafka-producer-network-thread | producer-35] INFO Metadata - [Producer clientId=producer-35] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.385 [kafka-producer-network-thread | producer-35] INFO TransactionManager - [Producer clientId=producer-35] ProducerId set to 14135 with epoch 0
13:47:25.386 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.386 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.386 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.386 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045386
13:47:25.386 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-37
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.387 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-37] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.387 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-37] Instantiated an idempotent producer.
13:47:25.388 [kafka-producer-network-thread | producer-36] INFO Metadata - [Producer clientId=producer-36] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.388 [kafka-producer-network-thread | producer-36] INFO TransactionManager - [Producer clientId=producer-36] ProducerId set to 13239 with epoch 0
13:47:25.389 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.389 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.389 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.389 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045389
13:47:25.389 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-38
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.390 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-38] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.390 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-38] Instantiated an idempotent producer.
13:47:25.390 [kafka-producer-network-thread | producer-37] INFO Metadata - [Producer clientId=producer-37] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.390 [kafka-producer-network-thread | producer-37] INFO TransactionManager - [Producer clientId=producer-37] ProducerId set to 14139 with epoch 0
13:47:25.392 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.392 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.392 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.392 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045392
13:47:25.392 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-39
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.393 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-39] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.393 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-39] Instantiated an idempotent producer.
13:47:25.393 [kafka-producer-network-thread | producer-38] INFO Metadata - [Producer clientId=producer-38] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.393 [kafka-producer-network-thread | producer-38] INFO TransactionManager - [Producer clientId=producer-38] ProducerId set to 12226 with epoch 0
13:47:25.395 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.395 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.395 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.395 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045395
13:47:25.395 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-40
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.396 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-40] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.396 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-40] Instantiated an idempotent producer.
13:47:25.396 [kafka-producer-network-thread | producer-39] INFO Metadata - [Producer clientId=producer-39] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.396 [kafka-producer-network-thread | producer-39] INFO TransactionManager - [Producer clientId=producer-39] ProducerId set to 13240 with epoch 0
13:47:25.398 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.398 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.398 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.398 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045398
13:47:25.398 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-41
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.399 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-41] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.399 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-41] Instantiated an idempotent producer.
13:47:25.399 [kafka-producer-network-thread | producer-40] INFO Metadata - [Producer clientId=producer-40] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.399 [kafka-producer-network-thread | producer-40] INFO TransactionManager - [Producer clientId=producer-40] ProducerId set to 13243 with epoch 0
13:47:25.401 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.401 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.401 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.401 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045401
13:47:25.401 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-42
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.402 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-42] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.402 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-42] Instantiated an idempotent producer.
13:47:25.402 [kafka-producer-network-thread | producer-41] INFO Metadata - [Producer clientId=producer-41] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.402 [kafka-producer-network-thread | producer-41] INFO TransactionManager - [Producer clientId=producer-41] ProducerId set to 14145 with epoch 0
13:47:25.404 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.404 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.404 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.404 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045404
13:47:25.405 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-43
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.405 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-43] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.405 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-43] Instantiated an idempotent producer.
13:47:25.405 [kafka-producer-network-thread | producer-42] INFO Metadata - [Producer clientId=producer-42] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.406 [kafka-producer-network-thread | producer-42] INFO TransactionManager - [Producer clientId=producer-42] ProducerId set to 14146 with epoch 0
13:47:25.407 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.407 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.407 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.407 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045407
13:47:25.408 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-44
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.408 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-44] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.408 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-44] Instantiated an idempotent producer.
13:47:25.408 [kafka-producer-network-thread | producer-43] INFO Metadata - [Producer clientId=producer-43] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.409 [kafka-producer-network-thread | producer-43] INFO TransactionManager - [Producer clientId=producer-43] ProducerId set to 14148 with epoch 0
13:47:25.410 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.410 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.410 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.410 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045410
13:47:25.411 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-45
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.411 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-45] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.411 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-45] Instantiated an idempotent producer.
13:47:25.411 [kafka-producer-network-thread | producer-44] INFO Metadata - [Producer clientId=producer-44] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.411 [kafka-producer-network-thread | producer-44] INFO TransactionManager - [Producer clientId=producer-44] ProducerId set to 12232 with epoch 0
13:47:25.413 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.413 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.413 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.413 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045413
13:47:25.414 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-46
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.414 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-46] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.414 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-46] Instantiated an idempotent producer.
13:47:25.415 [kafka-producer-network-thread | producer-45] INFO Metadata - [Producer clientId=producer-45] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.415 [kafka-producer-network-thread | producer-45] INFO TransactionManager - [Producer clientId=producer-45] ProducerId set to 14150 with epoch 0
13:47:25.416 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.416 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.416 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.416 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045416
13:47:25.416 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-47
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.416 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-47] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.417 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-47] Instantiated an idempotent producer.
13:47:25.417 [kafka-producer-network-thread | producer-46] INFO Metadata - [Producer clientId=producer-46] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.417 [kafka-producer-network-thread | producer-46] INFO TransactionManager - [Producer clientId=producer-46] ProducerId set to 13247 with epoch 0
13:47:25.418 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.418 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.418 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.418 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045418
13:47:25.418 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-48
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.419 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-48] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.419 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-48] Instantiated an idempotent producer.
13:47:25.420 [kafka-producer-network-thread | producer-47] INFO Metadata - [Producer clientId=producer-47] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.420 [kafka-producer-network-thread | producer-47] INFO TransactionManager - [Producer clientId=producer-47] ProducerId set to 13250 with epoch 0
13:47:25.421 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.421 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.421 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.421 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045421
13:47:25.421 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-49
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.421 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-49] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.422 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-49] Instantiated an idempotent producer.
13:47:25.422 [kafka-producer-network-thread | producer-48] INFO Metadata - [Producer clientId=producer-48] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.422 [kafka-producer-network-thread | producer-48] INFO TransactionManager - [Producer clientId=producer-48] ProducerId set to 12235 with epoch 0
13:47:25.423 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.423 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.423 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.423 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045423
13:47:25.423 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-50
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.424 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-50] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.424 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-50] Instantiated an idempotent producer.
13:47:25.424 [kafka-producer-network-thread | producer-49] INFO Metadata - [Producer clientId=producer-49] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.425 [kafka-producer-network-thread | producer-49] INFO TransactionManager - [Producer clientId=producer-49] ProducerId set to 12236 with epoch 0
13:47:25.425 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.425 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.425 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.425 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045425
13:47:25.426 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-51
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.426 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-51] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.426 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-51] Instantiated an idempotent producer.
13:47:25.427 [kafka-producer-network-thread | producer-50] INFO Metadata - [Producer clientId=producer-50] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.427 [kafka-producer-network-thread | producer-50] INFO TransactionManager - [Producer clientId=producer-50] ProducerId set to 14153 with epoch 0
13:47:25.428 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.428 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.428 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.428 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045428
13:47:25.428 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-52
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.428 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-52] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.428 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-52] Instantiated an idempotent producer.
13:47:25.429 [kafka-producer-network-thread | producer-51] INFO Metadata - [Producer clientId=producer-51] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.429 [kafka-producer-network-thread | producer-51] INFO TransactionManager - [Producer clientId=producer-51] ProducerId set to 12238 with epoch 0
13:47:25.430 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.430 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.430 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.430 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045430
13:47:25.430 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-53
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.431 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-53] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.431 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-53] Instantiated an idempotent producer.
13:47:25.431 [kafka-producer-network-thread | producer-52] INFO Metadata - [Producer clientId=producer-52] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.431 [kafka-producer-network-thread | producer-52] INFO TransactionManager - [Producer clientId=producer-52] ProducerId set to 12239 with epoch 0
13:47:25.432 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.432 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.432 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.432 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045432
13:47:25.433 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-54
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.433 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-54] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.433 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-54] Instantiated an idempotent producer.
13:47:25.434 [kafka-producer-network-thread | producer-53] INFO Metadata - [Producer clientId=producer-53] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.434 [kafka-producer-network-thread | producer-53] INFO TransactionManager - [Producer clientId=producer-53] ProducerId set to 12241 with epoch 0
13:47:25.435 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.435 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.435 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.435 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045435
13:47:25.435 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-55
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.435 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-55] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.435 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-55] Instantiated an idempotent producer.
13:47:25.436 [kafka-producer-network-thread | producer-54] INFO Metadata - [Producer clientId=producer-54] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.436 [kafka-producer-network-thread | producer-54] INFO TransactionManager - [Producer clientId=producer-54] ProducerId set to 13254 with epoch 0
13:47:25.437 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.437 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.437 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.437 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045437
13:47:25.437 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-56
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.438 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-56] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.438 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-56] Instantiated an idempotent producer.
13:47:25.438 [kafka-producer-network-thread | producer-55] INFO Metadata - [Producer clientId=producer-55] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.438 [kafka-producer-network-thread | producer-55] INFO TransactionManager - [Producer clientId=producer-55] ProducerId set to 13256 with epoch 0
13:47:25.452 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.452 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.452 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.452 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045452
13:47:25.452 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-57
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.453 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-57] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.453 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-57] Instantiated an idempotent producer.
13:47:25.454 [kafka-producer-network-thread | producer-56] INFO Metadata - [Producer clientId=producer-56] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.454 [kafka-producer-network-thread | producer-56] INFO TransactionManager - [Producer clientId=producer-56] ProducerId set to 14159 with epoch 0
13:47:25.455 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.455 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.455 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.455 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045455
13:47:25.455 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-58
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.455 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-58] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.456 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-58] Instantiated an idempotent producer.
13:47:25.457 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.457 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.457 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.457 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045457
13:47:25.457 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-59
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.458 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-59] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.458 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-59] Instantiated an idempotent producer.
13:47:25.459 [kafka-producer-network-thread | producer-58] INFO Metadata - [Producer clientId=producer-58] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.459 [kafka-producer-network-thread | producer-58] INFO TransactionManager - [Producer clientId=producer-58] ProducerId set to 14161 with epoch 0
13:47:25.459 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.459 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.459 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.459 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045459
13:47:25.460 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-60
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.460 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-60] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.461 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-60] Instantiated an idempotent producer.
13:47:25.461 [kafka-producer-network-thread | producer-57] INFO Metadata - [Producer clientId=producer-57] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.461 [kafka-producer-network-thread | producer-57] INFO TransactionManager - [Producer clientId=producer-57] ProducerId set to 14162 with epoch 0
13:47:25.461 [kafka-producer-network-thread | producer-59] INFO Metadata - [Producer clientId=producer-59] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.461 [kafka-producer-network-thread | producer-59] INFO TransactionManager - [Producer clientId=producer-59] ProducerId set to 13260 with epoch 0
13:47:25.462 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.462 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.462 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.462 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045462
13:47:25.463 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-61
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.463 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-61] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.464 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-61] Instantiated an idempotent producer.
13:47:25.464 [kafka-producer-network-thread | producer-60] INFO Metadata - [Producer clientId=producer-60] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.464 [kafka-producer-network-thread | producer-60] INFO TransactionManager - [Producer clientId=producer-60] ProducerId set to 14163 with epoch 0
13:47:25.465 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.465 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.465 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.465 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045465
13:47:25.466 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-62
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.466 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-62] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.466 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-62] Instantiated an idempotent producer.
13:47:25.467 [kafka-producer-network-thread | producer-61] INFO Metadata - [Producer clientId=producer-61] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.467 [kafka-producer-network-thread | producer-61] INFO TransactionManager - [Producer clientId=producer-61] ProducerId set to 12248 with epoch 0
13:47:25.468 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.468 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.468 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.468 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045468
13:47:25.469 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-63
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.469 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-63] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.469 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-63] Instantiated an idempotent producer.
13:47:25.470 [kafka-producer-network-thread | producer-62] INFO Metadata - [Producer clientId=producer-62] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.470 [kafka-producer-network-thread | producer-62] INFO TransactionManager - [Producer clientId=producer-62] ProducerId set to 14165 with epoch 0
13:47:25.471 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.471 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.471 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.471 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045471
13:47:25.472 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-64
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.472 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-64] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.472 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-64] Instantiated an idempotent producer.
13:47:25.473 [kafka-producer-network-thread | producer-63] INFO Metadata - [Producer clientId=producer-63] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.473 [kafka-producer-network-thread | producer-63] INFO TransactionManager - [Producer clientId=producer-63] ProducerId set to 13264 with epoch 0
13:47:25.474 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.474 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.474 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.474 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045474
13:47:25.474 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-65
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.475 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-65] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.475 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-65] Instantiated an idempotent producer.
13:47:25.475 [kafka-producer-network-thread | producer-64] INFO Metadata - [Producer clientId=producer-64] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.476 [kafka-producer-network-thread | producer-64] INFO TransactionManager - [Producer clientId=producer-64] ProducerId set to 12252 with epoch 0
13:47:25.477 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.477 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.477 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.477 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045477
13:47:25.477 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-66
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.478 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-66] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.478 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-66] Instantiated an idempotent producer.
13:47:25.478 [kafka-producer-network-thread | producer-65] INFO Metadata - [Producer clientId=producer-65] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.478 [kafka-producer-network-thread | producer-65] INFO TransactionManager - [Producer clientId=producer-65] ProducerId set to 12254 with epoch 0
13:47:25.479 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.479 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.479 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.480 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045479
13:47:25.480 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-67
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.480 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-67] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.480 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-67] Instantiated an idempotent producer.
13:47:25.481 [kafka-producer-network-thread | producer-66] INFO Metadata - [Producer clientId=producer-66] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.481 [kafka-producer-network-thread | producer-66] INFO TransactionManager - [Producer clientId=producer-66] ProducerId set to 12256 with epoch 0
13:47:25.482 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.482 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.482 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.482 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045482
13:47:25.483 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-68
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.483 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-68] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.483 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-68] Instantiated an idempotent producer.
13:47:25.484 [kafka-producer-network-thread | producer-67] INFO Metadata - [Producer clientId=producer-67] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.484 [kafka-producer-network-thread | producer-67] INFO TransactionManager - [Producer clientId=producer-67] ProducerId set to 14169 with epoch 0
13:47:25.485 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.485 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.485 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.485 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045485
13:47:25.485 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-69
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.486 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-69] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.486 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-69] Instantiated an idempotent producer.
13:47:25.487 [kafka-producer-network-thread | producer-68] INFO Metadata - [Producer clientId=producer-68] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.487 [kafka-producer-network-thread | producer-68] INFO TransactionManager - [Producer clientId=producer-68] ProducerId set to 14170 with epoch 0
13:47:25.488 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.488 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.488 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.488 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045488
13:47:25.489 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-70
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.489 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-70] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.489 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-70] Instantiated an idempotent producer.
13:47:25.490 [kafka-producer-network-thread | producer-69] INFO Metadata - [Producer clientId=producer-69] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.490 [kafka-producer-network-thread | producer-69] INFO TransactionManager - [Producer clientId=producer-69] ProducerId set to 13267 with epoch 0
13:47:25.491 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.491 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.491 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.491 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045491
13:47:25.491 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-71
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.492 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-71] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.492 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-71] Instantiated an idempotent producer.
13:47:25.492 [kafka-producer-network-thread | producer-70] INFO Metadata - [Producer clientId=producer-70] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.493 [kafka-producer-network-thread | producer-70] INFO TransactionManager - [Producer clientId=producer-70] ProducerId set to 12259 with epoch 0
13:47:25.493 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.494 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.494 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.494 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045494
13:47:25.494 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-72
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.495 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-72] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.495 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-72] Instantiated an idempotent producer.
13:47:25.495 [kafka-producer-network-thread | producer-71] INFO Metadata - [Producer clientId=producer-71] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.496 [kafka-producer-network-thread | producer-71] INFO TransactionManager - [Producer clientId=producer-71] ProducerId set to 14172 with epoch 0
13:47:25.496 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.497 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.497 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.497 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045497
13:47:25.497 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-73
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.498 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-73] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.498 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-73] Instantiated an idempotent producer.
13:47:25.498 [kafka-producer-network-thread | producer-72] INFO Metadata - [Producer clientId=producer-72] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.499 [kafka-producer-network-thread | producer-72] INFO TransactionManager - [Producer clientId=producer-72] ProducerId set to 14174 with epoch 0
13:47:25.500 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.500 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.500 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.500 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045500
13:47:25.500 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-74
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.501 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-74] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.501 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-74] Instantiated an idempotent producer.
13:47:25.501 [kafka-producer-network-thread | producer-73] INFO Metadata - [Producer clientId=producer-73] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.502 [kafka-producer-network-thread | producer-73] INFO TransactionManager - [Producer clientId=producer-73] ProducerId set to 13270 with epoch 0
13:47:25.502 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.502 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.502 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.502 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045502
13:47:25.503 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-75
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.503 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-75] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.503 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-75] Instantiated an idempotent producer.
13:47:25.504 [kafka-producer-network-thread | producer-74] INFO Metadata - [Producer clientId=producer-74] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.504 [kafka-producer-network-thread | producer-74] INFO TransactionManager - [Producer clientId=producer-74] ProducerId set to 13271 with epoch 0
13:47:25.505 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.505 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.505 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.505 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045505
13:47:25.505 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-76
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.506 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-76] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.506 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-76] Instantiated an idempotent producer.
13:47:25.507 [kafka-producer-network-thread | producer-75] INFO Metadata - [Producer clientId=producer-75] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.507 [kafka-producer-network-thread | producer-75] INFO TransactionManager - [Producer clientId=producer-75] ProducerId set to 12263 with epoch 0
13:47:25.508 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.508 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.508 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.508 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045508
13:47:25.509 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-77
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.509 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-77] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.509 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-77] Instantiated an idempotent producer.
13:47:25.510 [kafka-producer-network-thread | producer-76] INFO Metadata - [Producer clientId=producer-76] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.510 [kafka-producer-network-thread | producer-76] INFO TransactionManager - [Producer clientId=producer-76] ProducerId set to 14178 with epoch 0
13:47:25.510 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.511 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.511 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.511 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045511
13:47:25.511 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-78
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.511 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-78] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.511 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-78] Instantiated an idempotent producer.
13:47:25.512 [kafka-producer-network-thread | producer-77] INFO Metadata - [Producer clientId=producer-77] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.512 [kafka-producer-network-thread | producer-77] INFO TransactionManager - [Producer clientId=producer-77] ProducerId set to 12265 with epoch 0
13:47:25.513 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.513 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.513 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.513 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045513
13:47:25.513 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-79
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.514 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-79] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.514 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-79] Instantiated an idempotent producer.
13:47:25.515 [kafka-producer-network-thread | producer-78] INFO Metadata - [Producer clientId=producer-78] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.515 [kafka-producer-network-thread | producer-78] INFO TransactionManager - [Producer clientId=producer-78] ProducerId set to 13275 with epoch 0
13:47:25.516 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.516 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.516 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.516 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045516
13:47:25.516 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-80
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.517 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-80] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.517 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-80] Instantiated an idempotent producer.
13:47:25.518 [kafka-producer-network-thread | producer-79] INFO Metadata - [Producer clientId=producer-79] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.518 [kafka-producer-network-thread | producer-79] INFO TransactionManager - [Producer clientId=producer-79] ProducerId set to 12266 with epoch 0
13:47:25.522 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.522 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.522 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.522 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045522
13:47:25.522 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-81
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.523 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-81] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.523 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-81] Instantiated an idempotent producer.
13:47:25.523 [kafka-producer-network-thread | producer-80] INFO Metadata - [Producer clientId=producer-80] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.524 [kafka-producer-network-thread | producer-80] INFO TransactionManager - [Producer clientId=producer-80] ProducerId set to 12269 with epoch 0
13:47:25.524 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.524 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.524 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.524 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045524
13:47:25.525 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-82
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.525 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-82] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.525 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-82] Instantiated an idempotent producer.
13:47:25.526 [kafka-producer-network-thread | producer-81] INFO Metadata - [Producer clientId=producer-81] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.526 [kafka-producer-network-thread | producer-81] INFO TransactionManager - [Producer clientId=producer-81] ProducerId set to 12270 with epoch 0
13:47:25.527 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.527 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.527 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.527 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045527
13:47:25.527 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-83
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.528 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-83] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.528 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-83] Instantiated an idempotent producer.
13:47:25.531 [kafka-producer-network-thread | producer-82] INFO Metadata - [Producer clientId=producer-82] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.531 [kafka-producer-network-thread | producer-82] INFO TransactionManager - [Producer clientId=producer-82] ProducerId set to 14180 with epoch 0
13:47:25.532 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.532 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.532 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.532 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045532
13:47:25.532 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-84
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.533 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-84] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.533 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-84] Instantiated an idempotent producer.
13:47:25.533 [kafka-producer-network-thread | producer-83] INFO Metadata - [Producer clientId=producer-83] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.534 [kafka-producer-network-thread | producer-83] INFO TransactionManager - [Producer clientId=producer-83] ProducerId set to 12274 with epoch 0
13:47:25.534 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.535 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.535 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.535 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045535
13:47:25.535 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-85
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.536 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-85] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.536 [kafka-producer-network-thread | producer-84] INFO Metadata - [Producer clientId=producer-84] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.536 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-85] Instantiated an idempotent producer.
13:47:25.536 [kafka-producer-network-thread | producer-84] INFO TransactionManager - [Producer clientId=producer-84] ProducerId set to 13279 with epoch 0
13:47:25.538 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.538 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.538 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.538 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045538
13:47:25.538 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-86
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.539 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-86] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.539 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-86] Instantiated an idempotent producer.
13:47:25.541 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.541 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.541 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.541 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045541
13:47:25.541 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-87
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.542 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-87] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.542 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-87] Instantiated an idempotent producer.
13:47:25.542 [kafka-producer-network-thread | producer-85] INFO Metadata - [Producer clientId=producer-85] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.543 [kafka-producer-network-thread | producer-85] INFO TransactionManager - [Producer clientId=producer-85] ProducerId set to 13283 with epoch 0
13:47:25.544 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.544 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.544 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.544 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045544
13:47:25.544 [kafka-producer-network-thread | producer-86] INFO Metadata - [Producer clientId=producer-86] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.544 [kafka-producer-network-thread | producer-86] INFO TransactionManager - [Producer clientId=producer-86] ProducerId set to 14184 with epoch 0
13:47:25.544 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-88
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.544 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-88] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.545 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-88] Instantiated an idempotent producer.
13:47:25.546 [kafka-producer-network-thread | producer-87] INFO Metadata - [Producer clientId=producer-87] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.546 [kafka-producer-network-thread | producer-87] INFO TransactionManager - [Producer clientId=producer-87] ProducerId set to 12275 with epoch 0
13:47:25.546 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.546 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.546 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.546 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045546
13:47:25.547 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-89
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.547 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-89] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.547 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-89] Instantiated an idempotent producer.
13:47:25.548 [kafka-producer-network-thread | producer-88] INFO Metadata - [Producer clientId=producer-88] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.548 [kafka-producer-network-thread | producer-88] INFO TransactionManager - [Producer clientId=producer-88] ProducerId set to 14186 with epoch 0
13:47:25.549 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.549 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.549 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.549 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045549
13:47:25.549 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-90
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.550 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-90] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.550 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-90] Instantiated an idempotent producer.
13:47:25.554 [kafka-producer-network-thread | producer-89] INFO Metadata - [Producer clientId=producer-89] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.554 [kafka-producer-network-thread | producer-89] INFO TransactionManager - [Producer clientId=producer-89] ProducerId set to 13285 with epoch 0
13:47:25.555 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.555 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.555 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.555 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045555
13:47:25.556 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-91
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.556 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-91] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.556 [kafka-producer-network-thread | producer-90] INFO Metadata - [Producer clientId=producer-90] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.556 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-91] Instantiated an idempotent producer.
13:47:25.556 [kafka-producer-network-thread | producer-90] INFO TransactionManager - [Producer clientId=producer-90] ProducerId set to 13286 with epoch 0
13:47:25.560 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.560 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.560 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.560 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045560
13:47:25.560 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-92
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.561 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-92] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.561 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-92] Instantiated an idempotent producer.
13:47:25.562 [kafka-producer-network-thread | producer-91] INFO Metadata - [Producer clientId=producer-91] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.562 [kafka-producer-network-thread | producer-91] INFO TransactionManager - [Producer clientId=producer-91] ProducerId set to 12280 with epoch 0
13:47:25.563 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.563 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.563 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.563 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045563
13:47:25.563 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-93
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.563 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-93] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.563 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-93] Instantiated an idempotent producer.
13:47:25.564 [kafka-producer-network-thread | producer-92] INFO Metadata - [Producer clientId=producer-92] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.564 [kafka-producer-network-thread | producer-92] INFO TransactionManager - [Producer clientId=producer-92] ProducerId set to 14189 with epoch 0
13:47:25.565 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.565 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.565 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.565 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045565
13:47:25.565 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-94
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.566 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-94] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.566 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-94] Instantiated an idempotent producer.
13:47:25.567 [kafka-producer-network-thread | producer-93] INFO Metadata - [Producer clientId=producer-93] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.567 [kafka-producer-network-thread | producer-93] INFO TransactionManager - [Producer clientId=producer-93] ProducerId set to 12283 with epoch 0
13:47:25.568 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.568 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.568 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.568 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045568
13:47:25.568 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-95
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.569 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-95] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.569 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-95] Instantiated an idempotent producer.
13:47:25.570 [kafka-producer-network-thread | producer-94] INFO Metadata - [Producer clientId=producer-94] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.570 [kafka-producer-network-thread | producer-94] INFO TransactionManager - [Producer clientId=producer-94] ProducerId set to 12284 with epoch 0
13:47:25.570 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.570 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.571 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.571 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045570
13:47:25.571 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-96
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.572 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-96] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.572 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-96] Instantiated an idempotent producer.
13:47:25.573 [kafka-producer-network-thread | producer-95] INFO Metadata - [Producer clientId=producer-95] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.573 [kafka-producer-network-thread | producer-95] INFO TransactionManager - [Producer clientId=producer-95] ProducerId set to 13290 with epoch 0
13:47:25.573 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.573 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.573 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.573 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045573
13:47:25.574 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-97
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.574 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-97] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.574 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-97] Instantiated an idempotent producer.
13:47:25.575 [kafka-producer-network-thread | producer-96] INFO Metadata - [Producer clientId=producer-96] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.575 [kafka-producer-network-thread | producer-96] INFO TransactionManager - [Producer clientId=producer-96] ProducerId set to 13291 with epoch 0
13:47:25.576 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.576 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.576 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.576 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045576
13:47:25.576 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-98
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.577 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-98] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.577 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-98] Instantiated an idempotent producer.
13:47:25.578 [kafka-producer-network-thread | producer-97] INFO Metadata - [Producer clientId=producer-97] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.579 [kafka-producer-network-thread | producer-97] INFO TransactionManager - [Producer clientId=producer-97] ProducerId set to 13294 with epoch 0
13:47:25.589 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.589 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.589 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.589 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045589
13:47:25.589 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-99
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.590 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-99] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.590 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-99] Instantiated an idempotent producer.
13:47:25.591 [kafka-producer-network-thread | producer-98] INFO Metadata - [Producer clientId=producer-98] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.591 [kafka-producer-network-thread | producer-98] INFO TransactionManager - [Producer clientId=producer-98] ProducerId set to 13297 with epoch 0
13:47:25.592 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.592 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.592 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.592 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045592
13:47:25.592 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-100
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.592 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-100] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.592 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-100] Instantiated an idempotent producer.
13:47:25.593 [kafka-producer-network-thread | producer-99] INFO Metadata - [Producer clientId=producer-99] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.593 [kafka-producer-network-thread | producer-99] INFO TransactionManager - [Producer clientId=producer-99] ProducerId set to 14196 with epoch 0
13:47:25.594 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.594 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.594 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.594 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045594
13:47:25.594 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-101
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.595 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-101] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.595 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-101] Instantiated an idempotent producer.
13:47:25.596 [kafka-producer-network-thread | producer-100] INFO Metadata - [Producer clientId=producer-100] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.596 [kafka-producer-network-thread | producer-100] INFO TransactionManager - [Producer clientId=producer-100] ProducerId set to 12293 with epoch 0
13:47:25.597 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.597 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.597 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.597 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045597
13:47:25.597 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-102
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.598 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-102] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.598 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-102] Instantiated an idempotent producer.
13:47:25.599 [kafka-producer-network-thread | producer-101] INFO Metadata - [Producer clientId=producer-101] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.599 [kafka-producer-network-thread | producer-101] INFO TransactionManager - [Producer clientId=producer-101] ProducerId set to 13300 with epoch 0
13:47:25.600 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.600 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.600 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.600 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045600
13:47:25.600 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-103
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.600 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-103] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.600 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-103] Instantiated an idempotent producer.
13:47:25.601 [kafka-producer-network-thread | producer-102] INFO Metadata - [Producer clientId=producer-102] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.602 [kafka-producer-network-thread | producer-102] INFO TransactionManager - [Producer clientId=producer-102] ProducerId set to 12295 with epoch 0
13:47:25.602 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.602 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.602 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.602 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045602
13:47:25.602 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-104
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.603 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-104] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.603 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-104] Instantiated an idempotent producer.
13:47:25.603 [kafka-producer-network-thread | producer-103] INFO Metadata - [Producer clientId=producer-103] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.603 [kafka-producer-network-thread | producer-103] INFO TransactionManager - [Producer clientId=producer-103] ProducerId set to 12296 with epoch 0
13:47:25.604 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.604 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.604 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.604 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045604
13:47:25.604 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-105
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.605 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-105] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.605 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-105] Instantiated an idempotent producer.
13:47:25.606 [kafka-producer-network-thread | producer-104] INFO Metadata - [Producer clientId=producer-104] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.606 [kafka-producer-network-thread | producer-104] INFO TransactionManager - [Producer clientId=producer-104] ProducerId set to 13302 with epoch 0
13:47:25.606 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.606 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.606 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.606 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045606
13:47:25.607 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-106
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.607 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-106] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.607 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-106] Instantiated an idempotent producer.
13:47:25.608 [kafka-producer-network-thread | producer-105] INFO Metadata - [Producer clientId=producer-105] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.608 [kafka-producer-network-thread | producer-105] INFO TransactionManager - [Producer clientId=producer-105] ProducerId set to 12299 with epoch 0
13:47:25.609 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.609 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.609 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.609 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045609
13:47:25.610 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-107
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.610 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-107] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.610 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-107] Instantiated an idempotent producer.
13:47:25.610 [kafka-producer-network-thread | producer-106] INFO Metadata - [Producer clientId=producer-106] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.610 [kafka-producer-network-thread | producer-106] INFO TransactionManager - [Producer clientId=producer-106] ProducerId set to 13304 with epoch 0
13:47:25.612 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.612 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.612 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.612 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045612
13:47:25.613 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-108
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.613 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-108] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.614 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-108] Instantiated an idempotent producer.
13:47:25.614 [kafka-producer-network-thread | producer-107] INFO Metadata - [Producer clientId=producer-107] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.615 [kafka-producer-network-thread | producer-107] INFO TransactionManager - [Producer clientId=producer-107] ProducerId set to 14200 with epoch 0
13:47:25.615 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.615 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.615 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.615 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045615
13:47:25.616 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-109
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.616 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-109] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.616 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-109] Instantiated an idempotent producer.
13:47:25.617 [kafka-producer-network-thread | producer-108] INFO Metadata - [Producer clientId=producer-108] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.617 [kafka-producer-network-thread | producer-108] INFO TransactionManager - [Producer clientId=producer-108] ProducerId set to 14201 with epoch 0
13:47:25.618 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.618 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.618 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.618 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045618
13:47:25.619 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-110
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.619 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-110] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.620 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-110] Instantiated an idempotent producer.
13:47:25.621 [kafka-producer-network-thread | producer-109] INFO Metadata - [Producer clientId=producer-109] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.621 [kafka-producer-network-thread | producer-109] INFO TransactionManager - [Producer clientId=producer-109] ProducerId set to 13307 with epoch 0
13:47:25.621 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.621 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.621 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.621 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045621
13:47:25.622 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-111
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.622 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-111] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.622 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-111] Instantiated an idempotent producer.
13:47:25.624 [kafka-producer-network-thread | producer-110] INFO Metadata - [Producer clientId=producer-110] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.624 [kafka-producer-network-thread | producer-110] INFO TransactionManager - [Producer clientId=producer-110] ProducerId set to 14204 with epoch 0
13:47:25.625 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.625 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.625 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.625 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045625
13:47:25.625 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-112
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.626 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-112] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.626 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-112] Instantiated an idempotent producer.
13:47:25.628 [kafka-producer-network-thread | producer-111] INFO Metadata - [Producer clientId=producer-111] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.628 [kafka-producer-network-thread | producer-111] INFO TransactionManager - [Producer clientId=producer-111] ProducerId set to 13311 with epoch 0
13:47:25.628 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.628 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.629 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.629 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045628
13:47:25.629 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-113
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.629 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-113] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.630 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-113] Instantiated an idempotent producer.
13:47:25.631 [kafka-producer-network-thread | producer-112] INFO Metadata - [Producer clientId=producer-112] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.631 [kafka-producer-network-thread | producer-112] INFO TransactionManager - [Producer clientId=producer-112] ProducerId set to 14205 with epoch 0
13:47:25.631 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.631 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.631 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.631 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045631
13:47:25.632 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-114
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.632 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-114] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.632 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-114] Instantiated an idempotent producer.
13:47:25.634 [kafka-producer-network-thread | producer-113] INFO Metadata - [Producer clientId=producer-113] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.634 [kafka-producer-network-thread | producer-113] INFO TransactionManager - [Producer clientId=producer-113] ProducerId set to 14208 with epoch 0
13:47:25.634 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.634 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.634 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.634 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045634
13:47:25.634 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-115
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.635 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-115] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.635 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-115] Instantiated an idempotent producer.
13:47:25.636 [kafka-producer-network-thread | producer-114] INFO Metadata - [Producer clientId=producer-114] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.636 [kafka-producer-network-thread | producer-114] INFO TransactionManager - [Producer clientId=producer-114] ProducerId set to 14209 with epoch 0
13:47:25.637 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.637 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.637 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.637 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045637
13:47:25.638 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-116
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.638 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-116] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.638 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-116] Instantiated an idempotent producer.
13:47:25.639 [kafka-producer-network-thread | producer-115] INFO Metadata - [Producer clientId=producer-115] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.639 [kafka-producer-network-thread | producer-115] INFO TransactionManager - [Producer clientId=producer-115] ProducerId set to 13316 with epoch 0
13:47:25.640 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.640 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.640 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.640 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045640
13:47:25.640 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-117
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.640 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-117] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.640 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-117] Instantiated an idempotent producer.
13:47:25.641 [kafka-producer-network-thread | producer-116] INFO Metadata - [Producer clientId=producer-116] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.641 [kafka-producer-network-thread | producer-116] INFO TransactionManager - [Producer clientId=producer-116] ProducerId set to 13318 with epoch 0
13:47:25.642 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.642 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.642 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.642 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045642
13:47:25.642 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-118
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.643 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-118] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.643 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-118] Instantiated an idempotent producer.
13:47:25.643 [kafka-producer-network-thread | producer-117] INFO Metadata - [Producer clientId=producer-117] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.644 [kafka-producer-network-thread | producer-117] INFO TransactionManager - [Producer clientId=producer-117] ProducerId set to 14210 with epoch 0
13:47:25.644 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.644 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.644 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.644 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045644
13:47:25.645 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-119
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.645 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-119] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.645 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-119] Instantiated an idempotent producer.
13:47:25.646 [kafka-producer-network-thread | producer-118] INFO Metadata - [Producer clientId=producer-118] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.646 [kafka-producer-network-thread | producer-118] INFO TransactionManager - [Producer clientId=producer-118] ProducerId set to 12305 with epoch 0
13:47:25.646 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.646 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.646 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.646 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045646
13:47:25.647 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-120
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.647 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-120] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.647 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-120] Instantiated an idempotent producer.
13:47:25.648 [kafka-producer-network-thread | producer-119] INFO Metadata - [Producer clientId=producer-119] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.648 [kafka-producer-network-thread | producer-119] INFO TransactionManager - [Producer clientId=producer-119] ProducerId set to 13322 with epoch 0
13:47:25.649 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.649 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.649 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.649 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045649
13:47:25.649 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-121
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.649 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-121] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.649 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-121] Instantiated an idempotent producer.
13:47:25.650 [kafka-producer-network-thread | producer-120] INFO Metadata - [Producer clientId=producer-120] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.650 [kafka-producer-network-thread | producer-120] INFO TransactionManager - [Producer clientId=producer-120] ProducerId set to 12306 with epoch 0
13:47:25.651 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.651 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.651 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.651 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045651
13:47:25.651 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-122
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.652 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-122] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.652 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-122] Instantiated an idempotent producer.
13:47:25.652 [kafka-producer-network-thread | producer-121] INFO Metadata - [Producer clientId=producer-121] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.653 [kafka-producer-network-thread | producer-121] INFO TransactionManager - [Producer clientId=producer-121] ProducerId set to 12308 with epoch 0
13:47:25.653 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.653 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.653 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.653 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045653
13:47:25.654 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-123
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.654 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-123] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.654 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-123] Instantiated an idempotent producer.
13:47:25.655 [kafka-producer-network-thread | producer-122] INFO Metadata - [Producer clientId=producer-122] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.655 [kafka-producer-network-thread | producer-122] INFO TransactionManager - [Producer clientId=producer-122] ProducerId set to 13324 with epoch 0
13:47:25.656 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.656 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.656 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.656 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045656
13:47:25.657 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-124
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.657 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-124] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.657 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-124] Instantiated an idempotent producer.
13:47:25.658 [kafka-producer-network-thread | producer-123] INFO Metadata - [Producer clientId=producer-123] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.658 [kafka-producer-network-thread | producer-123] INFO TransactionManager - [Producer clientId=producer-123] ProducerId set to 14215 with epoch 0
13:47:25.659 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.659 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.659 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.659 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045659
13:47:25.659 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-125
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.660 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-125] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.660 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-125] Instantiated an idempotent producer.
13:47:25.660 [kafka-producer-network-thread | producer-124] INFO Metadata - [Producer clientId=producer-124] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.660 [kafka-producer-network-thread | producer-124] INFO TransactionManager - [Producer clientId=producer-124] ProducerId set to 13326 with epoch 0
13:47:25.664 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.664 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.664 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.664 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045664
13:47:25.664 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-126
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.664 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-126] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.665 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-126] Instantiated an idempotent producer.
13:47:25.665 [kafka-producer-network-thread | producer-125] INFO Metadata - [Producer clientId=producer-125] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.666 [kafka-producer-network-thread | producer-125] INFO TransactionManager - [Producer clientId=producer-125] ProducerId set to 14217 with epoch 0
13:47:25.666 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.666 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.666 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.666 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045666
13:47:25.667 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-127
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.667 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-127] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.667 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-127] Instantiated an idempotent producer.
13:47:25.669 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.669 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.669 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.669 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045669
13:47:25.669 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-128
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.670 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-128] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.670 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-128] Instantiated an idempotent producer.
13:47:25.670 [kafka-producer-network-thread | producer-127] INFO Metadata - [Producer clientId=producer-127] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.670 [kafka-producer-network-thread | producer-127] INFO TransactionManager - [Producer clientId=producer-127] ProducerId set to 14219 with epoch 0
13:47:25.672 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.672 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.672 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.672 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045672
13:47:25.672 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-129
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.673 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-129] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.673 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-129] Instantiated an idempotent producer.
13:47:25.674 [kafka-producer-network-thread | producer-128] INFO Metadata - [Producer clientId=producer-128] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.674 [kafka-producer-network-thread | producer-128] INFO TransactionManager - [Producer clientId=producer-128] ProducerId set to 12318 with epoch 0
13:47:25.674 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.675 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.675 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.675 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045674
13:47:25.675 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-130
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.675 [kafka-producer-network-thread | producer-126] INFO Metadata - [Producer clientId=producer-126] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.675 [kafka-producer-network-thread | producer-126] INFO TransactionManager - [Producer clientId=producer-126] ProducerId set to 14221 with epoch 0
13:47:25.675 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-130] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.675 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-130] Instantiated an idempotent producer.
13:47:25.679 [kafka-producer-network-thread | producer-129] INFO Metadata - [Producer clientId=producer-129] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.679 [kafka-producer-network-thread | producer-129] INFO TransactionManager - [Producer clientId=producer-129] ProducerId set to 14222 with epoch 0
13:47:25.680 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.680 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.680 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.680 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045680
13:47:25.680 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-131
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.681 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-131] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.681 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-131] Instantiated an idempotent producer.
13:47:25.682 [kafka-producer-network-thread | producer-130] INFO Metadata - [Producer clientId=producer-130] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.682 [kafka-producer-network-thread | producer-130] INFO TransactionManager - [Producer clientId=producer-130] ProducerId set to 12320 with epoch 0
13:47:25.682 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.682 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.682 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.682 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045682
13:47:25.683 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-132
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.683 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-132] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.683 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-132] Instantiated an idempotent producer.
13:47:25.685 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.685 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.685 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.685 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045685
13:47:25.685 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-133
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.686 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-133] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.686 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-133] Instantiated an idempotent producer.
13:47:25.687 [kafka-producer-network-thread | producer-131] INFO Metadata - [Producer clientId=producer-131] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.688 [kafka-producer-network-thread | producer-131] INFO TransactionManager - [Producer clientId=producer-131] ProducerId set to 13335 with epoch 0
13:47:25.688 [kafka-producer-network-thread | producer-132] INFO Metadata - [Producer clientId=producer-132] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.688 [kafka-producer-network-thread | producer-132] INFO TransactionManager - [Producer clientId=producer-132] ProducerId set to 13334 with epoch 0
13:47:25.688 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.688 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.688 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.688 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045688
13:47:25.689 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-134
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.689 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-134] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.689 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-134] Instantiated an idempotent producer.
13:47:25.690 [kafka-producer-network-thread | producer-133] INFO Metadata - [Producer clientId=producer-133] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.690 [kafka-producer-network-thread | producer-133] INFO TransactionManager - [Producer clientId=producer-133] ProducerId set to 14223 with epoch 0
13:47:25.691 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.691 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.691 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.691 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045691
13:47:25.692 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-135
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.692 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-135] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.692 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-135] Instantiated an idempotent producer.
13:47:25.694 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.694 [kafka-producer-network-thread | producer-134] INFO Metadata - [Producer clientId=producer-134] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.694 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.694 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.694 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045694
13:47:25.694 [kafka-producer-network-thread | producer-134] INFO TransactionManager - [Producer clientId=producer-134] ProducerId set to 13338 with epoch 0
13:47:25.694 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-136
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.695 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-136] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.695 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-136] Instantiated an idempotent producer.
13:47:25.697 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.698 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.698 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.698 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045697
13:47:25.698 [kafka-producer-network-thread | producer-135] INFO Metadata - [Producer clientId=producer-135] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.698 [kafka-producer-network-thread | producer-135] INFO TransactionManager - [Producer clientId=producer-135] ProducerId set to 14226 with epoch 0
13:47:25.698 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-137
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.699 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-137] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.699 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-137] Instantiated an idempotent producer.
13:47:25.699 [kafka-producer-network-thread | producer-136] INFO Metadata - [Producer clientId=producer-136] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.699 [kafka-producer-network-thread | producer-136] INFO TransactionManager - [Producer clientId=producer-136] ProducerId set to 13341 with epoch 0
13:47:25.701 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.701 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.701 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.701 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045701
13:47:25.702 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-138
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.702 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-138] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.702 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-138] Instantiated an idempotent producer.
13:47:25.703 [kafka-producer-network-thread | producer-137] INFO Metadata - [Producer clientId=producer-137] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.703 [kafka-producer-network-thread | producer-137] INFO TransactionManager - [Producer clientId=producer-137] ProducerId set to 13344 with epoch 0
13:47:25.704 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.705 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.705 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.705 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045704
13:47:25.705 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-139
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.706 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-139] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.706 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-139] Instantiated an idempotent producer.
13:47:25.706 [kafka-producer-network-thread | producer-138] INFO Metadata - [Producer clientId=producer-138] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.706 [kafka-producer-network-thread | producer-138] INFO TransactionManager - [Producer clientId=producer-138] ProducerId set to 13345 with epoch 0
13:47:25.707 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.708 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.708 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.708 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045708
13:47:25.708 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-140
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.709 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-140] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.709 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-140] Instantiated an idempotent producer.
13:47:25.709 [kafka-producer-network-thread | producer-139] INFO Metadata - [Producer clientId=producer-139] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.709 [kafka-producer-network-thread | producer-139] INFO TransactionManager - [Producer clientId=producer-139] ProducerId set to 14230 with epoch 0
13:47:25.711 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.711 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.711 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.711 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045711
13:47:25.711 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-141
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.712 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-141] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.712 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-141] Instantiated an idempotent producer.
13:47:25.712 [kafka-producer-network-thread | producer-140] INFO Metadata - [Producer clientId=producer-140] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.712 [kafka-producer-network-thread | producer-140] INFO TransactionManager - [Producer clientId=producer-140] ProducerId set to 12325 with epoch 0
13:47:25.714 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.714 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.714 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.714 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045714
13:47:25.714 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-142
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.715 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-142] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.715 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-142] Instantiated an idempotent producer.
13:47:25.715 [kafka-producer-network-thread | producer-141] INFO Metadata - [Producer clientId=producer-141] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.715 [kafka-producer-network-thread | producer-141] INFO TransactionManager - [Producer clientId=producer-141] ProducerId set to 12326 with epoch 0
13:47:25.716 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.716 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.716 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.716 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045716
13:47:25.717 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-143
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.717 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-143] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.717 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-143] Instantiated an idempotent producer.
13:47:25.718 [kafka-producer-network-thread | producer-142] INFO Metadata - [Producer clientId=producer-142] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.718 [kafka-producer-network-thread | producer-142] INFO TransactionManager - [Producer clientId=producer-142] ProducerId set to 12328 with epoch 0
13:47:25.719 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.719 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.719 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.719 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045719
13:47:25.720 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-144
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.720 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-144] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.720 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-144] Instantiated an idempotent producer.
13:47:25.721 [kafka-producer-network-thread | producer-143] INFO Metadata - [Producer clientId=producer-143] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.721 [kafka-producer-network-thread | producer-143] INFO TransactionManager - [Producer clientId=producer-143] ProducerId set to 12330 with epoch 0
13:47:25.722 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.723 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.723 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.723 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045722
13:47:25.724 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-145
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.724 [kafka-producer-network-thread | producer-144] INFO Metadata - [Producer clientId=producer-144] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.724 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-145] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.724 [kafka-producer-network-thread | producer-144] INFO TransactionManager - [Producer clientId=producer-144] ProducerId set to 13350 with epoch 0
13:47:25.724 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-145] Instantiated an idempotent producer.
13:47:25.727 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.727 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.727 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.727 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045727
13:47:25.728 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-146
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.728 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-146] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.728 [kafka-producer-network-thread | producer-145] INFO Metadata - [Producer clientId=producer-145] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.728 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-146] Instantiated an idempotent producer.
13:47:25.728 [kafka-producer-network-thread | producer-145] INFO TransactionManager - [Producer clientId=producer-145] ProducerId set to 13353 with epoch 0
13:47:25.730 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.730 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.730 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.730 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045730
13:47:25.731 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-147
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.731 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-147] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.731 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-147] Instantiated an idempotent producer.
13:47:25.732 [kafka-producer-network-thread | producer-146] INFO Metadata - [Producer clientId=producer-146] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.732 [kafka-producer-network-thread | producer-146] INFO TransactionManager - [Producer clientId=producer-146] ProducerId set to 14235 with epoch 0
13:47:25.733 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.733 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.733 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.734 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045733
13:47:25.734 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-148
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.734 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-148] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.735 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-148] Instantiated an idempotent producer.
13:47:25.735 [kafka-producer-network-thread | producer-147] INFO Metadata - [Producer clientId=producer-147] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.735 [kafka-producer-network-thread | producer-147] INFO TransactionManager - [Producer clientId=producer-147] ProducerId set to 13356 with epoch 0
13:47:25.737 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.737 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.737 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.737 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045737
13:47:25.737 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-149
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.738 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-149] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.738 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-149] Instantiated an idempotent producer.
13:47:25.738 [kafka-producer-network-thread | producer-148] INFO Metadata - [Producer clientId=producer-148] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.738 [kafka-producer-network-thread | producer-148] INFO TransactionManager - [Producer clientId=producer-148] ProducerId set to 14238 with epoch 0
13:47:25.740 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.740 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.740 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.740 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045740
13:47:25.741 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-150
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.741 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-150] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.741 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-150] Instantiated an idempotent producer.
13:47:25.742 [kafka-producer-network-thread | producer-149] INFO Metadata - [Producer clientId=producer-149] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.742 [kafka-producer-network-thread | producer-149] INFO TransactionManager - [Producer clientId=producer-149] ProducerId set to 12338 with epoch 0
13:47:25.743 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.743 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.743 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.743 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045743
13:47:25.744 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-151
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.744 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-151] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.744 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-151] Instantiated an idempotent producer.
13:47:25.745 [kafka-producer-network-thread | producer-150] INFO Metadata - [Producer clientId=producer-150] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.745 [kafka-producer-network-thread | producer-150] INFO TransactionManager - [Producer clientId=producer-150] ProducerId set to 14241 with epoch 0
13:47:25.746 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.746 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.746 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.746 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045746
13:47:25.747 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-152
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.747 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-152] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.747 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-152] Instantiated an idempotent producer.
13:47:25.748 [kafka-producer-network-thread | producer-151] INFO Metadata - [Producer clientId=producer-151] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.748 [kafka-producer-network-thread | producer-151] INFO TransactionManager - [Producer clientId=producer-151] ProducerId set to 13357 with epoch 0
13:47:25.750 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.750 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.750 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.750 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045750
13:47:25.751 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-153
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.751 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-153] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.751 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-153] Instantiated an idempotent producer.
13:47:25.752 [kafka-producer-network-thread | producer-152] INFO Metadata - [Producer clientId=producer-152] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.752 [kafka-producer-network-thread | producer-152] INFO TransactionManager - [Producer clientId=producer-152] ProducerId set to 14244 with epoch 0
13:47:25.753 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.753 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.753 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.753 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045753
13:47:25.754 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-154
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.754 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-154] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.754 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-154] Instantiated an idempotent producer.
13:47:25.756 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.756 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.756 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.756 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045756
13:47:25.757 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-155
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.757 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-155] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.757 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-155] Instantiated an idempotent producer.
13:47:25.758 [kafka-producer-network-thread | producer-154] INFO Metadata - [Producer clientId=producer-154] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.758 [kafka-producer-network-thread | producer-154] INFO TransactionManager - [Producer clientId=producer-154] ProducerId set to 13360 with epoch 0
13:47:25.763 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.763 [kafka-producer-network-thread | producer-153] INFO Metadata - [Producer clientId=producer-153] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.763 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.763 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.763 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045763
13:47:25.763 [kafka-producer-network-thread | producer-153] INFO TransactionManager - [Producer clientId=producer-153] ProducerId set to 13362 with epoch 0
13:47:25.763 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-156
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.764 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-156] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.764 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-156] Instantiated an idempotent producer.
13:47:25.766 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.766 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.766 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.766 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045766
13:47:25.767 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-157
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.767 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-157] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.767 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-157] Instantiated an idempotent producer.
13:47:25.767 [kafka-producer-network-thread | producer-155] INFO Metadata - [Producer clientId=producer-155] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.767 [kafka-producer-network-thread | producer-155] INFO TransactionManager - [Producer clientId=producer-155] ProducerId set to 14250 with epoch 0
13:47:25.769 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.770 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.770 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.770 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045769
13:47:25.770 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-158
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.770 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-158] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.770 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-158] Instantiated an idempotent producer.
13:47:25.771 [kafka-producer-network-thread | producer-156] INFO Metadata - [Producer clientId=producer-156] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.771 [kafka-producer-network-thread | producer-156] INFO TransactionManager - [Producer clientId=producer-156] ProducerId set to 13366 with epoch 0
13:47:25.772 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.772 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.772 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.773 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045772
13:47:25.773 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-159
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.774 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-159] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.774 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-159] Instantiated an idempotent producer.
13:47:25.774 [kafka-producer-network-thread | producer-158] INFO Metadata - [Producer clientId=producer-158] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.774 [kafka-producer-network-thread | producer-158] INFO TransactionManager - [Producer clientId=producer-158] ProducerId set to 14252 with epoch 0
13:47:25.775 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.776 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.776 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.776 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045776
13:47:25.776 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-160
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.777 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-160] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.777 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-160] Instantiated an idempotent producer.
13:47:25.777 [kafka-producer-network-thread | producer-159] INFO Metadata - [Producer clientId=producer-159] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.778 [kafka-producer-network-thread | producer-159] INFO TransactionManager - [Producer clientId=producer-159] ProducerId set to 12345 with epoch 0
13:47:25.778 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.778 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.778 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.778 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045778
13:47:25.779 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-161
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.779 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-161] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.779 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-161] Instantiated an idempotent producer.
13:47:25.780 [kafka-producer-network-thread | producer-160] INFO Metadata - [Producer clientId=producer-160] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.780 [kafka-producer-network-thread | producer-160] INFO TransactionManager - [Producer clientId=producer-160] ProducerId set to 12347 with epoch 0
13:47:25.781 [kafka-producer-network-thread | producer-157] INFO Metadata - [Producer clientId=producer-157] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.781 [kafka-producer-network-thread | producer-157] INFO TransactionManager - [Producer clientId=producer-157] ProducerId set to 13368 with epoch 0
13:47:25.781 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.781 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.781 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.781 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045781
13:47:25.782 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-162
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.782 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-162] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.782 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-162] Instantiated an idempotent producer.
13:47:25.783 [kafka-producer-network-thread | producer-161] INFO Metadata - [Producer clientId=producer-161] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.783 [kafka-producer-network-thread | producer-161] INFO TransactionManager - [Producer clientId=producer-161] ProducerId set to 12348 with epoch 0
13:47:25.785 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.785 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.785 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.785 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045785
13:47:25.785 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-163
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.786 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-163] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.786 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-163] Instantiated an idempotent producer.
13:47:25.786 [kafka-producer-network-thread | producer-162] INFO Metadata - [Producer clientId=producer-162] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.787 [kafka-producer-network-thread | producer-162] INFO TransactionManager - [Producer clientId=producer-162] ProducerId set to 13371 with epoch 0
13:47:25.788 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.788 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.788 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.788 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045788
13:47:25.788 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-164
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.789 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-164] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.789 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-164] Instantiated an idempotent producer.
13:47:25.789 [kafka-producer-network-thread | producer-163] INFO Metadata - [Producer clientId=producer-163] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.789 [kafka-producer-network-thread | producer-163] INFO TransactionManager - [Producer clientId=producer-163] ProducerId set to 12351 with epoch 0
13:47:25.790 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.791 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.791 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.791 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045791
13:47:25.791 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-165
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.791 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-165] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.792 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-165] Instantiated an idempotent producer.
13:47:25.792 [kafka-producer-network-thread | producer-164] INFO Metadata - [Producer clientId=producer-164] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.792 [kafka-producer-network-thread | producer-164] INFO TransactionManager - [Producer clientId=producer-164] ProducerId set to 14254 with epoch 0
13:47:25.793 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.793 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.794 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.794 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045793
13:47:25.794 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-166
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.794 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-166] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.794 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-166] Instantiated an idempotent producer.
13:47:25.796 [kafka-producer-network-thread | producer-165] INFO Metadata - [Producer clientId=producer-165] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.796 [kafka-producer-network-thread | producer-165] INFO TransactionManager - [Producer clientId=producer-165] ProducerId set to 12352 with epoch 0
13:47:25.797 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.797 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.797 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.797 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045797
13:47:25.797 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-167
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.798 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-167] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.798 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-167] Instantiated an idempotent producer.
13:47:25.798 [kafka-producer-network-thread | producer-166] INFO Metadata - [Producer clientId=producer-166] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.798 [kafka-producer-network-thread | producer-166] INFO TransactionManager - [Producer clientId=producer-166] ProducerId set to 14257 with epoch 0
13:47:25.800 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.800 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.800 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.800 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045800
13:47:25.800 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-168
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.800 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-168] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.801 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-168] Instantiated an idempotent producer.
13:47:25.801 [kafka-producer-network-thread | producer-167] INFO Metadata - [Producer clientId=producer-167] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.801 [kafka-producer-network-thread | producer-167] INFO TransactionManager - [Producer clientId=producer-167] ProducerId set to 14259 with epoch 0
13:47:25.802 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.802 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.802 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.802 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045802
13:47:25.803 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-169
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.803 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-169] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.803 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-169] Instantiated an idempotent producer.
13:47:25.804 [kafka-producer-network-thread | producer-168] INFO Metadata - [Producer clientId=producer-168] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.804 [kafka-producer-network-thread | producer-168] INFO TransactionManager - [Producer clientId=producer-168] ProducerId set to 13377 with epoch 0
13:47:25.805 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.805 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.805 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.805 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045805
13:47:25.806 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-170
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.806 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-170] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.806 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-170] Instantiated an idempotent producer.
13:47:25.807 [kafka-producer-network-thread | producer-169] INFO Metadata - [Producer clientId=producer-169] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.807 [kafka-producer-network-thread | producer-169] INFO TransactionManager - [Producer clientId=producer-169] ProducerId set to 12355 with epoch 0
13:47:25.808 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.808 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.808 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.808 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045808
13:47:25.808 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-171
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.809 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-171] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.809 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-171] Instantiated an idempotent producer.
13:47:25.810 [kafka-producer-network-thread | producer-170] INFO Metadata - [Producer clientId=producer-170] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.810 [kafka-producer-network-thread | producer-170] INFO TransactionManager - [Producer clientId=producer-170] ProducerId set to 13378 with epoch 0
13:47:25.811 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.811 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.811 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.811 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045811
13:47:25.811 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-172
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.812 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-172] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.812 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-172] Instantiated an idempotent producer.
13:47:25.815 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.815 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.815 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.815 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045815
13:47:25.815 [kafka-producer-network-thread | producer-171] INFO Metadata - [Producer clientId=producer-171] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.816 [kafka-producer-network-thread | producer-171] INFO TransactionManager - [Producer clientId=producer-171] ProducerId set to 14262 with epoch 0
13:47:25.816 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-173
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.816 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-173] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.816 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-173] Instantiated an idempotent producer.
13:47:25.818 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.818 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.818 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.818 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045818
13:47:25.819 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-174
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.819 [kafka-producer-network-thread | producer-172] INFO Metadata - [Producer clientId=producer-172] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.819 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-174] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.819 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-174] Instantiated an idempotent producer.
13:47:25.819 [kafka-producer-network-thread | producer-172] INFO TransactionManager - [Producer clientId=producer-172] ProducerId set to 12358 with epoch 0
13:47:25.819 [kafka-producer-network-thread | producer-173] INFO Metadata - [Producer clientId=producer-173] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.820 [kafka-producer-network-thread | producer-173] INFO TransactionManager - [Producer clientId=producer-173] ProducerId set to 13381 with epoch 0
13:47:25.821 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.821 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.821 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.821 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045821
13:47:25.821 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-175
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.822 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-175] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.822 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-175] Instantiated an idempotent producer.
13:47:25.824 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.824 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.824 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.824 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045824
13:47:25.825 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-176
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.825 [kafka-producer-network-thread | producer-174] INFO Metadata - [Producer clientId=producer-174] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.825 [kafka-producer-network-thread | producer-174] INFO TransactionManager - [Producer clientId=producer-174] ProducerId set to 12360 with epoch 0
13:47:25.825 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-176] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.825 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-176] Instantiated an idempotent producer.
13:47:25.826 [kafka-producer-network-thread | producer-175] INFO Metadata - [Producer clientId=producer-175] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.827 [kafka-producer-network-thread | producer-175] INFO TransactionManager - [Producer clientId=producer-175] ProducerId set to 14266 with epoch 0
13:47:25.827 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.827 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.827 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.827 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045827
13:47:25.828 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-177
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.828 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-177] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.828 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-177] Instantiated an idempotent producer.
13:47:25.829 [kafka-producer-network-thread | producer-176] INFO Metadata - [Producer clientId=producer-176] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.829 [kafka-producer-network-thread | producer-176] INFO TransactionManager - [Producer clientId=producer-176] ProducerId set to 14267 with epoch 0
13:47:25.830 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.830 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.830 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.830 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045830
13:47:25.831 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-178
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.831 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-178] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.831 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-178] Instantiated an idempotent producer.
13:47:25.832 [kafka-producer-network-thread | producer-177] INFO Metadata - [Producer clientId=producer-177] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.832 [kafka-producer-network-thread | producer-177] INFO TransactionManager - [Producer clientId=producer-177] ProducerId set to 13386 with epoch 0
13:47:25.833 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.833 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.833 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.833 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045833
13:47:25.834 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-179
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.834 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-179] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.834 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-179] Instantiated an idempotent producer.
13:47:25.835 [kafka-producer-network-thread | producer-178] INFO Metadata - [Producer clientId=producer-178] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.835 [kafka-producer-network-thread | producer-178] INFO TransactionManager - [Producer clientId=producer-178] ProducerId set to 13387 with epoch 0
13:47:25.836 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.836 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.836 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.836 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045836
13:47:25.837 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-180
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.837 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-180] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.837 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-180] Instantiated an idempotent producer.
13:47:25.837 [kafka-producer-network-thread | producer-179] INFO Metadata - [Producer clientId=producer-179] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.837 [kafka-producer-network-thread | producer-179] INFO TransactionManager - [Producer clientId=producer-179] ProducerId set to 13388 with epoch 0
13:47:25.839 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.839 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.839 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.839 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045839
13:47:25.840 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-181
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.840 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-181] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.840 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-181] Instantiated an idempotent producer.
13:47:25.841 [kafka-producer-network-thread | producer-180] INFO Metadata - [Producer clientId=producer-180] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.841 [kafka-producer-network-thread | producer-180] INFO TransactionManager - [Producer clientId=producer-180] ProducerId set to 14272 with epoch 0
13:47:25.842 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.842 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.842 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.842 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045842
13:47:25.842 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-182
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.843 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-182] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.843 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-182] Instantiated an idempotent producer.
13:47:25.843 [kafka-producer-network-thread | producer-181] INFO Metadata - [Producer clientId=producer-181] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.844 [kafka-producer-network-thread | producer-181] INFO TransactionManager - [Producer clientId=producer-181] ProducerId set to 14273 with epoch 0
13:47:25.846 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.846 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.846 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.846 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045846
13:47:25.846 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-183
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.847 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-183] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.847 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-183] Instantiated an idempotent producer.
13:47:25.848 [kafka-producer-network-thread | producer-182] INFO Metadata - [Producer clientId=producer-182] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.848 [kafka-producer-network-thread | producer-182] INFO TransactionManager - [Producer clientId=producer-182] ProducerId set to 14275 with epoch 0
13:47:25.849 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.849 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.849 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.849 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045849
13:47:25.849 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-184
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.850 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-184] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.850 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-184] Instantiated an idempotent producer.
13:47:25.851 [kafka-producer-network-thread | producer-183] INFO Metadata - [Producer clientId=producer-183] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.851 [kafka-producer-network-thread | producer-183] INFO TransactionManager - [Producer clientId=producer-183] ProducerId set to 14276 with epoch 0
13:47:25.852 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.852 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.852 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.852 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045852
13:47:25.852 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-185
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.853 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-185] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.853 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-185] Instantiated an idempotent producer.
13:47:25.853 [kafka-producer-network-thread | producer-184] INFO Metadata - [Producer clientId=producer-184] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.853 [kafka-producer-network-thread | producer-184] INFO TransactionManager - [Producer clientId=producer-184] ProducerId set to 14277 with epoch 0
13:47:25.854 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.855 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.855 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.855 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045855
13:47:25.855 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-186
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.856 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-186] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.856 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-186] Instantiated an idempotent producer.
13:47:25.856 [kafka-producer-network-thread | producer-185] INFO Metadata - [Producer clientId=producer-185] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.856 [kafka-producer-network-thread | producer-185] INFO TransactionManager - [Producer clientId=producer-185] ProducerId set to 12367 with epoch 0
13:47:25.858 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.858 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.858 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.858 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045858
13:47:25.858 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-187
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.858 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-187] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.859 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-187] Instantiated an idempotent producer.
13:47:25.859 [kafka-producer-network-thread | producer-186] INFO Metadata - [Producer clientId=producer-186] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.859 [kafka-producer-network-thread | producer-186] INFO TransactionManager - [Producer clientId=producer-186] ProducerId set to 13396 with epoch 0
13:47:25.861 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.861 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.861 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.861 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045861
13:47:25.861 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-188
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.862 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-188] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.862 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-188] Instantiated an idempotent producer.
13:47:25.863 [kafka-producer-network-thread | producer-187] INFO Metadata - [Producer clientId=producer-187] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.863 [kafka-producer-network-thread | producer-187] INFO TransactionManager - [Producer clientId=producer-187] ProducerId set to 13398 with epoch 0
13:47:25.864 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.864 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.864 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.864 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045864
13:47:25.864 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-189
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.865 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-189] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.865 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-189] Instantiated an idempotent producer.
13:47:25.866 [kafka-producer-network-thread | producer-188] INFO Metadata - [Producer clientId=producer-188] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.866 [kafka-producer-network-thread | producer-188] INFO TransactionManager - [Producer clientId=producer-188] ProducerId set to 14280 with epoch 0
13:47:25.868 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.868 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.868 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.868 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045868
13:47:25.868 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-190
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.869 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-190] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.869 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-190] Instantiated an idempotent producer.
13:47:25.869 [kafka-producer-network-thread | producer-189] INFO Metadata - [Producer clientId=producer-189] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.869 [kafka-producer-network-thread | producer-189] INFO TransactionManager - [Producer clientId=producer-189] ProducerId set to 14283 with epoch 0
13:47:25.871 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.871 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.871 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.871 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045871
13:47:25.871 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-191
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.872 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-191] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.872 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-191] Instantiated an idempotent producer.
13:47:25.872 [kafka-producer-network-thread | producer-190] INFO Metadata - [Producer clientId=producer-190] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.872 [kafka-producer-network-thread | producer-190] INFO TransactionManager - [Producer clientId=producer-190] ProducerId set to 12372 with epoch 0
13:47:25.874 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.874 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.874 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.874 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045874
13:47:25.874 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-192
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.875 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-192] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.875 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-192] Instantiated an idempotent producer.
13:47:25.875 [kafka-producer-network-thread | producer-191] INFO Metadata - [Producer clientId=producer-191] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.875 [kafka-producer-network-thread | producer-191] INFO TransactionManager - [Producer clientId=producer-191] ProducerId set to 12373 with epoch 0
13:47:25.877 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.878 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.878 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.878 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045878
13:47:25.878 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-193
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.878 [kafka-producer-network-thread | producer-192] INFO Metadata - [Producer clientId=producer-192] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.878 [kafka-producer-network-thread | producer-192] INFO TransactionManager - [Producer clientId=producer-192] ProducerId set to 12375 with epoch 0
13:47:25.879 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-193] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.879 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-193] Instantiated an idempotent producer.
13:47:25.882 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.882 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.882 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.882 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045882
13:47:25.883 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-194
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.883 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-194] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.883 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-194] Instantiated an idempotent producer.
13:47:25.883 [kafka-producer-network-thread | producer-193] INFO Metadata - [Producer clientId=producer-193] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.884 [kafka-producer-network-thread | producer-193] INFO TransactionManager - [Producer clientId=producer-193] ProducerId set to 13403 with epoch 0
13:47:25.885 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.885 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.885 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.885 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045885
13:47:25.885 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-195
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.886 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-195] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.886 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-195] Instantiated an idempotent producer.
13:47:25.886 [kafka-producer-network-thread | producer-194] INFO Metadata - [Producer clientId=producer-194] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.886 [kafka-producer-network-thread | producer-194] INFO TransactionManager - [Producer clientId=producer-194] ProducerId set to 13404 with epoch 0
13:47:25.888 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.888 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.888 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.888 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045888
13:47:25.888 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-196
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.889 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-196] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.889 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-196] Instantiated an idempotent producer.
13:47:25.889 [kafka-producer-network-thread | producer-195] INFO Metadata - [Producer clientId=producer-195] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.889 [kafka-producer-network-thread | producer-195] INFO TransactionManager - [Producer clientId=producer-195] ProducerId set to 14289 with epoch 0
13:47:25.891 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.891 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.891 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.891 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045891
13:47:25.891 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-197
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.892 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-197] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.892 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-197] Instantiated an idempotent producer.
13:47:25.893 [kafka-producer-network-thread | producer-196] INFO Metadata - [Producer clientId=producer-196] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.893 [kafka-producer-network-thread | producer-196] INFO TransactionManager - [Producer clientId=producer-196] ProducerId set to 14291 with epoch 0
13:47:25.894 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.894 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.894 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.894 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045894
13:47:25.894 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-198
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.895 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-198] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.895 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-198] Instantiated an idempotent producer.
13:47:25.895 [kafka-producer-network-thread | producer-197] INFO Metadata - [Producer clientId=producer-197] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.896 [kafka-producer-network-thread | producer-197] INFO TransactionManager - [Producer clientId=producer-197] ProducerId set to 13405 with epoch 0
13:47:25.897 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.897 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.897 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.897 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045897
13:47:25.897 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-199
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.898 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-199] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.898 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-199] Instantiated an idempotent producer.
13:47:25.900 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.900 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.900 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.900 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045900
13:47:25.900 [kafka-producer-network-thread | producer-198] INFO Metadata - [Producer clientId=producer-198] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.900 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-200
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.901 [kafka-producer-network-thread | producer-198] INFO TransactionManager - [Producer clientId=producer-198] ProducerId set to 13409 with epoch 0
13:47:25.901 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-200] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.901 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-200] Instantiated an idempotent producer.
13:47:25.902 [kafka-producer-network-thread | producer-199] INFO Metadata - [Producer clientId=producer-199] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.902 [kafka-producer-network-thread | producer-199] INFO TransactionManager - [Producer clientId=producer-199] ProducerId set to 12382 with epoch 0
13:47:25.903 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.903 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.903 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.903 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045903
13:47:25.903 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-201
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.904 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-201] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.904 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-201] Instantiated an idempotent producer.
13:47:25.905 [kafka-producer-network-thread | producer-200] INFO Metadata - [Producer clientId=producer-200] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.905 [kafka-producer-network-thread | producer-200] INFO TransactionManager - [Producer clientId=producer-200] ProducerId set to 13411 with epoch 0
13:47:25.906 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.906 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.906 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.906 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045906
13:47:25.906 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-202
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.907 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-202] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.907 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-202] Instantiated an idempotent producer.
13:47:25.907 [kafka-producer-network-thread | producer-201] INFO Metadata - [Producer clientId=producer-201] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.907 [kafka-producer-network-thread | producer-201] INFO TransactionManager - [Producer clientId=producer-201] ProducerId set to 14294 with epoch 0
13:47:25.910 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.910 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.910 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.910 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045910
13:47:25.911 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-203
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.911 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-203] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.911 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-203] Instantiated an idempotent producer.
13:47:25.911 [kafka-producer-network-thread | producer-202] INFO Metadata - [Producer clientId=producer-202] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.911 [kafka-producer-network-thread | producer-202] INFO TransactionManager - [Producer clientId=producer-202] ProducerId set to 14297 with epoch 0
13:47:25.913 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.913 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.913 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.913 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045913
13:47:25.914 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-204
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.914 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-204] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.914 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-204] Instantiated an idempotent producer.
13:47:25.915 [kafka-producer-network-thread | producer-203] INFO Metadata - [Producer clientId=producer-203] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.915 [kafka-producer-network-thread | producer-203] INFO TransactionManager - [Producer clientId=producer-203] ProducerId set to 13413 with epoch 0
13:47:25.916 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.916 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.916 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.916 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045916
13:47:25.917 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-205
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.917 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-205] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.917 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-205] Instantiated an idempotent producer.
13:47:25.918 [kafka-producer-network-thread | producer-204] INFO Metadata - [Producer clientId=producer-204] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.918 [kafka-producer-network-thread | producer-204] INFO TransactionManager - [Producer clientId=producer-204] ProducerId set to 13414 with epoch 0
13:47:25.919 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.919 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.919 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.919 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045919
13:47:25.920 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-206
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.920 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-206] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.920 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-206] Instantiated an idempotent producer.
13:47:25.921 [kafka-producer-network-thread | producer-205] INFO Metadata - [Producer clientId=producer-205] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.921 [kafka-producer-network-thread | producer-205] INFO TransactionManager - [Producer clientId=producer-205] ProducerId set to 14301 with epoch 0
13:47:25.922 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.922 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.922 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.922 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045922
13:47:25.923 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-207
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.923 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-207] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.923 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-207] Instantiated an idempotent producer.
13:47:25.923 [kafka-producer-network-thread | producer-206] INFO Metadata - [Producer clientId=producer-206] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.924 [kafka-producer-network-thread | producer-206] INFO TransactionManager - [Producer clientId=producer-206] ProducerId set to 12389 with epoch 0
13:47:25.925 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.925 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.925 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.925 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045925
13:47:25.926 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-208
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.926 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-208] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.926 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-208] Instantiated an idempotent producer.
13:47:25.927 [kafka-producer-network-thread | producer-207] INFO Metadata - [Producer clientId=producer-207] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.927 [kafka-producer-network-thread | producer-207] INFO TransactionManager - [Producer clientId=producer-207] ProducerId set to 12391 with epoch 0
13:47:25.928 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.928 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.928 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.928 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045928
13:47:25.928 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-209
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.929 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-209] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.929 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-209] Instantiated an idempotent producer.
13:47:25.929 [kafka-producer-network-thread | producer-208] INFO Metadata - [Producer clientId=producer-208] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.929 [kafka-producer-network-thread | producer-208] INFO TransactionManager - [Producer clientId=producer-208] ProducerId set to 13417 with epoch 0
13:47:25.931 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.931 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.931 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.931 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045931
13:47:25.931 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-210
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.932 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-210] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.932 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-210] Instantiated an idempotent producer.
13:47:25.932 [kafka-producer-network-thread | producer-209] INFO Metadata - [Producer clientId=producer-209] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.933 [kafka-producer-network-thread | producer-209] INFO TransactionManager - [Producer clientId=producer-209] ProducerId set to 14304 with epoch 0
13:47:25.934 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.934 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.934 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.934 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045934
13:47:25.934 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-211
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.935 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-211] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.935 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-211] Instantiated an idempotent producer.
13:47:25.935 [kafka-producer-network-thread | producer-210] INFO Metadata - [Producer clientId=producer-210] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.936 [kafka-producer-network-thread | producer-210] INFO TransactionManager - [Producer clientId=producer-210] ProducerId set to 14306 with epoch 0
13:47:25.937 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.937 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.937 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.937 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045937
13:47:25.937 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-212
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.938 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-212] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.938 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-212] Instantiated an idempotent producer.
13:47:25.939 [kafka-producer-network-thread | producer-211] INFO Metadata - [Producer clientId=producer-211] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.939 [kafka-producer-network-thread | producer-211] INFO TransactionManager - [Producer clientId=producer-211] ProducerId set to 13419 with epoch 0
13:47:25.940 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.940 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.940 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.940 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045940
13:47:25.940 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-213
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.941 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-213] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.941 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-213] Instantiated an idempotent producer.
13:47:25.942 [kafka-producer-network-thread | producer-212] INFO Metadata - [Producer clientId=producer-212] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.942 [kafka-producer-network-thread | producer-212] INFO TransactionManager - [Producer clientId=producer-212] ProducerId set to 12397 with epoch 0
13:47:25.943 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.943 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.943 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.943 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045943
13:47:25.943 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-214
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.944 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-214] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.944 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-214] Instantiated an idempotent producer.
13:47:25.944 [kafka-producer-network-thread | producer-213] INFO Metadata - [Producer clientId=producer-213] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.944 [kafka-producer-network-thread | producer-213] INFO TransactionManager - [Producer clientId=producer-213] ProducerId set to 14309 with epoch 0
13:47:25.945 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.945 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.946 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.946 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045945
13:47:25.946 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-215
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.946 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-215] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.946 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-215] Instantiated an idempotent producer.
13:47:25.947 [kafka-producer-network-thread | producer-214] INFO Metadata - [Producer clientId=producer-214] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.947 [kafka-producer-network-thread | producer-214] INFO TransactionManager - [Producer clientId=producer-214] ProducerId set to 12400 with epoch 0
13:47:25.948 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.948 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.948 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.948 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045948
13:47:25.949 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-216
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.949 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-216] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.949 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-216] Instantiated an idempotent producer.
13:47:25.950 [kafka-producer-network-thread | producer-215] INFO Metadata - [Producer clientId=producer-215] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.950 [kafka-producer-network-thread | producer-215] INFO TransactionManager - [Producer clientId=producer-215] ProducerId set to 12402 with epoch 0
13:47:25.951 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.951 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.951 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.951 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045951
13:47:25.952 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-217
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.952 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-217] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.952 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-217] Instantiated an idempotent producer.
13:47:25.953 [kafka-producer-network-thread | producer-216] INFO Metadata - [Producer clientId=producer-216] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.953 [kafka-producer-network-thread | producer-216] INFO TransactionManager - [Producer clientId=producer-216] ProducerId set to 12404 with epoch 0
13:47:25.954 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.954 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.954 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.954 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045954
13:47:25.954 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-218
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.955 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-218] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.955 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-218] Instantiated an idempotent producer.
13:47:25.957 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.957 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.957 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.957 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045957
13:47:25.957 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-219
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.958 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-219] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.958 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-219] Instantiated an idempotent producer.
13:47:25.959 [kafka-producer-network-thread | producer-218] INFO Metadata - [Producer clientId=producer-218] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.959 [kafka-producer-network-thread | producer-218] INFO TransactionManager - [Producer clientId=producer-218] ProducerId set to 14315 with epoch 0
13:47:25.961 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.961 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.961 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.961 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045961
13:47:25.962 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-220
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.962 [kafka-producer-network-thread | producer-219] INFO Metadata - [Producer clientId=producer-219] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.962 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-220] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.962 [kafka-producer-network-thread | producer-219] INFO TransactionManager - [Producer clientId=producer-219] ProducerId set to 14316 with epoch 0
13:47:25.962 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-220] Instantiated an idempotent producer.
13:47:25.964 [kafka-producer-network-thread | producer-217] INFO Metadata - [Producer clientId=producer-217] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.964 [kafka-producer-network-thread | producer-217] INFO TransactionManager - [Producer clientId=producer-217] ProducerId set to 13426 with epoch 0
13:47:25.964 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.964 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.964 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.964 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045964
13:47:25.965 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-221
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.965 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-221] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.965 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-221] Instantiated an idempotent producer.
13:47:25.966 [kafka-producer-network-thread | producer-220] INFO Metadata - [Producer clientId=producer-220] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.966 [kafka-producer-network-thread | producer-220] INFO TransactionManager - [Producer clientId=producer-220] ProducerId set to 13427 with epoch 0
13:47:25.968 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.968 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.968 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.968 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045968
13:47:25.968 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-222
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.968 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-222] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.969 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-222] Instantiated an idempotent producer.
13:47:25.970 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.970 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.970 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.970 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045970
13:47:25.971 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-223
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.971 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-223] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.971 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-223] Instantiated an idempotent producer.
13:47:25.972 [kafka-producer-network-thread | producer-221] INFO Metadata - [Producer clientId=producer-221] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.972 [kafka-producer-network-thread | producer-221] INFO TransactionManager - [Producer clientId=producer-221] ProducerId set to 13428 with epoch 0
13:47:25.973 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.974 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.974 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.974 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045973
13:47:25.974 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-224
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.975 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-224] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.975 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-224] Instantiated an idempotent producer.
13:47:25.975 [kafka-producer-network-thread | producer-223] INFO Metadata - [Producer clientId=producer-223] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.975 [kafka-producer-network-thread | producer-222] INFO Metadata - [Producer clientId=producer-222] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.975 [kafka-producer-network-thread | producer-223] INFO TransactionManager - [Producer clientId=producer-223] ProducerId set to 12412 with epoch 0
13:47:25.975 [kafka-producer-network-thread | producer-222] INFO TransactionManager - [Producer clientId=producer-222] ProducerId set to 14318 with epoch 0
13:47:25.976 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.977 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.977 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.977 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045977
13:47:25.977 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-225
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.978 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-225] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.978 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-225] Instantiated an idempotent producer.
13:47:25.978 [kafka-producer-network-thread | producer-224] INFO Metadata - [Producer clientId=producer-224] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.978 [kafka-producer-network-thread | producer-224] INFO TransactionManager - [Producer clientId=producer-224] ProducerId set to 12414 with epoch 0
13:47:25.979 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.979 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.979 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.979 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045979
13:47:25.980 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-226
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.980 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-226] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.980 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-226] Instantiated an idempotent producer.
13:47:25.981 [kafka-producer-network-thread | producer-225] INFO Metadata - [Producer clientId=producer-225] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.981 [kafka-producer-network-thread | producer-225] INFO TransactionManager - [Producer clientId=producer-225] ProducerId set to 14321 with epoch 0
13:47:25.982 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.982 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.982 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.982 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045982
13:47:25.983 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-227
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.983 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-227] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.983 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-227] Instantiated an idempotent producer.
13:47:25.984 [kafka-producer-network-thread | producer-226] INFO Metadata - [Producer clientId=producer-226] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.984 [kafka-producer-network-thread | producer-226] INFO TransactionManager - [Producer clientId=producer-226] ProducerId set to 13434 with epoch 0
13:47:25.985 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.985 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.985 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.985 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045985
13:47:25.986 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-228
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.986 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-228] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.986 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-228] Instantiated an idempotent producer.
13:47:25.987 [kafka-producer-network-thread | producer-227] INFO Metadata - [Producer clientId=producer-227] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.987 [kafka-producer-network-thread | producer-227] INFO TransactionManager - [Producer clientId=producer-227] ProducerId set to 13435 with epoch 0
13:47:25.988 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.988 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.988 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.988 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045988
13:47:25.989 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-229
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.989 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-229] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.989 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-229] Instantiated an idempotent producer.
13:47:25.990 [kafka-producer-network-thread | producer-228] INFO Metadata - [Producer clientId=producer-228] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.990 [kafka-producer-network-thread | producer-228] INFO TransactionManager - [Producer clientId=producer-228] ProducerId set to 14326 with epoch 0
13:47:25.991 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.991 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.991 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.991 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045991
13:47:25.991 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-230
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.992 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-230] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.992 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-230] Instantiated an idempotent producer.
13:47:25.993 [kafka-producer-network-thread | producer-229] INFO Metadata - [Producer clientId=producer-229] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.993 [kafka-producer-network-thread | producer-229] INFO TransactionManager - [Producer clientId=producer-229] ProducerId set to 14328 with epoch 0
13:47:25.994 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.994 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.994 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.994 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045994
13:47:25.994 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-231
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.995 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-231] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.995 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-231] Instantiated an idempotent producer.
13:47:25.995 [kafka-producer-network-thread | producer-230] INFO Metadata - [Producer clientId=producer-230] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.995 [kafka-producer-network-thread | producer-230] INFO TransactionManager - [Producer clientId=producer-230] ProducerId set to 12418 with epoch 0
13:47:25.997 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.997 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.997 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.997 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045997
13:47:25.997 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-232
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.998 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-232] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.998 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-232] Instantiated an idempotent producer.
13:47:25.998 [kafka-producer-network-thread | producer-231] INFO Metadata - [Producer clientId=producer-231] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.998 [kafka-producer-network-thread | producer-231] INFO TransactionManager - [Producer clientId=producer-231] ProducerId set to 12421 with epoch 0
13:47:26.000 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.000 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.000 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.000 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046000
13:47:26.000 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-233
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.000 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-233] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.000 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-233] Instantiated an idempotent producer.
13:47:26.001 [kafka-producer-network-thread | producer-232] INFO Metadata - [Producer clientId=producer-232] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.001 [kafka-producer-network-thread | producer-232] INFO TransactionManager - [Producer clientId=producer-232] ProducerId set to 14329 with epoch 0
13:47:26.002 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.002 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.002 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.002 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046002
13:47:26.003 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-234
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.003 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-234] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.003 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-234] Instantiated an idempotent producer.
13:47:26.004 [kafka-producer-network-thread | producer-233] INFO Metadata - [Producer clientId=producer-233] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.004 [kafka-producer-network-thread | producer-233] INFO TransactionManager - [Producer clientId=producer-233] ProducerId set to 12424 with epoch 0
13:47:26.006 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.006 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.006 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.006 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046006
13:47:26.007 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-235
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.007 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-235] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.007 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-235] Instantiated an idempotent producer.
13:47:26.008 [kafka-producer-network-thread | producer-234] INFO Metadata - [Producer clientId=producer-234] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.008 [kafka-producer-network-thread | producer-234] INFO TransactionManager - [Producer clientId=producer-234] ProducerId set to 14333 with epoch 0
13:47:26.009 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.009 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.009 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.009 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046009
13:47:26.010 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-236
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.010 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-236] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.010 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-236] Instantiated an idempotent producer.
13:47:26.011 [kafka-producer-network-thread | producer-235] INFO Metadata - [Producer clientId=producer-235] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.011 [kafka-producer-network-thread | producer-235] INFO TransactionManager - [Producer clientId=producer-235] ProducerId set to 14335 with epoch 0
13:47:26.012 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.012 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.012 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.012 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046012
13:47:26.013 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-237
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.013 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-237] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.013 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-237] Instantiated an idempotent producer.
13:47:26.014 [kafka-producer-network-thread | producer-236] INFO Metadata - [Producer clientId=producer-236] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.014 [kafka-producer-network-thread | producer-236] INFO TransactionManager - [Producer clientId=producer-236] ProducerId set to 14336 with epoch 0
13:47:26.015 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.015 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.015 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.015 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046015
13:47:26.016 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-238
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.016 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-238] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.016 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-238] Instantiated an idempotent producer.
13:47:26.017 [kafka-producer-network-thread | producer-237] INFO Metadata - [Producer clientId=producer-237] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.017 [kafka-producer-network-thread | producer-237] INFO TransactionManager - [Producer clientId=producer-237] ProducerId set to 12429 with epoch 0
13:47:26.018 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.018 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.018 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.018 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046018
13:47:26.019 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-239
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.019 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-239] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.019 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-239] Instantiated an idempotent producer.
13:47:26.020 [kafka-producer-network-thread | producer-238] INFO Metadata - [Producer clientId=producer-238] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.020 [kafka-producer-network-thread | producer-238] INFO TransactionManager - [Producer clientId=producer-238] ProducerId set to 14338 with epoch 0
13:47:26.021 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.021 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.021 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.021 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046021
13:47:26.022 [kafka-producer-network-thread | producer-239] INFO Metadata - [Producer clientId=producer-239] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.023 [kafka-producer-network-thread | producer-239] INFO TransactionManager - [Producer clientId=producer-239] ProducerId set to 13444 with epoch 0
13:47:26.023 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-240
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.024 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-240] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.024 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-240] Instantiated an idempotent producer.
13:47:26.027 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.027 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.027 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.027 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046027
13:47:26.028 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-241
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.028 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-241] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.028 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-241] Instantiated an idempotent producer.
13:47:26.029 [kafka-producer-network-thread | producer-240] INFO Metadata - [Producer clientId=producer-240] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.029 [kafka-producer-network-thread | producer-240] INFO TransactionManager - [Producer clientId=producer-240] ProducerId set to 14342 with epoch 0
13:47:26.030 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.031 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.031 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.031 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046030
13:47:26.031 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-242
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.031 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-242] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.031 [kafka-producer-network-thread | producer-241] INFO Metadata - [Producer clientId=producer-241] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.031 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-242] Instantiated an idempotent producer.
13:47:26.032 [kafka-producer-network-thread | producer-241] INFO TransactionManager - [Producer clientId=producer-241] ProducerId set to 13447 with epoch 0
13:47:26.035 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.035 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.035 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.035 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046035
13:47:26.035 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-243
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.036 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-243] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.036 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-243] Instantiated an idempotent producer.
13:47:26.036 [kafka-producer-network-thread | producer-242] INFO Metadata - [Producer clientId=producer-242] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.037 [kafka-producer-network-thread | producer-242] INFO TransactionManager - [Producer clientId=producer-242] ProducerId set to 14346 with epoch 0
13:47:26.038 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.038 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.038 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.038 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046038
13:47:26.038 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-244
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.039 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-244] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.039 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-244] Instantiated an idempotent producer.
13:47:26.041 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.041 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.041 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.041 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046041
13:47:26.041 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-245
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.042 [kafka-producer-network-thread | producer-243] INFO Metadata - [Producer clientId=producer-243] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.042 [kafka-producer-network-thread | producer-243] INFO TransactionManager - [Producer clientId=producer-243] ProducerId set to 12435 with epoch 0
13:47:26.042 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-245] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.042 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-245] Instantiated an idempotent producer.
13:47:26.044 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.044 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.044 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.044 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046044
13:47:26.044 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-246
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.045 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-246] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.045 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-246] Instantiated an idempotent producer.
13:47:26.046 [kafka-producer-network-thread | producer-244] INFO Metadata - [Producer clientId=producer-244] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.046 [kafka-producer-network-thread | producer-244] INFO TransactionManager - [Producer clientId=producer-244] ProducerId set to 14347 with epoch 0
13:47:26.046 [kafka-producer-network-thread | producer-245] INFO Metadata - [Producer clientId=producer-245] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.046 [kafka-producer-network-thread | producer-245] INFO TransactionManager - [Producer clientId=producer-245] ProducerId set to 14348 with epoch 0
13:47:26.047 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.047 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.047 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.047 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046047
13:47:26.048 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-247
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.048 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-247] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.048 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-247] Instantiated an idempotent producer.
13:47:26.048 [kafka-producer-network-thread | producer-246] INFO Metadata - [Producer clientId=producer-246] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.049 [kafka-producer-network-thread | producer-246] INFO TransactionManager - [Producer clientId=producer-246] ProducerId set to 14350 with epoch 0
13:47:26.050 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.050 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.050 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.050 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046050
13:47:26.051 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-248
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.051 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-248] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.051 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-248] Instantiated an idempotent producer.
13:47:26.052 [kafka-producer-network-thread | producer-247] INFO Metadata - [Producer clientId=producer-247] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.052 [kafka-producer-network-thread | producer-247] INFO TransactionManager - [Producer clientId=producer-247] ProducerId set to 14353 with epoch 0
13:47:26.054 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.054 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.054 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.054 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046054
13:47:26.054 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-249
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.055 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-249] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.055 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-249] Instantiated an idempotent producer.
13:47:26.055 [kafka-producer-network-thread | producer-248] INFO Metadata - [Producer clientId=producer-248] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.055 [kafka-producer-network-thread | producer-248] INFO TransactionManager - [Producer clientId=producer-248] ProducerId set to 12439 with epoch 0
13:47:26.057 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.057 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.057 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.057 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046057
13:47:26.057 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-250
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.058 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-250] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.058 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-250] Instantiated an idempotent producer.
13:47:26.058 [kafka-producer-network-thread | producer-249] INFO Metadata - [Producer clientId=producer-249] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.058 [kafka-producer-network-thread | producer-249] INFO TransactionManager - [Producer clientId=producer-249] ProducerId set to 12441 with epoch 0
13:47:26.060 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.060 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.060 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.060 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046060
13:47:26.060 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-251
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.061 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-251] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.061 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-251] Instantiated an idempotent producer.
13:47:26.061 [kafka-producer-network-thread | producer-250] INFO Metadata - [Producer clientId=producer-250] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.061 [kafka-producer-network-thread | producer-250] INFO TransactionManager - [Producer clientId=producer-250] ProducerId set to 14356 with epoch 0
13:47:26.062 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.062 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.063 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.063 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046062
13:47:26.063 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-252
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.064 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-252] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.064 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-252] Instantiated an idempotent producer.
13:47:26.064 [kafka-producer-network-thread | producer-251] INFO Metadata - [Producer clientId=producer-251] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.064 [kafka-producer-network-thread | producer-251] INFO TransactionManager - [Producer clientId=producer-251] ProducerId set to 14358 with epoch 0
13:47:26.065 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.065 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.065 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.065 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046065
13:47:26.066 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-253
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.066 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-253] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.066 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-253] Instantiated an idempotent producer.
13:47:26.067 [kafka-producer-network-thread | producer-252] INFO Metadata - [Producer clientId=producer-252] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.067 [kafka-producer-network-thread | producer-252] INFO TransactionManager - [Producer clientId=producer-252] ProducerId set to 12442 with epoch 0
13:47:26.068 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.068 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.068 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.068 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046068
13:47:26.069 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-254
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.069 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-254] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.069 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-254] Instantiated an idempotent producer.
13:47:26.070 [kafka-producer-network-thread | producer-253] INFO Metadata - [Producer clientId=producer-253] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.070 [kafka-producer-network-thread | producer-253] INFO TransactionManager - [Producer clientId=producer-253] ProducerId set to 12443 with epoch 0
13:47:26.071 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.071 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.071 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.071 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046071
13:47:26.071 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-255
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.072 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-255] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.072 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-255] Instantiated an idempotent producer.
13:47:26.074 [kafka-producer-network-thread | producer-254] INFO Metadata - [Producer clientId=producer-254] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.074 [kafka-producer-network-thread | producer-254] INFO TransactionManager - [Producer clientId=producer-254] ProducerId set to 14363 with epoch 0
13:47:26.087 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.087 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.087 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.087 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046087
13:47:26.088 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-256
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.088 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-256] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.088 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-256] Instantiated an idempotent producer.
13:47:26.089 [kafka-producer-network-thread | producer-255] INFO Metadata - [Producer clientId=producer-255] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.089 [kafka-producer-network-thread | producer-255] INFO TransactionManager - [Producer clientId=producer-255] ProducerId set to 13459 with epoch 0
13:47:26.090 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.090 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.090 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.090 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046090
13:47:26.091 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-257
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.091 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-257] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.091 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-257] Instantiated an idempotent producer.
13:47:26.092 [kafka-producer-network-thread | producer-256] INFO Metadata - [Producer clientId=producer-256] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.092 [kafka-producer-network-thread | producer-256] INFO TransactionManager - [Producer clientId=producer-256] ProducerId set to 13461 with epoch 0
13:47:26.093 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.093 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.093 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.093 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046093
13:47:26.093 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-258
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.094 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-258] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.094 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-258] Instantiated an idempotent producer.
13:47:26.094 [kafka-producer-network-thread | producer-257] INFO Metadata - [Producer clientId=producer-257] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.094 [kafka-producer-network-thread | producer-257] INFO TransactionManager - [Producer clientId=producer-257] ProducerId set to 12447 with epoch 0
13:47:26.095 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.095 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.095 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.095 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046095
13:47:26.096 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-259
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.096 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-259] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.096 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-259] Instantiated an idempotent producer.
13:47:26.097 [kafka-producer-network-thread | producer-258] INFO Metadata - [Producer clientId=producer-258] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.097 [kafka-producer-network-thread | producer-258] INFO TransactionManager - [Producer clientId=producer-258] ProducerId set to 12448 with epoch 0
13:47:26.098 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.098 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.098 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.098 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046098
13:47:26.098 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-260
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.099 [kafka-producer-network-thread | producer-259] INFO Metadata - [Producer clientId=producer-259] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.099 [kafka-producer-network-thread | producer-259] INFO TransactionManager - [Producer clientId=producer-259] ProducerId set to 13462 with epoch 0
13:47:26.099 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-260] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.099 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-260] Instantiated an idempotent producer.
13:47:26.101 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.101 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.101 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.101 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046101
13:47:26.102 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-261
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.102 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-261] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.102 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-261] Instantiated an idempotent producer.
13:47:26.102 [kafka-producer-network-thread | producer-260] INFO Metadata - [Producer clientId=producer-260] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.103 [kafka-producer-network-thread | producer-260] INFO TransactionManager - [Producer clientId=producer-260] ProducerId set to 12451 with epoch 0
13:47:26.104 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.104 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.104 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.104 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046104
13:47:26.104 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-262
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.105 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-262] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.105 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-262] Instantiated an idempotent producer.
13:47:26.105 [kafka-producer-network-thread | producer-261] INFO Metadata - [Producer clientId=producer-261] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.106 [kafka-producer-network-thread | producer-261] INFO TransactionManager - [Producer clientId=producer-261] ProducerId set to 12453 with epoch 0
13:47:26.107 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.107 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.107 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.107 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046107
13:47:26.107 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-263
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.108 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-263] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.108 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-263] Instantiated an idempotent producer.
13:47:26.108 [kafka-producer-network-thread | producer-262] INFO Metadata - [Producer clientId=producer-262] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.108 [kafka-producer-network-thread | producer-262] INFO TransactionManager - [Producer clientId=producer-262] ProducerId set to 13464 with epoch 0
13:47:26.109 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.109 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.109 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.109 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046109
13:47:26.110 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-264
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.110 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-264] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.110 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-264] Instantiated an idempotent producer.
13:47:26.111 [kafka-producer-network-thread | producer-263] INFO Metadata - [Producer clientId=producer-263] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.111 [kafka-producer-network-thread | producer-263] INFO TransactionManager - [Producer clientId=producer-263] ProducerId set to 13466 with epoch 0
13:47:26.112 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.112 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.112 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.112 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046112
13:47:26.112 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-265
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.113 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-265] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.113 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-265] Instantiated an idempotent producer.
13:47:26.114 [kafka-producer-network-thread | producer-264] INFO Metadata - [Producer clientId=producer-264] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.114 [kafka-producer-network-thread | producer-264] INFO TransactionManager - [Producer clientId=producer-264] ProducerId set to 13467 with epoch 0
13:47:26.115 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.115 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.115 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.115 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046115
13:47:26.115 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-266
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.116 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-266] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.116 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-266] Instantiated an idempotent producer.
13:47:26.116 [kafka-producer-network-thread | producer-265] INFO Metadata - [Producer clientId=producer-265] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.117 [kafka-producer-network-thread | producer-265] INFO TransactionManager - [Producer clientId=producer-265] ProducerId set to 14373 with epoch 0
13:47:26.117 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.117 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.118 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.118 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046117
13:47:26.118 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-267
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.119 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-267] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.119 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-267] Instantiated an idempotent producer.
13:47:26.119 [kafka-producer-network-thread | producer-266] INFO Metadata - [Producer clientId=producer-266] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.119 [kafka-producer-network-thread | producer-266] INFO TransactionManager - [Producer clientId=producer-266] ProducerId set to 12457 with epoch 0
13:47:26.120 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.120 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.120 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.120 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046120
13:47:26.121 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-268
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.122 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-268] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.122 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-268] Instantiated an idempotent producer.
13:47:26.122 [kafka-producer-network-thread | producer-267] INFO Metadata - [Producer clientId=producer-267] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.122 [kafka-producer-network-thread | producer-267] INFO TransactionManager - [Producer clientId=producer-267] ProducerId set to 13469 with epoch 0
13:47:26.123 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.123 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.123 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.123 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046123
13:47:26.124 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-269
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.124 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-269] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.124 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-269] Instantiated an idempotent producer.
13:47:26.125 [kafka-producer-network-thread | producer-268] INFO Metadata - [Producer clientId=producer-268] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.125 [kafka-producer-network-thread | producer-268] INFO TransactionManager - [Producer clientId=producer-268] ProducerId set to 14377 with epoch 0
13:47:26.126 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.126 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.126 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.126 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046126
13:47:26.126 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-270
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.127 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-270] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.127 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-270] Instantiated an idempotent producer.
13:47:26.128 [kafka-producer-network-thread | producer-269] INFO Metadata - [Producer clientId=producer-269] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.128 [kafka-producer-network-thread | producer-269] INFO TransactionManager - [Producer clientId=producer-269] ProducerId set to 14378 with epoch 0
13:47:26.129 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.129 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.129 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.129 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046129
13:47:26.129 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-271
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.129 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-271] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.129 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-271] Instantiated an idempotent producer.
13:47:26.130 [kafka-producer-network-thread | producer-270] INFO Metadata - [Producer clientId=producer-270] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.130 [kafka-producer-network-thread | producer-270] INFO TransactionManager - [Producer clientId=producer-270] ProducerId set to 12460 with epoch 0
13:47:26.131 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.131 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.131 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.131 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046131
13:47:26.131 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-272
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.132 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-272] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.132 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-272] Instantiated an idempotent producer.
13:47:26.132 [kafka-producer-network-thread | producer-271] INFO Metadata - [Producer clientId=producer-271] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.132 [kafka-producer-network-thread | producer-271] INFO TransactionManager - [Producer clientId=producer-271] ProducerId set to 13470 with epoch 0
13:47:26.133 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.133 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.133 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.133 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046133
13:47:26.134 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-273
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.135 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-273] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.135 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-273] Instantiated an idempotent producer.
13:47:26.135 [kafka-producer-network-thread | producer-272] INFO Metadata - [Producer clientId=producer-272] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.135 [kafka-producer-network-thread | producer-272] INFO TransactionManager - [Producer clientId=producer-272] ProducerId set to 13471 with epoch 0
13:47:26.136 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.136 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.136 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.136 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046136
13:47:26.137 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-274
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.137 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-274] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.137 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-274] Instantiated an idempotent producer.
13:47:26.138 [kafka-producer-network-thread | producer-273] INFO Metadata - [Producer clientId=producer-273] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.138 [kafka-producer-network-thread | producer-273] INFO TransactionManager - [Producer clientId=producer-273] ProducerId set to 12463 with epoch 0
13:47:26.139 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.139 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.139 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.139 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046139
13:47:26.139 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-275
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.140 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-275] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.140 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-275] Instantiated an idempotent producer.
13:47:26.140 [kafka-producer-network-thread | producer-274] INFO Metadata - [Producer clientId=producer-274] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.140 [kafka-producer-network-thread | producer-274] INFO TransactionManager - [Producer clientId=producer-274] ProducerId set to 12464 with epoch 0
13:47:26.155 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.155 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.155 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.155 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046155
13:47:26.155 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-276
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.156 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-276] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.156 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-276] Instantiated an idempotent producer.
13:47:26.157 [kafka-producer-network-thread | producer-275] INFO Metadata - [Producer clientId=producer-275] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.157 [kafka-producer-network-thread | producer-275] INFO TransactionManager - [Producer clientId=producer-275] ProducerId set to 14385 with epoch 0
13:47:26.158 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.158 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.158 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.158 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046158
13:47:26.158 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-277
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.159 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-277] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.159 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-277] Instantiated an idempotent producer.
13:47:26.159 [kafka-producer-network-thread | producer-276] INFO Metadata - [Producer clientId=producer-276] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.159 [kafka-producer-network-thread | producer-276] INFO TransactionManager - [Producer clientId=producer-276] ProducerId set to 13475 with epoch 0
13:47:26.160 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.160 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.160 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.160 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046160
13:47:26.161 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-278
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.161 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-278] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.161 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-278] Instantiated an idempotent producer.
13:47:26.161 [kafka-producer-network-thread | producer-277] INFO Metadata - [Producer clientId=producer-277] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.162 [kafka-producer-network-thread | producer-277] INFO TransactionManager - [Producer clientId=producer-277] ProducerId set to 14386 with epoch 0
13:47:26.162 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.163 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.163 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.163 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046163
13:47:26.163 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-279
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.164 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-279] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.164 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-279] Instantiated an idempotent producer.
13:47:26.164 [kafka-producer-network-thread | producer-278] INFO Metadata - [Producer clientId=producer-278] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.164 [kafka-producer-network-thread | producer-278] INFO TransactionManager - [Producer clientId=producer-278] ProducerId set to 14387 with epoch 0
13:47:26.165 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.165 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.165 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.165 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046165
13:47:26.165 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-280
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.166 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-280] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.166 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-280] Instantiated an idempotent producer.
13:47:26.167 [kafka-producer-network-thread | producer-279] INFO Metadata - [Producer clientId=producer-279] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.167 [kafka-producer-network-thread | producer-279] INFO TransactionManager - [Producer clientId=producer-279] ProducerId set to 14388 with epoch 0
13:47:26.168 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.168 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.168 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.168 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046168
13:47:26.168 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-281
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.169 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-281] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.169 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-281] Instantiated an idempotent producer.
13:47:26.169 [kafka-producer-network-thread | producer-280] INFO Metadata - [Producer clientId=producer-280] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.169 [kafka-producer-network-thread | producer-280] INFO TransactionManager - [Producer clientId=producer-280] ProducerId set to 14389 with epoch 0
13:47:26.170 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.170 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.170 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.170 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046170
13:47:26.171 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-282
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.171 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-282] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.171 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-282] Instantiated an idempotent producer.
13:47:26.172 [kafka-producer-network-thread | producer-281] INFO Metadata - [Producer clientId=producer-281] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.172 [kafka-producer-network-thread | producer-281] INFO TransactionManager - [Producer clientId=producer-281] ProducerId set to 14392 with epoch 0
13:47:26.174 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.175 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.175 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.175 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046174
13:47:26.175 [kafka-producer-network-thread | producer-282] INFO Metadata - [Producer clientId=producer-282] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.175 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-283
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.175 [kafka-producer-network-thread | producer-282] INFO TransactionManager - [Producer clientId=producer-282] ProducerId set to 14393 with epoch 0
13:47:26.176 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-283] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.176 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-283] Instantiated an idempotent producer.
13:47:26.177 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.178 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.178 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.178 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046178
13:47:26.178 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-284
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.178 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-284] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.179 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-284] Instantiated an idempotent producer.
13:47:26.179 [kafka-producer-network-thread | producer-283] INFO Metadata - [Producer clientId=producer-283] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.179 [kafka-producer-network-thread | producer-283] INFO TransactionManager - [Producer clientId=producer-283] ProducerId set to 14394 with epoch 0
13:47:26.180 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.180 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.180 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.180 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046180
13:47:26.181 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-285
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.181 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-285] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.181 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-285] Instantiated an idempotent producer.
13:47:26.182 [kafka-producer-network-thread | producer-284] INFO Metadata - [Producer clientId=producer-284] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.182 [kafka-producer-network-thread | producer-284] INFO TransactionManager - [Producer clientId=producer-284] ProducerId set to 14395 with epoch 0
13:47:26.183 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.183 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.183 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.183 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046183
13:47:26.184 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-286
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.184 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-286] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.184 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-286] Instantiated an idempotent producer.
13:47:26.185 [kafka-producer-network-thread | producer-285] INFO Metadata - [Producer clientId=producer-285] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.185 [kafka-producer-network-thread | producer-285] INFO TransactionManager - [Producer clientId=producer-285] ProducerId set to 14396 with epoch 0
13:47:26.186 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.186 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.186 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.186 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046186
13:47:26.186 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-287
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.187 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-287] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.187 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-287] Instantiated an idempotent producer.
13:47:26.187 [kafka-producer-network-thread | producer-286] INFO Metadata - [Producer clientId=producer-286] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.187 [kafka-producer-network-thread | producer-286] INFO TransactionManager - [Producer clientId=producer-286] ProducerId set to 13482 with epoch 0
13:47:26.188 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.188 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.188 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.188 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046188
13:47:26.189 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-288
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.189 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-288] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.189 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-288] Instantiated an idempotent producer.
13:47:26.190 [kafka-producer-network-thread | producer-287] INFO Metadata - [Producer clientId=producer-287] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.190 [kafka-producer-network-thread | producer-287] INFO TransactionManager - [Producer clientId=producer-287] ProducerId set to 14398 with epoch 0
13:47:26.191 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.191 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.191 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.191 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046191
13:47:26.191 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-289
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.192 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-289] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.192 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-289] Instantiated an idempotent producer.
13:47:26.192 [kafka-producer-network-thread | producer-288] INFO Metadata - [Producer clientId=producer-288] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.192 [kafka-producer-network-thread | producer-288] INFO TransactionManager - [Producer clientId=producer-288] ProducerId set to 14399 with epoch 0
13:47:26.193 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.193 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.193 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.193 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046193
13:47:26.194 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-290
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.194 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-290] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.194 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-290] Instantiated an idempotent producer.
13:47:26.195 [kafka-producer-network-thread | producer-289] INFO Metadata - [Producer clientId=producer-289] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.195 [kafka-producer-network-thread | producer-289] INFO TransactionManager - [Producer clientId=producer-289] ProducerId set to 12481 with epoch 0
13:47:26.196 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.196 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.196 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.196 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046196
13:47:26.196 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-291
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.197 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-291] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.197 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-291] Instantiated an idempotent producer.
13:47:26.197 [kafka-producer-network-thread | producer-290] INFO Metadata - [Producer clientId=producer-290] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.197 [kafka-producer-network-thread | producer-290] INFO TransactionManager - [Producer clientId=producer-290] ProducerId set to 14403 with epoch 0
13:47:26.198 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.198 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.198 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.198 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046198
13:47:26.199 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-292
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.199 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-292] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.199 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-292] Instantiated an idempotent producer.
13:47:26.199 [kafka-producer-network-thread | producer-291] INFO Metadata - [Producer clientId=producer-291] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.200 [kafka-producer-network-thread | producer-291] INFO TransactionManager - [Producer clientId=producer-291] ProducerId set to 14405 with epoch 0
13:47:26.200 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.201 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.201 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.201 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046200
13:47:26.201 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-293
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.201 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-293] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.202 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-293] Instantiated an idempotent producer.
13:47:26.202 [kafka-producer-network-thread | producer-292] INFO Metadata - [Producer clientId=producer-292] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.202 [kafka-producer-network-thread | producer-292] INFO TransactionManager - [Producer clientId=producer-292] ProducerId set to 12485 with epoch 0
13:47:26.203 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.203 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.203 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.203 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046203
13:47:26.203 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-294
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.204 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-294] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.204 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-294] Instantiated an idempotent producer.
13:47:26.205 [kafka-producer-network-thread | producer-293] INFO Metadata - [Producer clientId=producer-293] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.205 [kafka-producer-network-thread | producer-293] INFO TransactionManager - [Producer clientId=producer-293] ProducerId set to 12487 with epoch 0
13:47:26.206 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.206 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.206 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.206 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046206
13:47:26.206 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-295
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.206 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-295] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.206 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-295] Instantiated an idempotent producer.
13:47:26.207 [kafka-producer-network-thread | producer-294] INFO Metadata - [Producer clientId=producer-294] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.207 [kafka-producer-network-thread | producer-294] INFO TransactionManager - [Producer clientId=producer-294] ProducerId set to 13485 with epoch 0
13:47:26.208 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.208 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.208 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.208 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046208
13:47:26.208 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-296
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.209 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-296] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.209 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-296] Instantiated an idempotent producer.
13:47:26.210 [kafka-producer-network-thread | producer-295] INFO Metadata - [Producer clientId=producer-295] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.210 [kafka-producer-network-thread | producer-295] INFO TransactionManager - [Producer clientId=producer-295] ProducerId set to 12488 with epoch 0
13:47:26.210 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.210 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.211 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.211 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046210
13:47:26.211 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-297
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.212 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-297] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.212 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-297] Instantiated an idempotent producer.
13:47:26.212 [kafka-producer-network-thread | producer-296] INFO Metadata - [Producer clientId=producer-296] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.212 [kafka-producer-network-thread | producer-296] INFO TransactionManager - [Producer clientId=producer-296] ProducerId set to 13488 with epoch 0
13:47:26.213 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.213 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.213 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.213 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046213
13:47:26.214 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-298
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.214 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-298] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.214 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-298] Instantiated an idempotent producer.
13:47:26.215 [kafka-producer-network-thread | producer-297] INFO Metadata - [Producer clientId=producer-297] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.215 [kafka-producer-network-thread | producer-297] INFO TransactionManager - [Producer clientId=producer-297] ProducerId set to 14409 with epoch 0
13:47:26.216 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.216 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.216 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.216 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046216
13:47:26.216 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-299
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.217 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-299] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.217 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-299] Instantiated an idempotent producer.
13:47:26.217 [kafka-producer-network-thread | producer-298] INFO Metadata - [Producer clientId=producer-298] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.218 [kafka-producer-network-thread | producer-298] INFO TransactionManager - [Producer clientId=producer-298] ProducerId set to 13491 with epoch 0
13:47:26.218 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.218 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.218 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.219 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046218
13:47:26.219 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-300
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.220 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-300] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.220 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-300] Instantiated an idempotent producer.
13:47:26.220 [kafka-producer-network-thread | producer-299] INFO Metadata - [Producer clientId=producer-299] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.220 [kafka-producer-network-thread | producer-299] INFO TransactionManager - [Producer clientId=producer-299] ProducerId set to 13494 with epoch 0
13:47:26.221 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.221 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.221 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.221 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046221
13:47:26.222 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-301
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.222 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-301] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.222 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-301] Instantiated an idempotent producer.
13:47:26.222 [kafka-producer-network-thread | producer-300] INFO Metadata - [Producer clientId=producer-300] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.223 [kafka-producer-network-thread | producer-300] INFO TransactionManager - [Producer clientId=producer-300] ProducerId set to 14411 with epoch 0
13:47:26.223 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.224 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.224 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.224 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046223
13:47:26.224 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-302
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.224 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-302] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.224 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-302] Instantiated an idempotent producer.
13:47:26.225 [kafka-producer-network-thread | producer-301] INFO Metadata - [Producer clientId=producer-301] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.225 [kafka-producer-network-thread | producer-301] INFO TransactionManager - [Producer clientId=producer-301] ProducerId set to 12492 with epoch 0
13:47:26.226 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.226 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.226 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.226 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046226
13:47:26.226 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-303
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.226 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-303] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.227 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-303] Instantiated an idempotent producer.
13:47:26.227 [kafka-producer-network-thread | producer-302] INFO Metadata - [Producer clientId=producer-302] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.227 [kafka-producer-network-thread | producer-302] INFO TransactionManager - [Producer clientId=producer-302] ProducerId set to 13496 with epoch 0
13:47:26.228 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.228 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.228 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.228 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046228
13:47:26.228 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-304
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.229 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-304] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.229 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-304] Instantiated an idempotent producer.
13:47:26.230 [kafka-producer-network-thread | producer-303] INFO Metadata - [Producer clientId=producer-303] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.230 [kafka-producer-network-thread | producer-303] INFO TransactionManager - [Producer clientId=producer-303] ProducerId set to 12495 with epoch 0
13:47:26.231 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.231 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.231 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.231 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046231
13:47:26.231 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-305
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.232 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-305] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.232 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-305] Instantiated an idempotent producer.
13:47:26.232 [kafka-producer-network-thread | producer-304] INFO Metadata - [Producer clientId=producer-304] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.233 [kafka-producer-network-thread | producer-304] INFO TransactionManager - [Producer clientId=producer-304] ProducerId set to 14414 with epoch 0
13:47:26.233 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.233 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.233 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.233 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046233
13:47:26.234 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-306
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.234 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-306] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.234 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-306] Instantiated an idempotent producer.
13:47:26.235 [kafka-producer-network-thread | producer-305] INFO Metadata - [Producer clientId=producer-305] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.235 [kafka-producer-network-thread | producer-305] INFO TransactionManager - [Producer clientId=producer-305] ProducerId set to 12499 with epoch 0
13:47:26.236 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.236 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.236 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.236 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046236
13:47:26.236 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-307
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.237 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-307] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.237 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-307] Instantiated an idempotent producer.
13:47:26.237 [kafka-producer-network-thread | producer-306] INFO Metadata - [Producer clientId=producer-306] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.237 [kafka-producer-network-thread | producer-306] INFO TransactionManager - [Producer clientId=producer-306] ProducerId set to 12501 with epoch 0
13:47:26.238 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.238 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.238 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.238 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046238
13:47:26.238 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-308
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.239 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-308] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.239 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-308] Instantiated an idempotent producer.
13:47:26.239 [kafka-producer-network-thread | producer-307] INFO Metadata - [Producer clientId=producer-307] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.240 [kafka-producer-network-thread | producer-307] INFO TransactionManager - [Producer clientId=producer-307] ProducerId set to 14415 with epoch 0
13:47:26.240 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.240 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.240 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.240 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046240
13:47:26.241 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-309
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.241 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-309] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.241 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-309] Instantiated an idempotent producer.
13:47:26.242 [kafka-producer-network-thread | producer-308] INFO Metadata - [Producer clientId=producer-308] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.242 [kafka-producer-network-thread | producer-308] INFO TransactionManager - [Producer clientId=producer-308] ProducerId set to 13499 with epoch 0
13:47:26.242 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.243 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.243 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.243 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046242
13:47:26.244 [kafka-producer-network-thread | producer-309] INFO Metadata - [Producer clientId=producer-309] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.244 [kafka-producer-network-thread | producer-309] INFO TransactionManager - [Producer clientId=producer-309] ProducerId set to 13500 with epoch 0
13:47:26.247 [qtp435803541-28] INFO LocalWorker - Created 309 producers in 1001.529161 ms from {
  "topics" : [ "test-topic-0000000-FGdYwL4", "test-topic-0000001-8XkVdYY", "test-topic-0000002-AnoRVV8", "test-topic-0000003-KFfayTM", "test-topic-0000004-20ZHReU", "test-topic-0000005-z0C2FwA", "test-topic-0000006-c-q-i_g", "test-topic-0000007-0MzD9Ik", "test-topic-0000008-0nz4Z_4", "test-topic-0000009-AqQ2Zlw", "test-topic-0000010-NyjSQ9A", "test-topic-0000011-zxqm4Mw", "test-topic-0000012-YCyXSbE", "test-topic-0000013-FjDWcwQ", "test-topic-0000014-CFLlGHs", "test-topic-0000015-URbXFF4", "test-topic-0000016-sZJ3Jho", "test-topic-0000017--qoxjPU", "test-topic-0000018-o_iMPj4", "test-topic-0000019-KoBZyHg", "test-topic-0000020-M_uOt0w", "test-topic-0000021-g1wDjUE", "test-topic-0000022-SNsKA5U", "test-topic-0000023-UFWJKKU", "test-topic-0000024-G8RFGsk", "test-topic-0000025-6uZz340", "test-topic-0000026-PbTraa0", "test-topic-0000027-Xa_RnUU", "test-topic-0000028-3nLVSQs", "test-topic-0000029-Sq99nJQ", "test-topic-0000030-SxXiKuo", "test-topic-0000031-DjUOkAw", "test-topic-0000032-uNikqf8", "test-topic-0000033-I9YklqI", "test-topic-0000034-P1Rw2WM", "test-topic-0000035-xhp6_oA", "test-topic-0000036-KEdU3IU", "test-topic-0000037-2r-FtRk", "test-topic-0000038-aoczOmE", "test-topic-0000039-DLNOGX4", "test-topic-0000040-ctRrJ_E", "test-topic-0000041-Ni38W-8", "test-topic-0000042-IpLh0uQ", "test-topic-0000043-CI9z7bU", "test-topic-0000044-HLDd740", "test-topic-0000045-5ePkOy4", "test-topic-0000046-P0FMkh4", "test-topic-0000047-Ci_iHCk", "test-topic-0000048-cYfObxU", "test-topic-0000049-9ea7a3Q", "test-topic-0000050-n3f7BfU", "test-topic-0000051-A0OfkLI", "test-topic-0000052-AfpVojk", "test-topic-0000053-Wz-ZTHE", "test-topic-0000054-omow84U", "test-topic-0000055-C3trC3o", "test-topic-0000056-Hx4phh4", "test-topic-0000057-b1ROO2s", "test-topic-0000058-ru5jUZw", "test-topic-0000059-2eeNhoM", "test-topic-0000060-YhVhRN4", "test-topic-0000061-btSl6bw", "test-topic-0000062-rNORlD0", "test-topic-0000063-TutZTB8", "test-topic-0000064-JLHPfAM", "test-topic-0000065-9yyIq1M", "test-topic-0000066-iVHj7R4", "test-topic-0000067-6rhS1nY", "test-topic-0000068-BieU9RA", "test-topic-0000069-j5MG-i8", "test-topic-0000070-toSKqSk", "test-topic-0000071-VWYOjwM", "test-topic-0000072-atXhL_g", "test-topic-0000073-HZ6O7Og", "test-topic-0000074-qfrgGP4", "test-topic-0000075-2Is6uhc", "test-topic-0000076-9xcr8KU", "test-topic-0000077-bmvIbiY", "test-topic-0000078-Wk4biHA", "test-topic-0000079-4XRk71U", "test-topic-0000080-GSwinHI", "test-topic-0000081-slvhhyc", "test-topic-0000082-x9QjlwQ", "test-topic-0000083-g-BmxjQ", "test-topic-0000084-fyVCbbE", "test-topic-0000085-_VhFHj0", "test-topic-0000086-cFlu7XU", "test-topic-0000087-81GfjoE", "test-topic-0000088-m_LR2ic", "test-topic-0000089-x68IQU4", "test-topic-0000090-2-rWqDI", "test-topic-0000091-DPFMLNo", "test-topic-0000092-JXGTSos", "test-topic-0000093-bXeEJlM", "test-topic-0000094-EbfdF94", "test-topic-0000095-zPq6gTM", "test-topic-0000096-mZKQCwo", "test-topic-0000097-rYrnvdk", "test-topic-0000098-H_jRR9A", "test-topic-0000099-1cEYHFU", "test-topic-0000100-tJC42sY", "test-topic-0000101-LhC-54M", "test-topic-0000102-l_C9r5E", "test-topic-0000103-7T4hNlo", "test-topic-0000104--zE_tVI", "test-topic-0000105-9pKxJ4U", "test-topic-0000106-DPglyWA", "test-topic-0000107-fjH0hDM", "test-topic-0000108-NB7wiDg", "test-topic-0000109-8qoD6Cs", "test-topic-0000110-mZfst7E", "test-topic-0000111-F9DCrSI", "test-topic-0000112-6kLoZnM", "test-topic-0000113-cTWFNVA", "test-topic-0000114-W7btOqk", "test-topic-0000115-6QgytUA", "test-topic-0000116-7UdnOfU", "test-topic-0000117-qR0MMec", "test-topic-0000118-8tUi_6Q", "test-topic-0000119-SlKUM_g", "test-topic-0000120-0BOroSI", "test-topic-0000121-MbWpUXY", "test-topic-0000122-BF9iF7A", "test-topic-0000123-NQtdm4o", "test-topic-0000124-amAHj1M", "test-topic-0000125-hZwj-ZY", "test-topic-0000126-uv0Lyw8", "test-topic-0000127-yWtvaYk", "test-topic-0000128-VV-rVFU", "test-topic-0000129-hjtxynQ", "test-topic-0000130-Qg40Jrk", "test-topic-0000131-xgUrqV0", "test-topic-0000132-cm7Hf-c", "test-topic-0000133-98k_qFM", "test-topic-0000134-Sxkgttc", "test-topic-0000135-E9VX0MI", "test-topic-0000136-Y9wEdEA", "test-topic-0000137-Aei-Pwg", "test-topic-0000138-jGAmpUk", "test-topic-0000139-OuBTmUg", "test-topic-0000140-EL2B4IY", "test-topic-0000141-sMY3in0", "test-topic-0000142-PXtC-SI", "test-topic-0000143-6mgkLNE", "test-topic-0000144-I87Cc1c", "test-topic-0000145-c-Awvi4", "test-topic-0000146-mwLxECY", "test-topic-0000147-daxMmRU", "test-topic-0000148-jGtN0UQ", "test-topic-0000149-oEEgv68", "test-topic-0000150-aU4kmlM", "test-topic-0000151-TzSMYyE", "test-topic-0000152-_ZPbr1E", "test-topic-0000153-7WDuOCQ", "test-topic-0000154-akFkJ1U", "test-topic-0000155-lbbml9M", "test-topic-0000156-bv1bM3c", "test-topic-0000157--IfLOsc", "test-topic-0000158-6CVrNxA", "test-topic-0000159-g4aXvWA", "test-topic-0000160-mjkwCiM", "test-topic-0000161-wcsZU2U", "test-topic-0000162-MJrR-xo", "test-topic-0000163-_ZTSuc8", "test-topic-0000164-gepakbQ", "test-topic-0000165-K5Vt5OE", "test-topic-0000166-FI2baz0", "test-topic-0000167-BwF1nXw", "test-topic-0000168-5AaQRwA", "test-topic-0000169-frnmqbA", "test-topic-0000170-Z0q4Nvo", "test-topic-0000171-TTgHNZY", "test-topic-0000172-zC5ZI88", "test-topic-0000173-6CJkJ1w", "test-topic-0000174-hJfH_wE", "test-topic-0000175-nKeyHaA", "test-topic-0000176-BBDA9F8", "test-topic-0000177-9whUEAI", "test-topic-0000178-yN-12bs", "test-topic-0000179-Z_sMFPQ", "test-topic-0000180-mtow198", "test-topic-0000181-ILkihtM", "test-topic-0000182-FHEBZ8A", "test-topic-0000183-Q_DaKzs", "test-topic-0000184-YsWG3PQ", "test-topic-0000185-PO-JbZY", "test-topic-0000186-TMi6IGE", "test-topic-0000187-a7MsovY", "test-topic-0000188-c6J0hjY", "test-topic-0000189-Br5CACQ", "test-topic-0000190-2u2ROx8", "test-topic-0000191-PNN1Bfk", "test-topic-0000192-qIO7V7Q", "test-topic-0000193-ngfcLus", "test-topic-0000194-K-KCWTE", "test-topic-0000195-ur-Cgeo", "test-topic-0000196-IG_hwmw", "test-topic-0000197-CIa3XGw", "test-topic-0000198-MRrztgM", "test-topic-0000199-CtttN8Y", "test-topic-0000200-viNaANQ", "test-topic-0000201-rmNvfr4", "test-topic-0000202-3wtSyrE", "test-topic-0000203-9hn2q10", "test-topic-0000204-qe1T4lQ", "test-topic-0000205-2mMmqQg", "test-topic-0000206-sMqOXZA", "test-topic-0000207-bDTZgNE", "test-topic-0000208-zYqakMk", "test-topic-0000209-PZuErwo", "test-topic-0000210-IbT0AKY", "test-topic-0000211-_2UT4Bs", "test-topic-0000212-WR9CMwQ", "test-topic-0000213-a7hif5U", "test-topic-0000214-MyxBVy0", "test-topic-0000215-Zb4mOoY", "test-topic-0000216-PzoM90k", "test-topic-0000217-XNxlkQ4", "test-topic-0000218-6mkEIxQ", "test-topic-0000219-9wHMOjI", "test-topic-0000220-uOm4gtE", "test-topic-0000221-7QIO4vA", "test-topic-0000222-0FOfLX4", "test-topic-0000223-NBqvIZI", "test-topic-0000224-vd-16Eg", "test-topic-0000225-Xfv4mUc", "test-topic-0000226-cmxwGEA", "test-topic-0000227-PhYZ_-4", "test-topic-0000228-j6bdXE8", "test-topic-0000229-0fBbwTU", "test-topic-0000230-4s4B6Wc", "test-topic-0000231-W7upruI", "test-topic-0000232-L-U4evs", "test-topic-0000233-0IL1GHA", "test-topic-0000234-MztKqbA", "test-topic-0000235-daWCzN0", "test-topic-0000236-5rPzsFQ", "test-topic-0000237-x236eMI", "test-topic-0000238-ATNTxQ8", "test-topic-0000239-m_eFS6M", "test-topic-0000240-vwD5iNc", "test-topic-0000241-hsO-5Ig", "test-topic-0000242-5iXW5yk", "test-topic-0000243-fpyKxcw", "test-topic-0000244-CATmwfU", "test-topic-0000245-wLMd2DQ", "test-topic-0000246-Bq6i99k", "test-topic-0000247-9BaoGEM", "test-topic-0000248-1cRH_ZI", "test-topic-0000249-j-ThMcs", "test-topic-0000250-hNzff68", "test-topic-0000251-eeL7Zsc", "test-topic-0000252-fa1UjIY", "test-topic-0000253-71qwhGg", "test-topic-0000254-CpZ6PWw", "test-topic-0000255-qWOKGG0", "test-topic-0000256-GzCULh8", "test-topic-0000257-P_M3hrc", "test-topic-0000258-Rv9SxIc", "test-topic-0000259-x2gdERw", "test-topic-0000260-DnsmC54", "test-topic-0000261-w2mnyns", "test-topic-0000262-Z_n6Lqs", "test-topic-0000263-OjpC5g8", "test-topic-0000264-eT2e8rU", "test-topic-0000265-JPOr-Ag", "test-topic-0000266-pK4XlDY", "test-topic-0000267-CjvJg1c", "test-topic-0000268-xHueAw8", "test-topic-0000269-7mR6KMk", "test-topic-0000270-tS64jLw", "test-topic-0000271-ZxlpV1c", "test-topic-0000272-GXSuIMg", "test-topic-0000273-EO6kLrs", "test-topic-0000274-WBszb4M", "test-topic-0000275-I49nzkY", "test-topic-0000276-6JL1QfE", "test-topic-0000277-YF-_KfA", "test-topic-0000278-zWRdAgQ", "test-topic-0000279-M7JpqrA", "test-topic-0000280-Y3fRkQ4", "test-topic-0000281-FQQUyA4", "test-topic-0000282-WxYsVXA", "test-topic-0000283-MdXNdPY", "test-topic-0000284-Agh4b5c", "test-topic-0000285-SwrrYM0", "test-topic-0000286-yTITFyk", "test-topic-0000287-3fcwIsk", "test-topic-0000288-AZcX53o", "test-topic-0000289-gnsmK30", "test-topic-0000290-5aCzRUQ", "test-topic-0000291-mMcByrM", "test-topic-0000292-3RYn65c", "test-topic-0000293-H8U0kX0", "test-topic-0000294-ASiqRA4", "test-topic-0000295-5y9DMI4", "test-topic-0000296-217YnkM", "test-topic-0000297-6tCb4MU", "test-topic-0000298-cXyRfIQ", "test-topic-0000299-9nrgwQo", "test-topic-0000300-gX_eTcY", "test-topic-0000301-j62eWV0", "test-topic-0000302-DlyJbtk", "test-topic-0000303-EgI1jiw" ],
  "producerIndex" : 1,
  "isTpcH" : true
}
13:47:26.813 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-002-6pJt9n8-1-8f788499-14a2-4388-a193-c64fc8e13a09', protocol='range'}
13:47:26.813 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-005-28wZdjg-2-f9a6918c-9f67-4719-84a9-d58993c8a686', protocol='range'}
13:47:26.815 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-008-5QZvSRw-3-809c9842-8f62-49bb-8c73-55c3e140cdfa', protocol='range'}
13:47:26.823 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Finished assignment for group at generation 1: {consumer-sub-002-6pJt9n8-1-8f788499-14a2-4388-a193-c64fc8e13a09=Assignment(partitions=[test-topic-0000002-AnoRVV8-0])}
13:47:26.823 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Finished assignment for group at generation 1: {consumer-sub-005-28wZdjg-2-f9a6918c-9f67-4719-84a9-d58993c8a686=Assignment(partitions=[test-topic-0000005-z0C2FwA-0])}
13:47:26.823 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Finished assignment for group at generation 1: {consumer-sub-008-5QZvSRw-3-809c9842-8f62-49bb-8c73-55c3e140cdfa=Assignment(partitions=[test-topic-0000008-0nz4Z_4-0])}
13:47:26.828 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-008-5QZvSRw-3-809c9842-8f62-49bb-8c73-55c3e140cdfa', protocol='range'}
13:47:26.828 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-002-6pJt9n8-1-8f788499-14a2-4388-a193-c64fc8e13a09', protocol='range'}
13:47:26.828 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-005-28wZdjg-2-f9a6918c-9f67-4719-84a9-d58993c8a686', protocol='range'}
13:47:26.828 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Notifying assignor about the new Assignment(partitions=[test-topic-0000008-0nz4Z_4-0])
13:47:26.829 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Notifying assignor about the new Assignment(partitions=[test-topic-0000002-AnoRVV8-0])
13:47:26.829 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Notifying assignor about the new Assignment(partitions=[test-topic-0000005-z0C2FwA-0])
13:47:26.829 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-011-vfzfH9A-4-731f88af-6d6e-4dc9-95e0-8ba82b799454', protocol='range'}
13:47:26.829 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Finished assignment for group at generation 1: {consumer-sub-011-vfzfH9A-4-731f88af-6d6e-4dc9-95e0-8ba82b799454=Assignment(partitions=[test-topic-0000011-zxqm4Mw-0])}
13:47:26.831 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-011-vfzfH9A-4-731f88af-6d6e-4dc9-95e0-8ba82b799454', protocol='range'}
13:47:26.831 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Notifying assignor about the new Assignment(partitions=[test-topic-0000011-zxqm4Mw-0])
13:47:26.831 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Adding newly assigned partitions: test-topic-0000011-zxqm4Mw-0
13:47:26.832 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Adding newly assigned partitions: test-topic-0000008-0nz4Z_4-0
13:47:26.832 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Adding newly assigned partitions: test-topic-0000005-z0C2FwA-0
13:47:26.832 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Adding newly assigned partitions: test-topic-0000002-AnoRVV8-0
13:47:26.839 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Found no committed offset for partition test-topic-0000011-zxqm4Mw-0
13:47:26.839 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Found no committed offset for partition test-topic-0000002-AnoRVV8-0
13:47:26.839 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Found no committed offset for partition test-topic-0000005-z0C2FwA-0
13:47:26.840 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Found no committed offset for partition test-topic-0000008-0nz4Z_4-0
13:47:26.844 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-014-h9wlUsU-5-3d5358a1-edfd-41bc-aee9-8883790397c3', protocol='range'}
13:47:26.844 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Finished assignment for group at generation 1: {consumer-sub-014-h9wlUsU-5-3d5358a1-edfd-41bc-aee9-8883790397c3=Assignment(partitions=[test-topic-0000014-CFLlGHs-0])}
13:47:26.846 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-014-h9wlUsU-5-3d5358a1-edfd-41bc-aee9-8883790397c3', protocol='range'}
13:47:26.846 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Notifying assignor about the new Assignment(partitions=[test-topic-0000014-CFLlGHs-0])
13:47:26.846 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Adding newly assigned partitions: test-topic-0000014-CFLlGHs-0
13:47:26.846 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Found no committed offset for partition test-topic-0000014-CFLlGHs-0
13:47:26.848 [pool-7-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-008-5QZvSRw-3, groupId=sub-008-5QZvSRw] Resetting offset for partition test-topic-0000008-0nz4Z_4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:26.848 [pool-9-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-014-h9wlUsU-5, groupId=sub-014-h9wlUsU] Resetting offset for partition test-topic-0000014-CFLlGHs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:26.848 [pool-8-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-011-vfzfH9A-4, groupId=sub-011-vfzfH9A] Resetting offset for partition test-topic-0000011-zxqm4Mw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.848 [pool-5-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-002-6pJt9n8-1, groupId=sub-002-6pJt9n8] Resetting offset for partition test-topic-0000002-AnoRVV8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.849 [pool-6-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-005-28wZdjg-2, groupId=sub-005-28wZdjg] Resetting offset for partition test-topic-0000005-z0C2FwA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.852 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-017-jJK44Wo-6-93ab2526-0b00-482f-8c38-ca651f8ccf3f', protocol='range'}
13:47:26.852 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Finished assignment for group at generation 1: {consumer-sub-017-jJK44Wo-6-93ab2526-0b00-482f-8c38-ca651f8ccf3f=Assignment(partitions=[test-topic-0000017--qoxjPU-0])}
13:47:26.854 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-017-jJK44Wo-6-93ab2526-0b00-482f-8c38-ca651f8ccf3f', protocol='range'}
13:47:26.854 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Notifying assignor about the new Assignment(partitions=[test-topic-0000017--qoxjPU-0])
13:47:26.854 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Adding newly assigned partitions: test-topic-0000017--qoxjPU-0
13:47:26.855 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Found no committed offset for partition test-topic-0000017--qoxjPU-0
13:47:26.857 [pool-10-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-017-jJK44Wo-6, groupId=sub-017-jJK44Wo] Resetting offset for partition test-topic-0000017--qoxjPU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.862 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-020-KL6yeeg-7-13ca6c0b-0792-40c1-bef6-77351eed41fc', protocol='range'}
13:47:26.862 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Finished assignment for group at generation 1: {consumer-sub-020-KL6yeeg-7-13ca6c0b-0792-40c1-bef6-77351eed41fc=Assignment(partitions=[test-topic-0000020-M_uOt0w-0])}
13:47:26.864 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-020-KL6yeeg-7-13ca6c0b-0792-40c1-bef6-77351eed41fc', protocol='range'}
13:47:26.864 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Notifying assignor about the new Assignment(partitions=[test-topic-0000020-M_uOt0w-0])
13:47:26.865 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Adding newly assigned partitions: test-topic-0000020-M_uOt0w-0
13:47:26.865 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Found no committed offset for partition test-topic-0000020-M_uOt0w-0
13:47:26.868 [pool-11-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-020-KL6yeeg-7, groupId=sub-020-KL6yeeg] Resetting offset for partition test-topic-0000020-M_uOt0w-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.869 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-023-Sc7rr-s-8-072fd039-3829-4bc4-8c10-0019c42e1cd7', protocol='range'}
13:47:26.869 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Finished assignment for group at generation 1: {consumer-sub-023-Sc7rr-s-8-072fd039-3829-4bc4-8c10-0019c42e1cd7=Assignment(partitions=[test-topic-0000023-UFWJKKU-0])}
13:47:26.871 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-023-Sc7rr-s-8-072fd039-3829-4bc4-8c10-0019c42e1cd7', protocol='range'}
13:47:26.871 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Notifying assignor about the new Assignment(partitions=[test-topic-0000023-UFWJKKU-0])
13:47:26.871 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Adding newly assigned partitions: test-topic-0000023-UFWJKKU-0
13:47:26.872 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Found no committed offset for partition test-topic-0000023-UFWJKKU-0
13:47:26.873 [pool-12-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-023-Sc7rr-s-8, groupId=sub-023-Sc7rr-s] Resetting offset for partition test-topic-0000023-UFWJKKU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.875 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-026-DpHAoCo-9-fdc1aea6-c633-422d-a7be-c6cac19b7539', protocol='range'}
13:47:26.875 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Finished assignment for group at generation 1: {consumer-sub-026-DpHAoCo-9-fdc1aea6-c633-422d-a7be-c6cac19b7539=Assignment(partitions=[test-topic-0000026-PbTraa0-0])}
13:47:26.877 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-026-DpHAoCo-9-fdc1aea6-c633-422d-a7be-c6cac19b7539', protocol='range'}
13:47:26.877 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Notifying assignor about the new Assignment(partitions=[test-topic-0000026-PbTraa0-0])
13:47:26.877 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Adding newly assigned partitions: test-topic-0000026-PbTraa0-0
13:47:26.878 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Found no committed offset for partition test-topic-0000026-PbTraa0-0
13:47:26.880 [pool-13-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-026-DpHAoCo-9, groupId=sub-026-DpHAoCo] Resetting offset for partition test-topic-0000026-PbTraa0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.881 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-029-YeUzVKw-10-5fd7da0d-6907-4a33-aa28-10a04f45587d', protocol='range'}
13:47:26.882 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Finished assignment for group at generation 1: {consumer-sub-029-YeUzVKw-10-5fd7da0d-6907-4a33-aa28-10a04f45587d=Assignment(partitions=[test-topic-0000029-Sq99nJQ-0])}
13:47:26.883 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-029-YeUzVKw-10-5fd7da0d-6907-4a33-aa28-10a04f45587d', protocol='range'}
13:47:26.884 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Notifying assignor about the new Assignment(partitions=[test-topic-0000029-Sq99nJQ-0])
13:47:26.884 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Adding newly assigned partitions: test-topic-0000029-Sq99nJQ-0
13:47:26.884 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Found no committed offset for partition test-topic-0000029-Sq99nJQ-0
13:47:26.886 [pool-14-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-029-YeUzVKw-10, groupId=sub-029-YeUzVKw] Resetting offset for partition test-topic-0000029-Sq99nJQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.888 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-032-r4YZhPU-11-c3c26292-31ca-412e-b76b-f5f492eecee7', protocol='range'}
13:47:26.889 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Finished assignment for group at generation 1: {consumer-sub-032-r4YZhPU-11-c3c26292-31ca-412e-b76b-f5f492eecee7=Assignment(partitions=[test-topic-0000032-uNikqf8-0])}
13:47:26.890 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-032-r4YZhPU-11-c3c26292-31ca-412e-b76b-f5f492eecee7', protocol='range'}
13:47:26.891 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Notifying assignor about the new Assignment(partitions=[test-topic-0000032-uNikqf8-0])
13:47:26.891 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Adding newly assigned partitions: test-topic-0000032-uNikqf8-0
13:47:26.891 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Found no committed offset for partition test-topic-0000032-uNikqf8-0
13:47:26.893 [pool-15-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-032-r4YZhPU-11, groupId=sub-032-r4YZhPU] Resetting offset for partition test-topic-0000032-uNikqf8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.895 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-035-AuoUT6k-12-6346eb87-995b-4970-a3c2-17bf0a4c3d3a', protocol='range'}
13:47:26.895 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Finished assignment for group at generation 1: {consumer-sub-035-AuoUT6k-12-6346eb87-995b-4970-a3c2-17bf0a4c3d3a=Assignment(partitions=[test-topic-0000035-xhp6_oA-0])}
13:47:26.897 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-035-AuoUT6k-12-6346eb87-995b-4970-a3c2-17bf0a4c3d3a', protocol='range'}
13:47:26.897 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Notifying assignor about the new Assignment(partitions=[test-topic-0000035-xhp6_oA-0])
13:47:26.897 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Adding newly assigned partitions: test-topic-0000035-xhp6_oA-0
13:47:26.898 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Found no committed offset for partition test-topic-0000035-xhp6_oA-0
13:47:26.899 [pool-16-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-035-AuoUT6k-12, groupId=sub-035-AuoUT6k] Resetting offset for partition test-topic-0000035-xhp6_oA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.907 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-038-KClQAEM-13-1cbadd5a-4333-4704-b9f2-c05078138e7f', protocol='range'}
13:47:26.907 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Finished assignment for group at generation 1: {consumer-sub-038-KClQAEM-13-1cbadd5a-4333-4704-b9f2-c05078138e7f=Assignment(partitions=[test-topic-0000038-aoczOmE-0])}
13:47:26.909 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-038-KClQAEM-13-1cbadd5a-4333-4704-b9f2-c05078138e7f', protocol='range'}
13:47:26.909 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Notifying assignor about the new Assignment(partitions=[test-topic-0000038-aoczOmE-0])
13:47:26.909 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Adding newly assigned partitions: test-topic-0000038-aoczOmE-0
13:47:26.909 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Found no committed offset for partition test-topic-0000038-aoczOmE-0
13:47:26.911 [pool-17-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-038-KClQAEM-13, groupId=sub-038-KClQAEM] Resetting offset for partition test-topic-0000038-aoczOmE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:26.912 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-041-t9PKIe0-14-2be82650-082f-41d9-8cb2-1cd13812d3d0', protocol='range'}
13:47:26.912 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Finished assignment for group at generation 1: {consumer-sub-041-t9PKIe0-14-2be82650-082f-41d9-8cb2-1cd13812d3d0=Assignment(partitions=[test-topic-0000041-Ni38W-8-0])}
13:47:26.914 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-041-t9PKIe0-14-2be82650-082f-41d9-8cb2-1cd13812d3d0', protocol='range'}
13:47:26.914 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Notifying assignor about the new Assignment(partitions=[test-topic-0000041-Ni38W-8-0])
13:47:26.914 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Adding newly assigned partitions: test-topic-0000041-Ni38W-8-0
13:47:26.915 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Found no committed offset for partition test-topic-0000041-Ni38W-8-0
13:47:26.916 [pool-18-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-041-t9PKIe0-14, groupId=sub-041-t9PKIe0] Resetting offset for partition test-topic-0000041-Ni38W-8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.917 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-044-_n5fOqk-15-e4c285eb-9dac-4772-9716-7e4c269a2559', protocol='range'}
13:47:26.917 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Finished assignment for group at generation 1: {consumer-sub-044-_n5fOqk-15-e4c285eb-9dac-4772-9716-7e4c269a2559=Assignment(partitions=[test-topic-0000044-HLDd740-0])}
13:47:26.919 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-044-_n5fOqk-15-e4c285eb-9dac-4772-9716-7e4c269a2559', protocol='range'}
13:47:26.919 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Notifying assignor about the new Assignment(partitions=[test-topic-0000044-HLDd740-0])
13:47:26.919 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Adding newly assigned partitions: test-topic-0000044-HLDd740-0
13:47:26.920 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Found no committed offset for partition test-topic-0000044-HLDd740-0
13:47:26.921 [pool-19-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-044-_n5fOqk-15, groupId=sub-044-_n5fOqk] Resetting offset for partition test-topic-0000044-HLDd740-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:26.924 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-047-S-X33T4-16-723b0863-9428-4ed3-80d4-3cc4aaac66dc', protocol='range'}
13:47:26.924 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Finished assignment for group at generation 1: {consumer-sub-047-S-X33T4-16-723b0863-9428-4ed3-80d4-3cc4aaac66dc=Assignment(partitions=[test-topic-0000047-Ci_iHCk-0])}
13:47:26.926 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-047-S-X33T4-16-723b0863-9428-4ed3-80d4-3cc4aaac66dc', protocol='range'}
13:47:26.926 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Notifying assignor about the new Assignment(partitions=[test-topic-0000047-Ci_iHCk-0])
13:47:26.926 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Adding newly assigned partitions: test-topic-0000047-Ci_iHCk-0
13:47:26.927 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Found no committed offset for partition test-topic-0000047-Ci_iHCk-0
13:47:26.929 [pool-20-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-047-S-X33T4-16, groupId=sub-047-S-X33T4] Resetting offset for partition test-topic-0000047-Ci_iHCk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.931 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-050-FKJ6dKc-17-f4444449-c6cc-41fd-b2f7-d8d9cb807620', protocol='range'}
13:47:26.932 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Finished assignment for group at generation 1: {consumer-sub-050-FKJ6dKc-17-f4444449-c6cc-41fd-b2f7-d8d9cb807620=Assignment(partitions=[test-topic-0000050-n3f7BfU-0])}
13:47:26.933 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-050-FKJ6dKc-17-f4444449-c6cc-41fd-b2f7-d8d9cb807620', protocol='range'}
13:47:26.933 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Notifying assignor about the new Assignment(partitions=[test-topic-0000050-n3f7BfU-0])
13:47:26.933 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Adding newly assigned partitions: test-topic-0000050-n3f7BfU-0
13:47:26.934 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Found no committed offset for partition test-topic-0000050-n3f7BfU-0
13:47:26.936 [pool-21-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-050-FKJ6dKc-17, groupId=sub-050-FKJ6dKc] Resetting offset for partition test-topic-0000050-n3f7BfU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:26.936 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-053-3OvowAU-18-cef1be47-bebe-4fce-94ff-75e10c0e7f5e', protocol='range'}
13:47:26.936 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Finished assignment for group at generation 1: {consumer-sub-053-3OvowAU-18-cef1be47-bebe-4fce-94ff-75e10c0e7f5e=Assignment(partitions=[test-topic-0000053-Wz-ZTHE-0])}
13:47:26.938 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-053-3OvowAU-18-cef1be47-bebe-4fce-94ff-75e10c0e7f5e', protocol='range'}
13:47:26.938 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Notifying assignor about the new Assignment(partitions=[test-topic-0000053-Wz-ZTHE-0])
13:47:26.938 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Adding newly assigned partitions: test-topic-0000053-Wz-ZTHE-0
13:47:26.939 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Found no committed offset for partition test-topic-0000053-Wz-ZTHE-0
13:47:26.940 [pool-22-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-053-3OvowAU-18, groupId=sub-053-3OvowAU] Resetting offset for partition test-topic-0000053-Wz-ZTHE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:26.944 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-056-7GWVmy8-19-a1266d37-a0a5-48b8-99c4-d5f7ff3095cf', protocol='range'}
13:47:26.944 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Finished assignment for group at generation 1: {consumer-sub-056-7GWVmy8-19-a1266d37-a0a5-48b8-99c4-d5f7ff3095cf=Assignment(partitions=[test-topic-0000056-Hx4phh4-0])}
13:47:26.945 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-056-7GWVmy8-19-a1266d37-a0a5-48b8-99c4-d5f7ff3095cf', protocol='range'}
13:47:26.945 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Notifying assignor about the new Assignment(partitions=[test-topic-0000056-Hx4phh4-0])
13:47:26.945 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Adding newly assigned partitions: test-topic-0000056-Hx4phh4-0
13:47:26.946 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Found no committed offset for partition test-topic-0000056-Hx4phh4-0
13:47:26.947 [pool-23-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-056-7GWVmy8-19, groupId=sub-056-7GWVmy8] Resetting offset for partition test-topic-0000056-Hx4phh4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.954 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-059-PRMMTYA-20-db584db0-06e0-4522-9aa3-90642c798f3a', protocol='range'}
13:47:26.954 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Finished assignment for group at generation 1: {consumer-sub-059-PRMMTYA-20-db584db0-06e0-4522-9aa3-90642c798f3a=Assignment(partitions=[test-topic-0000059-2eeNhoM-0])}
13:47:26.956 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-059-PRMMTYA-20-db584db0-06e0-4522-9aa3-90642c798f3a', protocol='range'}
13:47:26.956 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Notifying assignor about the new Assignment(partitions=[test-topic-0000059-2eeNhoM-0])
13:47:26.956 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Adding newly assigned partitions: test-topic-0000059-2eeNhoM-0
13:47:26.957 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Found no committed offset for partition test-topic-0000059-2eeNhoM-0
13:47:26.958 [pool-24-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-059-PRMMTYA-20, groupId=sub-059-PRMMTYA] Resetting offset for partition test-topic-0000059-2eeNhoM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.961 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-062-Ium84nQ-21-6139ed74-9428-4e7e-9b2c-76f7bdf47a35', protocol='range'}
13:47:26.961 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Finished assignment for group at generation 1: {consumer-sub-062-Ium84nQ-21-6139ed74-9428-4e7e-9b2c-76f7bdf47a35=Assignment(partitions=[test-topic-0000062-rNORlD0-0])}
13:47:26.963 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-062-Ium84nQ-21-6139ed74-9428-4e7e-9b2c-76f7bdf47a35', protocol='range'}
13:47:26.963 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000062-rNORlD0-0])
13:47:26.963 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Adding newly assigned partitions: test-topic-0000062-rNORlD0-0
13:47:26.964 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Found no committed offset for partition test-topic-0000062-rNORlD0-0
13:47:26.965 [pool-25-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-062-Ium84nQ-21, groupId=sub-062-Ium84nQ] Resetting offset for partition test-topic-0000062-rNORlD0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.966 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-065-kktaSis-22-bf46199c-0624-40e1-a557-7e63612e30a6', protocol='range'}
13:47:26.967 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Finished assignment for group at generation 1: {consumer-sub-065-kktaSis-22-bf46199c-0624-40e1-a557-7e63612e30a6=Assignment(partitions=[test-topic-0000065-9yyIq1M-0])}
13:47:26.968 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-065-kktaSis-22-bf46199c-0624-40e1-a557-7e63612e30a6', protocol='range'}
13:47:26.968 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Notifying assignor about the new Assignment(partitions=[test-topic-0000065-9yyIq1M-0])
13:47:26.968 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Adding newly assigned partitions: test-topic-0000065-9yyIq1M-0
13:47:26.969 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Found no committed offset for partition test-topic-0000065-9yyIq1M-0
13:47:26.970 [pool-26-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-065-kktaSis-22, groupId=sub-065-kktaSis] Resetting offset for partition test-topic-0000065-9yyIq1M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:26.973 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-068-Ji5gaPU-23-19cd400e-e86e-4a31-ad36-22d481df0eac', protocol='range'}
13:47:26.973 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Finished assignment for group at generation 1: {consumer-sub-068-Ji5gaPU-23-19cd400e-e86e-4a31-ad36-22d481df0eac=Assignment(partitions=[test-topic-0000068-BieU9RA-0])}
13:47:26.975 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-068-Ji5gaPU-23-19cd400e-e86e-4a31-ad36-22d481df0eac', protocol='range'}
13:47:26.975 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Notifying assignor about the new Assignment(partitions=[test-topic-0000068-BieU9RA-0])
13:47:26.975 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Adding newly assigned partitions: test-topic-0000068-BieU9RA-0
13:47:26.976 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Found no committed offset for partition test-topic-0000068-BieU9RA-0
13:47:26.977 [pool-27-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-068-Ji5gaPU-23, groupId=sub-068-Ji5gaPU] Resetting offset for partition test-topic-0000068-BieU9RA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:26.978 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-071-J3wy12s-24-7063b7cc-7c03-4b1d-93b0-1b5c40bc9d8e', protocol='range'}
13:47:26.978 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Finished assignment for group at generation 1: {consumer-sub-071-J3wy12s-24-7063b7cc-7c03-4b1d-93b0-1b5c40bc9d8e=Assignment(partitions=[test-topic-0000071-VWYOjwM-0])}
13:47:26.980 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-071-J3wy12s-24-7063b7cc-7c03-4b1d-93b0-1b5c40bc9d8e', protocol='range'}
13:47:26.980 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Notifying assignor about the new Assignment(partitions=[test-topic-0000071-VWYOjwM-0])
13:47:26.980 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Adding newly assigned partitions: test-topic-0000071-VWYOjwM-0
13:47:26.981 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Found no committed offset for partition test-topic-0000071-VWYOjwM-0
13:47:26.982 [pool-28-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-071-J3wy12s-24, groupId=sub-071-J3wy12s] Resetting offset for partition test-topic-0000071-VWYOjwM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:26.986 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-074-OhduXsk-25-0ec884a4-c0d6-470e-a80f-c7c42181c0b4', protocol='range'}
13:47:26.986 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Finished assignment for group at generation 1: {consumer-sub-074-OhduXsk-25-0ec884a4-c0d6-470e-a80f-c7c42181c0b4=Assignment(partitions=[test-topic-0000074-qfrgGP4-0])}
13:47:26.988 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-074-OhduXsk-25-0ec884a4-c0d6-470e-a80f-c7c42181c0b4', protocol='range'}
13:47:26.988 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Notifying assignor about the new Assignment(partitions=[test-topic-0000074-qfrgGP4-0])
13:47:26.988 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Adding newly assigned partitions: test-topic-0000074-qfrgGP4-0
13:47:26.988 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Found no committed offset for partition test-topic-0000074-qfrgGP4-0
13:47:26.990 [pool-29-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-074-OhduXsk-25, groupId=sub-074-OhduXsk] Resetting offset for partition test-topic-0000074-qfrgGP4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.000 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-080-rGHvUyw-27-80ee91b0-74cf-4c1f-ba30-2e6c9b800f73', protocol='range'}
13:47:27.000 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-077-kf_A-30-26-7c2873bc-089a-4612-9357-4f122b95e2d0', protocol='range'}
13:47:27.000 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Finished assignment for group at generation 1: {consumer-sub-077-kf_A-30-26-7c2873bc-089a-4612-9357-4f122b95e2d0=Assignment(partitions=[test-topic-0000077-bmvIbiY-0])}
13:47:27.000 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Finished assignment for group at generation 1: {consumer-sub-080-rGHvUyw-27-80ee91b0-74cf-4c1f-ba30-2e6c9b800f73=Assignment(partitions=[test-topic-0000080-GSwinHI-0])}
13:47:27.002 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-077-kf_A-30-26-7c2873bc-089a-4612-9357-4f122b95e2d0', protocol='range'}
13:47:27.002 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-080-rGHvUyw-27-80ee91b0-74cf-4c1f-ba30-2e6c9b800f73', protocol='range'}
13:47:27.002 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Notifying assignor about the new Assignment(partitions=[test-topic-0000077-bmvIbiY-0])
13:47:27.002 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Notifying assignor about the new Assignment(partitions=[test-topic-0000080-GSwinHI-0])
13:47:27.002 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Adding newly assigned partitions: test-topic-0000077-bmvIbiY-0
13:47:27.002 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Adding newly assigned partitions: test-topic-0000080-GSwinHI-0
13:47:27.002 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Found no committed offset for partition test-topic-0000077-bmvIbiY-0
13:47:27.003 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Found no committed offset for partition test-topic-0000080-GSwinHI-0
13:47:27.004 [pool-31-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-080-rGHvUyw-27, groupId=sub-080-rGHvUyw] Resetting offset for partition test-topic-0000080-GSwinHI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.004 [pool-30-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-077-kf_A-30-26, groupId=sub-077-kf_A-30] Resetting offset for partition test-topic-0000077-bmvIbiY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.023 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-083-CCXFO58-28-16613d5f-0adf-481e-995f-9841136adfa5', protocol='range'}
13:47:27.023 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Finished assignment for group at generation 1: {consumer-sub-083-CCXFO58-28-16613d5f-0adf-481e-995f-9841136adfa5=Assignment(partitions=[test-topic-0000083-g-BmxjQ-0])}
13:47:27.024 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-086-VXzAfEs-29-21ccb2df-6890-4b1f-8ecf-95c6c7f03772', protocol='range'}
13:47:27.024 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Finished assignment for group at generation 1: {consumer-sub-086-VXzAfEs-29-21ccb2df-6890-4b1f-8ecf-95c6c7f03772=Assignment(partitions=[test-topic-0000086-cFlu7XU-0])}
13:47:27.025 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-083-CCXFO58-28-16613d5f-0adf-481e-995f-9841136adfa5', protocol='range'}
13:47:27.025 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Notifying assignor about the new Assignment(partitions=[test-topic-0000083-g-BmxjQ-0])
13:47:27.026 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Adding newly assigned partitions: test-topic-0000083-g-BmxjQ-0
13:47:27.026 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Found no committed offset for partition test-topic-0000083-g-BmxjQ-0
13:47:27.026 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-086-VXzAfEs-29-21ccb2df-6890-4b1f-8ecf-95c6c7f03772', protocol='range'}
13:47:27.026 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-089-BLOZYn0-30-628fc7ff-ba8d-442d-bb54-bac762ec10a1', protocol='range'}
13:47:27.026 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Notifying assignor about the new Assignment(partitions=[test-topic-0000086-cFlu7XU-0])
13:47:27.026 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Adding newly assigned partitions: test-topic-0000086-cFlu7XU-0
13:47:27.026 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Finished assignment for group at generation 1: {consumer-sub-089-BLOZYn0-30-628fc7ff-ba8d-442d-bb54-bac762ec10a1=Assignment(partitions=[test-topic-0000089-x68IQU4-0])}
13:47:27.027 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Found no committed offset for partition test-topic-0000086-cFlu7XU-0
13:47:27.028 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-089-BLOZYn0-30-628fc7ff-ba8d-442d-bb54-bac762ec10a1', protocol='range'}
13:47:27.028 [pool-33-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-086-VXzAfEs-29, groupId=sub-086-VXzAfEs] Resetting offset for partition test-topic-0000086-cFlu7XU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.028 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Notifying assignor about the new Assignment(partitions=[test-topic-0000089-x68IQU4-0])
13:47:27.028 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Adding newly assigned partitions: test-topic-0000089-x68IQU4-0
13:47:27.029 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Found no committed offset for partition test-topic-0000089-x68IQU4-0
13:47:27.036 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-092-UVWIdU0-31-39ff6be8-3057-40db-afdf-b7c99526be9a', protocol='range'}
13:47:27.036 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Finished assignment for group at generation 1: {consumer-sub-092-UVWIdU0-31-39ff6be8-3057-40db-afdf-b7c99526be9a=Assignment(partitions=[test-topic-0000092-JXGTSos-0])}
13:47:27.050 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-098-AHs-bqI-33-3b030e93-85a1-46d0-a58e-3fce11ac3238', protocol='range'}
13:47:27.050 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Finished assignment for group at generation 1: {consumer-sub-098-AHs-bqI-33-3b030e93-85a1-46d0-a58e-3fce11ac3238=Assignment(partitions=[test-topic-0000098-H_jRR9A-0])}
13:47:27.052 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-098-AHs-bqI-33-3b030e93-85a1-46d0-a58e-3fce11ac3238', protocol='range'}
13:47:27.052 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Notifying assignor about the new Assignment(partitions=[test-topic-0000098-H_jRR9A-0])
13:47:27.052 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Adding newly assigned partitions: test-topic-0000098-H_jRR9A-0
13:47:27.053 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Found no committed offset for partition test-topic-0000098-H_jRR9A-0
13:47:27.054 [pool-37-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-098-AHs-bqI-33, groupId=sub-098-AHs-bqI] Resetting offset for partition test-topic-0000098-H_jRR9A-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.058 [pool-34-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-089-BLOZYn0-30, groupId=sub-089-BLOZYn0] Resetting offset for partition test-topic-0000089-x68IQU4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.060 [pool-32-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-083-CCXFO58-28, groupId=sub-083-CCXFO58] Resetting offset for partition test-topic-0000083-g-BmxjQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.062 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-101-Ca9dsZA-34-319a2c18-4700-4fd8-b1e7-9952abeb1a4b', protocol='range'}
13:47:27.062 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Finished assignment for group at generation 1: {consumer-sub-101-Ca9dsZA-34-319a2c18-4700-4fd8-b1e7-9952abeb1a4b=Assignment(partitions=[test-topic-0000101-LhC-54M-0])}
13:47:27.063 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-092-UVWIdU0-31-39ff6be8-3057-40db-afdf-b7c99526be9a', protocol='range'}
13:47:27.063 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Notifying assignor about the new Assignment(partitions=[test-topic-0000092-JXGTSos-0])
13:47:27.063 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Adding newly assigned partitions: test-topic-0000092-JXGTSos-0
13:47:27.063 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-095-FqcULd4-32-6cf9ce82-713e-4e5b-b159-6e9ff299756c', protocol='range'}
13:47:27.064 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Finished assignment for group at generation 1: {consumer-sub-095-FqcULd4-32-6cf9ce82-713e-4e5b-b159-6e9ff299756c=Assignment(partitions=[test-topic-0000095-zPq6gTM-0])}
13:47:27.064 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-101-Ca9dsZA-34-319a2c18-4700-4fd8-b1e7-9952abeb1a4b', protocol='range'}
13:47:27.064 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Notifying assignor about the new Assignment(partitions=[test-topic-0000101-LhC-54M-0])
13:47:27.064 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Adding newly assigned partitions: test-topic-0000101-LhC-54M-0
13:47:27.065 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Found no committed offset for partition test-topic-0000101-LhC-54M-0
13:47:27.065 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Found no committed offset for partition test-topic-0000092-JXGTSos-0
13:47:27.066 [pool-38-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-101-Ca9dsZA-34, groupId=sub-101-Ca9dsZA] Resetting offset for partition test-topic-0000101-LhC-54M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.067 [pool-35-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-092-UVWIdU0-31, groupId=sub-092-UVWIdU0] Resetting offset for partition test-topic-0000092-JXGTSos-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.068 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-104-PSzEn5A-35-4ddc1bd5-2afa-4041-b3cd-239498bf00fb', protocol='range'}
13:47:27.068 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Finished assignment for group at generation 1: {consumer-sub-104-PSzEn5A-35-4ddc1bd5-2afa-4041-b3cd-239498bf00fb=Assignment(partitions=[test-topic-0000104--zE_tVI-0])}
13:47:27.069 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-095-FqcULd4-32-6cf9ce82-713e-4e5b-b159-6e9ff299756c', protocol='range'}
13:47:27.069 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Notifying assignor about the new Assignment(partitions=[test-topic-0000095-zPq6gTM-0])
13:47:27.069 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Adding newly assigned partitions: test-topic-0000095-zPq6gTM-0
13:47:27.070 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-104-PSzEn5A-35-4ddc1bd5-2afa-4041-b3cd-239498bf00fb', protocol='range'}
13:47:27.070 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Notifying assignor about the new Assignment(partitions=[test-topic-0000104--zE_tVI-0])
13:47:27.070 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Adding newly assigned partitions: test-topic-0000104--zE_tVI-0
13:47:27.071 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Found no committed offset for partition test-topic-0000104--zE_tVI-0
13:47:27.072 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Found no committed offset for partition test-topic-0000095-zPq6gTM-0
13:47:27.073 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-107-OReCH5E-36-78174b04-0b27-4c6c-a36a-4b456601473b', protocol='range'}
13:47:27.073 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Finished assignment for group at generation 1: {consumer-sub-107-OReCH5E-36-78174b04-0b27-4c6c-a36a-4b456601473b=Assignment(partitions=[test-topic-0000107-fjH0hDM-0])}
13:47:27.079 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-110-3jOB2Ps-37-a740afbb-54f1-46aa-897a-32d65be0d2f4', protocol='range'}
13:47:27.079 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Finished assignment for group at generation 1: {consumer-sub-110-3jOB2Ps-37-a740afbb-54f1-46aa-897a-32d65be0d2f4=Assignment(partitions=[test-topic-0000110-mZfst7E-0])}
13:47:27.079 [pool-39-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-104-PSzEn5A-35, groupId=sub-104-PSzEn5A] Resetting offset for partition test-topic-0000104--zE_tVI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.080 [pool-36-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-095-FqcULd4-32, groupId=sub-095-FqcULd4] Resetting offset for partition test-topic-0000095-zPq6gTM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.081 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-107-OReCH5E-36-78174b04-0b27-4c6c-a36a-4b456601473b', protocol='range'}
13:47:27.081 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Notifying assignor about the new Assignment(partitions=[test-topic-0000107-fjH0hDM-0])
13:47:27.081 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Adding newly assigned partitions: test-topic-0000107-fjH0hDM-0
13:47:27.082 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-110-3jOB2Ps-37-a740afbb-54f1-46aa-897a-32d65be0d2f4', protocol='range'}
13:47:27.082 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Notifying assignor about the new Assignment(partitions=[test-topic-0000110-mZfst7E-0])
13:47:27.082 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Adding newly assigned partitions: test-topic-0000110-mZfst7E-0
13:47:27.083 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Found no committed offset for partition test-topic-0000107-fjH0hDM-0
13:47:27.084 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Found no committed offset for partition test-topic-0000110-mZfst7E-0
13:47:27.084 [pool-40-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-107-OReCH5E-36, groupId=sub-107-OReCH5E] Resetting offset for partition test-topic-0000107-fjH0hDM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.087 [pool-41-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-110-3jOB2Ps-37, groupId=sub-110-3jOB2Ps] Resetting offset for partition test-topic-0000110-mZfst7E-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.088 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-116-bave-3U-39-389ee98d-15fd-4d14-9a24-36b4bc348953', protocol='range'}
13:47:27.089 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Finished assignment for group at generation 1: {consumer-sub-116-bave-3U-39-389ee98d-15fd-4d14-9a24-36b4bc348953=Assignment(partitions=[test-topic-0000116-7UdnOfU-0])}
13:47:27.089 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-113-MyqQE38-38-922ede0f-3a7d-43fe-93cf-af271a39dd2d', protocol='range'}
13:47:27.090 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Finished assignment for group at generation 1: {consumer-sub-113-MyqQE38-38-922ede0f-3a7d-43fe-93cf-af271a39dd2d=Assignment(partitions=[test-topic-0000113-cTWFNVA-0])}
13:47:27.090 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-116-bave-3U-39-389ee98d-15fd-4d14-9a24-36b4bc348953', protocol='range'}
13:47:27.091 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Notifying assignor about the new Assignment(partitions=[test-topic-0000116-7UdnOfU-0])
13:47:27.091 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Adding newly assigned partitions: test-topic-0000116-7UdnOfU-0
13:47:27.091 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Found no committed offset for partition test-topic-0000116-7UdnOfU-0
13:47:27.091 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-113-MyqQE38-38-922ede0f-3a7d-43fe-93cf-af271a39dd2d', protocol='range'}
13:47:27.092 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Notifying assignor about the new Assignment(partitions=[test-topic-0000113-cTWFNVA-0])
13:47:27.092 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Adding newly assigned partitions: test-topic-0000113-cTWFNVA-0
13:47:27.092 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Found no committed offset for partition test-topic-0000113-cTWFNVA-0
13:47:27.093 [pool-43-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-116-bave-3U-39, groupId=sub-116-bave-3U] Resetting offset for partition test-topic-0000116-7UdnOfU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.094 [pool-42-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-113-MyqQE38-38, groupId=sub-113-MyqQE38] Resetting offset for partition test-topic-0000113-cTWFNVA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.101 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-119-jj2jlEI-40-db96ff6d-39a0-4e82-a6c6-04d3498245f7', protocol='range'}
13:47:27.101 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Finished assignment for group at generation 1: {consumer-sub-119-jj2jlEI-40-db96ff6d-39a0-4e82-a6c6-04d3498245f7=Assignment(partitions=[test-topic-0000119-SlKUM_g-0])}
13:47:27.101 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-122-JQEf4IY-41-673716fc-9927-4a2d-a9fc-627c20dcfb2b', protocol='range'}
13:47:27.101 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Finished assignment for group at generation 1: {consumer-sub-122-JQEf4IY-41-673716fc-9927-4a2d-a9fc-627c20dcfb2b=Assignment(partitions=[test-topic-0000122-BF9iF7A-0])}
13:47:27.103 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-119-jj2jlEI-40-db96ff6d-39a0-4e82-a6c6-04d3498245f7', protocol='range'}
13:47:27.103 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Notifying assignor about the new Assignment(partitions=[test-topic-0000119-SlKUM_g-0])
13:47:27.103 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Adding newly assigned partitions: test-topic-0000119-SlKUM_g-0
13:47:27.103 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Found no committed offset for partition test-topic-0000119-SlKUM_g-0
13:47:27.105 [pool-44-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-119-jj2jlEI-40, groupId=sub-119-jj2jlEI] Resetting offset for partition test-topic-0000119-SlKUM_g-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.106 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-125-CejEoPg-42-e6df77de-ca5e-4b40-8460-43fa11700289', protocol='range'}
13:47:27.106 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Finished assignment for group at generation 1: {consumer-sub-125-CejEoPg-42-e6df77de-ca5e-4b40-8460-43fa11700289=Assignment(partitions=[test-topic-0000125-hZwj-ZY-0])}
13:47:27.109 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-128-L92zuD0-43-44e6a727-4814-4e57-8964-8235c6c350b3', protocol='range'}
13:47:27.109 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-122-JQEf4IY-41-673716fc-9927-4a2d-a9fc-627c20dcfb2b', protocol='range'}
13:47:27.109 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Notifying assignor about the new Assignment(partitions=[test-topic-0000122-BF9iF7A-0])
13:47:27.109 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Finished assignment for group at generation 1: {consumer-sub-128-L92zuD0-43-44e6a727-4814-4e57-8964-8235c6c350b3=Assignment(partitions=[test-topic-0000128-VV-rVFU-0])}
13:47:27.109 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Adding newly assigned partitions: test-topic-0000122-BF9iF7A-0
13:47:27.110 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Found no committed offset for partition test-topic-0000122-BF9iF7A-0
13:47:27.111 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-128-L92zuD0-43-44e6a727-4814-4e57-8964-8235c6c350b3', protocol='range'}
13:47:27.111 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Notifying assignor about the new Assignment(partitions=[test-topic-0000128-VV-rVFU-0])
13:47:27.111 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Adding newly assigned partitions: test-topic-0000128-VV-rVFU-0
13:47:27.112 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Found no committed offset for partition test-topic-0000128-VV-rVFU-0
13:47:27.113 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-125-CejEoPg-42-e6df77de-ca5e-4b40-8460-43fa11700289', protocol='range'}
13:47:27.113 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Notifying assignor about the new Assignment(partitions=[test-topic-0000125-hZwj-ZY-0])
13:47:27.113 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Adding newly assigned partitions: test-topic-0000125-hZwj-ZY-0
13:47:27.113 [pool-45-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-122-JQEf4IY-41, groupId=sub-122-JQEf4IY] Resetting offset for partition test-topic-0000122-BF9iF7A-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.113 [pool-47-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-128-L92zuD0-43, groupId=sub-128-L92zuD0] Resetting offset for partition test-topic-0000128-VV-rVFU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.113 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Found no committed offset for partition test-topic-0000125-hZwj-ZY-0
13:47:27.114 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-131-5hwf5SE-44-d52a39e7-2ebc-4f98-8b13-c3ac565899fc', protocol='range'}
13:47:27.115 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Finished assignment for group at generation 1: {consumer-sub-131-5hwf5SE-44-d52a39e7-2ebc-4f98-8b13-c3ac565899fc=Assignment(partitions=[test-topic-0000131-xgUrqV0-0])}
13:47:27.115 [pool-46-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-125-CejEoPg-42, groupId=sub-125-CejEoPg] Resetting offset for partition test-topic-0000125-hZwj-ZY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.117 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-131-5hwf5SE-44-d52a39e7-2ebc-4f98-8b13-c3ac565899fc', protocol='range'}
13:47:27.117 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Notifying assignor about the new Assignment(partitions=[test-topic-0000131-xgUrqV0-0])
13:47:27.117 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Adding newly assigned partitions: test-topic-0000131-xgUrqV0-0
13:47:27.117 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Found no committed offset for partition test-topic-0000131-xgUrqV0-0
13:47:27.119 [pool-48-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-131-5hwf5SE-44, groupId=sub-131-5hwf5SE] Resetting offset for partition test-topic-0000131-xgUrqV0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.121 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-134-HsIPgPc-45-70543c7a-2485-4284-94d5-eb2810941f9c', protocol='range'}
13:47:27.122 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Finished assignment for group at generation 1: {consumer-sub-134-HsIPgPc-45-70543c7a-2485-4284-94d5-eb2810941f9c=Assignment(partitions=[test-topic-0000134-Sxkgttc-0])}
13:47:27.123 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-134-HsIPgPc-45-70543c7a-2485-4284-94d5-eb2810941f9c', protocol='range'}
13:47:27.123 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Notifying assignor about the new Assignment(partitions=[test-topic-0000134-Sxkgttc-0])
13:47:27.123 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Adding newly assigned partitions: test-topic-0000134-Sxkgttc-0
13:47:27.124 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Found no committed offset for partition test-topic-0000134-Sxkgttc-0
13:47:27.125 [pool-49-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-134-HsIPgPc-45, groupId=sub-134-HsIPgPc] Resetting offset for partition test-topic-0000134-Sxkgttc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.125 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-137-hiju0Qw-46-c26342d1-6083-4e1a-ad06-6f7410e30293', protocol='range'}
13:47:27.126 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Finished assignment for group at generation 1: {consumer-sub-137-hiju0Qw-46-c26342d1-6083-4e1a-ad06-6f7410e30293=Assignment(partitions=[test-topic-0000137-Aei-Pwg-0])}
13:47:27.128 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-137-hiju0Qw-46-c26342d1-6083-4e1a-ad06-6f7410e30293', protocol='range'}
13:47:27.129 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Notifying assignor about the new Assignment(partitions=[test-topic-0000137-Aei-Pwg-0])
13:47:27.129 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Adding newly assigned partitions: test-topic-0000137-Aei-Pwg-0
13:47:27.129 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Found no committed offset for partition test-topic-0000137-Aei-Pwg-0
13:47:27.131 [pool-50-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-137-hiju0Qw-46, groupId=sub-137-hiju0Qw] Resetting offset for partition test-topic-0000137-Aei-Pwg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.131 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-140-qIRKxm8-47-d61af1ec-0fd2-414d-afe7-297891c24b00', protocol='range'}
13:47:27.131 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Finished assignment for group at generation 1: {consumer-sub-140-qIRKxm8-47-d61af1ec-0fd2-414d-afe7-297891c24b00=Assignment(partitions=[test-topic-0000140-EL2B4IY-0])}
13:47:27.132 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-140-qIRKxm8-47-d61af1ec-0fd2-414d-afe7-297891c24b00', protocol='range'}
13:47:27.132 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Notifying assignor about the new Assignment(partitions=[test-topic-0000140-EL2B4IY-0])
13:47:27.132 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Adding newly assigned partitions: test-topic-0000140-EL2B4IY-0
13:47:27.133 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Found no committed offset for partition test-topic-0000140-EL2B4IY-0
13:47:27.134 [pool-51-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-140-qIRKxm8-47, groupId=sub-140-qIRKxm8] Resetting offset for partition test-topic-0000140-EL2B4IY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.138 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-143-Rsowa4I-48-39396204-ecec-420a-b644-6fe87e0c6487', protocol='range'}
13:47:27.138 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Finished assignment for group at generation 1: {consumer-sub-143-Rsowa4I-48-39396204-ecec-420a-b644-6fe87e0c6487=Assignment(partitions=[test-topic-0000143-6mgkLNE-0])}
13:47:27.140 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-143-Rsowa4I-48-39396204-ecec-420a-b644-6fe87e0c6487', protocol='range'}
13:47:27.140 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Notifying assignor about the new Assignment(partitions=[test-topic-0000143-6mgkLNE-0])
13:47:27.140 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Adding newly assigned partitions: test-topic-0000143-6mgkLNE-0
13:47:27.140 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Found no committed offset for partition test-topic-0000143-6mgkLNE-0
13:47:27.142 [pool-52-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-143-Rsowa4I-48, groupId=sub-143-Rsowa4I] Resetting offset for partition test-topic-0000143-6mgkLNE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.151 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-146-p_YEMQg-49-da5769b1-13ee-4316-bd7e-bb154dfc9c26', protocol='range'}
13:47:27.151 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Finished assignment for group at generation 1: {consumer-sub-146-p_YEMQg-49-da5769b1-13ee-4316-bd7e-bb154dfc9c26=Assignment(partitions=[test-topic-0000146-mwLxECY-0])}
13:47:27.153 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-146-p_YEMQg-49-da5769b1-13ee-4316-bd7e-bb154dfc9c26', protocol='range'}
13:47:27.153 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Notifying assignor about the new Assignment(partitions=[test-topic-0000146-mwLxECY-0])
13:47:27.153 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Adding newly assigned partitions: test-topic-0000146-mwLxECY-0
13:47:27.153 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Found no committed offset for partition test-topic-0000146-mwLxECY-0
13:47:27.154 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-149-mud_F7E-50-7c2787b0-357d-4277-a61f-d4cfce3c452d', protocol='range'}
13:47:27.154 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Finished assignment for group at generation 1: {consumer-sub-149-mud_F7E-50-7c2787b0-357d-4277-a61f-d4cfce3c452d=Assignment(partitions=[test-topic-0000149-oEEgv68-0])}
13:47:27.154 [pool-53-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-146-p_YEMQg-49, groupId=sub-146-p_YEMQg] Resetting offset for partition test-topic-0000146-mwLxECY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.156 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-149-mud_F7E-50-7c2787b0-357d-4277-a61f-d4cfce3c452d', protocol='range'}
13:47:27.156 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Notifying assignor about the new Assignment(partitions=[test-topic-0000149-oEEgv68-0])
13:47:27.156 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Adding newly assigned partitions: test-topic-0000149-oEEgv68-0
13:47:27.157 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Found no committed offset for partition test-topic-0000149-oEEgv68-0
13:47:27.158 [pool-54-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-149-mud_F7E-50, groupId=sub-149-mud_F7E] Resetting offset for partition test-topic-0000149-oEEgv68-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.159 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-152-UGEJeFY-51-3df85ea4-6179-4dc7-bb22-db8612f9f3c6', protocol='range'}
13:47:27.159 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Finished assignment for group at generation 1: {consumer-sub-152-UGEJeFY-51-3df85ea4-6179-4dc7-bb22-db8612f9f3c6=Assignment(partitions=[test-topic-0000152-_ZPbr1E-0])}
13:47:27.161 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-152-UGEJeFY-51-3df85ea4-6179-4dc7-bb22-db8612f9f3c6', protocol='range'}
13:47:27.161 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Notifying assignor about the new Assignment(partitions=[test-topic-0000152-_ZPbr1E-0])
13:47:27.161 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Adding newly assigned partitions: test-topic-0000152-_ZPbr1E-0
13:47:27.161 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Found no committed offset for partition test-topic-0000152-_ZPbr1E-0
13:47:27.162 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-155-Z5T-xls-52-6dc893dd-254f-48d5-aeae-bc0005b0b42f', protocol='range'}
13:47:27.162 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Finished assignment for group at generation 1: {consumer-sub-155-Z5T-xls-52-6dc893dd-254f-48d5-aeae-bc0005b0b42f=Assignment(partitions=[test-topic-0000155-lbbml9M-0])}
13:47:27.163 [pool-55-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-152-UGEJeFY-51, groupId=sub-152-UGEJeFY] Resetting offset for partition test-topic-0000152-_ZPbr1E-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.164 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-155-Z5T-xls-52-6dc893dd-254f-48d5-aeae-bc0005b0b42f', protocol='range'}
13:47:27.164 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Notifying assignor about the new Assignment(partitions=[test-topic-0000155-lbbml9M-0])
13:47:27.164 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Adding newly assigned partitions: test-topic-0000155-lbbml9M-0
13:47:27.165 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Found no committed offset for partition test-topic-0000155-lbbml9M-0
13:47:27.166 [pool-56-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-155-Z5T-xls-52, groupId=sub-155-Z5T-xls] Resetting offset for partition test-topic-0000155-lbbml9M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.169 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-158-s6pzAPM-53-0533c59c-51b8-4937-9784-971ceb6b5e59', protocol='range'}
13:47:27.170 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Finished assignment for group at generation 1: {consumer-sub-158-s6pzAPM-53-0533c59c-51b8-4937-9784-971ceb6b5e59=Assignment(partitions=[test-topic-0000158-6CVrNxA-0])}
13:47:27.171 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-158-s6pzAPM-53-0533c59c-51b8-4937-9784-971ceb6b5e59', protocol='range'}
13:47:27.171 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Notifying assignor about the new Assignment(partitions=[test-topic-0000158-6CVrNxA-0])
13:47:27.172 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Adding newly assigned partitions: test-topic-0000158-6CVrNxA-0
13:47:27.172 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Found no committed offset for partition test-topic-0000158-6CVrNxA-0
13:47:27.174 [pool-57-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-158-s6pzAPM-53, groupId=sub-158-s6pzAPM] Resetting offset for partition test-topic-0000158-6CVrNxA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.176 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-161-pmw2YkA-54-fd20b23f-0a5d-49bd-9ff0-4a047515e44c', protocol='range'}
13:47:27.176 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Finished assignment for group at generation 1: {consumer-sub-161-pmw2YkA-54-fd20b23f-0a5d-49bd-9ff0-4a047515e44c=Assignment(partitions=[test-topic-0000161-wcsZU2U-0])}
13:47:27.178 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-161-pmw2YkA-54-fd20b23f-0a5d-49bd-9ff0-4a047515e44c', protocol='range'}
13:47:27.178 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Notifying assignor about the new Assignment(partitions=[test-topic-0000161-wcsZU2U-0])
13:47:27.178 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Adding newly assigned partitions: test-topic-0000161-wcsZU2U-0
13:47:27.178 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Found no committed offset for partition test-topic-0000161-wcsZU2U-0
13:47:27.180 [pool-58-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-161-pmw2YkA-54, groupId=sub-161-pmw2YkA] Resetting offset for partition test-topic-0000161-wcsZU2U-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.180 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-164-c0L1gIA-55-d5a425e6-bdb4-4509-9bc2-a67746302f98', protocol='range'}
13:47:27.180 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Finished assignment for group at generation 1: {consumer-sub-164-c0L1gIA-55-d5a425e6-bdb4-4509-9bc2-a67746302f98=Assignment(partitions=[test-topic-0000164-gepakbQ-0])}
13:47:27.181 [qtp435803541-29] INFO WorkerHandler - Start load publish-rate: 3333333.3333333335 msg/s -- payload-size: 0 -- producer index: 1
13:47:27.182 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-164-c0L1gIA-55-d5a425e6-bdb4-4509-9bc2-a67746302f98', protocol='range'}
13:47:27.182 [qtp435803541-29] INFO LocalWorker - Number of commands 1667 | Commands per batch 17 | Batches per producer 99
13:47:27.182 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Notifying assignor about the new Assignment(partitions=[test-topic-0000164-gepakbQ-0])
13:47:27.183 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Adding newly assigned partitions: test-topic-0000164-gepakbQ-0
13:47:27.183 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Found no committed offset for partition test-topic-0000164-gepakbQ-0
13:47:27.185 [pool-59-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-164-c0L1gIA-55, groupId=sub-164-c0L1gIA] Resetting offset for partition test-topic-0000164-gepakbQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.186 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-167-Nnszxcg-56-b311d82e-730b-436c-9d5e-a7491a9ea67b', protocol='range'}
13:47:27.186 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Finished assignment for group at generation 1: {consumer-sub-167-Nnszxcg-56-b311d82e-730b-436c-9d5e-a7491a9ea67b=Assignment(partitions=[test-topic-0000167-BwF1nXw-0])}
13:47:27.188 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-167-Nnszxcg-56-b311d82e-730b-436c-9d5e-a7491a9ea67b', protocol='range'}
13:47:27.188 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Notifying assignor about the new Assignment(partitions=[test-topic-0000167-BwF1nXw-0])
13:47:27.188 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Adding newly assigned partitions: test-topic-0000167-BwF1nXw-0
13:47:27.188 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Found no committed offset for partition test-topic-0000167-BwF1nXw-0
13:47:27.190 [pool-60-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-167-Nnszxcg-56, groupId=sub-167-Nnszxcg] Resetting offset for partition test-topic-0000167-BwF1nXw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.196 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-170-xjFOjPo-57-5ed4f893-e88a-4d4e-a1de-cb9cd90b0942', protocol='range'}
13:47:27.197 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Finished assignment for group at generation 1: {consumer-sub-170-xjFOjPo-57-5ed4f893-e88a-4d4e-a1de-cb9cd90b0942=Assignment(partitions=[test-topic-0000170-Z0q4Nvo-0])}
13:47:27.199 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-170-xjFOjPo-57-5ed4f893-e88a-4d4e-a1de-cb9cd90b0942', protocol='range'}
13:47:27.199 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Notifying assignor about the new Assignment(partitions=[test-topic-0000170-Z0q4Nvo-0])
13:47:27.199 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Adding newly assigned partitions: test-topic-0000170-Z0q4Nvo-0
13:47:27.200 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Found no committed offset for partition test-topic-0000170-Z0q4Nvo-0
13:47:27.200 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-173-ASqOG_U-58-f9c8d3f4-ba89-4237-8f1c-95d3a7485c57', protocol='range'}
13:47:27.200 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Finished assignment for group at generation 1: {consumer-sub-173-ASqOG_U-58-f9c8d3f4-ba89-4237-8f1c-95d3a7485c57=Assignment(partitions=[test-topic-0000173-6CJkJ1w-0])}
13:47:27.201 [pool-61-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-170-xjFOjPo-57, groupId=sub-170-xjFOjPo] Resetting offset for partition test-topic-0000170-Z0q4Nvo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.202 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-176-sOqVDj8-59-436da102-43ab-405b-a630-dd0c924cae1b', protocol='range'}
13:47:27.202 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Finished assignment for group at generation 1: {consumer-sub-176-sOqVDj8-59-436da102-43ab-405b-a630-dd0c924cae1b=Assignment(partitions=[test-topic-0000176-BBDA9F8-0])}
13:47:27.202 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-173-ASqOG_U-58-f9c8d3f4-ba89-4237-8f1c-95d3a7485c57', protocol='range'}
13:47:27.202 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Notifying assignor about the new Assignment(partitions=[test-topic-0000173-6CJkJ1w-0])
13:47:27.202 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Adding newly assigned partitions: test-topic-0000173-6CJkJ1w-0
13:47:27.203 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Found no committed offset for partition test-topic-0000173-6CJkJ1w-0
13:47:27.203 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-176-sOqVDj8-59-436da102-43ab-405b-a630-dd0c924cae1b', protocol='range'}
13:47:27.204 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Notifying assignor about the new Assignment(partitions=[test-topic-0000176-BBDA9F8-0])
13:47:27.204 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Adding newly assigned partitions: test-topic-0000176-BBDA9F8-0
13:47:27.204 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Found no committed offset for partition test-topic-0000176-BBDA9F8-0
13:47:27.204 [pool-62-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-173-ASqOG_U-58, groupId=sub-173-ASqOG_U] Resetting offset for partition test-topic-0000173-6CJkJ1w-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.205 [pool-63-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-176-sOqVDj8-59, groupId=sub-176-sOqVDj8] Resetting offset for partition test-topic-0000176-BBDA9F8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.207 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-179-U_eIN4k-60-724feec0-f178-4288-b258-4ed680e535d1', protocol='range'}
13:47:27.207 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Finished assignment for group at generation 1: {consumer-sub-179-U_eIN4k-60-724feec0-f178-4288-b258-4ed680e535d1=Assignment(partitions=[test-topic-0000179-Z_sMFPQ-0])}
13:47:27.209 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-179-U_eIN4k-60-724feec0-f178-4288-b258-4ed680e535d1', protocol='range'}
13:47:27.209 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Notifying assignor about the new Assignment(partitions=[test-topic-0000179-Z_sMFPQ-0])
13:47:27.209 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Adding newly assigned partitions: test-topic-0000179-Z_sMFPQ-0
13:47:27.209 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Found no committed offset for partition test-topic-0000179-Z_sMFPQ-0
13:47:27.211 [pool-64-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-179-U_eIN4k-60, groupId=sub-179-U_eIN4k] Resetting offset for partition test-topic-0000179-Z_sMFPQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.216 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-185-eOw6LnQ-62-49dc2a3e-a7ea-473a-a7fc-7fa5d1622c72', protocol='range'}
13:47:27.216 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Finished assignment for group at generation 1: {consumer-sub-185-eOw6LnQ-62-49dc2a3e-a7ea-473a-a7fc-7fa5d1622c72=Assignment(partitions=[test-topic-0000185-PO-JbZY-0])}
13:47:27.217 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-182-fLKr5eA-61-db8a0173-669e-40e6-9d6e-d633d97c8c45', protocol='range'}
13:47:27.217 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Finished assignment for group at generation 1: {consumer-sub-182-fLKr5eA-61-db8a0173-669e-40e6-9d6e-d633d97c8c45=Assignment(partitions=[test-topic-0000182-FHEBZ8A-0])}
13:47:27.217 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-185-eOw6LnQ-62-49dc2a3e-a7ea-473a-a7fc-7fa5d1622c72', protocol='range'}
13:47:27.218 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000185-PO-JbZY-0])
13:47:27.218 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Adding newly assigned partitions: test-topic-0000185-PO-JbZY-0
13:47:27.218 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Found no committed offset for partition test-topic-0000185-PO-JbZY-0
13:47:27.219 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-182-fLKr5eA-61-db8a0173-669e-40e6-9d6e-d633d97c8c45', protocol='range'}
13:47:27.219 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Notifying assignor about the new Assignment(partitions=[test-topic-0000182-FHEBZ8A-0])
13:47:27.219 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Adding newly assigned partitions: test-topic-0000182-FHEBZ8A-0
13:47:27.219 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Found no committed offset for partition test-topic-0000182-FHEBZ8A-0
13:47:27.219 [pool-66-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-185-eOw6LnQ-62, groupId=sub-185-eOw6LnQ] Resetting offset for partition test-topic-0000185-PO-JbZY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.221 [pool-65-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-182-fLKr5eA-61, groupId=sub-182-fLKr5eA] Resetting offset for partition test-topic-0000182-FHEBZ8A-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.225 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.226 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-191-lBEvzoE-64-07ce3648-0081-473d-b2ea-d4ccf96c2585', protocol='range'}
13:47:27.226 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Finished assignment for group at generation 1: {consumer-sub-191-lBEvzoE-64-07ce3648-0081-473d-b2ea-d4ccf96c2585=Assignment(partitions=[test-topic-0000191-PNN1Bfk-0])}
13:47:27.226 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-188-e8Nf0Co-63-6b993404-0e53-4668-980c-17f02a2c84de', protocol='range'}
13:47:27.227 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Finished assignment for group at generation 1: {consumer-sub-188-e8Nf0Co-63-6b993404-0e53-4668-980c-17f02a2c84de=Assignment(partitions=[test-topic-0000188-c6J0hjY-0])}
13:47:27.227 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-191-lBEvzoE-64-07ce3648-0081-473d-b2ea-d4ccf96c2585', protocol='range'}
13:47:27.228 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Notifying assignor about the new Assignment(partitions=[test-topic-0000191-PNN1Bfk-0])
13:47:27.228 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Adding newly assigned partitions: test-topic-0000191-PNN1Bfk-0
13:47:27.228 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Found no committed offset for partition test-topic-0000191-PNN1Bfk-0
13:47:27.229 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-188-e8Nf0Co-63-6b993404-0e53-4668-980c-17f02a2c84de', protocol='range'}
13:47:27.229 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Notifying assignor about the new Assignment(partitions=[test-topic-0000188-c6J0hjY-0])
13:47:27.229 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Adding newly assigned partitions: test-topic-0000188-c6J0hjY-0
13:47:27.229 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Found no committed offset for partition test-topic-0000188-c6J0hjY-0
13:47:27.229 [pool-68-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-191-lBEvzoE-64, groupId=sub-191-lBEvzoE] Resetting offset for partition test-topic-0000191-PNN1Bfk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.231 [pool-67-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-188-e8Nf0Co-63, groupId=sub-188-e8Nf0Co] Resetting offset for partition test-topic-0000188-c6J0hjY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.232 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-194-AYLbIW8-65-55a7fc23-7467-43f9-aff7-e16bda169da2', protocol='range'}
13:47:27.232 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Finished assignment for group at generation 1: {consumer-sub-194-AYLbIW8-65-55a7fc23-7467-43f9-aff7-e16bda169da2=Assignment(partitions=[test-topic-0000194-K-KCWTE-0])}
13:47:27.233 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-197-x1osWkA-66-125bf17f-3127-464f-996a-e488cfde02c2', protocol='range'}
13:47:27.233 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Finished assignment for group at generation 1: {consumer-sub-197-x1osWkA-66-125bf17f-3127-464f-996a-e488cfde02c2=Assignment(partitions=[test-topic-0000197-CIa3XGw-0])}
13:47:27.234 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-194-AYLbIW8-65-55a7fc23-7467-43f9-aff7-e16bda169da2', protocol='range'}
13:47:27.234 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Notifying assignor about the new Assignment(partitions=[test-topic-0000194-K-KCWTE-0])
13:47:27.234 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Adding newly assigned partitions: test-topic-0000194-K-KCWTE-0
13:47:27.234 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Found no committed offset for partition test-topic-0000194-K-KCWTE-0
13:47:27.235 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-197-x1osWkA-66-125bf17f-3127-464f-996a-e488cfde02c2', protocol='range'}
13:47:27.235 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Notifying assignor about the new Assignment(partitions=[test-topic-0000197-CIa3XGw-0])
13:47:27.235 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Adding newly assigned partitions: test-topic-0000197-CIa3XGw-0
13:47:27.235 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Found no committed offset for partition test-topic-0000197-CIa3XGw-0
13:47:27.236 [pool-69-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-194-AYLbIW8-65, groupId=sub-194-AYLbIW8] Resetting offset for partition test-topic-0000194-K-KCWTE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.238 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-200-nWDAepo-67-b6982a80-b4a1-4cb5-a10c-74aa106a449c', protocol='range'}
13:47:27.238 [pool-70-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-197-x1osWkA-66, groupId=sub-197-x1osWkA] Resetting offset for partition test-topic-0000197-CIa3XGw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.238 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Finished assignment for group at generation 1: {consumer-sub-200-nWDAepo-67-b6982a80-b4a1-4cb5-a10c-74aa106a449c=Assignment(partitions=[test-topic-0000200-viNaANQ-0])}
13:47:27.240 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-200-nWDAepo-67-b6982a80-b4a1-4cb5-a10c-74aa106a449c', protocol='range'}
13:47:27.240 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Notifying assignor about the new Assignment(partitions=[test-topic-0000200-viNaANQ-0])
13:47:27.240 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Adding newly assigned partitions: test-topic-0000200-viNaANQ-0
13:47:27.240 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Found no committed offset for partition test-topic-0000200-viNaANQ-0
13:47:27.241 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-203-gcpAuDY-68-c51441f3-60df-45e8-9ade-33367f9bf177', protocol='range'}
13:47:27.242 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Finished assignment for group at generation 1: {consumer-sub-203-gcpAuDY-68-c51441f3-60df-45e8-9ade-33367f9bf177=Assignment(partitions=[test-topic-0000203-9hn2q10-0])}
13:47:27.242 [pool-71-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-200-nWDAepo-67, groupId=sub-200-nWDAepo] Resetting offset for partition test-topic-0000200-viNaANQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.243 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-203-gcpAuDY-68-c51441f3-60df-45e8-9ade-33367f9bf177', protocol='range'}
13:47:27.243 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Notifying assignor about the new Assignment(partitions=[test-topic-0000203-9hn2q10-0])
13:47:27.243 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Adding newly assigned partitions: test-topic-0000203-9hn2q10-0
13:47:27.244 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Found no committed offset for partition test-topic-0000203-9hn2q10-0
13:47:27.246 [pool-72-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-203-gcpAuDY-68, groupId=sub-203-gcpAuDY] Resetting offset for partition test-topic-0000203-9hn2q10-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.247 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-206-mE-iXvM-69-2b34de5a-4e9e-4736-89aa-dda572617c74', protocol='range'}
13:47:27.247 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Finished assignment for group at generation 1: {consumer-sub-206-mE-iXvM-69-2b34de5a-4e9e-4736-89aa-dda572617c74=Assignment(partitions=[test-topic-0000206-sMqOXZA-0])}
13:47:27.248 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-206-mE-iXvM-69-2b34de5a-4e9e-4736-89aa-dda572617c74', protocol='range'}
13:47:27.248 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Notifying assignor about the new Assignment(partitions=[test-topic-0000206-sMqOXZA-0])
13:47:27.249 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Adding newly assigned partitions: test-topic-0000206-sMqOXZA-0
13:47:27.249 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Found no committed offset for partition test-topic-0000206-sMqOXZA-0
13:47:27.251 [pool-73-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-206-mE-iXvM-69, groupId=sub-206-mE-iXvM] Resetting offset for partition test-topic-0000206-sMqOXZA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.258 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-212-sdMrzi8-71-89bf0721-7e72-42a8-a30c-5b8fa00fb21f', protocol='range'}
13:47:27.259 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Finished assignment for group at generation 1: {consumer-sub-212-sdMrzi8-71-89bf0721-7e72-42a8-a30c-5b8fa00fb21f=Assignment(partitions=[test-topic-0000212-WR9CMwQ-0])}
13:47:27.260 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-212-sdMrzi8-71-89bf0721-7e72-42a8-a30c-5b8fa00fb21f', protocol='range'}
13:47:27.261 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Notifying assignor about the new Assignment(partitions=[test-topic-0000212-WR9CMwQ-0])
13:47:27.261 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Adding newly assigned partitions: test-topic-0000212-WR9CMwQ-0
13:47:27.261 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Found no committed offset for partition test-topic-0000212-WR9CMwQ-0
13:47:27.262 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-209-I8XtIkQ-70-2c0b0aa5-c9aa-4875-b72d-b11841d5c582', protocol='range'}
13:47:27.262 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Finished assignment for group at generation 1: {consumer-sub-209-I8XtIkQ-70-2c0b0aa5-c9aa-4875-b72d-b11841d5c582=Assignment(partitions=[test-topic-0000209-PZuErwo-0])}
13:47:27.263 [pool-75-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-212-sdMrzi8-71, groupId=sub-212-sdMrzi8] Resetting offset for partition test-topic-0000212-WR9CMwQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.264 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-209-I8XtIkQ-70-2c0b0aa5-c9aa-4875-b72d-b11841d5c582', protocol='range'}
13:47:27.264 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000209-PZuErwo-0])
13:47:27.264 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Adding newly assigned partitions: test-topic-0000209-PZuErwo-0
13:47:27.265 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Found no committed offset for partition test-topic-0000209-PZuErwo-0
13:47:27.266 [pool-74-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-209-I8XtIkQ-70, groupId=sub-209-I8XtIkQ] Resetting offset for partition test-topic-0000209-PZuErwo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.270 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-215-2NGygFY-72-b56164dd-3cd6-4a2f-af3a-b916b189ebf8', protocol='range'}
13:47:27.270 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Finished assignment for group at generation 1: {consumer-sub-215-2NGygFY-72-b56164dd-3cd6-4a2f-af3a-b916b189ebf8=Assignment(partitions=[test-topic-0000215-Zb4mOoY-0])}
13:47:27.271 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-215-2NGygFY-72-b56164dd-3cd6-4a2f-af3a-b916b189ebf8', protocol='range'}
13:47:27.271 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Notifying assignor about the new Assignment(partitions=[test-topic-0000215-Zb4mOoY-0])
13:47:27.271 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Adding newly assigned partitions: test-topic-0000215-Zb4mOoY-0
13:47:27.272 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Found no committed offset for partition test-topic-0000215-Zb4mOoY-0
13:47:27.273 [pool-76-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-215-2NGygFY-72, groupId=sub-215-2NGygFY] Resetting offset for partition test-topic-0000215-Zb4mOoY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.277 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-218-FyCfM7w-73-33e9ffd8-c160-4741-8ecd-83a9e45136f3', protocol='range'}
13:47:27.277 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Finished assignment for group at generation 1: {consumer-sub-218-FyCfM7w-73-33e9ffd8-c160-4741-8ecd-83a9e45136f3=Assignment(partitions=[test-topic-0000218-6mkEIxQ-0])}
13:47:27.278 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-218-FyCfM7w-73-33e9ffd8-c160-4741-8ecd-83a9e45136f3', protocol='range'}
13:47:27.278 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Notifying assignor about the new Assignment(partitions=[test-topic-0000218-6mkEIxQ-0])
13:47:27.279 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Adding newly assigned partitions: test-topic-0000218-6mkEIxQ-0
13:47:27.279 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Found no committed offset for partition test-topic-0000218-6mkEIxQ-0
13:47:27.280 [pool-77-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-218-FyCfM7w-73, groupId=sub-218-FyCfM7w] Resetting offset for partition test-topic-0000218-6mkEIxQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.282 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-221-skRvMk0-74-88754948-7f56-495d-b124-ef92717f3337', protocol='range'}
13:47:27.282 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Finished assignment for group at generation 1: {consumer-sub-221-skRvMk0-74-88754948-7f56-495d-b124-ef92717f3337=Assignment(partitions=[test-topic-0000221-7QIO4vA-0])}
13:47:27.284 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-221-skRvMk0-74-88754948-7f56-495d-b124-ef92717f3337', protocol='range'}
13:47:27.284 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Notifying assignor about the new Assignment(partitions=[test-topic-0000221-7QIO4vA-0])
13:47:27.284 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-224-ps_IW0s-75-6e427e3a-b9d3-4390-863e-25730d787b37', protocol='range'}
13:47:27.284 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Adding newly assigned partitions: test-topic-0000221-7QIO4vA-0
13:47:27.284 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Finished assignment for group at generation 1: {consumer-sub-224-ps_IW0s-75-6e427e3a-b9d3-4390-863e-25730d787b37=Assignment(partitions=[test-topic-0000224-vd-16Eg-0])}
13:47:27.284 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Found no committed offset for partition test-topic-0000221-7QIO4vA-0
13:47:27.286 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-224-ps_IW0s-75-6e427e3a-b9d3-4390-863e-25730d787b37', protocol='range'}
13:47:27.286 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Notifying assignor about the new Assignment(partitions=[test-topic-0000224-vd-16Eg-0])
13:47:27.286 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Adding newly assigned partitions: test-topic-0000224-vd-16Eg-0
13:47:27.286 [pool-78-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-221-skRvMk0-74, groupId=sub-221-skRvMk0] Resetting offset for partition test-topic-0000221-7QIO4vA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.286 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Found no committed offset for partition test-topic-0000224-vd-16Eg-0
13:47:27.286 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.288 [pool-79-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-224-ps_IW0s-75, groupId=sub-224-ps_IW0s] Resetting offset for partition test-topic-0000224-vd-16Eg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.289 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-0 after sending 136 messages. Shutting down.
13:47:27.289 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.290 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-227-CI5qRC4-76-34fb7dfa-ecb1-471c-a761-58343d43796e', protocol='range'}
13:47:27.290 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Finished assignment for group at generation 1: {consumer-sub-227-CI5qRC4-76-34fb7dfa-ecb1-471c-a761-58343d43796e=Assignment(partitions=[test-topic-0000227-PhYZ_-4-0])}
13:47:27.292 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-227-CI5qRC4-76-34fb7dfa-ecb1-471c-a761-58343d43796e', protocol='range'}
13:47:27.292 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Notifying assignor about the new Assignment(partitions=[test-topic-0000227-PhYZ_-4-0])
13:47:27.292 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Adding newly assigned partitions: test-topic-0000227-PhYZ_-4-0
13:47:27.293 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Found no committed offset for partition test-topic-0000227-PhYZ_-4-0
13:47:27.294 [pool-80-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-227-CI5qRC4-76, groupId=sub-227-CI5qRC4] Resetting offset for partition test-topic-0000227-PhYZ_-4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.294 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-230-ZxkW-J4-77-f0042df0-bf7e-4878-9141-f9c256290032', protocol='range'}
13:47:27.294 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Finished assignment for group at generation 1: {consumer-sub-230-ZxkW-J4-77-f0042df0-bf7e-4878-9141-f9c256290032=Assignment(partitions=[test-topic-0000230-4s4B6Wc-0])}
13:47:27.296 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-230-ZxkW-J4-77-f0042df0-bf7e-4878-9141-f9c256290032', protocol='range'}
13:47:27.296 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Notifying assignor about the new Assignment(partitions=[test-topic-0000230-4s4B6Wc-0])
13:47:27.296 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Adding newly assigned partitions: test-topic-0000230-4s4B6Wc-0
13:47:27.297 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Found no committed offset for partition test-topic-0000230-4s4B6Wc-0
13:47:27.298 [pool-81-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-230-ZxkW-J4-77, groupId=sub-230-ZxkW-J4] Resetting offset for partition test-topic-0000230-4s4B6Wc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.300 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-233-DyuGDYs-78-2f4c5f13-564f-49a9-82b0-bc171d219570', protocol='range'}
13:47:27.300 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Finished assignment for group at generation 1: {consumer-sub-233-DyuGDYs-78-2f4c5f13-564f-49a9-82b0-bc171d219570=Assignment(partitions=[test-topic-0000233-0IL1GHA-0])}
13:47:27.302 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-233-DyuGDYs-78-2f4c5f13-564f-49a9-82b0-bc171d219570', protocol='range'}
13:47:27.302 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Notifying assignor about the new Assignment(partitions=[test-topic-0000233-0IL1GHA-0])
13:47:27.302 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Adding newly assigned partitions: test-topic-0000233-0IL1GHA-0
13:47:27.303 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Found no committed offset for partition test-topic-0000233-0IL1GHA-0
13:47:27.304 [pool-82-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-233-DyuGDYs-78, groupId=sub-233-DyuGDYs] Resetting offset for partition test-topic-0000233-0IL1GHA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.307 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-236-QpyZKpQ-79-4ec37d98-d77f-4fdd-8e94-c0ff00e1c11f', protocol='range'}
13:47:27.307 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Finished assignment for group at generation 1: {consumer-sub-236-QpyZKpQ-79-4ec37d98-d77f-4fdd-8e94-c0ff00e1c11f=Assignment(partitions=[test-topic-0000236-5rPzsFQ-0])}
13:47:27.309 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-236-QpyZKpQ-79-4ec37d98-d77f-4fdd-8e94-c0ff00e1c11f', protocol='range'}
13:47:27.309 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000236-5rPzsFQ-0])
13:47:27.309 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Adding newly assigned partitions: test-topic-0000236-5rPzsFQ-0
13:47:27.310 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Found no committed offset for partition test-topic-0000236-5rPzsFQ-0
13:47:27.311 [pool-83-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-236-QpyZKpQ-79, groupId=sub-236-QpyZKpQ] Resetting offset for partition test-topic-0000236-5rPzsFQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.315 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-239-t3Nr_TI-80-43c0b98d-b35e-404e-aec1-bc42d9b58964', protocol='range'}
13:47:27.315 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Finished assignment for group at generation 1: {consumer-sub-239-t3Nr_TI-80-43c0b98d-b35e-404e-aec1-bc42d9b58964=Assignment(partitions=[test-topic-0000239-m_eFS6M-0])}
13:47:27.316 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-239-t3Nr_TI-80-43c0b98d-b35e-404e-aec1-bc42d9b58964', protocol='range'}
13:47:27.316 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Notifying assignor about the new Assignment(partitions=[test-topic-0000239-m_eFS6M-0])
13:47:27.317 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Adding newly assigned partitions: test-topic-0000239-m_eFS6M-0
13:47:27.317 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Found no committed offset for partition test-topic-0000239-m_eFS6M-0
13:47:27.319 [pool-84-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-239-t3Nr_TI-80, groupId=sub-239-t3Nr_TI] Resetting offset for partition test-topic-0000239-m_eFS6M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.321 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.324 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-1 after sending 136 messages. Shutting down.
13:47:27.324 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.326 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-242-Bh6f6XI-81-b78f5f0a-8447-40ca-ae30-269937985336', protocol='range'}
13:47:27.326 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-245-ycGychY-82-0d6623f4-b061-415e-9823-d00a159cb2a9', protocol='range'}
13:47:27.326 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Finished assignment for group at generation 1: {consumer-sub-245-ycGychY-82-0d6623f4-b061-415e-9823-d00a159cb2a9=Assignment(partitions=[test-topic-0000245-wLMd2DQ-0])}
13:47:27.327 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Finished assignment for group at generation 1: {consumer-sub-242-Bh6f6XI-81-b78f5f0a-8447-40ca-ae30-269937985336=Assignment(partitions=[test-topic-0000242-5iXW5yk-0])}
13:47:27.328 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-242-Bh6f6XI-81-b78f5f0a-8447-40ca-ae30-269937985336', protocol='range'}
13:47:27.328 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-245-ycGychY-82-0d6623f4-b061-415e-9823-d00a159cb2a9', protocol='range'}
13:47:27.328 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Notifying assignor about the new Assignment(partitions=[test-topic-0000242-5iXW5yk-0])
13:47:27.328 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Adding newly assigned partitions: test-topic-0000242-5iXW5yk-0
13:47:27.329 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Notifying assignor about the new Assignment(partitions=[test-topic-0000245-wLMd2DQ-0])
13:47:27.329 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Adding newly assigned partitions: test-topic-0000245-wLMd2DQ-0
13:47:27.329 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Found no committed offset for partition test-topic-0000242-5iXW5yk-0
13:47:27.329 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Found no committed offset for partition test-topic-0000245-wLMd2DQ-0
13:47:27.331 [pool-85-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-242-Bh6f6XI-81, groupId=sub-242-Bh6f6XI] Resetting offset for partition test-topic-0000242-5iXW5yk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.331 [pool-86-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-245-ycGychY-82, groupId=sub-245-ycGychY] Resetting offset for partition test-topic-0000245-wLMd2DQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.341 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-248-m9k_AXQ-83-d4d79b69-896c-4649-a3b5-07c46abd4313', protocol='range'}
13:47:27.342 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Finished assignment for group at generation 1: {consumer-sub-248-m9k_AXQ-83-d4d79b69-896c-4649-a3b5-07c46abd4313=Assignment(partitions=[test-topic-0000248-1cRH_ZI-0])}
13:47:27.343 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-248-m9k_AXQ-83-d4d79b69-896c-4649-a3b5-07c46abd4313', protocol='range'}
13:47:27.343 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000248-1cRH_ZI-0])
13:47:27.343 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Adding newly assigned partitions: test-topic-0000248-1cRH_ZI-0
13:47:27.344 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Found no committed offset for partition test-topic-0000248-1cRH_ZI-0
13:47:27.345 [pool-87-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-248-m9k_AXQ-83, groupId=sub-248-m9k_AXQ] Resetting offset for partition test-topic-0000248-1cRH_ZI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.351 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.352 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-2 after sending 136 messages. Shutting down.
13:47:27.353 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-251-P61INns-84-8bfb76cc-8a4c-4ce2-ad8f-556da26dbfeb', protocol='range'}
13:47:27.353 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.353 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Finished assignment for group at generation 1: {consumer-sub-251-P61INns-84-8bfb76cc-8a4c-4ce2-ad8f-556da26dbfeb=Assignment(partitions=[test-topic-0000251-eeL7Zsc-0])}
13:47:27.354 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-251-P61INns-84-8bfb76cc-8a4c-4ce2-ad8f-556da26dbfeb', protocol='range'}
13:47:27.355 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Notifying assignor about the new Assignment(partitions=[test-topic-0000251-eeL7Zsc-0])
13:47:27.355 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Adding newly assigned partitions: test-topic-0000251-eeL7Zsc-0
13:47:27.355 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Found no committed offset for partition test-topic-0000251-eeL7Zsc-0
13:47:27.357 [pool-88-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-251-P61INns-84, groupId=sub-251-P61INns] Resetting offset for partition test-topic-0000251-eeL7Zsc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.361 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-257-41n5rmU-86-acf2952e-2f77-4a29-a1d3-1af4a2f5ef3d', protocol='range'}
13:47:27.362 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-254-hjh2HZQ-85-62b8c060-c57d-47e3-8222-0e648f538fc8', protocol='range'}
13:47:27.362 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Finished assignment for group at generation 1: {consumer-sub-257-41n5rmU-86-acf2952e-2f77-4a29-a1d3-1af4a2f5ef3d=Assignment(partitions=[test-topic-0000257-P_M3hrc-0])}
13:47:27.362 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Finished assignment for group at generation 1: {consumer-sub-254-hjh2HZQ-85-62b8c060-c57d-47e3-8222-0e648f538fc8=Assignment(partitions=[test-topic-0000254-CpZ6PWw-0])}
13:47:27.363 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-254-hjh2HZQ-85-62b8c060-c57d-47e3-8222-0e648f538fc8', protocol='range'}
13:47:27.363 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000254-CpZ6PWw-0])
13:47:27.364 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Adding newly assigned partitions: test-topic-0000254-CpZ6PWw-0
13:47:27.364 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-257-41n5rmU-86-acf2952e-2f77-4a29-a1d3-1af4a2f5ef3d', protocol='range'}
13:47:27.364 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Notifying assignor about the new Assignment(partitions=[test-topic-0000257-P_M3hrc-0])
13:47:27.364 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Adding newly assigned partitions: test-topic-0000257-P_M3hrc-0
13:47:27.364 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Found no committed offset for partition test-topic-0000254-CpZ6PWw-0
13:47:27.364 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Found no committed offset for partition test-topic-0000257-P_M3hrc-0
13:47:27.366 [pool-89-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-254-hjh2HZQ-85, groupId=sub-254-hjh2HZQ] Resetting offset for partition test-topic-0000254-CpZ6PWw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.366 [pool-90-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-257-41n5rmU-86, groupId=sub-257-41n5rmU] Resetting offset for partition test-topic-0000257-P_M3hrc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.371 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-260-nhO5cZo-87-63d0a23d-5298-4552-baed-0926cf2041bb', protocol='range'}
13:47:27.371 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Finished assignment for group at generation 1: {consumer-sub-260-nhO5cZo-87-63d0a23d-5298-4552-baed-0926cf2041bb=Assignment(partitions=[test-topic-0000260-DnsmC54-0])}
13:47:27.373 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-260-nhO5cZo-87-63d0a23d-5298-4552-baed-0926cf2041bb', protocol='range'}
13:47:27.373 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Notifying assignor about the new Assignment(partitions=[test-topic-0000260-DnsmC54-0])
13:47:27.373 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Adding newly assigned partitions: test-topic-0000260-DnsmC54-0
13:47:27.374 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Found no committed offset for partition test-topic-0000260-DnsmC54-0
13:47:27.374 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.375 [pool-91-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-260-nhO5cZo-87, groupId=sub-260-nhO5cZo] Resetting offset for partition test-topic-0000260-DnsmC54-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.375 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-3 after sending 136 messages. Shutting down.
13:47:27.375 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.376 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-263-KhJJCEI-88-2ac8fb2c-b847-4127-ae15-feeda7bcdf75', protocol='range'}
13:47:27.376 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Finished assignment for group at generation 1: {consumer-sub-263-KhJJCEI-88-2ac8fb2c-b847-4127-ae15-feeda7bcdf75=Assignment(partitions=[test-topic-0000263-OjpC5g8-0])}
13:47:27.378 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-263-KhJJCEI-88-2ac8fb2c-b847-4127-ae15-feeda7bcdf75', protocol='range'}
13:47:27.378 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-266-DtdrO2U-89-1ab97276-4051-49c6-aba8-3079d6a7855f', protocol='range'}
13:47:27.378 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Notifying assignor about the new Assignment(partitions=[test-topic-0000263-OjpC5g8-0])
13:47:27.378 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Adding newly assigned partitions: test-topic-0000263-OjpC5g8-0
13:47:27.378 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Finished assignment for group at generation 1: {consumer-sub-266-DtdrO2U-89-1ab97276-4051-49c6-aba8-3079d6a7855f=Assignment(partitions=[test-topic-0000266-pK4XlDY-0])}
13:47:27.379 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Found no committed offset for partition test-topic-0000263-OjpC5g8-0
13:47:27.380 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-266-DtdrO2U-89-1ab97276-4051-49c6-aba8-3079d6a7855f', protocol='range'}
13:47:27.380 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Notifying assignor about the new Assignment(partitions=[test-topic-0000266-pK4XlDY-0])
13:47:27.380 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Adding newly assigned partitions: test-topic-0000266-pK4XlDY-0
13:47:27.381 [pool-92-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-263-KhJJCEI-88, groupId=sub-263-KhJJCEI] Resetting offset for partition test-topic-0000263-OjpC5g8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.381 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Found no committed offset for partition test-topic-0000266-pK4XlDY-0
13:47:27.383 [pool-93-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-266-DtdrO2U-89, groupId=sub-266-DtdrO2U] Resetting offset for partition test-topic-0000266-pK4XlDY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.384 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-269-U6vcn9Y-90-3a4c7166-fd6e-439c-b21a-27ce71062056', protocol='range'}
13:47:27.384 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Finished assignment for group at generation 1: {consumer-sub-269-U6vcn9Y-90-3a4c7166-fd6e-439c-b21a-27ce71062056=Assignment(partitions=[test-topic-0000269-7mR6KMk-0])}
13:47:27.387 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-269-U6vcn9Y-90-3a4c7166-fd6e-439c-b21a-27ce71062056', protocol='range'}
13:47:27.387 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Notifying assignor about the new Assignment(partitions=[test-topic-0000269-7mR6KMk-0])
13:47:27.387 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Adding newly assigned partitions: test-topic-0000269-7mR6KMk-0
13:47:27.387 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Found no committed offset for partition test-topic-0000269-7mR6KMk-0
13:47:27.389 [pool-94-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-269-U6vcn9Y-90, groupId=sub-269-U6vcn9Y] Resetting offset for partition test-topic-0000269-7mR6KMk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.394 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.394 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-272-iyWy1Xg-91-f901542b-a75c-4b24-ba5f-aa75c244dda9', protocol='range'}
13:47:27.394 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Finished assignment for group at generation 1: {consumer-sub-272-iyWy1Xg-91-f901542b-a75c-4b24-ba5f-aa75c244dda9=Assignment(partitions=[test-topic-0000272-GXSuIMg-0])}
13:47:27.395 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-4 after sending 136 messages. Shutting down.
13:47:27.396 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.396 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-272-iyWy1Xg-91-f901542b-a75c-4b24-ba5f-aa75c244dda9', protocol='range'}
13:47:27.396 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Notifying assignor about the new Assignment(partitions=[test-topic-0000272-GXSuIMg-0])
13:47:27.396 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Adding newly assigned partitions: test-topic-0000272-GXSuIMg-0
13:47:27.397 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Found no committed offset for partition test-topic-0000272-GXSuIMg-0
13:47:27.398 [pool-95-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-272-iyWy1Xg-91, groupId=sub-272-iyWy1Xg] Resetting offset for partition test-topic-0000272-GXSuIMg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.402 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-275-vG7rzWg-92-dfc5386c-a02d-45d5-b108-eb13809f0668', protocol='range'}
13:47:27.403 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Finished assignment for group at generation 1: {consumer-sub-275-vG7rzWg-92-dfc5386c-a02d-45d5-b108-eb13809f0668=Assignment(partitions=[test-topic-0000275-I49nzkY-0])}
13:47:27.405 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-275-vG7rzWg-92-dfc5386c-a02d-45d5-b108-eb13809f0668', protocol='range'}
13:47:27.405 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Notifying assignor about the new Assignment(partitions=[test-topic-0000275-I49nzkY-0])
13:47:27.405 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Adding newly assigned partitions: test-topic-0000275-I49nzkY-0
13:47:27.405 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Found no committed offset for partition test-topic-0000275-I49nzkY-0
13:47:27.406 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-278-1tayTsg-93-9719dd9c-a1b2-4e6c-bdd2-38587dd39e14', protocol='range'}
13:47:27.406 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Finished assignment for group at generation 1: {consumer-sub-278-1tayTsg-93-9719dd9c-a1b2-4e6c-bdd2-38587dd39e14=Assignment(partitions=[test-topic-0000278-zWRdAgQ-0])}
13:47:27.407 [pool-96-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-275-vG7rzWg-92, groupId=sub-275-vG7rzWg] Resetting offset for partition test-topic-0000275-I49nzkY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.408 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-278-1tayTsg-93-9719dd9c-a1b2-4e6c-bdd2-38587dd39e14', protocol='range'}
13:47:27.408 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Notifying assignor about the new Assignment(partitions=[test-topic-0000278-zWRdAgQ-0])
13:47:27.408 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Adding newly assigned partitions: test-topic-0000278-zWRdAgQ-0
13:47:27.409 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Found no committed offset for partition test-topic-0000278-zWRdAgQ-0
13:47:27.410 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.410 [pool-97-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-278-1tayTsg-93, groupId=sub-278-1tayTsg] Resetting offset for partition test-topic-0000278-zWRdAgQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.410 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-281-hYTH_Cs-94-d9399126-343d-45ae-b38e-23e476b54076', protocol='range'}
13:47:27.411 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Finished assignment for group at generation 1: {consumer-sub-281-hYTH_Cs-94-d9399126-343d-45ae-b38e-23e476b54076=Assignment(partitions=[test-topic-0000281-FQQUyA4-0])}
13:47:27.412 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-5 after sending 136 messages. Shutting down.
13:47:27.412 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.412 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-281-hYTH_Cs-94-d9399126-343d-45ae-b38e-23e476b54076', protocol='range'}
13:47:27.413 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Notifying assignor about the new Assignment(partitions=[test-topic-0000281-FQQUyA4-0])
13:47:27.413 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Adding newly assigned partitions: test-topic-0000281-FQQUyA4-0
13:47:27.413 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Found no committed offset for partition test-topic-0000281-FQQUyA4-0
13:47:27.414 [pool-98-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-281-hYTH_Cs-94, groupId=sub-281-hYTH_Cs] Resetting offset for partition test-topic-0000281-FQQUyA4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.419 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-284-dW1PM8U-95-4e0129aa-9bb4-4d3a-b013-8c1ce8497112', protocol='range'}
13:47:27.419 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Finished assignment for group at generation 1: {consumer-sub-284-dW1PM8U-95-4e0129aa-9bb4-4d3a-b013-8c1ce8497112=Assignment(partitions=[test-topic-0000284-Agh4b5c-0])}
13:47:27.420 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-284-dW1PM8U-95-4e0129aa-9bb4-4d3a-b013-8c1ce8497112', protocol='range'}
13:47:27.420 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Notifying assignor about the new Assignment(partitions=[test-topic-0000284-Agh4b5c-0])
13:47:27.420 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Adding newly assigned partitions: test-topic-0000284-Agh4b5c-0
13:47:27.421 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Found no committed offset for partition test-topic-0000284-Agh4b5c-0
13:47:27.422 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-287-aBu5cu8-96-37b37836-68f5-4438-91dd-c0e08d44b894', protocol='range'}
13:47:27.422 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Finished assignment for group at generation 1: {consumer-sub-287-aBu5cu8-96-37b37836-68f5-4438-91dd-c0e08d44b894=Assignment(partitions=[test-topic-0000287-3fcwIsk-0])}
13:47:27.422 [pool-99-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-284-dW1PM8U-95, groupId=sub-284-dW1PM8U] Resetting offset for partition test-topic-0000284-Agh4b5c-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.425 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-287-aBu5cu8-96-37b37836-68f5-4438-91dd-c0e08d44b894', protocol='range'}
13:47:27.425 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Notifying assignor about the new Assignment(partitions=[test-topic-0000287-3fcwIsk-0])
13:47:27.425 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Adding newly assigned partitions: test-topic-0000287-3fcwIsk-0
13:47:27.425 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Found no committed offset for partition test-topic-0000287-3fcwIsk-0
13:47:27.427 [pool-100-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-287-aBu5cu8-96, groupId=sub-287-aBu5cu8] Resetting offset for partition test-topic-0000287-3fcwIsk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.428 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-290-rV8Kfqc-97-53c49796-0afa-47cf-9369-f3ca05edc678', protocol='range'}
13:47:27.428 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Finished assignment for group at generation 1: {consumer-sub-290-rV8Kfqc-97-53c49796-0afa-47cf-9369-f3ca05edc678=Assignment(partitions=[test-topic-0000290-5aCzRUQ-0])}
13:47:27.428 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.430 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-290-rV8Kfqc-97-53c49796-0afa-47cf-9369-f3ca05edc678', protocol='range'}
13:47:27.430 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-6 after sending 136 messages. Shutting down.
13:47:27.430 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Notifying assignor about the new Assignment(partitions=[test-topic-0000290-5aCzRUQ-0])
13:47:27.430 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 1667 | Max 3334
13:47:27.430 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Adding newly assigned partitions: test-topic-0000290-5aCzRUQ-0
13:47:27.431 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Found no committed offset for partition test-topic-0000290-5aCzRUQ-0
13:47:27.433 [pool-101-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-290-rV8Kfqc-97, groupId=sub-290-rV8Kfqc] Resetting offset for partition test-topic-0000290-5aCzRUQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.440 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-293-18lz3Qk-98-e6565a8c-7697-47ac-af75-63e9b82da44a', protocol='range'}
13:47:27.440 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Finished assignment for group at generation 1: {consumer-sub-293-18lz3Qk-98-e6565a8c-7697-47ac-af75-63e9b82da44a=Assignment(partitions=[test-topic-0000293-H8U0kX0-0])}
13:47:27.442 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-293-18lz3Qk-98-e6565a8c-7697-47ac-af75-63e9b82da44a', protocol='range'}
13:47:27.442 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Notifying assignor about the new Assignment(partitions=[test-topic-0000293-H8U0kX0-0])
13:47:27.442 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Adding newly assigned partitions: test-topic-0000293-H8U0kX0-0
13:47:27.443 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Found no committed offset for partition test-topic-0000293-H8U0kX0-0
13:47:27.444 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-296-xM-Hg_s-99-5adeaa4d-572d-4292-adb3-7617b3530861', protocol='range'}
13:47:27.444 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Finished assignment for group at generation 1: {consumer-sub-296-xM-Hg_s-99-5adeaa4d-572d-4292-adb3-7617b3530861=Assignment(partitions=[test-topic-0000296-217YnkM-0])}
13:47:27.445 [pool-102-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-293-18lz3Qk-98, groupId=sub-293-18lz3Qk] Resetting offset for partition test-topic-0000293-H8U0kX0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.446 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-296-xM-Hg_s-99-5adeaa4d-572d-4292-adb3-7617b3530861', protocol='range'}
13:47:27.446 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Notifying assignor about the new Assignment(partitions=[test-topic-0000296-217YnkM-0])
13:47:27.446 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Adding newly assigned partitions: test-topic-0000296-217YnkM-0
13:47:27.446 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Found no committed offset for partition test-topic-0000296-217YnkM-0
13:47:27.447 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.448 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-299-V-SUwIA-100-42a09731-826b-449b-99e1-6ec6b010bae9', protocol='range'}
13:47:27.448 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Finished assignment for group at generation 1: {consumer-sub-299-V-SUwIA-100-42a09731-826b-449b-99e1-6ec6b010bae9=Assignment(partitions=[test-topic-0000299-9nrgwQo-0])}
13:47:27.448 [pool-103-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-296-xM-Hg_s-99, groupId=sub-296-xM-Hg_s] Resetting offset for partition test-topic-0000296-217YnkM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.449 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 1-7 after sending 136 messages. Shutting down.
13:47:27.450 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-299-V-SUwIA-100-42a09731-826b-449b-99e1-6ec6b010bae9', protocol='range'}
13:47:27.450 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Notifying assignor about the new Assignment(partitions=[test-topic-0000299-9nrgwQo-0])
13:47:27.450 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Adding newly assigned partitions: test-topic-0000299-9nrgwQo-0
13:47:27.450 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Found no committed offset for partition test-topic-0000299-9nrgwQo-0
13:47:27.452 [pool-104-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-299-V-SUwIA-100, groupId=sub-299-V-SUwIA] Resetting offset for partition test-topic-0000299-9nrgwQo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.454 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-302-dY8BOm4-101-a930c212-dabf-4459-9347-fc4ed8820195', protocol='range'}
13:47:27.454 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Finished assignment for group at generation 1: {consumer-sub-302-dY8BOm4-101-a930c212-dabf-4459-9347-fc4ed8820195=Assignment(partitions=[test-topic-0000302-DlyJbtk-0])}
13:47:27.456 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-302-dY8BOm4-101-a930c212-dabf-4459-9347-fc4ed8820195', protocol='range'}
13:47:27.456 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Notifying assignor about the new Assignment(partitions=[test-topic-0000302-DlyJbtk-0])
13:47:27.456 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Adding newly assigned partitions: test-topic-0000302-DlyJbtk-0
13:47:27.456 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Found no committed offset for partition test-topic-0000302-DlyJbtk-0
13:47:27.458 [pool-105-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-302-dY8BOm4-101, groupId=sub-302-dY8BOm4] Resetting offset for partition test-topic-0000302-DlyJbtk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
