13:47:15.642 [main] INFO log - Logging initialized @3697ms to org.eclipse.jetty.util.log.Slf4jLog
13:47:15.724 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
13:47:15.756 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@323e8306{/,null,AVAILABLE}
13:47:15.772 [main] INFO AbstractConnector - Started ServerConnector@733c423e{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
13:47:15.772 [main] INFO Server - Started @3830ms
13:47:15.774 [main] INFO PrometheusMetricsProvider - Started Prometheus stats endpoint at 0.0.0.0:8081
13:47:15.812 [main] INFO BenchmarkWorker - Starting benchmark with config: {
  "httpPort" : 8080,
  "statsPort" : 8081
}
13:47:15.856 [main] INFO Javalin - 
 _________________________________________
|        _                  _ _           |
|       | | __ ___   ____ _| (_)_ __      |
|    _  | |/ _` \ \ / / _` | | | '_ \     |
|   | |_| | (_| |\ V / (_| | | | | | |    |
|    \___/ \__,_| \_/ \__,_|_|_|_| |_|    |
|_________________________________________|
|                                         |
|    https://javalin.io/documentation     |
|_________________________________________|
13:47:15.858 [main] INFO Javalin - Starting Javalin ...
13:47:15.865 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
13:47:15.878 [main] INFO session - DefaultSessionIdManager workerName=node0
13:47:15.878 [main] INFO session - No SessionScavenger set, using defaults
13:47:15.879 [main] INFO session - node0 Scavenging every 660000ms
13:47:15.880 [main] INFO ContextHandler - Started i.j.e.j.@69b2f8e5{/,null,AVAILABLE}
13:47:15.881 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@a10c1b5{/,null,AVAILABLE}
13:47:15.882 [main] INFO AbstractConnector - Started ServerConnector@c3c4c1c{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
13:47:15.882 [main] INFO Server - Started @3941ms
13:47:15.882 [main] INFO EmbeddedServer - Jetty is listening on: [http://localhost:8080]
13:47:15.882 [main] INFO Javalin - Javalin has started \o/
13:47:15.952 [main] INFO InstanceWorkerStats - Instance worker stats initialized.
13:47:20.910 [qtp435803541-24] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
13:47:20.936 [qtp435803541-24] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

13:47:20.991 [qtp435803541-24] INFO AppInfoParser - Kafka version: 3.6.1
13:47:20.991 [qtp435803541-24] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:20.991 [qtp435803541-24] INFO AppInfoParser - Kafka startTimeMs: 1717336040990
13:47:24.491 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-003-0UoWg7A-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-003-0UoWg7A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.529 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.529 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.529 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044529
13:47:24.530 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Subscribed to topic(s): test-topic-0000003-KFfayTM
13:47:24.535 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-006-aUhexWc-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-006-aUhexWc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.542 [pool-5-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.543 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.544 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] (Re-)joining group
13:47:24.545 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.545 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.545 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044545
13:47:24.546 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Subscribed to topic(s): test-topic-0000006-c-q-i_g
13:47:24.547 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-009-cMbbSZU-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-009-cMbbSZU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.550 [pool-6-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.550 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.551 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] (Re-)joining group
13:47:24.557 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.558 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.558 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044557
13:47:24.558 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Subscribed to topic(s): test-topic-0000009-AqQ2Zlw
13:47:24.559 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-012-eu2G-4s-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-012-eu2G-4s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.560 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Request joining group due to: need to re-join with the given member-id: consumer-sub-006-aUhexWc-2-ef47cab8-1868-4b2e-812e-6f1dae868b6c
13:47:24.560 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Request joining group due to: need to re-join with the given member-id: consumer-sub-003-0UoWg7A-1-3c859a36-127e-4b0e-ab61-97d6a38913f3
13:47:24.560 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.560 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.561 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] (Re-)joining group
13:47:24.561 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] (Re-)joining group
13:47:24.563 [pool-7-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.564 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.564 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] (Re-)joining group
13:47:24.568 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.568 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.568 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Request joining group due to: need to re-join with the given member-id: consumer-sub-009-cMbbSZU-3-2bca2ea4-85c8-4655-9e82-b57e23cc889c
13:47:24.568 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044568
13:47:24.569 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.569 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] (Re-)joining group
13:47:24.569 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Subscribed to topic(s): test-topic-0000012-YCyXSbE
13:47:24.570 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-015-ApWU4ds-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-015-ApWU4ds
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.572 [pool-8-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.573 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.573 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] (Re-)joining group
13:47:24.576 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Request joining group due to: need to re-join with the given member-id: consumer-sub-012-eu2G-4s-4-233f7c66-1649-410b-9665-d3cfeff50859
13:47:24.576 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.576 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] (Re-)joining group
13:47:24.578 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.578 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.579 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044578
13:47:24.579 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Subscribed to topic(s): test-topic-0000015-URbXFF4
13:47:24.580 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-018-OpDGV-0-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-018-OpDGV-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.582 [pool-9-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.583 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.583 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] (Re-)joining group
13:47:24.586 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Request joining group due to: need to re-join with the given member-id: consumer-sub-015-ApWU4ds-5-0a08a230-89b8-4f45-812d-55e97a37c8b1
13:47:24.586 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.586 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] (Re-)joining group
13:47:24.588 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.588 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.588 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044588
13:47:24.589 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Subscribed to topic(s): test-topic-0000018-o_iMPj4
13:47:24.590 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-021-i3NgyAI-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-021-i3NgyAI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.592 [pool-10-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.592 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.593 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] (Re-)joining group
13:47:24.595 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Request joining group due to: need to re-join with the given member-id: consumer-sub-018-OpDGV-0-6-1838bd7b-9c06-465f-9b99-af517319c178
13:47:24.596 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.596 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] (Re-)joining group
13:47:24.597 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.597 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.597 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044597
13:47:24.598 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Subscribed to topic(s): test-topic-0000021-g1wDjUE
13:47:24.599 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-024-8BS-0vU-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-024-8BS-0vU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.602 [pool-11-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.603 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.603 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] (Re-)joining group
13:47:24.606 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.606 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.606 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044606
13:47:24.607 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Subscribed to topic(s): test-topic-0000024-G8RFGsk
13:47:24.607 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Request joining group due to: need to re-join with the given member-id: consumer-sub-021-i3NgyAI-7-f533da0a-68ee-4f5c-aaf6-9f88561e9a6d
13:47:24.607 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.607 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] (Re-)joining group
13:47:24.608 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-027-gbjWpRs-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-027-gbjWpRs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.610 [pool-12-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.611 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.612 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] (Re-)joining group
13:47:24.614 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.614 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.614 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044614
13:47:24.614 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Request joining group due to: need to re-join with the given member-id: consumer-sub-024-8BS-0vU-8-123df7d0-537b-4a4a-a052-7ef92b9aab15
13:47:24.614 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Subscribed to topic(s): test-topic-0000027-Xa_RnUU
13:47:24.615 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.615 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] (Re-)joining group
13:47:24.616 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-030-ug8aBAo-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-030-ug8aBAo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.618 [pool-13-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.619 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.619 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.619 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.619 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044619
13:47:24.619 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Subscribed to topic(s): test-topic-0000030-SxXiKuo
13:47:24.619 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] (Re-)joining group
13:47:24.620 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-033-ar1WBTU-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-033-ar1WBTU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.623 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Request joining group due to: need to re-join with the given member-id: consumer-sub-027-gbjWpRs-9-d955083d-8990-4e4b-9b0c-bc812cc476c4
13:47:24.623 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.623 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] (Re-)joining group
13:47:24.624 [pool-14-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.624 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.625 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] (Re-)joining group
13:47:24.626 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.626 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.626 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044626
13:47:24.626 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Subscribed to topic(s): test-topic-0000033-I9YklqI
13:47:24.627 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-036-TUEqcZ8-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-036-TUEqcZ8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.628 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Request joining group due to: need to re-join with the given member-id: consumer-sub-030-ug8aBAo-10-4d8f2780-5a70-45f7-83c6-fe5248d91679
13:47:24.628 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.628 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] (Re-)joining group
13:47:24.630 [pool-15-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.631 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.631 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] (Re-)joining group
13:47:24.632 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.633 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.633 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044632
13:47:24.633 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Subscribed to topic(s): test-topic-0000036-KEdU3IU
13:47:24.634 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-039-uNVajws-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-039-uNVajws
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.637 [pool-16-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.634 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Request joining group due to: need to re-join with the given member-id: consumer-sub-033-ar1WBTU-11-ebffdaea-1f44-4d4f-adb5-c7774a7ba6f3
13:47:24.638 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.638 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.638 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] (Re-)joining group
13:47:24.641 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.641 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.641 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044641
13:47:24.641 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Subscribed to topic(s): test-topic-0000039-DLNOGX4
13:47:24.642 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] (Re-)joining group
13:47:24.645 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Request joining group due to: need to re-join with the given member-id: consumer-sub-036-TUEqcZ8-12-ebc8cb3a-eade-4b95-859b-67ad5248dff3
13:47:24.646 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.646 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] (Re-)joining group
13:47:24.648 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-042-7jZZFn4-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-042-7jZZFn4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.651 [pool-17-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.651 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.653 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.653 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.653 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044653
13:47:24.653 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Subscribed to topic(s): test-topic-0000042-IpLh0uQ
13:47:24.653 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] (Re-)joining group
13:47:24.654 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-045-5U4Mi-w-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-045-5U4Mi-w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.656 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Request joining group due to: need to re-join with the given member-id: consumer-sub-039-uNVajws-13-b661e1b1-a484-4d0e-96a4-25c49bbddc06
13:47:24.656 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.656 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] (Re-)joining group
13:47:24.657 [pool-18-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.658 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.660 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.660 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.660 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044660
13:47:24.660 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Subscribed to topic(s): test-topic-0000045-5ePkOy4
13:47:24.660 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] (Re-)joining group
13:47:24.661 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-048-sKkuCFk-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-048-sKkuCFk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.664 [pool-19-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.664 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.665 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] (Re-)joining group
13:47:24.667 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.668 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.668 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Request joining group due to: need to re-join with the given member-id: consumer-sub-045-5U4Mi-w-15-1530983f-96a9-4c18-805a-5a226e481554
13:47:24.668 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044667
13:47:24.668 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.668 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] (Re-)joining group
13:47:24.668 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Subscribed to topic(s): test-topic-0000048-cYfObxU
13:47:24.669 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-051-yzXOEeo-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-051-yzXOEeo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.671 [pool-20-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.672 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.673 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Request joining group due to: need to re-join with the given member-id: consumer-sub-042-7jZZFn4-14-a7e2bc68-fe36-486d-9307-065a24061320
13:47:24.673 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.673 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] (Re-)joining group
13:47:24.673 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.673 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.673 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044673
13:47:24.674 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Subscribed to topic(s): test-topic-0000051-A0OfkLI
13:47:24.675 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] (Re-)joining group
13:47:24.678 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Request joining group due to: need to re-join with the given member-id: consumer-sub-048-sKkuCFk-16-b60cf4a1-e873-4180-8850-0d11e703327a
13:47:24.679 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.679 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] (Re-)joining group
13:47:24.681 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-054-73hEJ48-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-054-73hEJ48
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.682 [pool-21-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.683 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.683 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] (Re-)joining group
13:47:24.685 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.685 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.685 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044685
13:47:24.685 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Request joining group due to: need to re-join with the given member-id: consumer-sub-051-yzXOEeo-17-998cb597-36c9-46e6-b4f6-0e64b22711eb
13:47:24.685 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.685 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Subscribed to topic(s): test-topic-0000054-omow84U
13:47:24.685 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] (Re-)joining group
13:47:24.686 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-057-Rt1H-Uc-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-057-Rt1H-Uc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.688 [pool-22-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.688 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.689 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] (Re-)joining group
13:47:24.690 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.691 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.691 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044690
13:47:24.691 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Request joining group due to: need to re-join with the given member-id: consumer-sub-054-73hEJ48-18-1f4bf7b1-09f5-40f0-98eb-8d59474f6826
13:47:24.691 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Subscribed to topic(s): test-topic-0000057-b1ROO2s
13:47:24.691 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.691 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] (Re-)joining group
13:47:24.692 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-060-DVzPiDs-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-060-DVzPiDs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.694 [pool-23-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.694 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.694 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] (Re-)joining group
13:47:24.696 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.696 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.696 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044696
13:47:24.696 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Request joining group due to: need to re-join with the given member-id: consumer-sub-057-Rt1H-Uc-19-c970361d-ff92-4129-9a0d-e30726025902
13:47:24.697 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Subscribed to topic(s): test-topic-0000060-YhVhRN4
13:47:24.697 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.697 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] (Re-)joining group
13:47:24.697 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-063-DWLnvh0-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-063-DWLnvh0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.700 [pool-24-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.700 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.700 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.700 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044700
13:47:24.700 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.700 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Subscribed to topic(s): test-topic-0000063-TutZTB8
13:47:24.701 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] (Re-)joining group
13:47:24.701 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-066-badRioQ-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-066-badRioQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.703 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Request joining group due to: need to re-join with the given member-id: consumer-sub-060-DVzPiDs-20-e4ff19d8-0daf-4dc9-9fa4-3ee25f29b2de
13:47:24.704 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.704 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] (Re-)joining group
13:47:24.704 [pool-25-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.704 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.705 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] (Re-)joining group
13:47:24.705 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.705 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.706 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044705
13:47:24.706 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Subscribed to topic(s): test-topic-0000066-iVHj7R4
13:47:24.707 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-069-zacfn0w-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-069-zacfn0w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.707 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Request joining group due to: need to re-join with the given member-id: consumer-sub-063-DWLnvh0-21-5bb12345-d466-4b32-b791-7595cb6632b6
13:47:24.708 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.708 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] (Re-)joining group
13:47:24.709 [pool-26-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.709 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.710 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] (Re-)joining group
13:47:24.711 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.711 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.711 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044711
13:47:24.711 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Subscribed to topic(s): test-topic-0000069-j5MG-i8
13:47:24.712 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-066-badRioQ-22-f5ce6f55-9e20-4a7c-a804-6e04df93cb13
13:47:24.712 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-072-rcD_DSA-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-072-rcD_DSA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.712 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.713 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] (Re-)joining group
13:47:24.714 [pool-27-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.714 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.715 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] (Re-)joining group
13:47:24.716 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.716 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.716 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044716
13:47:24.716 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Subscribed to topic(s): test-topic-0000072-atXhL_g
13:47:24.717 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Request joining group due to: need to re-join with the given member-id: consumer-sub-069-zacfn0w-23-0222871c-cd5a-4ce0-aa72-c802d877e237
13:47:24.717 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.717 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] (Re-)joining group
13:47:24.718 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-075-h4sM5Kk-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-075-h4sM5Kk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.720 [pool-28-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.720 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.720 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.720 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044720
13:47:24.721 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Subscribed to topic(s): test-topic-0000075-2Is6uhc
13:47:24.721 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.721 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] (Re-)joining group
13:47:24.722 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-078-KB6LNSk-26
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-078-KB6LNSk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.724 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Request joining group due to: need to re-join with the given member-id: consumer-sub-072-rcD_DSA-24-11939ce4-8de2-4ecc-ae22-8644ed5733a9
13:47:24.724 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.724 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] (Re-)joining group
13:47:24.724 [pool-29-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.725 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.725 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.725 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.725 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044725
13:47:24.725 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Subscribed to topic(s): test-topic-0000078-Wk4biHA
13:47:24.726 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] (Re-)joining group
13:47:24.727 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-081-LEfrf2U-27
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-081-LEfrf2U
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.729 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Request joining group due to: need to re-join with the given member-id: consumer-sub-075-h4sM5Kk-25-ff28c2d9-715a-4e01-92f9-966712525214
13:47:24.729 [pool-30-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.729 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.729 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] (Re-)joining group
13:47:24.729 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.730 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] (Re-)joining group
13:47:24.731 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.731 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.731 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044730
13:47:24.731 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Subscribed to topic(s): test-topic-0000081-slvhhyc
13:47:24.732 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-084-q-2xFSQ-28
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-084-q-2xFSQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.732 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Request joining group due to: need to re-join with the given member-id: consumer-sub-078-KB6LNSk-26-8fef32cf-f9b0-45a4-a5c3-6c3de597249e
13:47:24.732 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.733 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] (Re-)joining group
13:47:24.734 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.734 [pool-31-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.734 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.734 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044734
13:47:24.734 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Subscribed to topic(s): test-topic-0000084-fyVCbbE
13:47:24.734 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.735 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-087-d0I0Wbs-29
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-087-d0I0Wbs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.736 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] (Re-)joining group
13:47:24.737 [pool-32-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.737 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.738 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.738 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.738 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044738
13:47:24.738 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Request joining group due to: need to re-join with the given member-id: consumer-sub-081-LEfrf2U-27-32cb27a5-ca1d-4eea-b9c5-904571f55944
13:47:24.738 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Subscribed to topic(s): test-topic-0000087-81GfjoE
13:47:24.738 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.739 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] (Re-)joining group
13:47:24.739 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] (Re-)joining group
13:47:24.741 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-090-d75WZU8-30
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-090-d75WZU8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.742 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-084-q-2xFSQ-28-21e215f5-f272-45cc-8adf-ea758964b392
13:47:24.742 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.742 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] (Re-)joining group
13:47:24.744 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.744 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.744 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044744
13:47:24.744 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Subscribed to topic(s): test-topic-0000090-2-rWqDI
13:47:24.748 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-093-Cs1epd4-31
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-093-Cs1epd4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.749 [pool-33-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.750 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.751 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.751 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.751 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044751
13:47:24.751 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Subscribed to topic(s): test-topic-0000093-bXeEJlM
13:47:24.752 [pool-34-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.752 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.754 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] (Re-)joining group
13:47:24.756 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] (Re-)joining group
13:47:24.756 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Request joining group due to: need to re-join with the given member-id: consumer-sub-087-d0I0Wbs-29-933d6f8e-c773-4379-9576-d39ec985b295
13:47:24.757 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.757 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] (Re-)joining group
13:47:24.758 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Request joining group due to: need to re-join with the given member-id: consumer-sub-090-d75WZU8-30-8c31ff25-60d9-418a-8df8-8029eca665e5
13:47:24.759 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.759 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] (Re-)joining group
13:47:24.760 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-096-d8pEiis-32
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-096-d8pEiis
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.762 [pool-35-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.764 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.764 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] (Re-)joining group
13:47:24.766 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.766 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.766 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044766
13:47:24.767 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Subscribed to topic(s): test-topic-0000096-mZKQCwo
13:47:24.767 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Request joining group due to: need to re-join with the given member-id: consumer-sub-093-Cs1epd4-31-4ecc8049-8780-41bb-b83c-f4755bd625ba
13:47:24.767 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.767 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] (Re-)joining group
13:47:24.768 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-099-zH2uJSI-33
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-099-zH2uJSI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.770 [pool-36-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.770 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.771 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.771 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.771 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044771
13:47:24.771 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Subscribed to topic(s): test-topic-0000099-1cEYHFU
13:47:24.781 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] (Re-)joining group
13:47:24.782 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-102-w7piq0s-34
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-102-w7piq0s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.783 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Request joining group due to: need to re-join with the given member-id: consumer-sub-096-d8pEiis-32-b7eb56a3-53f0-407e-8810-6d8b09d51ef7
13:47:24.783 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.783 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] (Re-)joining group
13:47:24.785 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.785 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.785 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044785
13:47:24.785 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Subscribed to topic(s): test-topic-0000102-l_C9r5E
13:47:24.785 [pool-37-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.786 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.787 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] (Re-)joining group
13:47:24.787 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-105-gjMdpGk-35
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-105-gjMdpGk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.789 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Request joining group due to: need to re-join with the given member-id: consumer-sub-099-zH2uJSI-33-3fffd459-1c88-417f-8ccb-13daba620900
13:47:24.789 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.789 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] (Re-)joining group
13:47:24.790 [pool-38-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.791 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.791 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.791 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.791 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044791
13:47:24.791 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Subscribed to topic(s): test-topic-0000105-9pKxJ4U
13:47:24.791 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] (Re-)joining group
13:47:24.793 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-108-VQMvh1w-36
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-108-VQMvh1w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.793 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Request joining group due to: need to re-join with the given member-id: consumer-sub-102-w7piq0s-34-7395eb1f-8ca4-4add-9ddd-44bec07d5504
13:47:24.793 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.794 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] (Re-)joining group
13:47:24.795 [pool-39-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.795 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.796 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.796 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] (Re-)joining group
13:47:24.796 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.797 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044796
13:47:24.797 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Subscribed to topic(s): test-topic-0000108-NB7wiDg
13:47:24.798 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Request joining group due to: need to re-join with the given member-id: consumer-sub-105-gjMdpGk-35-d21733a5-91d5-4b27-85e4-2f070fa28e41
13:47:24.799 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.799 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] (Re-)joining group
13:47:24.801 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-111-rfLDPtE-37
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-111-rfLDPtE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.803 [pool-40-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.803 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.804 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] (Re-)joining group
13:47:24.804 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.804 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.804 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044804
13:47:24.805 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Subscribed to topic(s): test-topic-0000111-F9DCrSI
13:47:24.806 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Request joining group due to: need to re-join with the given member-id: consumer-sub-108-VQMvh1w-36-c1059523-2c6f-4158-9996-6bd47cb8859b
13:47:24.806 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-114-CjI2vXU-38
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-114-CjI2vXU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.807 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.807 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] (Re-)joining group
13:47:24.807 [pool-41-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.808 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.808 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] (Re-)joining group
13:47:24.811 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Request joining group due to: need to re-join with the given member-id: consumer-sub-111-rfLDPtE-37-55f3a809-fdd5-4f2b-aca7-b5790f12abc0
13:47:24.811 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.811 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] (Re-)joining group
13:47:24.818 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.818 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.818 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044818
13:47:24.818 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Subscribed to topic(s): test-topic-0000114-W7btOqk
13:47:24.819 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-117-oxxQs5w-39
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-117-oxxQs5w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.822 [pool-42-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.822 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.822 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.822 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044822
13:47:24.822 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.822 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Subscribed to topic(s): test-topic-0000117-qR0MMec
13:47:24.823 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] (Re-)joining group
13:47:24.823 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-120-3MwEZaA-40
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-120-3MwEZaA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.830 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Request joining group due to: need to re-join with the given member-id: consumer-sub-114-CjI2vXU-38-169fd2d1-b90c-41e3-b102-d7982460bfaf
13:47:24.830 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.830 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] (Re-)joining group
13:47:24.830 [pool-43-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.831 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.831 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.831 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044831
13:47:24.831 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.831 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Subscribed to topic(s): test-topic-0000120-0BOroSI
13:47:24.832 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] (Re-)joining group
13:47:24.834 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-123-8btZO2A-41
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-123-8btZO2A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.834 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Request joining group due to: need to re-join with the given member-id: consumer-sub-117-oxxQs5w-39-f8465de1-ac7a-4797-b612-960ac6c9a114
13:47:24.835 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.835 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] (Re-)joining group
13:47:24.837 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.837 [pool-44-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.837 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.838 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044837
13:47:24.838 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.838 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Subscribed to topic(s): test-topic-0000123-NQtdm4o
13:47:24.839 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-126-X5sjNKg-42
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-126-X5sjNKg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.841 [pool-45-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.842 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.842 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.842 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.842 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044842
13:47:24.842 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Subscribed to topic(s): test-topic-0000126-uv0Lyw8
13:47:24.843 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] (Re-)joining group
13:47:24.845 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-129-8OESq3A-43
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-129-8OESq3A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.847 [pool-46-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.847 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.848 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.848 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.848 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044848
13:47:24.848 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Subscribed to topic(s): test-topic-0000129-hjtxynQ
13:47:24.850 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] (Re-)joining group
13:47:24.851 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Request joining group due to: need to re-join with the given member-id: consumer-sub-120-3MwEZaA-40-8aa20cbb-ea75-49b5-b54f-799d35c02c7f
13:47:24.851 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.851 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] (Re-)joining group
13:47:24.851 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-132-eXc28iU-44
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-132-eXc28iU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.852 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Request joining group due to: need to re-join with the given member-id: consumer-sub-123-8btZO2A-41-d00ceeb4-4d66-48c3-829e-4e32b1cd4e7d
13:47:24.852 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.853 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] (Re-)joining group
13:47:24.854 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.855 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.855 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044854
13:47:24.855 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Subscribed to topic(s): test-topic-0000132-cm7Hf-c
13:47:24.855 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] (Re-)joining group
13:47:24.857 [pool-47-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.857 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.857 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Request joining group due to: need to re-join with the given member-id: consumer-sub-126-X5sjNKg-42-e5d70a86-52f4-458f-9e40-5b14a59f8cd7
13:47:24.857 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.857 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] (Re-)joining group
13:47:24.861 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] (Re-)joining group
13:47:24.861 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-135-plEHZ4o-45
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-135-plEHZ4o
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.863 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Request joining group due to: need to re-join with the given member-id: consumer-sub-129-8OESq3A-43-9227cf78-3f65-49ce-a476-065e1ad15730
13:47:24.863 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.863 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] (Re-)joining group
13:47:24.864 [pool-48-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.864 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.864 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.864 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.864 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044864
13:47:24.864 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Subscribed to topic(s): test-topic-0000135-E9VX0MI
13:47:24.867 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] (Re-)joining group
13:47:24.869 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-138-ZgGbhcY-46
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-138-ZgGbhcY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.871 [pool-49-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.869 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Request joining group due to: need to re-join with the given member-id: consumer-sub-132-eXc28iU-44-cabe07aa-1443-459a-8ce8-73c1e7382e8a
13:47:24.872 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.872 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.872 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] (Re-)joining group
13:47:24.872 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] (Re-)joining group
13:47:24.874 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Request joining group due to: need to re-join with the given member-id: consumer-sub-135-plEHZ4o-45-d33885d7-2cac-4d73-ab95-2ba69391b6ad
13:47:24.874 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.874 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.874 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] (Re-)joining group
13:47:24.874 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.875 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044874
13:47:24.875 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Subscribed to topic(s): test-topic-0000138-jGAmpUk
13:47:24.876 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-141-3_O-qMI-47
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-141-3_O-qMI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.877 [pool-50-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.878 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.878 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] (Re-)joining group
13:47:24.879 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.879 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.879 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044878
13:47:24.879 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Subscribed to topic(s): test-topic-0000141-sMY3in0
13:47:24.880 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Request joining group due to: need to re-join with the given member-id: consumer-sub-138-ZgGbhcY-46-dfb4b484-b0e5-4416-9a56-6bae98450193
13:47:24.880 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.881 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] (Re-)joining group
13:47:24.882 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-144-7NIlz98-48
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-144-7NIlz98
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.884 [pool-51-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.884 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.885 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.885 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.885 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044885
13:47:24.885 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Subscribed to topic(s): test-topic-0000144-I87Cc1c
13:47:24.885 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] (Re-)joining group
13:47:24.886 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-147-jNBMJq4-49
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-147-jNBMJq4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.887 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Request joining group due to: need to re-join with the given member-id: consumer-sub-141-3_O-qMI-47-440be29d-f149-48cf-961c-88a149f52206
13:47:24.887 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.887 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] (Re-)joining group
13:47:24.889 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.889 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.889 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044889
13:47:24.889 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Subscribed to topic(s): test-topic-0000147-daxMmRU
13:47:24.890 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-150-2w0ayDQ-50
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-150-2w0ayDQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.892 [pool-52-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.892 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.892 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] (Re-)joining group
13:47:24.893 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.893 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.893 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044893
13:47:24.894 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Subscribed to topic(s): test-topic-0000150-aU4kmlM
13:47:24.894 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Request joining group due to: need to re-join with the given member-id: consumer-sub-144-7NIlz98-48-988877ff-e01d-4288-8bcc-dbdde754aad8
13:47:24.894 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.895 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] (Re-)joining group
13:47:24.895 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-153-XIln-9M-51
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-153-XIln-9M
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.896 [pool-53-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.896 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.905 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] (Re-)joining group
13:47:24.906 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.906 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.906 [pool-54-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.906 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044906
13:47:24.907 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Subscribed to topic(s): test-topic-0000153-7WDuOCQ
13:47:24.907 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.907 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Request joining group due to: need to re-join with the given member-id: consumer-sub-147-jNBMJq4-49-6be70f66-10b7-480b-a6bc-104eb2fa77d7
13:47:24.907 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.907 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] (Re-)joining group
13:47:24.907 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] (Re-)joining group
13:47:24.908 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-156-yGFwrQQ-52
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-156-yGFwrQQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.909 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-150-2w0ayDQ-50-0f535b83-9ba3-4628-9646-7d4d754ad5b7
13:47:24.909 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.909 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] (Re-)joining group
13:47:24.911 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.911 [pool-55-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.911 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.911 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044911
13:47:24.911 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.911 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Subscribed to topic(s): test-topic-0000156-bv1bM3c
13:47:24.912 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-159-mZHXHFA-53
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-159-mZHXHFA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.912 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] (Re-)joining group
13:47:24.914 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Request joining group due to: need to re-join with the given member-id: consumer-sub-153-XIln-9M-51-303c719e-ceba-470d-91c4-491207f3c4e8
13:47:24.915 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.915 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.915 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] (Re-)joining group
13:47:24.915 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.915 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044915
13:47:24.915 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Subscribed to topic(s): test-topic-0000159-g4aXvWA
13:47:24.915 [pool-56-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.915 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.917 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-162-CuU3Xlg-54
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-162-CuU3Xlg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.917 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] (Re-)joining group
13:47:24.919 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-156-yGFwrQQ-52-1bdb7036-9f7a-4c11-bfd5-6783464c427d
13:47:24.919 [pool-57-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.919 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.919 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] (Re-)joining group
13:47:24.920 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.920 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] (Re-)joining group
13:47:24.921 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.921 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.921 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044920
13:47:24.921 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Subscribed to topic(s): test-topic-0000162-MJrR-xo
13:47:24.922 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Request joining group due to: need to re-join with the given member-id: consumer-sub-159-mZHXHFA-53-b6848800-3036-43b2-b57f-9d1476bb95e9
13:47:24.922 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-165-Rp8SVso-55
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-165-Rp8SVso
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.922 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.922 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] (Re-)joining group
13:47:24.924 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.924 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.924 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044924
13:47:24.925 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Subscribed to topic(s): test-topic-0000165-K5Vt5OE
13:47:24.929 [pool-58-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.929 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.929 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-168-9VyMs40-56
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-168-9VyMs40
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.931 [pool-59-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.931 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.931 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] (Re-)joining group
13:47:24.932 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.932 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.932 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044932
13:47:24.932 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Subscribed to topic(s): test-topic-0000168-5AaQRwA
13:47:24.933 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] (Re-)joining group
13:47:24.933 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Request joining group due to: need to re-join with the given member-id: consumer-sub-162-CuU3Xlg-54-3c38cfa1-9a76-401e-837c-06e5905f8196
13:47:24.934 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.934 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] (Re-)joining group
13:47:24.935 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Request joining group due to: need to re-join with the given member-id: consumer-sub-165-Rp8SVso-55-9c0bef42-cee7-486e-ad3b-54423e65e848
13:47:24.935 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.935 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] (Re-)joining group
13:47:24.937 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-171-dhED_pg-57
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-171-dhED_pg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.939 [pool-60-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.939 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.940 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.940 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.940 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] (Re-)joining group
13:47:24.940 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044940
13:47:24.940 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Subscribed to topic(s): test-topic-0000171-TTgHNZY
13:47:24.942 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Request joining group due to: need to re-join with the given member-id: consumer-sub-168-9VyMs40-56-602ae3f0-f3c5-44a9-a8c9-c56d4b802150
13:47:24.942 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.942 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] (Re-)joining group
13:47:24.945 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-174-VtGKXiA-58
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-174-VtGKXiA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.947 [pool-61-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.947 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.948 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.948 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.948 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044948
13:47:24.948 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Subscribed to topic(s): test-topic-0000174-hJfH_wE
13:47:24.948 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] (Re-)joining group
13:47:24.950 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-177-7kd9GC8-59
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-177-7kd9GC8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.950 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Request joining group due to: need to re-join with the given member-id: consumer-sub-171-dhED_pg-57-eafe6c49-f93a-4b13-8afa-4afa92c14a57
13:47:24.950 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.950 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] (Re-)joining group
13:47:24.952 [pool-62-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.952 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.952 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.952 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044952
13:47:24.953 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.953 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Subscribed to topic(s): test-topic-0000177-9whUEAI
13:47:24.953 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-180-L4cWf7o-60
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-180-L4cWf7o
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.955 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] (Re-)joining group
13:47:24.956 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.956 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.956 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044956
13:47:24.956 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Subscribed to topic(s): test-topic-0000180-mtow198
13:47:24.957 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Request joining group due to: need to re-join with the given member-id: consumer-sub-174-VtGKXiA-58-fa6f4e28-0c32-4358-88ac-e30c64550e53
13:47:24.957 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.957 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] (Re-)joining group
13:47:24.959 [pool-63-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.959 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-183-_icEX9A-61
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-183-_icEX9A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.959 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.959 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] (Re-)joining group
13:47:24.961 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Request joining group due to: need to re-join with the given member-id: consumer-sub-177-7kd9GC8-59-d8b9a23a-8ae4-45bb-8c84-961397b78c8b
13:47:24.961 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.961 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] (Re-)joining group
13:47:24.966 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.966 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.966 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044966
13:47:24.966 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Subscribed to topic(s): test-topic-0000183-Q_DaKzs
13:47:24.966 [pool-64-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.967 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.967 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] (Re-)joining group
13:47:24.967 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-186-tb5lhHw-62
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-186-tb5lhHw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.969 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Request joining group due to: need to re-join with the given member-id: consumer-sub-180-L4cWf7o-60-07b5304c-0494-4620-b7c5-29ed69731108
13:47:24.969 [pool-65-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.970 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.970 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.970 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] (Re-)joining group
13:47:24.971 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.971 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.971 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044971
13:47:24.971 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Subscribed to topic(s): test-topic-0000186-TMi6IGE
13:47:24.973 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] (Re-)joining group
13:47:24.975 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-189-nUp5ynA-63
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-189-nUp5ynA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.975 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Request joining group due to: need to re-join with the given member-id: consumer-sub-183-_icEX9A-61-79dea89a-d5d5-4a7f-bf74-5bdb52626bc2
13:47:24.975 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.975 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] (Re-)joining group
13:47:24.977 [pool-66-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.977 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.978 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.978 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.978 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044978
13:47:24.978 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Subscribed to topic(s): test-topic-0000189-Br5CACQ
13:47:24.981 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] (Re-)joining group
13:47:24.982 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-192-h9BuMY0-64
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-192-h9BuMY0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.984 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Request joining group due to: need to re-join with the given member-id: consumer-sub-186-tb5lhHw-62-f50e472c-9ade-4a05-b195-d0acd3a1bb52
13:47:24.984 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.984 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] (Re-)joining group
13:47:24.985 [pool-67-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.985 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:24.985 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.985 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.985 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044985
13:47:24.985 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] (Re-)joining group
13:47:24.985 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Subscribed to topic(s): test-topic-0000192-qIO7V7Q
13:47:24.986 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-195-xI9sSec-65
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-195-xI9sSec
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.987 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Request joining group due to: need to re-join with the given member-id: consumer-sub-189-nUp5ynA-63-39467be7-ff40-451d-9503-ffc23002c911
13:47:24.987 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.987 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] (Re-)joining group
13:47:24.988 [pool-68-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.989 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:24.989 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.989 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.989 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044989
13:47:24.989 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Subscribed to topic(s): test-topic-0000195-ur-Cgeo
13:47:24.993 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] (Re-)joining group
13:47:24.995 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-198-MIarouE-66
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-198-MIarouE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:24.995 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Request joining group due to: need to re-join with the given member-id: consumer-sub-192-h9BuMY0-64-b9667911-fec2-430b-a1ff-6379e105729c
13:47:24.996 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:24.996 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] (Re-)joining group
13:47:24.997 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:24.998 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:24.998 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336044997
13:47:24.998 [pool-69-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:24.998 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Subscribed to topic(s): test-topic-0000198-MRrztgM
13:47:24.998 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:24.999 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-201-DRMyqV0-67
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-201-DRMyqV0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.001 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.001 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.001 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045001
13:47:25.001 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Subscribed to topic(s): test-topic-0000201-rmNvfr4
13:47:25.003 [pool-70-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.003 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.003 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] (Re-)joining group
13:47:25.004 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] (Re-)joining group
13:47:25.005 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Request joining group due to: need to re-join with the given member-id: consumer-sub-195-xI9sSec-65-7b260926-8e34-4ca9-9dfd-1bf4e1d3ea1e
13:47:25.005 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Request joining group due to: need to re-join with the given member-id: consumer-sub-198-MIarouE-66-94a47337-c16a-4f74-907c-98202220f8cb
13:47:25.006 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.005 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-204-38mBm0s-68
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-204-38mBm0s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.006 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] (Re-)joining group
13:47:25.006 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.006 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] (Re-)joining group
13:47:25.007 [pool-71-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.007 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.009 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.010 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.010 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045009
13:47:25.010 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Subscribed to topic(s): test-topic-0000204-qe1T4lQ
13:47:25.010 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] (Re-)joining group
13:47:25.011 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-207-jL30q_M-69
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-207-jL30q_M
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.013 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Request joining group due to: need to re-join with the given member-id: consumer-sub-201-DRMyqV0-67-89a1dddc-5788-4b11-80e1-ce0fbff26b69
13:47:25.013 [pool-72-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.013 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.013 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.013 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] (Re-)joining group
13:47:25.014 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.014 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.014 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045014
13:47:25.015 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Subscribed to topic(s): test-topic-0000207-bDTZgNE
13:47:25.016 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] (Re-)joining group
13:47:25.017 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-210-ZQk298Y-70
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-210-ZQk298Y
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.018 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Request joining group due to: need to re-join with the given member-id: consumer-sub-204-38mBm0s-68-e9e2db1a-e5da-41cb-a470-d09a49e70034
13:47:25.018 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.018 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] (Re-)joining group
13:47:25.020 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.020 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.020 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045020
13:47:25.020 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Subscribed to topic(s): test-topic-0000210-IbT0AKY
13:47:25.021 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-213-7fDmYK4-71
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-213-7fDmYK4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.022 [pool-74-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.023 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.023 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.023 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.023 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045023
13:47:25.024 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Subscribed to topic(s): test-topic-0000213-a7hif5U
13:47:25.024 [pool-73-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.024 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.024 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] (Re-)joining group
13:47:25.026 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Request joining group due to: need to re-join with the given member-id: consumer-sub-210-ZQk298Y-70-b972ce9c-7d01-48bc-8bdd-da81f46ff154
13:47:25.026 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.026 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] (Re-)joining group
13:47:25.032 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] (Re-)joining group
13:47:25.034 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Request joining group due to: need to re-join with the given member-id: consumer-sub-207-jL30q_M-69-613346be-213a-4e0b-8ce3-23ce63f32abe
13:47:25.034 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.034 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] (Re-)joining group
13:47:25.041 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-216-cOjc_gA-72
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-216-cOjc_gA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.043 [pool-75-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.043 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.043 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] (Re-)joining group
13:47:25.044 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.044 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.044 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045043
13:47:25.044 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Subscribed to topic(s): test-topic-0000216-PzoM90k
13:47:25.045 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-219-zge6Hqg-73
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-219-zge6Hqg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.045 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Request joining group due to: need to re-join with the given member-id: consumer-sub-213-7fDmYK4-71-952af2b6-14d0-42da-961d-a447919dc420
13:47:25.045 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.046 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] (Re-)joining group
13:47:25.047 [pool-76-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.047 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.048 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] (Re-)joining group
13:47:25.048 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.048 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.048 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045048
13:47:25.048 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Subscribed to topic(s): test-topic-0000219-9wHMOjI
13:47:25.050 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Request joining group due to: need to re-join with the given member-id: consumer-sub-216-cOjc_gA-72-e8a44d61-03fa-4abd-83db-23e67b6dc98b
13:47:25.050 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.050 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-222-Bh6PWik-74
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-222-Bh6PWik
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.050 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] (Re-)joining group
13:47:25.052 [pool-77-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.052 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.052 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] (Re-)joining group
13:47:25.053 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.053 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.053 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045053
13:47:25.053 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Subscribed to topic(s): test-topic-0000222-0FOfLX4
13:47:25.054 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Request joining group due to: need to re-join with the given member-id: consumer-sub-219-zge6Hqg-73-0cc26bfc-4a3c-454c-be74-cf0892b1fefe
13:47:25.054 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.054 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] (Re-)joining group
13:47:25.054 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-225-X6fowHo-75
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-225-X6fowHo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.056 [pool-78-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.056 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.056 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] (Re-)joining group
13:47:25.057 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.057 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.057 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045057
13:47:25.058 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Subscribed to topic(s): test-topic-0000225-Xfv4mUc
13:47:25.058 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Request joining group due to: need to re-join with the given member-id: consumer-sub-222-Bh6PWik-74-5a119084-a18d-4db1-8887-3981e02e2d8b
13:47:25.058 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.058 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] (Re-)joining group
13:47:25.058 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-228-RZlr8_o-76
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-228-RZlr8_o
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.060 [pool-79-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.060 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.062 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.062 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.062 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045062
13:47:25.062 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Subscribed to topic(s): test-topic-0000228-j6bdXE8
13:47:25.062 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] (Re-)joining group
13:47:25.064 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Request joining group due to: need to re-join with the given member-id: consumer-sub-225-X6fowHo-75-e84e15de-c310-4f06-85c2-310444260fef
13:47:25.064 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.064 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] (Re-)joining group
13:47:25.065 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-231-OB5fv-Q-77
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-231-OB5fv-Q
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.066 [pool-80-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.066 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.068 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.068 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.068 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045068
13:47:25.068 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Subscribed to topic(s): test-topic-0000231-W7upruI
13:47:25.069 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] (Re-)joining group
13:47:25.071 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Request joining group due to: need to re-join with the given member-id: consumer-sub-228-RZlr8_o-76-52387017-6147-4a81-b2b3-13da2584bf5b
13:47:25.071 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.071 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] (Re-)joining group
13:47:25.073 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-234-Wkn5HAk-78
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-234-Wkn5HAk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.075 [pool-81-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.075 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.076 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.076 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.076 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045076
13:47:25.076 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Subscribed to topic(s): test-topic-0000234-MztKqbA
13:47:25.077 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] (Re-)joining group
13:47:25.079 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-237-e0zoYsA-79
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-237-e0zoYsA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.079 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Request joining group due to: need to re-join with the given member-id: consumer-sub-231-OB5fv-Q-77-c6a8b7c4-8ca9-413e-a856-cfc57c6aec32
13:47:25.079 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.079 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] (Re-)joining group
13:47:25.081 [pool-82-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.081 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.081 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.081 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.081 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045081
13:47:25.081 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Subscribed to topic(s): test-topic-0000237-x236eMI
13:47:25.081 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] (Re-)joining group
13:47:25.082 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-240-vyR70kw-80
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-240-vyR70kw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.083 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Request joining group due to: need to re-join with the given member-id: consumer-sub-234-Wkn5HAk-78-a02e5c3c-c25c-4b02-b7b1-89ad15a6b81c
13:47:25.083 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.083 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] (Re-)joining group
13:47:25.083 [pool-83-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.084 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.084 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] (Re-)joining group
13:47:25.085 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.085 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.085 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045085
13:47:25.085 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Subscribed to topic(s): test-topic-0000240-vwD5iNc
13:47:25.086 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Request joining group due to: need to re-join with the given member-id: consumer-sub-237-e0zoYsA-79-f69ec73f-3676-4c5e-b49e-a16e1b6b57b9
13:47:25.086 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-243-K9G8MCY-81
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-243-K9G8MCY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.086 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.086 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] (Re-)joining group
13:47:25.088 [pool-84-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.088 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.088 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.088 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.088 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045088
13:47:25.088 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Subscribed to topic(s): test-topic-0000243-fpyKxcw
13:47:25.088 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] (Re-)joining group
13:47:25.090 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Request joining group due to: need to re-join with the given member-id: consumer-sub-240-vyR70kw-80-f67d9901-edf6-45b8-a642-9f7ca45cb235
13:47:25.090 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-246-uUsGb-s-82
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-246-uUsGb-s
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.090 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.090 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] (Re-)joining group
13:47:25.092 [pool-85-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.092 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.093 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.093 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.093 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045092
13:47:25.092 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] (Re-)joining group
13:47:25.093 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Subscribed to topic(s): test-topic-0000246-Bq6i99k
13:47:25.094 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-249-zHjl4eA-83
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-249-zHjl4eA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.094 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Request joining group due to: need to re-join with the given member-id: consumer-sub-243-K9G8MCY-81-405831a9-fdf2-492d-b437-fa6b3c7ac77f
13:47:25.095 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.095 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] (Re-)joining group
13:47:25.095 [pool-86-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.096 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.096 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] (Re-)joining group
13:47:25.096 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.096 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.096 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045096
13:47:25.096 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Subscribed to topic(s): test-topic-0000249-j-ThMcs
13:47:25.097 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-252-EmLjkEo-84
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-252-EmLjkEo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.098 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Request joining group due to: need to re-join with the given member-id: consumer-sub-246-uUsGb-s-82-3ee0b3bf-c72f-436c-9097-7813dba39529
13:47:25.098 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.098 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] (Re-)joining group
13:47:25.099 [pool-87-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.099 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.099 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] (Re-)joining group
13:47:25.100 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.100 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.100 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045100
13:47:25.100 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Subscribed to topic(s): test-topic-0000252-fa1UjIY
13:47:25.101 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Request joining group due to: need to re-join with the given member-id: consumer-sub-249-zHjl4eA-83-0b71fa37-0193-467b-8626-aa56c188a577
13:47:25.101 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.101 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] (Re-)joining group
13:47:25.102 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-255-OykRCRA-85
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-255-OykRCRA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.103 [pool-88-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.104 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.104 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] (Re-)joining group
13:47:25.105 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.105 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.105 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045105
13:47:25.105 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Subscribed to topic(s): test-topic-0000255-qWOKGG0
13:47:25.106 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-258-E3w5eVc-86
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-258-E3w5eVc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.106 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Request joining group due to: need to re-join with the given member-id: consumer-sub-252-EmLjkEo-84-49d5ee02-9316-4d0b-aad5-c8c344609d01
13:47:25.106 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.106 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] (Re-)joining group
13:47:25.108 [pool-89-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.108 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.109 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.109 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.109 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045109
13:47:25.109 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Subscribed to topic(s): test-topic-0000258-Rv9SxIc
13:47:25.111 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] (Re-)joining group
13:47:25.112 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-261-0MZJWCA-87
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-261-0MZJWCA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.114 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Request joining group due to: need to re-join with the given member-id: consumer-sub-255-OykRCRA-85-349f68c8-dff0-4066-8e31-24229486e6cd
13:47:25.114 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.114 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] (Re-)joining group
13:47:25.115 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.115 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.115 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045115
13:47:25.115 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Subscribed to topic(s): test-topic-0000261-w2mnyns
13:47:25.116 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-264-xDpyMxE-88
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-264-xDpyMxE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.118 [pool-90-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.118 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.119 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.119 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045118
13:47:25.119 [pool-91-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.119 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.119 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Subscribed to topic(s): test-topic-0000264-eT2e8rU
13:47:25.119 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.119 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] (Re-)joining group
13:47:25.120 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] (Re-)joining group
13:47:25.120 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-267-ss7aMOo-89
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-267-ss7aMOo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.122 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Request joining group due to: need to re-join with the given member-id: consumer-sub-261-0MZJWCA-87-268383bc-942b-4358-80da-49d15862c336
13:47:25.122 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Request joining group due to: need to re-join with the given member-id: consumer-sub-258-E3w5eVc-86-fbc6f10a-bfa6-4ebc-8903-70a35504ce89
13:47:25.122 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.122 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] (Re-)joining group
13:47:25.122 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.123 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] (Re-)joining group
13:47:25.123 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.123 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.123 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045123
13:47:25.123 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Subscribed to topic(s): test-topic-0000267-CjvJg1c
13:47:25.124 [pool-92-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.124 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-270-aPNzw1o-90
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-270-aPNzw1o
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.124 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.125 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] (Re-)joining group
13:47:25.126 [pool-93-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.126 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.126 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] (Re-)joining group
13:47:25.127 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Request joining group due to: need to re-join with the given member-id: consumer-sub-264-xDpyMxE-88-c2653c93-5f82-4089-9c36-69d70d732f38
13:47:25.127 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.127 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] (Re-)joining group
13:47:25.127 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.127 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.127 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045127
13:47:25.127 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Subscribed to topic(s): test-topic-0000270-tS64jLw
13:47:25.128 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-273-eqL_byk-91
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-273-eqL_byk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.129 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Request joining group due to: need to re-join with the given member-id: consumer-sub-267-ss7aMOo-89-b4f09981-8759-4d93-af93-f9826a663476
13:47:25.129 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.129 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] (Re-)joining group
13:47:25.130 [pool-94-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.130 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.130 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] (Re-)joining group
13:47:25.131 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.131 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.131 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045131
13:47:25.131 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Subscribed to topic(s): test-topic-0000273-EO6kLrs
13:47:25.132 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Request joining group due to: need to re-join with the given member-id: consumer-sub-270-aPNzw1o-90-1ada19ec-e32d-48f3-8f0d-648fb91a1bf9
13:47:25.132 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.132 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] (Re-)joining group
13:47:25.132 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-276-M_73Af4-92
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-276-M_73Af4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.134 [pool-95-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.135 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.135 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.135 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.135 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045135
13:47:25.135 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Subscribed to topic(s): test-topic-0000276-6JL1QfE
13:47:25.135 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] (Re-)joining group
13:47:25.137 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-279-DMHO4yA-93
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-279-DMHO4yA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.137 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Request joining group due to: need to re-join with the given member-id: consumer-sub-273-eqL_byk-91-9a8ef42b-ec72-44fe-b89c-a032b752fef6
13:47:25.137 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.137 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] (Re-)joining group
13:47:25.139 [pool-96-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.139 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.139 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.139 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.139 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045139
13:47:25.140 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Subscribed to topic(s): test-topic-0000279-M7JpqrA
13:47:25.140 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] (Re-)joining group
13:47:25.140 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-282-TogoQgQ-94
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-282-TogoQgQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.141 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Request joining group due to: need to re-join with the given member-id: consumer-sub-276-M_73Af4-92-eae216e7-6c24-47dc-9815-fa4973f440f0
13:47:25.142 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.142 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] (Re-)joining group
13:47:25.143 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.143 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.143 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045143
13:47:25.143 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Subscribed to topic(s): test-topic-0000282-WxYsVXA
13:47:25.144 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-285-smiSWoo-95
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-285-smiSWoo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.144 [pool-97-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.145 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.146 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.146 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.146 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045146
13:47:25.146 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Subscribed to topic(s): test-topic-0000285-SwrrYM0
13:47:25.146 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] (Re-)joining group
13:47:25.147 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-288-DoWSTjQ-96
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-288-DoWSTjQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.149 [pool-99-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.149 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.149 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Request joining group due to: need to re-join with the given member-id: consumer-sub-279-DMHO4yA-93-cbb9ee97-5254-458a-a27f-d15dc521a685
13:47:25.149 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.149 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] (Re-)joining group
13:47:25.149 [pool-98-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.150 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.150 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.150 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.150 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045150
13:47:25.150 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] (Re-)joining group
13:47:25.150 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Subscribed to topic(s): test-topic-0000288-AZcX53o
13:47:25.152 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] (Re-)joining group
13:47:25.152 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-291-el6WLME-97
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-291-el6WLME
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.154 [pool-100-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.154 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Request joining group due to: need to re-join with the given member-id: consumer-sub-285-smiSWoo-95-bd11f87a-e503-46ea-be59-2e3305bc4cf2
13:47:25.154 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.154 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] (Re-)joining group
13:47:25.154 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.154 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-282-TogoQgQ-94-e2e92b81-d25b-4370-b3e8-c47c651fd6bd
13:47:25.155 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.155 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] (Re-)joining group
13:47:25.155 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.155 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.155 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045155
13:47:25.155 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Subscribed to topic(s): test-topic-0000291-mMcByrM
13:47:25.155 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] (Re-)joining group
13:47:25.156 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-294-cJqVTOk-98
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-294-cJqVTOk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.158 [pool-101-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.158 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-288-DoWSTjQ-96-b383ccda-9f01-43fd-8e5a-88447d67628c
13:47:25.158 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.158 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.158 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] (Re-)joining group
13:47:25.159 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.159 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.159 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045159
13:47:25.159 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Subscribed to topic(s): test-topic-0000294-ASiqRA4
13:47:25.159 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] (Re-)joining group
13:47:25.160 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-297-0dalijI-99
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-297-0dalijI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.161 [pool-102-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.162 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Request joining group due to: need to re-join with the given member-id: consumer-sub-291-el6WLME-97-9d192a98-289e-4792-87f6-5b1320826aa9
13:47:25.162 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Discovered group coordinator 10.0.0.216:9092 (id: 2147483647 rack: null)
13:47:25.162 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.162 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] (Re-)joining group
13:47:25.162 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] (Re-)joining group
13:47:25.163 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.163 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.163 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045163
13:47:25.163 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Subscribed to topic(s): test-topic-0000297-6tCb4MU
13:47:25.164 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Request joining group due to: need to re-join with the given member-id: consumer-sub-294-cJqVTOk-98-16bc701b-0d50-43b5-bb58-867fe423d261
13:47:25.164 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.164 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] (Re-)joining group
13:47:25.164 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-300-2CQVEBk-100
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-300-2CQVEBk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.166 [pool-103-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.166 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.166 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] (Re-)joining group
13:47:25.167 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.167 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.167 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045167
13:47:25.167 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Subscribed to topic(s): test-topic-0000300-gX_eTcY
13:47:25.168 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Request joining group due to: need to re-join with the given member-id: consumer-sub-297-0dalijI-99-e372742e-da1e-4d1d-b759-eb1e33e33c69
13:47:25.168 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.168 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] (Re-)joining group
13:47:25.169 [qtp435803541-29] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-303-YLtD0wE-101
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-303-YLtD0wE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

13:47:25.169 [pool-104-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.170 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Discovered group coordinator 10.0.0.229:9092 (id: 2147483645 rack: null)
13:47:25.170 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] (Re-)joining group
13:47:25.172 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Request joining group due to: need to re-join with the given member-id: consumer-sub-300-2CQVEBk-100-5024f32d-b8ae-466f-8340-00c2b1a32a98
13:47:25.172 [qtp435803541-29] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.172 [qtp435803541-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.172 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.172 [qtp435803541-29] INFO AppInfoParser - Kafka startTimeMs: 1717336045172
13:47:25.172 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] (Re-)joining group
13:47:25.172 [qtp435803541-29] INFO KafkaConsumer - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Subscribed to topic(s): test-topic-0000303-EgI1jiw
13:47:25.174 [pool-105-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.174 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Discovered group coordinator 10.0.0.52:9092 (id: 2147483646 rack: null)
13:47:25.175 [qtp435803541-29] INFO LocalWorker - Created 101 consumers in 695.350544 ms
13:47:25.175 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] (Re-)joining group
13:47:25.177 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Request joining group due to: need to re-join with the given member-id: consumer-sub-303-YLtD0wE-101-e788eec9-2583-4fff-a6a2-41cd03ee6209
13:47:25.177 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
13:47:25.177 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] (Re-)joining group
13:47:25.258 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.261 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.268 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
13:47:25.279 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.280 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.280 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.280 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045280
13:47:25.280 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.281 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-2] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.281 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
13:47:25.283 [kafka-producer-network-thread | producer-1] INFO Metadata - [Producer clientId=producer-1] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.284 [kafka-producer-network-thread | producer-1] INFO TransactionManager - [Producer clientId=producer-1] ProducerId set to 13202 with epoch 0
13:47:25.285 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.286 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.286 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.286 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045286
13:47:25.286 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.287 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-3] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.287 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
13:47:25.288 [kafka-producer-network-thread | producer-2] INFO Metadata - [Producer clientId=producer-2] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.288 [kafka-producer-network-thread | producer-2] INFO TransactionManager - [Producer clientId=producer-2] ProducerId set to 12205 with epoch 0
13:47:25.289 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.290 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.290 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.290 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045290
13:47:25.290 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.291 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-4] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.291 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-4] Instantiated an idempotent producer.
13:47:25.293 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.293 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.293 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.294 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045293
13:47:25.294 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.294 [kafka-producer-network-thread | producer-3] INFO Metadata - [Producer clientId=producer-3] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.295 [kafka-producer-network-thread | producer-3] INFO TransactionManager - [Producer clientId=producer-3] ProducerId set to 14107 with epoch 0
13:47:25.295 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-5] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.295 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-5] Instantiated an idempotent producer.
13:47:25.297 [kafka-producer-network-thread | producer-4] INFO Metadata - [Producer clientId=producer-4] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.297 [kafka-producer-network-thread | producer-4] INFO TransactionManager - [Producer clientId=producer-4] ProducerId set to 13207 with epoch 0
13:47:25.297 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.298 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.298 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.298 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045298
13:47:25.299 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.299 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-6] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.299 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-6] Instantiated an idempotent producer.
13:47:25.300 [kafka-producer-network-thread | producer-5] INFO Metadata - [Producer clientId=producer-5] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.300 [kafka-producer-network-thread | producer-5] INFO TransactionManager - [Producer clientId=producer-5] ProducerId set to 12208 with epoch 0
13:47:25.304 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.304 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.304 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.304 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045304
13:47:25.305 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.305 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-7] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.305 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-7] Instantiated an idempotent producer.
13:47:25.306 [kafka-producer-network-thread | producer-6] INFO Metadata - [Producer clientId=producer-6] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.306 [kafka-producer-network-thread | producer-6] INFO TransactionManager - [Producer clientId=producer-6] ProducerId set to 12209 with epoch 0
13:47:25.308 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.308 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.308 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.308 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045308
13:47:25.308 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.309 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-8] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.309 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-8] Instantiated an idempotent producer.
13:47:25.310 [kafka-producer-network-thread | producer-7] INFO Metadata - [Producer clientId=producer-7] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.310 [kafka-producer-network-thread | producer-7] INFO TransactionManager - [Producer clientId=producer-7] ProducerId set to 13210 with epoch 0
13:47:25.311 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.311 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.311 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.311 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045311
13:47:25.312 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.313 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-9] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.313 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-9] Instantiated an idempotent producer.
13:47:25.313 [kafka-producer-network-thread | producer-8] INFO Metadata - [Producer clientId=producer-8] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.313 [kafka-producer-network-thread | producer-8] INFO TransactionManager - [Producer clientId=producer-8] ProducerId set to 13211 with epoch 0
13:47:25.315 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.315 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.316 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.316 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045315
13:47:25.316 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.317 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-10] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.317 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-10] Instantiated an idempotent producer.
13:47:25.319 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.320 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.320 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.320 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045320
13:47:25.320 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.321 [kafka-producer-network-thread | producer-9] INFO Metadata - [Producer clientId=producer-9] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.321 [kafka-producer-network-thread | producer-9] INFO TransactionManager - [Producer clientId=producer-9] ProducerId set to 13213 with epoch 0
13:47:25.321 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-11] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.321 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-11] Instantiated an idempotent producer.
13:47:25.325 [kafka-producer-network-thread | producer-10] INFO Metadata - [Producer clientId=producer-10] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.325 [kafka-producer-network-thread | producer-10] INFO TransactionManager - [Producer clientId=producer-10] ProducerId set to 12211 with epoch 0
13:47:25.326 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.327 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.327 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.327 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045327
13:47:25.327 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.328 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-12] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.328 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-12] Instantiated an idempotent producer.
13:47:25.328 [kafka-producer-network-thread | producer-11] INFO Metadata - [Producer clientId=producer-11] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.328 [kafka-producer-network-thread | producer-11] INFO TransactionManager - [Producer clientId=producer-11] ProducerId set to 13216 with epoch 0
13:47:25.330 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.330 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.330 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.330 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045330
13:47:25.331 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.331 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-13] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.331 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-13] Instantiated an idempotent producer.
13:47:25.331 [kafka-producer-network-thread | producer-12] INFO Metadata - [Producer clientId=producer-12] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.332 [kafka-producer-network-thread | producer-12] INFO TransactionManager - [Producer clientId=producer-12] ProducerId set to 14118 with epoch 0
13:47:25.333 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.334 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.334 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.334 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045334
13:47:25.334 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.335 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-14] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.335 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-14] Instantiated an idempotent producer.
13:47:25.335 [kafka-producer-network-thread | producer-13] INFO Metadata - [Producer clientId=producer-13] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.336 [kafka-producer-network-thread | producer-13] INFO TransactionManager - [Producer clientId=producer-13] ProducerId set to 13217 with epoch 0
13:47:25.337 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.337 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.338 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.338 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045337
13:47:25.338 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.338 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-15] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.338 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-15] Instantiated an idempotent producer.
13:47:25.340 [kafka-producer-network-thread | producer-14] INFO Metadata - [Producer clientId=producer-14] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.340 [kafka-producer-network-thread | producer-14] INFO TransactionManager - [Producer clientId=producer-14] ProducerId set to 14120 with epoch 0
13:47:25.341 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.341 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.341 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.341 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045341
13:47:25.341 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.342 [kafka-producer-network-thread | producer-15] INFO Metadata - [Producer clientId=producer-15] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.342 [kafka-producer-network-thread | producer-15] INFO TransactionManager - [Producer clientId=producer-15] ProducerId set to 14121 with epoch 0
13:47:25.343 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-16] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.343 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-16] Instantiated an idempotent producer.
13:47:25.345 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.345 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.345 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.345 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045345
13:47:25.345 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.346 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-17] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.346 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-17] Instantiated an idempotent producer.
13:47:25.346 [kafka-producer-network-thread | producer-16] INFO Metadata - [Producer clientId=producer-16] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.346 [kafka-producer-network-thread | producer-16] INFO TransactionManager - [Producer clientId=producer-16] ProducerId set to 13222 with epoch 0
13:47:25.348 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.348 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.348 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.348 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045348
13:47:25.348 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.349 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-18] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.349 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-18] Instantiated an idempotent producer.
13:47:25.349 [kafka-producer-network-thread | producer-17] INFO Metadata - [Producer clientId=producer-17] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.350 [kafka-producer-network-thread | producer-17] INFO TransactionManager - [Producer clientId=producer-17] ProducerId set to 12217 with epoch 0
13:47:25.353 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.354 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.354 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.354 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045354
13:47:25.354 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.355 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-19] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.355 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-19] Instantiated an idempotent producer.
13:47:25.355 [kafka-producer-network-thread | producer-18] INFO Metadata - [Producer clientId=producer-18] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.356 [kafka-producer-network-thread | producer-18] INFO TransactionManager - [Producer clientId=producer-18] ProducerId set to 13229 with epoch 0
13:47:25.357 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.357 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.358 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.358 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045357
13:47:25.358 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.358 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-20] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.359 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-20] Instantiated an idempotent producer.
13:47:25.361 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.361 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.361 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.361 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045361
13:47:25.361 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.362 [kafka-producer-network-thread | producer-19] INFO Metadata - [Producer clientId=producer-19] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.362 [kafka-producer-network-thread | producer-19] INFO TransactionManager - [Producer clientId=producer-19] ProducerId set to 13232 with epoch 0
13:47:25.362 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-21] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.362 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-21] Instantiated an idempotent producer.
13:47:25.363 [kafka-producer-network-thread | producer-20] INFO Metadata - [Producer clientId=producer-20] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.363 [kafka-producer-network-thread | producer-20] INFO TransactionManager - [Producer clientId=producer-20] ProducerId set to 12219 with epoch 0
13:47:25.364 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.364 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.365 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.365 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045364
13:47:25.365 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.366 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-22] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.366 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-22] Instantiated an idempotent producer.
13:47:25.367 [kafka-producer-network-thread | producer-21] INFO Metadata - [Producer clientId=producer-21] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.367 [kafka-producer-network-thread | producer-21] INFO TransactionManager - [Producer clientId=producer-21] ProducerId set to 13233 with epoch 0
13:47:25.369 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.370 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.370 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.370 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045370
13:47:25.370 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.371 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-23] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.371 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-23] Instantiated an idempotent producer.
13:47:25.371 [kafka-producer-network-thread | producer-22] INFO Metadata - [Producer clientId=producer-22] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.371 [kafka-producer-network-thread | producer-22] INFO TransactionManager - [Producer clientId=producer-22] ProducerId set to 12222 with epoch 0
13:47:25.373 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.373 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.373 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.373 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045373
13:47:25.373 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.374 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-24] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.374 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-24] Instantiated an idempotent producer.
13:47:25.375 [kafka-producer-network-thread | producer-23] INFO Metadata - [Producer clientId=producer-23] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.375 [kafka-producer-network-thread | producer-23] INFO TransactionManager - [Producer clientId=producer-23] ProducerId set to 13235 with epoch 0
13:47:25.376 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.376 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.376 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.376 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045376
13:47:25.376 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-25
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.376 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-25] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.377 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-25] Instantiated an idempotent producer.
13:47:25.379 [kafka-producer-network-thread | producer-24] INFO Metadata - [Producer clientId=producer-24] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.379 [kafka-producer-network-thread | producer-24] INFO TransactionManager - [Producer clientId=producer-24] ProducerId set to 13236 with epoch 0
13:47:25.380 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.380 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.380 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.381 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045380
13:47:25.381 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-26
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.381 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-26] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.381 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-26] Instantiated an idempotent producer.
13:47:25.383 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.383 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.383 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.383 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045383
13:47:25.383 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-27
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.384 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-27] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.384 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-27] Instantiated an idempotent producer.
13:47:25.387 [kafka-producer-network-thread | producer-26] INFO Metadata - [Producer clientId=producer-26] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.387 [kafka-producer-network-thread | producer-26] INFO TransactionManager - [Producer clientId=producer-26] ProducerId set to 14136 with epoch 0
13:47:25.388 [kafka-producer-network-thread | producer-25] INFO Metadata - [Producer clientId=producer-25] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.388 [kafka-producer-network-thread | producer-25] INFO TransactionManager - [Producer clientId=producer-25] ProducerId set to 13238 with epoch 0
13:47:25.389 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.389 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.389 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.390 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045389
13:47:25.390 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-28
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.391 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-28] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.391 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-28] Instantiated an idempotent producer.
13:47:25.392 [kafka-producer-network-thread | producer-27] INFO Metadata - [Producer clientId=producer-27] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.392 [kafka-producer-network-thread | producer-27] INFO TransactionManager - [Producer clientId=producer-27] ProducerId set to 14140 with epoch 0
13:47:25.393 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.393 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.393 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.393 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045393
13:47:25.393 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-29
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.393 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-29] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.393 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-29] Instantiated an idempotent producer.
13:47:25.395 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.396 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.396 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.396 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045396
13:47:25.396 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-30
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.397 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-30] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.397 [kafka-producer-network-thread | producer-28] INFO Metadata - [Producer clientId=producer-28] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.397 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-30] Instantiated an idempotent producer.
13:47:25.397 [kafka-producer-network-thread | producer-28] INFO TransactionManager - [Producer clientId=producer-28] ProducerId set to 13241 with epoch 0
13:47:25.398 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.399 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.399 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.399 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045399
13:47:25.399 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-31
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.399 [kafka-producer-network-thread | producer-29] INFO Metadata - [Producer clientId=producer-29] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.399 [kafka-producer-network-thread | producer-29] INFO TransactionManager - [Producer clientId=producer-29] ProducerId set to 13242 with epoch 0
13:47:25.399 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-31] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.399 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-31] Instantiated an idempotent producer.
13:47:25.402 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.402 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.402 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.402 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045402
13:47:25.402 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-32
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.402 [kafka-producer-network-thread | producer-30] INFO Metadata - [Producer clientId=producer-30] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.402 [kafka-producer-network-thread | producer-30] INFO TransactionManager - [Producer clientId=producer-30] ProducerId set to 12227 with epoch 0
13:47:25.403 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-32] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.403 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-32] Instantiated an idempotent producer.
13:47:25.405 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.405 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.405 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.405 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045405
13:47:25.405 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-33
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.406 [kafka-producer-network-thread | producer-31] INFO Metadata - [Producer clientId=producer-31] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.406 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-33] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.406 [kafka-producer-network-thread | producer-31] INFO TransactionManager - [Producer clientId=producer-31] ProducerId set to 13244 with epoch 0
13:47:25.406 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-33] Instantiated an idempotent producer.
13:47:25.407 [kafka-producer-network-thread | producer-32] INFO Metadata - [Producer clientId=producer-32] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.407 [kafka-producer-network-thread | producer-32] INFO TransactionManager - [Producer clientId=producer-32] ProducerId set to 12229 with epoch 0
13:47:25.408 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.408 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.408 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.408 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045408
13:47:25.408 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-34
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.409 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-34] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.409 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-34] Instantiated an idempotent producer.
13:47:25.409 [kafka-producer-network-thread | producer-33] INFO Metadata - [Producer clientId=producer-33] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.410 [kafka-producer-network-thread | producer-33] INFO TransactionManager - [Producer clientId=producer-33] ProducerId set to 12230 with epoch 0
13:47:25.410 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.410 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.410 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.410 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045410
13:47:25.411 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-35
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.411 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-35] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.411 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-35] Instantiated an idempotent producer.
13:47:25.412 [kafka-producer-network-thread | producer-34] INFO Metadata - [Producer clientId=producer-34] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.412 [kafka-producer-network-thread | producer-34] INFO TransactionManager - [Producer clientId=producer-34] ProducerId set to 12233 with epoch 0
13:47:25.413 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.413 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.413 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.413 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045413
13:47:25.413 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-36
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.414 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-36] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.414 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-36] Instantiated an idempotent producer.
13:47:25.414 [kafka-producer-network-thread | producer-35] INFO Metadata - [Producer clientId=producer-35] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.414 [kafka-producer-network-thread | producer-35] INFO TransactionManager - [Producer clientId=producer-35] ProducerId set to 14149 with epoch 0
13:47:25.416 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.416 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.416 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.416 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045416
13:47:25.416 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-37
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.417 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-37] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.417 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-37] Instantiated an idempotent producer.
13:47:25.417 [kafka-producer-network-thread | producer-36] INFO Metadata - [Producer clientId=producer-36] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.417 [kafka-producer-network-thread | producer-36] INFO TransactionManager - [Producer clientId=producer-36] ProducerId set to 13248 with epoch 0
13:47:25.418 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.418 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.418 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.418 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045418
13:47:25.419 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-38
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.419 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-38] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.419 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-38] Instantiated an idempotent producer.
13:47:25.423 [kafka-producer-network-thread | producer-37] INFO Metadata - [Producer clientId=producer-37] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.423 [kafka-producer-network-thread | producer-37] INFO TransactionManager - [Producer clientId=producer-37] ProducerId set to 13251 with epoch 0
13:47:25.426 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.426 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.427 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.427 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045426
13:47:25.427 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-39
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.427 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-39] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.427 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-39] Instantiated an idempotent producer.
13:47:25.428 [kafka-producer-network-thread | producer-38] INFO Metadata - [Producer clientId=producer-38] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.428 [kafka-producer-network-thread | producer-38] INFO TransactionManager - [Producer clientId=producer-38] ProducerId set to 12237 with epoch 0
13:47:25.429 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.430 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.430 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.430 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045430
13:47:25.430 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-40
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.431 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-40] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.431 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-40] Instantiated an idempotent producer.
13:47:25.431 [kafka-producer-network-thread | producer-39] INFO Metadata - [Producer clientId=producer-39] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.431 [kafka-producer-network-thread | producer-39] INFO TransactionManager - [Producer clientId=producer-39] ProducerId set to 12240 with epoch 0
13:47:25.432 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.432 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.433 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.433 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045432
13:47:25.433 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-41
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.433 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-41] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.434 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-41] Instantiated an idempotent producer.
13:47:25.435 [kafka-producer-network-thread | producer-40] INFO Metadata - [Producer clientId=producer-40] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.435 [kafka-producer-network-thread | producer-40] INFO TransactionManager - [Producer clientId=producer-40] ProducerId set to 14155 with epoch 0
13:47:25.435 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.436 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.436 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.436 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045436
13:47:25.436 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-42
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.437 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-42] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.437 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-42] Instantiated an idempotent producer.
13:47:25.437 [kafka-producer-network-thread | producer-41] INFO Metadata - [Producer clientId=producer-41] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.437 [kafka-producer-network-thread | producer-41] INFO TransactionManager - [Producer clientId=producer-41] ProducerId set to 13255 with epoch 0
13:47:25.438 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.438 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.438 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.439 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045438
13:47:25.439 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-43
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.440 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-43] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.440 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-43] Instantiated an idempotent producer.
13:47:25.440 [kafka-producer-network-thread | producer-42] INFO Metadata - [Producer clientId=producer-42] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.440 [kafka-producer-network-thread | producer-42] INFO TransactionManager - [Producer clientId=producer-42] ProducerId set to 14157 with epoch 0
13:47:25.441 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.441 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.441 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.441 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045441
13:47:25.442 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-44
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.442 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-44] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.442 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-44] Instantiated an idempotent producer.
13:47:25.443 [kafka-producer-network-thread | producer-43] INFO Metadata - [Producer clientId=producer-43] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.443 [kafka-producer-network-thread | producer-43] INFO TransactionManager - [Producer clientId=producer-43] ProducerId set to 13257 with epoch 0
13:47:25.446 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.447 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.447 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.447 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045447
13:47:25.447 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-45
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.448 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-45] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.448 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-45] Instantiated an idempotent producer.
13:47:25.449 [kafka-producer-network-thread | producer-44] INFO Metadata - [Producer clientId=producer-44] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.449 [kafka-producer-network-thread | producer-44] INFO TransactionManager - [Producer clientId=producer-44] ProducerId set to 14158 with epoch 0
13:47:25.454 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.455 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.455 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.455 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045454
13:47:25.455 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-46
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.455 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-46] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.456 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-46] Instantiated an idempotent producer.
13:47:25.456 [kafka-producer-network-thread | producer-45] INFO Metadata - [Producer clientId=producer-45] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.456 [kafka-producer-network-thread | producer-45] INFO TransactionManager - [Producer clientId=producer-45] ProducerId set to 13259 with epoch 0
13:47:25.457 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.457 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.457 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.457 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045457
13:47:25.457 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-47
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.458 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-47] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.458 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-47] Instantiated an idempotent producer.
13:47:25.459 [kafka-producer-network-thread | producer-46] INFO Metadata - [Producer clientId=producer-46] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.459 [kafka-producer-network-thread | producer-46] INFO TransactionManager - [Producer clientId=producer-46] ProducerId set to 12244 with epoch 0
13:47:25.460 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.460 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.460 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.460 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045460
13:47:25.460 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-48
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.461 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-48] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.461 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-48] Instantiated an idempotent producer.
13:47:25.462 [kafka-producer-network-thread | producer-47] INFO Metadata - [Producer clientId=producer-47] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.462 [kafka-producer-network-thread | producer-47] INFO TransactionManager - [Producer clientId=producer-47] ProducerId set to 13261 with epoch 0
13:47:25.463 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.463 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.463 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.463 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045463
13:47:25.463 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-49
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.463 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-49] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.464 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-49] Instantiated an idempotent producer.
13:47:25.465 [kafka-producer-network-thread | producer-48] INFO Metadata - [Producer clientId=producer-48] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.465 [kafka-producer-network-thread | producer-48] INFO TransactionManager - [Producer clientId=producer-48] ProducerId set to 12247 with epoch 0
13:47:25.465 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.465 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.465 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.465 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045465
13:47:25.465 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-50
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.466 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-50] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.466 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-50] Instantiated an idempotent producer.
13:47:25.466 [kafka-producer-network-thread | producer-49] INFO Metadata - [Producer clientId=producer-49] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.467 [kafka-producer-network-thread | producer-49] INFO TransactionManager - [Producer clientId=producer-49] ProducerId set to 14164 with epoch 0
13:47:25.467 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.468 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.468 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.468 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045468
13:47:25.468 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-51
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.469 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-51] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.469 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-51] Instantiated an idempotent producer.
13:47:25.469 [kafka-producer-network-thread | producer-50] INFO Metadata - [Producer clientId=producer-50] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.469 [kafka-producer-network-thread | producer-50] INFO TransactionManager - [Producer clientId=producer-50] ProducerId set to 12249 with epoch 0
13:47:25.470 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.470 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.470 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.470 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045470
13:47:25.471 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-52
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.471 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-52] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.471 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-52] Instantiated an idempotent producer.
13:47:25.472 [kafka-producer-network-thread | producer-51] INFO Metadata - [Producer clientId=producer-51] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.472 [kafka-producer-network-thread | producer-51] INFO TransactionManager - [Producer clientId=producer-51] ProducerId set to 12250 with epoch 0
13:47:25.473 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.473 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.474 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.474 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045473
13:47:25.474 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-53
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.474 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-53] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.474 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-53] Instantiated an idempotent producer.
13:47:25.475 [kafka-producer-network-thread | producer-52] INFO Metadata - [Producer clientId=producer-52] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.475 [kafka-producer-network-thread | producer-52] INFO TransactionManager - [Producer clientId=producer-52] ProducerId set to 14166 with epoch 0
13:47:25.476 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.476 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.476 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.476 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045476
13:47:25.477 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-54
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.477 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-54] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.477 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-54] Instantiated an idempotent producer.
13:47:25.478 [kafka-producer-network-thread | producer-53] INFO Metadata - [Producer clientId=producer-53] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.478 [kafka-producer-network-thread | producer-53] INFO TransactionManager - [Producer clientId=producer-53] ProducerId set to 12253 with epoch 0
13:47:25.479 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.480 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.480 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.480 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045480
13:47:25.480 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-55
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.481 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-55] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.481 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-55] Instantiated an idempotent producer.
13:47:25.481 [kafka-producer-network-thread | producer-54] INFO Metadata - [Producer clientId=producer-54] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.481 [kafka-producer-network-thread | producer-54] INFO TransactionManager - [Producer clientId=producer-54] ProducerId set to 12257 with epoch 0
13:47:25.493 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.494 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.494 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.494 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045494
13:47:25.494 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-56
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.495 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-56] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.495 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-56] Instantiated an idempotent producer.
13:47:25.496 [kafka-producer-network-thread | producer-55] INFO Metadata - [Producer clientId=producer-55] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.496 [kafka-producer-network-thread | producer-55] INFO TransactionManager - [Producer clientId=producer-55] ProducerId set to 12260 with epoch 0
13:47:25.497 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.497 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.497 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.497 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045497
13:47:25.498 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-57
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.498 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-57] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.498 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-57] Instantiated an idempotent producer.
13:47:25.499 [kafka-producer-network-thread | producer-56] INFO Metadata - [Producer clientId=producer-56] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.499 [kafka-producer-network-thread | producer-56] INFO TransactionManager - [Producer clientId=producer-56] ProducerId set to 14175 with epoch 0
13:47:25.500 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.500 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.500 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.500 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045500
13:47:25.501 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-58
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.501 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-58] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.501 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-58] Instantiated an idempotent producer.
13:47:25.502 [kafka-producer-network-thread | producer-57] INFO Metadata - [Producer clientId=producer-57] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.502 [kafka-producer-network-thread | producer-57] INFO TransactionManager - [Producer clientId=producer-57] ProducerId set to 12261 with epoch 0
13:47:25.503 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.503 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.503 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.503 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045503
13:47:25.504 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-59
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.504 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-59] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.504 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-59] Instantiated an idempotent producer.
13:47:25.506 [kafka-producer-network-thread | producer-58] INFO Metadata - [Producer clientId=producer-58] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.506 [kafka-producer-network-thread | producer-58] INFO TransactionManager - [Producer clientId=producer-58] ProducerId set to 13272 with epoch 0
13:47:25.506 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.506 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.506 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.506 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045506
13:47:25.507 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-60
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.507 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-60] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.507 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-60] Instantiated an idempotent producer.
13:47:25.508 [kafka-producer-network-thread | producer-59] INFO Metadata - [Producer clientId=producer-59] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.508 [kafka-producer-network-thread | producer-59] INFO TransactionManager - [Producer clientId=producer-59] ProducerId set to 14177 with epoch 0
13:47:25.509 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.509 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.509 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.509 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045509
13:47:25.510 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-61
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.510 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-61] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.510 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-61] Instantiated an idempotent producer.
13:47:25.511 [kafka-producer-network-thread | producer-60] INFO Metadata - [Producer clientId=producer-60] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.511 [kafka-producer-network-thread | producer-60] INFO TransactionManager - [Producer clientId=producer-60] ProducerId set to 13273 with epoch 0
13:47:25.512 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.512 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.513 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.513 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045512
13:47:25.513 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-62
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.513 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-62] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.514 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-62] Instantiated an idempotent producer.
13:47:25.515 [kafka-producer-network-thread | producer-61] INFO Metadata - [Producer clientId=producer-61] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.515 [kafka-producer-network-thread | producer-61] INFO TransactionManager - [Producer clientId=producer-61] ProducerId set to 13276 with epoch 0
13:47:25.520 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.521 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.521 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.521 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045520
13:47:25.521 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-63
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.522 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-63] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.522 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-63] Instantiated an idempotent producer.
13:47:25.522 [kafka-producer-network-thread | producer-62] INFO Metadata - [Producer clientId=producer-62] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.522 [kafka-producer-network-thread | producer-62] INFO TransactionManager - [Producer clientId=producer-62] ProducerId set to 12267 with epoch 0
13:47:25.528 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.529 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.529 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.529 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045528
13:47:25.529 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-64
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.530 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-64] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.530 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-64] Instantiated an idempotent producer.
13:47:25.530 [kafka-producer-network-thread | producer-63] INFO Metadata - [Producer clientId=producer-63] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.530 [kafka-producer-network-thread | producer-63] INFO TransactionManager - [Producer clientId=producer-63] ProducerId set to 13278 with epoch 0
13:47:25.532 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.532 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.532 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.532 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045532
13:47:25.533 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-65
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.533 [kafka-producer-network-thread | producer-64] INFO Metadata - [Producer clientId=producer-64] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.533 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-65] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.533 [kafka-producer-network-thread | producer-64] INFO TransactionManager - [Producer clientId=producer-64] ProducerId set to 12273 with epoch 0
13:47:25.533 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-65] Instantiated an idempotent producer.
13:47:25.535 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.535 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.535 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.535 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045535
13:47:25.536 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-66
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.536 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-66] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.536 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-66] Instantiated an idempotent producer.
13:47:25.537 [kafka-producer-network-thread | producer-65] INFO Metadata - [Producer clientId=producer-65] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.537 [kafka-producer-network-thread | producer-65] INFO TransactionManager - [Producer clientId=producer-65] ProducerId set to 13280 with epoch 0
13:47:25.538 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.538 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.539 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.539 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045538
13:47:25.539 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-67
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.539 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-67] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.540 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-67] Instantiated an idempotent producer.
13:47:25.540 [kafka-producer-network-thread | producer-66] INFO Metadata - [Producer clientId=producer-66] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.540 [kafka-producer-network-thread | producer-66] INFO TransactionManager - [Producer clientId=producer-66] ProducerId set to 13281 with epoch 0
13:47:25.541 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.541 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.542 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.542 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045541
13:47:25.542 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-68
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.542 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-68] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.543 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-68] Instantiated an idempotent producer.
13:47:25.543 [kafka-producer-network-thread | producer-67] INFO Metadata - [Producer clientId=producer-67] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.543 [kafka-producer-network-thread | producer-67] INFO TransactionManager - [Producer clientId=producer-67] ProducerId set to 14183 with epoch 0
13:47:25.545 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.545 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.546 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.546 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045545
13:47:25.546 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-69
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.547 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-69] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.547 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-69] Instantiated an idempotent producer.
13:47:25.547 [kafka-producer-network-thread | producer-68] INFO Metadata - [Producer clientId=producer-68] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.547 [kafka-producer-network-thread | producer-68] INFO TransactionManager - [Producer clientId=producer-68] ProducerId set to 14185 with epoch 0
13:47:25.548 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.549 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.549 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.549 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045549
13:47:25.549 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-70
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.550 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-70] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.550 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-70] Instantiated an idempotent producer.
13:47:25.550 [kafka-producer-network-thread | producer-69] INFO Metadata - [Producer clientId=producer-69] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.550 [kafka-producer-network-thread | producer-69] INFO TransactionManager - [Producer clientId=producer-69] ProducerId set to 12277 with epoch 0
13:47:25.551 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.552 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.552 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.552 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045552
13:47:25.552 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-71
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.553 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-71] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.553 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-71] Instantiated an idempotent producer.
13:47:25.553 [kafka-producer-network-thread | producer-70] INFO Metadata - [Producer clientId=producer-70] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.553 [kafka-producer-network-thread | producer-70] INFO TransactionManager - [Producer clientId=producer-70] ProducerId set to 12278 with epoch 0
13:47:25.556 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.556 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.556 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.556 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045556
13:47:25.556 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-72
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.557 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-72] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.557 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-72] Instantiated an idempotent producer.
13:47:25.557 [kafka-producer-network-thread | producer-71] INFO Metadata - [Producer clientId=producer-71] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.557 [kafka-producer-network-thread | producer-71] INFO TransactionManager - [Producer clientId=producer-71] ProducerId set to 14188 with epoch 0
13:47:25.558 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.558 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.558 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.558 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045558
13:47:25.558 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-73
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.559 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-73] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.559 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-73] Instantiated an idempotent producer.
13:47:25.561 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.561 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.561 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.561 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045561
13:47:25.561 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-74
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.561 [kafka-producer-network-thread | producer-72] INFO Metadata - [Producer clientId=producer-72] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.561 [kafka-producer-network-thread | producer-72] INFO TransactionManager - [Producer clientId=producer-72] ProducerId set to 12279 with epoch 0
13:47:25.562 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-74] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.562 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-74] Instantiated an idempotent producer.
13:47:25.562 [kafka-producer-network-thread | producer-73] INFO Metadata - [Producer clientId=producer-73] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.563 [kafka-producer-network-thread | producer-73] INFO TransactionManager - [Producer clientId=producer-73] ProducerId set to 12281 with epoch 0
13:47:25.563 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.563 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.563 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.563 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045563
13:47:25.564 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-75
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.564 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-75] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.565 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-75] Instantiated an idempotent producer.
13:47:25.565 [kafka-producer-network-thread | producer-74] INFO Metadata - [Producer clientId=producer-74] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.565 [kafka-producer-network-thread | producer-74] INFO TransactionManager - [Producer clientId=producer-74] ProducerId set to 14190 with epoch 0
13:47:25.566 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.566 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.566 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.566 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045566
13:47:25.567 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-76
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.567 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-76] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.567 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-76] Instantiated an idempotent producer.
13:47:25.569 [kafka-producer-network-thread | producer-75] INFO Metadata - [Producer clientId=producer-75] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.569 [kafka-producer-network-thread | producer-75] INFO TransactionManager - [Producer clientId=producer-75] ProducerId set to 14191 with epoch 0
13:47:25.570 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.570 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.570 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.571 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045570
13:47:25.571 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-77
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.571 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-77] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.572 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-77] Instantiated an idempotent producer.
13:47:25.572 [kafka-producer-network-thread | producer-76] INFO Metadata - [Producer clientId=producer-76] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.573 [kafka-producer-network-thread | producer-76] INFO TransactionManager - [Producer clientId=producer-76] ProducerId set to 12285 with epoch 0
13:47:25.573 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.573 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.573 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.573 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045573
13:47:25.574 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-78
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.574 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-78] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.574 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-78] Instantiated an idempotent producer.
13:47:25.575 [kafka-producer-network-thread | producer-77] INFO Metadata - [Producer clientId=producer-77] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.575 [kafka-producer-network-thread | producer-77] INFO TransactionManager - [Producer clientId=producer-77] ProducerId set to 13292 with epoch 0
13:47:25.576 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.576 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.576 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.576 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045576
13:47:25.576 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-79
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.577 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-79] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.577 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-79] Instantiated an idempotent producer.
13:47:25.577 [kafka-producer-network-thread | producer-78] INFO Metadata - [Producer clientId=producer-78] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.577 [kafka-producer-network-thread | producer-78] INFO TransactionManager - [Producer clientId=producer-78] ProducerId set to 12287 with epoch 0
13:47:25.578 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.579 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.579 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.579 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045579
13:47:25.579 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-80
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.580 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-80] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.580 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-80] Instantiated an idempotent producer.
13:47:25.580 [kafka-producer-network-thread | producer-79] INFO Metadata - [Producer clientId=producer-79] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.580 [kafka-producer-network-thread | producer-79] INFO TransactionManager - [Producer clientId=producer-79] ProducerId set to 14192 with epoch 0
13:47:25.582 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.582 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.582 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.582 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045582
13:47:25.582 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-81
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.583 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-81] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.583 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-81] Instantiated an idempotent producer.
13:47:25.583 [kafka-producer-network-thread | producer-80] INFO Metadata - [Producer clientId=producer-80] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.583 [kafka-producer-network-thread | producer-80] INFO TransactionManager - [Producer clientId=producer-80] ProducerId set to 14193 with epoch 0
13:47:25.584 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.584 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.584 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.585 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045584
13:47:25.585 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-82
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.585 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-82] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.585 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-82] Instantiated an idempotent producer.
13:47:25.586 [kafka-producer-network-thread | producer-81] INFO Metadata - [Producer clientId=producer-81] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.586 [kafka-producer-network-thread | producer-81] INFO TransactionManager - [Producer clientId=producer-81] ProducerId set to 12288 with epoch 0
13:47:25.587 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.587 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.587 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.587 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045587
13:47:25.588 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-83
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.588 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-83] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.588 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-83] Instantiated an idempotent producer.
13:47:25.589 [kafka-producer-network-thread | producer-82] INFO Metadata - [Producer clientId=producer-82] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.589 [kafka-producer-network-thread | producer-82] INFO TransactionManager - [Producer clientId=producer-82] ProducerId set to 12290 with epoch 0
13:47:25.590 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.590 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.590 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.590 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045590
13:47:25.592 [kafka-producer-network-thread | producer-83] INFO Metadata - [Producer clientId=producer-83] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.592 [kafka-producer-network-thread | producer-83] INFO TransactionManager - [Producer clientId=producer-83] ProducerId set to 14195 with epoch 0
13:47:25.594 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-84
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.594 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-84] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.594 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-84] Instantiated an idempotent producer.
13:47:25.596 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.596 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.596 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.596 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045596
13:47:25.596 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-85
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.597 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-85] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.597 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-85] Instantiated an idempotent producer.
13:47:25.597 [kafka-producer-network-thread | producer-84] INFO Metadata - [Producer clientId=producer-84] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.597 [kafka-producer-network-thread | producer-84] INFO TransactionManager - [Producer clientId=producer-84] ProducerId set to 13299 with epoch 0
13:47:25.599 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.599 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.599 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.599 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045599
13:47:25.599 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-86
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.600 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-86] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.600 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-86] Instantiated an idempotent producer.
13:47:25.600 [kafka-producer-network-thread | producer-85] INFO Metadata - [Producer clientId=producer-85] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.600 [kafka-producer-network-thread | producer-85] INFO TransactionManager - [Producer clientId=producer-85] ProducerId set to 14197 with epoch 0
13:47:25.602 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.602 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.602 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.602 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045602
13:47:25.602 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-87
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.603 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-87] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.603 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-87] Instantiated an idempotent producer.
13:47:25.603 [kafka-producer-network-thread | producer-86] INFO Metadata - [Producer clientId=producer-86] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.604 [kafka-producer-network-thread | producer-86] INFO TransactionManager - [Producer clientId=producer-86] ProducerId set to 12297 with epoch 0
13:47:25.605 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.605 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.605 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.605 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045605
13:47:25.605 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-88
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.606 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-88] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.606 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-88] Instantiated an idempotent producer.
13:47:25.606 [kafka-producer-network-thread | producer-87] INFO Metadata - [Producer clientId=producer-87] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.606 [kafka-producer-network-thread | producer-87] INFO TransactionManager - [Producer clientId=producer-87] ProducerId set to 14198 with epoch 0
13:47:25.608 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.608 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.608 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.608 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045608
13:47:25.608 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-89
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.609 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-89] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.609 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-89] Instantiated an idempotent producer.
13:47:25.609 [kafka-producer-network-thread | producer-88] INFO Metadata - [Producer clientId=producer-88] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.609 [kafka-producer-network-thread | producer-88] INFO TransactionManager - [Producer clientId=producer-88] ProducerId set to 14199 with epoch 0
13:47:25.611 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.611 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.611 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.611 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045611
13:47:25.611 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-90
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.612 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-90] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.612 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-90] Instantiated an idempotent producer.
13:47:25.612 [kafka-producer-network-thread | producer-89] INFO Metadata - [Producer clientId=producer-89] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.613 [kafka-producer-network-thread | producer-89] INFO TransactionManager - [Producer clientId=producer-89] ProducerId set to 12301 with epoch 0
13:47:25.615 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.615 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.615 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.615 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045615
13:47:25.615 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-91
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.616 [kafka-producer-network-thread | producer-90] INFO Metadata - [Producer clientId=producer-90] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.616 [kafka-producer-network-thread | producer-90] INFO TransactionManager - [Producer clientId=producer-90] ProducerId set to 13306 with epoch 0
13:47:25.616 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-91] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.616 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-91] Instantiated an idempotent producer.
13:47:25.618 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.618 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.618 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.618 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045618
13:47:25.619 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-92
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.619 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-92] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.619 [kafka-producer-network-thread | producer-91] INFO Metadata - [Producer clientId=producer-91] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.619 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-92] Instantiated an idempotent producer.
13:47:25.619 [kafka-producer-network-thread | producer-91] INFO TransactionManager - [Producer clientId=producer-91] ProducerId set to 14203 with epoch 0
13:47:25.621 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.621 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.621 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.621 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045621
13:47:25.622 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-93
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.622 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-93] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.622 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-93] Instantiated an idempotent producer.
13:47:25.623 [kafka-producer-network-thread | producer-92] INFO Metadata - [Producer clientId=producer-92] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.623 [kafka-producer-network-thread | producer-92] INFO TransactionManager - [Producer clientId=producer-92] ProducerId set to 13308 with epoch 0
13:47:25.623 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.623 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.623 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.624 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045623
13:47:25.624 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-94
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.624 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-94] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.625 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-94] Instantiated an idempotent producer.
13:47:25.625 [kafka-producer-network-thread | producer-93] INFO Metadata - [Producer clientId=producer-93] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.626 [kafka-producer-network-thread | producer-93] INFO TransactionManager - [Producer clientId=producer-93] ProducerId set to 13309 with epoch 0
13:47:25.626 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.626 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.626 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.626 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045626
13:47:25.627 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-95
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.627 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-95] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.627 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-95] Instantiated an idempotent producer.
13:47:25.628 [kafka-producer-network-thread | producer-94] INFO Metadata - [Producer clientId=producer-94] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.628 [kafka-producer-network-thread | producer-94] INFO TransactionManager - [Producer clientId=producer-94] ProducerId set to 12302 with epoch 0
13:47:25.629 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.629 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.629 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.629 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045629
13:47:25.629 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-96
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.630 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-96] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.630 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-96] Instantiated an idempotent producer.
13:47:25.631 [kafka-producer-network-thread | producer-95] INFO Metadata - [Producer clientId=producer-95] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.631 [kafka-producer-network-thread | producer-95] INFO TransactionManager - [Producer clientId=producer-95] ProducerId set to 13313 with epoch 0
13:47:25.632 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.632 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.632 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.632 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045632
13:47:25.632 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-97
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.633 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-97] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.633 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-97] Instantiated an idempotent producer.
13:47:25.633 [kafka-producer-network-thread | producer-96] INFO Metadata - [Producer clientId=producer-96] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.633 [kafka-producer-network-thread | producer-96] INFO TransactionManager - [Producer clientId=producer-96] ProducerId set to 14207 with epoch 0
13:47:25.634 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.634 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.634 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.634 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045634
13:47:25.635 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-98
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.635 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-98] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.635 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-98] Instantiated an idempotent producer.
13:47:25.636 [kafka-producer-network-thread | producer-97] INFO Metadata - [Producer clientId=producer-97] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.636 [kafka-producer-network-thread | producer-97] INFO TransactionManager - [Producer clientId=producer-97] ProducerId set to 12303 with epoch 0
13:47:25.637 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.637 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.637 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.637 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045637
13:47:25.638 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-99
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.638 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-99] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.638 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-99] Instantiated an idempotent producer.
13:47:25.639 [kafka-producer-network-thread | producer-98] INFO Metadata - [Producer clientId=producer-98] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.639 [kafka-producer-network-thread | producer-98] INFO TransactionManager - [Producer clientId=producer-98] ProducerId set to 13317 with epoch 0
13:47:25.640 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.640 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.640 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.640 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045640
13:47:25.640 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-100
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.641 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-100] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.641 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-100] Instantiated an idempotent producer.
13:47:25.642 [kafka-producer-network-thread | producer-99] INFO Metadata - [Producer clientId=producer-99] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.642 [kafka-producer-network-thread | producer-99] INFO TransactionManager - [Producer clientId=producer-99] ProducerId set to 13319 with epoch 0
13:47:25.642 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.642 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.643 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.643 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045642
13:47:25.643 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-101
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.643 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-101] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.643 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-101] Instantiated an idempotent producer.
13:47:25.644 [kafka-producer-network-thread | producer-100] INFO Metadata - [Producer clientId=producer-100] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.644 [kafka-producer-network-thread | producer-100] INFO TransactionManager - [Producer clientId=producer-100] ProducerId set to 14211 with epoch 0
13:47:25.645 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.645 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.645 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.645 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045645
13:47:25.645 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-102
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.646 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-102] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.646 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-102] Instantiated an idempotent producer.
13:47:25.647 [kafka-producer-network-thread | producer-101] INFO Metadata - [Producer clientId=producer-101] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.647 [kafka-producer-network-thread | producer-101] INFO TransactionManager - [Producer clientId=producer-101] ProducerId set to 13320 with epoch 0
13:47:25.648 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.648 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.648 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.648 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045648
13:47:25.648 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-103
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.649 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-103] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.649 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-103] Instantiated an idempotent producer.
13:47:25.650 [kafka-producer-network-thread | producer-102] INFO Metadata - [Producer clientId=producer-102] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.650 [kafka-producer-network-thread | producer-102] INFO TransactionManager - [Producer clientId=producer-102] ProducerId set to 14213 with epoch 0
13:47:25.651 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.651 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.651 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.651 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045651
13:47:25.651 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-104
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.651 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-104] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.651 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-104] Instantiated an idempotent producer.
13:47:25.652 [kafka-producer-network-thread | producer-103] INFO Metadata - [Producer clientId=producer-103] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.652 [kafka-producer-network-thread | producer-103] INFO TransactionManager - [Producer clientId=producer-103] ProducerId set to 12307 with epoch 0
13:47:25.653 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.653 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.653 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.653 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045653
13:47:25.653 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-105
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.654 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-105] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.654 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-105] Instantiated an idempotent producer.
13:47:25.655 [kafka-producer-network-thread | producer-104] INFO Metadata - [Producer clientId=producer-104] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.655 [kafka-producer-network-thread | producer-104] INFO TransactionManager - [Producer clientId=producer-104] ProducerId set to 12310 with epoch 0
13:47:25.655 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.656 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.656 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.656 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045656
13:47:25.656 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-106
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.656 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-106] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.657 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-106] Instantiated an idempotent producer.
13:47:25.657 [kafka-producer-network-thread | producer-105] INFO Metadata - [Producer clientId=producer-105] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.657 [kafka-producer-network-thread | producer-105] INFO TransactionManager - [Producer clientId=producer-105] ProducerId set to 12311 with epoch 0
13:47:25.658 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.658 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.658 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.658 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045658
13:47:25.659 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-107
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.659 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-107] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.659 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-107] Instantiated an idempotent producer.
13:47:25.660 [kafka-producer-network-thread | producer-106] INFO Metadata - [Producer clientId=producer-106] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.660 [kafka-producer-network-thread | producer-106] INFO TransactionManager - [Producer clientId=producer-106] ProducerId set to 14216 with epoch 0
13:47:25.661 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.661 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.661 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.661 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045661
13:47:25.662 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-108
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.662 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-108] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.662 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-108] Instantiated an idempotent producer.
13:47:25.662 [kafka-producer-network-thread | producer-107] INFO Metadata - [Producer clientId=producer-107] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.663 [kafka-producer-network-thread | producer-107] INFO TransactionManager - [Producer clientId=producer-107] ProducerId set to 12313 with epoch 0
13:47:25.664 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.664 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.664 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.664 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045664
13:47:25.664 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-109
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.665 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-109] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.665 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-109] Instantiated an idempotent producer.
13:47:25.665 [kafka-producer-network-thread | producer-108] INFO Metadata - [Producer clientId=producer-108] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.665 [kafka-producer-network-thread | producer-108] INFO TransactionManager - [Producer clientId=producer-108] ProducerId set to 12314 with epoch 0
13:47:25.666 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.666 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.666 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.666 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045666
13:47:25.667 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-110
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.667 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-110] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.667 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-110] Instantiated an idempotent producer.
13:47:25.668 [kafka-producer-network-thread | producer-109] INFO Metadata - [Producer clientId=producer-109] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.668 [kafka-producer-network-thread | producer-109] INFO TransactionManager - [Producer clientId=producer-109] ProducerId set to 12315 with epoch 0
13:47:25.669 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.669 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.669 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.669 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045669
13:47:25.670 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-111
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.670 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-111] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.670 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-111] Instantiated an idempotent producer.
13:47:25.671 [kafka-producer-network-thread | producer-110] INFO Metadata - [Producer clientId=producer-110] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.671 [kafka-producer-network-thread | producer-110] INFO TransactionManager - [Producer clientId=producer-110] ProducerId set to 12316 with epoch 0
13:47:25.672 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.672 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.672 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.672 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045672
13:47:25.673 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-112
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.673 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-112] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.673 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-112] Instantiated an idempotent producer.
13:47:25.674 [kafka-producer-network-thread | producer-111] INFO Metadata - [Producer clientId=producer-111] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.674 [kafka-producer-network-thread | producer-111] INFO TransactionManager - [Producer clientId=producer-111] ProducerId set to 14220 with epoch 0
13:47:25.675 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.675 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.675 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.675 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045675
13:47:25.675 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-113
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.676 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-113] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.676 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-113] Instantiated an idempotent producer.
13:47:25.677 [kafka-producer-network-thread | producer-112] INFO Metadata - [Producer clientId=producer-112] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.677 [kafka-producer-network-thread | producer-112] INFO TransactionManager - [Producer clientId=producer-112] ProducerId set to 13330 with epoch 0
13:47:25.678 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.678 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.678 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.678 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045678
13:47:25.678 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-114
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.679 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-114] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.679 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-114] Instantiated an idempotent producer.
13:47:25.680 [kafka-producer-network-thread | producer-113] INFO Metadata - [Producer clientId=producer-113] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.680 [kafka-producer-network-thread | producer-113] INFO TransactionManager - [Producer clientId=producer-113] ProducerId set to 13331 with epoch 0
13:47:25.681 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.681 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.681 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.681 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045681
13:47:25.681 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-115
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.682 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-115] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.682 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-115] Instantiated an idempotent producer.
13:47:25.683 [kafka-producer-network-thread | producer-114] INFO Metadata - [Producer clientId=producer-114] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.683 [kafka-producer-network-thread | producer-114] INFO TransactionManager - [Producer clientId=producer-114] ProducerId set to 13333 with epoch 0
13:47:25.683 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.683 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.683 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.684 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045683
13:47:25.684 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-116
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.685 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-116] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.685 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-116] Instantiated an idempotent producer.
13:47:25.685 [kafka-producer-network-thread | producer-115] INFO Metadata - [Producer clientId=producer-115] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.685 [kafka-producer-network-thread | producer-115] INFO TransactionManager - [Producer clientId=producer-115] ProducerId set to 12321 with epoch 0
13:47:25.686 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.686 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.686 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.686 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045686
13:47:25.687 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-117
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.687 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-117] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.687 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-117] Instantiated an idempotent producer.
13:47:25.688 [kafka-producer-network-thread | producer-116] INFO Metadata - [Producer clientId=producer-116] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.688 [kafka-producer-network-thread | producer-116] INFO TransactionManager - [Producer clientId=producer-116] ProducerId set to 13336 with epoch 0
13:47:25.689 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.689 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.689 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.689 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045689
13:47:25.690 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-118
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.690 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-118] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.690 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-118] Instantiated an idempotent producer.
13:47:25.691 [kafka-producer-network-thread | producer-117] INFO Metadata - [Producer clientId=producer-117] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.691 [kafka-producer-network-thread | producer-117] INFO TransactionManager - [Producer clientId=producer-117] ProducerId set to 13337 with epoch 0
13:47:25.692 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.692 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.692 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.692 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045692
13:47:25.692 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-119
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.693 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-119] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.693 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-119] Instantiated an idempotent producer.
13:47:25.694 [kafka-producer-network-thread | producer-118] INFO Metadata - [Producer clientId=producer-118] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.694 [kafka-producer-network-thread | producer-118] INFO TransactionManager - [Producer clientId=producer-118] ProducerId set to 14225 with epoch 0
13:47:25.694 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.694 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.694 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.694 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045694
13:47:25.695 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-120
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.695 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-120] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.695 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-120] Instantiated an idempotent producer.
13:47:25.696 [kafka-producer-network-thread | producer-119] INFO Metadata - [Producer clientId=producer-119] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.696 [kafka-producer-network-thread | producer-119] INFO TransactionManager - [Producer clientId=producer-119] ProducerId set to 13339 with epoch 0
13:47:25.697 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.697 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.697 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.697 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045697
13:47:25.697 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-121
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.698 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-121] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.698 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-121] Instantiated an idempotent producer.
13:47:25.698 [kafka-producer-network-thread | producer-120] INFO Metadata - [Producer clientId=producer-120] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.699 [kafka-producer-network-thread | producer-120] INFO TransactionManager - [Producer clientId=producer-120] ProducerId set to 14227 with epoch 0
13:47:25.700 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.700 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.700 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.700 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045700
13:47:25.700 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-122
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.701 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-122] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.701 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-122] Instantiated an idempotent producer.
13:47:25.701 [kafka-producer-network-thread | producer-121] INFO Metadata - [Producer clientId=producer-121] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.702 [kafka-producer-network-thread | producer-121] INFO TransactionManager - [Producer clientId=producer-121] ProducerId set to 14228 with epoch 0
13:47:25.702 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.702 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.703 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.703 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045702
13:47:25.703 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-123
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.703 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-123] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.703 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-123] Instantiated an idempotent producer.
13:47:25.704 [kafka-producer-network-thread | producer-122] INFO Metadata - [Producer clientId=producer-122] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.704 [kafka-producer-network-thread | producer-122] INFO TransactionManager - [Producer clientId=producer-122] ProducerId set to 12323 with epoch 0
13:47:25.705 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.705 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.705 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.705 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045705
13:47:25.705 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-124
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.706 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-124] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.706 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-124] Instantiated an idempotent producer.
13:47:25.707 [kafka-producer-network-thread | producer-123] INFO Metadata - [Producer clientId=producer-123] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.707 [kafka-producer-network-thread | producer-123] INFO TransactionManager - [Producer clientId=producer-123] ProducerId set to 14229 with epoch 0
13:47:25.707 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.708 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.708 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.708 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045707
13:47:25.708 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-125
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.708 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-125] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.709 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-125] Instantiated an idempotent producer.
13:47:25.709 [kafka-producer-network-thread | producer-124] INFO Metadata - [Producer clientId=producer-124] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.709 [kafka-producer-network-thread | producer-124] INFO TransactionManager - [Producer clientId=producer-124] ProducerId set to 13347 with epoch 0
13:47:25.710 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.710 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.710 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.710 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045710
13:47:25.711 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-126
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.711 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-126] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.711 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-126] Instantiated an idempotent producer.
13:47:25.712 [kafka-producer-network-thread | producer-125] INFO Metadata - [Producer clientId=producer-125] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.712 [kafka-producer-network-thread | producer-125] INFO TransactionManager - [Producer clientId=producer-125] ProducerId set to 14231 with epoch 0
13:47:25.712 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.713 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.713 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.713 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045713
13:47:25.713 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-127
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.713 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-127] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.713 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-127] Instantiated an idempotent producer.
13:47:25.714 [kafka-producer-network-thread | producer-126] INFO Metadata - [Producer clientId=producer-126] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.714 [kafka-producer-network-thread | producer-126] INFO TransactionManager - [Producer clientId=producer-126] ProducerId set to 14232 with epoch 0
13:47:25.715 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.715 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.715 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.715 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045715
13:47:25.715 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-128
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.716 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-128] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.716 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-128] Instantiated an idempotent producer.
13:47:25.716 [kafka-producer-network-thread | producer-127] INFO Metadata - [Producer clientId=producer-127] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.716 [kafka-producer-network-thread | producer-127] INFO TransactionManager - [Producer clientId=producer-127] ProducerId set to 14234 with epoch 0
13:47:25.717 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.717 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.718 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.718 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045717
13:47:25.718 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-129
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.718 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-129] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.718 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-129] Instantiated an idempotent producer.
13:47:25.719 [kafka-producer-network-thread | producer-128] INFO Metadata - [Producer clientId=producer-128] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.719 [kafka-producer-network-thread | producer-128] INFO TransactionManager - [Producer clientId=producer-128] ProducerId set to 12329 with epoch 0
13:47:25.720 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.720 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.720 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.720 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045720
13:47:25.721 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-130
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.721 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-130] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.721 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-130] Instantiated an idempotent producer.
13:47:25.722 [kafka-producer-network-thread | producer-129] INFO Metadata - [Producer clientId=producer-129] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.722 [kafka-producer-network-thread | producer-129] INFO TransactionManager - [Producer clientId=producer-129] ProducerId set to 12331 with epoch 0
13:47:25.722 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.722 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.722 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.723 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045722
13:47:25.723 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-131
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.723 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-131] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.723 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-131] Instantiated an idempotent producer.
13:47:25.724 [kafka-producer-network-thread | producer-130] INFO Metadata - [Producer clientId=producer-130] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.724 [kafka-producer-network-thread | producer-130] INFO TransactionManager - [Producer clientId=producer-130] ProducerId set to 13351 with epoch 0
13:47:25.725 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.725 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.726 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.726 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045725
13:47:25.726 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-132
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.726 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-132] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.726 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-132] Instantiated an idempotent producer.
13:47:25.727 [kafka-producer-network-thread | producer-131] INFO Metadata - [Producer clientId=producer-131] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.727 [kafka-producer-network-thread | producer-131] INFO TransactionManager - [Producer clientId=producer-131] ProducerId set to 13352 with epoch 0
13:47:25.728 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.728 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.728 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.728 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045728
13:47:25.729 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-133
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.729 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-133] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.729 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-133] Instantiated an idempotent producer.
13:47:25.729 [kafka-producer-network-thread | producer-132] INFO Metadata - [Producer clientId=producer-132] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.730 [kafka-producer-network-thread | producer-132] INFO TransactionManager - [Producer clientId=producer-132] ProducerId set to 12334 with epoch 0
13:47:25.731 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.732 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.732 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.732 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045732
13:47:25.732 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-134
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.733 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-134] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.733 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-134] Instantiated an idempotent producer.
13:47:25.733 [kafka-producer-network-thread | producer-133] INFO Metadata - [Producer clientId=producer-133] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.733 [kafka-producer-network-thread | producer-133] INFO TransactionManager - [Producer clientId=producer-133] ProducerId set to 12335 with epoch 0
13:47:25.735 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.735 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.735 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.735 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045735
13:47:25.735 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-135
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.736 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-135] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.736 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-135] Instantiated an idempotent producer.
13:47:25.737 [kafka-producer-network-thread | producer-134] INFO Metadata - [Producer clientId=producer-134] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.738 [kafka-producer-network-thread | producer-134] INFO TransactionManager - [Producer clientId=producer-134] ProducerId set to 14237 with epoch 0
13:47:25.738 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.738 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.738 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.738 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045738
13:47:25.738 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-136
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.739 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-136] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.739 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-136] Instantiated an idempotent producer.
13:47:25.740 [kafka-producer-network-thread | producer-135] INFO Metadata - [Producer clientId=producer-135] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.740 [kafka-producer-network-thread | producer-135] INFO TransactionManager - [Producer clientId=producer-135] ProducerId set to 12337 with epoch 0
13:47:25.741 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.741 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.741 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.741 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045741
13:47:25.741 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-137
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.742 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-137] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.742 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-137] Instantiated an idempotent producer.
13:47:25.743 [kafka-producer-network-thread | producer-136] INFO Metadata - [Producer clientId=producer-136] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.743 [kafka-producer-network-thread | producer-136] INFO TransactionManager - [Producer clientId=producer-136] ProducerId set to 14239 with epoch 0
13:47:25.744 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.744 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.744 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.744 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045744
13:47:25.744 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-138
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.745 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-138] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.745 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-138] Instantiated an idempotent producer.
13:47:25.745 [kafka-producer-network-thread | producer-137] INFO Metadata - [Producer clientId=producer-137] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.746 [kafka-producer-network-thread | producer-137] INFO TransactionManager - [Producer clientId=producer-137] ProducerId set to 14242 with epoch 0
13:47:25.747 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.748 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.748 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.748 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045747
13:47:25.748 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-139
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.749 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-139] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.749 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-139] Instantiated an idempotent producer.
13:47:25.749 [kafka-producer-network-thread | producer-138] INFO Metadata - [Producer clientId=producer-138] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.749 [kafka-producer-network-thread | producer-138] INFO TransactionManager - [Producer clientId=producer-138] ProducerId set to 13359 with epoch 0
13:47:25.750 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.750 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.751 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.751 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045750
13:47:25.751 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-140
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.751 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-140] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.752 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-140] Instantiated an idempotent producer.
13:47:25.752 [kafka-producer-network-thread | producer-139] INFO Metadata - [Producer clientId=producer-139] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.752 [kafka-producer-network-thread | producer-139] INFO TransactionManager - [Producer clientId=producer-139] ProducerId set to 14243 with epoch 0
13:47:25.753 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.753 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.753 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.754 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045753
13:47:25.754 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-141
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.754 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-141] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.755 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-141] Instantiated an idempotent producer.
13:47:25.755 [kafka-producer-network-thread | producer-140] INFO Metadata - [Producer clientId=producer-140] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.755 [kafka-producer-network-thread | producer-140] INFO TransactionManager - [Producer clientId=producer-140] ProducerId set to 14245 with epoch 0
13:47:25.756 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.756 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.756 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.756 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045756
13:47:25.757 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-142
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.757 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-142] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.757 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-142] Instantiated an idempotent producer.
13:47:25.758 [kafka-producer-network-thread | producer-141] INFO Metadata - [Producer clientId=producer-141] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.758 [kafka-producer-network-thread | producer-141] INFO TransactionManager - [Producer clientId=producer-141] ProducerId set to 14247 with epoch 0
13:47:25.759 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.760 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.760 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.760 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045760
13:47:25.760 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-143
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.761 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-143] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.761 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-143] Instantiated an idempotent producer.
13:47:25.761 [kafka-producer-network-thread | producer-142] INFO Metadata - [Producer clientId=producer-142] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.761 [kafka-producer-network-thread | producer-142] INFO TransactionManager - [Producer clientId=producer-142] ProducerId set to 14248 with epoch 0
13:47:25.763 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.763 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.763 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.763 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045763
13:47:25.763 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-144
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.764 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-144] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.764 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-144] Instantiated an idempotent producer.
13:47:25.764 [kafka-producer-network-thread | producer-143] INFO Metadata - [Producer clientId=producer-143] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.764 [kafka-producer-network-thread | producer-143] INFO TransactionManager - [Producer clientId=producer-143] ProducerId set to 13363 with epoch 0
13:47:25.765 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.766 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.766 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.766 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045766
13:47:25.766 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-145
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.766 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-145] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.767 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-145] Instantiated an idempotent producer.
13:47:25.767 [kafka-producer-network-thread | producer-144] INFO Metadata - [Producer clientId=producer-144] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.767 [kafka-producer-network-thread | producer-144] INFO TransactionManager - [Producer clientId=producer-144] ProducerId set to 14249 with epoch 0
13:47:25.768 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.768 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.768 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.769 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045768
13:47:25.769 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-146
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.769 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-146] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.770 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-146] Instantiated an idempotent producer.
13:47:25.770 [kafka-producer-network-thread | producer-145] INFO Metadata - [Producer clientId=producer-145] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.770 [kafka-producer-network-thread | producer-145] INFO TransactionManager - [Producer clientId=producer-145] ProducerId set to 13365 with epoch 0
13:47:25.771 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.771 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.771 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.771 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045771
13:47:25.772 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-147
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.772 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-147] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.772 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-147] Instantiated an idempotent producer.
13:47:25.773 [kafka-producer-network-thread | producer-146] INFO Metadata - [Producer clientId=producer-146] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.773 [kafka-producer-network-thread | producer-146] INFO TransactionManager - [Producer clientId=producer-146] ProducerId set to 14251 with epoch 0
13:47:25.774 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.774 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.774 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.774 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045774
13:47:25.775 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-148
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.775 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-148] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.775 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-148] Instantiated an idempotent producer.
13:47:25.776 [kafka-producer-network-thread | producer-147] INFO Metadata - [Producer clientId=producer-147] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.776 [kafka-producer-network-thread | producer-147] INFO TransactionManager - [Producer clientId=producer-147] ProducerId set to 12343 with epoch 0
13:47:25.777 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.777 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.777 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.777 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045777
13:47:25.778 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-149
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.779 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-149] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.779 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-149] Instantiated an idempotent producer.
13:47:25.779 [kafka-producer-network-thread | producer-148] INFO Metadata - [Producer clientId=producer-148] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.779 [kafka-producer-network-thread | producer-148] INFO TransactionManager - [Producer clientId=producer-148] ProducerId set to 12346 with epoch 0
13:47:25.781 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.781 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.781 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.781 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045781
13:47:25.781 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-150
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.782 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-150] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.782 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-150] Instantiated an idempotent producer.
13:47:25.782 [kafka-producer-network-thread | producer-149] INFO TransactionManager - [Producer clientId=producer-149] ProducerId set to 13369 with epoch 0
13:47:25.783 [kafka-producer-network-thread | producer-149] INFO Metadata - [Producer clientId=producer-149] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.783 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.783 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.783 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.784 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045783
13:47:25.784 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-151
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.784 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-151] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.785 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-151] Instantiated an idempotent producer.
13:47:25.785 [kafka-producer-network-thread | producer-150] INFO Metadata - [Producer clientId=producer-150] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.785 [kafka-producer-network-thread | producer-150] INFO TransactionManager - [Producer clientId=producer-150] ProducerId set to 12349 with epoch 0
13:47:25.786 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.786 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.786 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.786 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045786
13:47:25.787 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-152
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.787 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-152] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.787 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-152] Instantiated an idempotent producer.
13:47:25.788 [kafka-producer-network-thread | producer-151] INFO Metadata - [Producer clientId=producer-151] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.788 [kafka-producer-network-thread | producer-151] INFO TransactionManager - [Producer clientId=producer-151] ProducerId set to 13372 with epoch 0
13:47:25.789 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.789 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.789 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.789 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045789
13:47:25.790 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-153
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.790 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-153] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.790 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-153] Instantiated an idempotent producer.
13:47:25.791 [kafka-producer-network-thread | producer-152] INFO Metadata - [Producer clientId=producer-152] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.791 [kafka-producer-network-thread | producer-152] INFO TransactionManager - [Producer clientId=producer-152] ProducerId set to 13373 with epoch 0
13:47:25.792 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.792 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.792 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.792 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045792
13:47:25.793 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-154
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.793 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-154] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.793 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-154] Instantiated an idempotent producer.
13:47:25.795 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.795 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.795 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.795 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045795
13:47:25.796 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-155
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.797 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-155] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.797 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-155] Instantiated an idempotent producer.
13:47:25.799 [kafka-producer-network-thread | producer-154] INFO Metadata - [Producer clientId=producer-154] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.799 [kafka-producer-network-thread | producer-154] INFO TransactionManager - [Producer clientId=producer-154] ProducerId set to 12353 with epoch 0
13:47:25.800 [kafka-producer-network-thread | producer-153] INFO Metadata - [Producer clientId=producer-153] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.800 [kafka-producer-network-thread | producer-153] INFO TransactionManager - [Producer clientId=producer-153] ProducerId set to 13374 with epoch 0
13:47:25.801 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.801 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.801 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.802 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045801
13:47:25.802 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-156
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.803 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-156] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.803 [kafka-producer-network-thread | producer-155] INFO Metadata - [Producer clientId=producer-155] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.807 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-156] Instantiated an idempotent producer.
13:47:25.807 [kafka-producer-network-thread | producer-155] INFO TransactionManager - [Producer clientId=producer-155] ProducerId set to 13376 with epoch 0
13:47:25.809 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.809 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.809 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.809 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045809
13:47:25.810 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-157
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.810 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-157] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.810 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-157] Instantiated an idempotent producer.
13:47:25.811 [kafka-producer-network-thread | producer-156] INFO Metadata - [Producer clientId=producer-156] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.811 [kafka-producer-network-thread | producer-156] INFO TransactionManager - [Producer clientId=producer-156] ProducerId set to 13379 with epoch 0
13:47:25.812 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.812 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.812 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.812 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045812
13:47:25.813 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-158
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.813 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-158] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.813 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-158] Instantiated an idempotent producer.
13:47:25.814 [kafka-producer-network-thread | producer-157] INFO Metadata - [Producer clientId=producer-157] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.814 [kafka-producer-network-thread | producer-157] INFO TransactionManager - [Producer clientId=producer-157] ProducerId set to 13380 with epoch 0
13:47:25.815 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.815 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.815 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.815 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045815
13:47:25.815 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-159
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.816 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-159] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.816 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-159] Instantiated an idempotent producer.
13:47:25.817 [kafka-producer-network-thread | producer-158] INFO Metadata - [Producer clientId=producer-158] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.817 [kafka-producer-network-thread | producer-158] INFO TransactionManager - [Producer clientId=producer-158] ProducerId set to 14263 with epoch 0
13:47:25.818 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.818 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.818 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.818 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045818
13:47:25.819 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-160
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.819 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-160] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.819 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-160] Instantiated an idempotent producer.
13:47:25.820 [kafka-producer-network-thread | producer-159] INFO Metadata - [Producer clientId=producer-159] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.820 [kafka-producer-network-thread | producer-159] INFO TransactionManager - [Producer clientId=producer-159] ProducerId set to 14264 with epoch 0
13:47:25.821 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.821 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.821 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.821 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045821
13:47:25.822 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-161
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.822 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-161] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.822 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-161] Instantiated an idempotent producer.
13:47:25.823 [kafka-producer-network-thread | producer-160] INFO Metadata - [Producer clientId=producer-160] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.823 [kafka-producer-network-thread | producer-160] INFO TransactionManager - [Producer clientId=producer-160] ProducerId set to 12359 with epoch 0
13:47:25.824 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.824 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.824 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.824 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045824
13:47:25.825 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-162
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.825 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-162] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.825 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-162] Instantiated an idempotent producer.
13:47:25.826 [kafka-producer-network-thread | producer-161] INFO Metadata - [Producer clientId=producer-161] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.826 [kafka-producer-network-thread | producer-161] INFO TransactionManager - [Producer clientId=producer-161] ProducerId set to 12361 with epoch 0
13:47:25.827 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.827 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.827 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.827 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045827
13:47:25.828 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-163
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.828 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-163] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.828 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-163] Instantiated an idempotent producer.
13:47:25.828 [kafka-producer-network-thread | producer-162] INFO Metadata - [Producer clientId=producer-162] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.829 [kafka-producer-network-thread | producer-162] INFO TransactionManager - [Producer clientId=producer-162] ProducerId set to 13384 with epoch 0
13:47:25.830 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.830 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.830 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.830 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045830
13:47:25.831 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-164
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.831 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-164] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.831 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-164] Instantiated an idempotent producer.
13:47:25.832 [kafka-producer-network-thread | producer-163] INFO Metadata - [Producer clientId=producer-163] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.832 [kafka-producer-network-thread | producer-163] INFO TransactionManager - [Producer clientId=producer-163] ProducerId set to 14268 with epoch 0
13:47:25.833 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.833 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.833 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.833 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045833
13:47:25.834 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-165
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.834 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-165] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.834 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-165] Instantiated an idempotent producer.
13:47:25.835 [kafka-producer-network-thread | producer-164] INFO Metadata - [Producer clientId=producer-164] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.835 [kafka-producer-network-thread | producer-164] INFO TransactionManager - [Producer clientId=producer-164] ProducerId set to 14270 with epoch 0
13:47:25.836 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.836 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.836 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.836 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045836
13:47:25.837 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-166
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.837 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-166] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.837 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-166] Instantiated an idempotent producer.
13:47:25.838 [kafka-producer-network-thread | producer-165] INFO Metadata - [Producer clientId=producer-165] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.838 [kafka-producer-network-thread | producer-165] INFO TransactionManager - [Producer clientId=producer-165] ProducerId set to 12362 with epoch 0
13:47:25.839 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.839 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.839 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.839 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045839
13:47:25.840 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-167
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.840 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-167] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.840 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-167] Instantiated an idempotent producer.
13:47:25.840 [kafka-producer-network-thread | producer-166] INFO Metadata - [Producer clientId=producer-166] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.841 [kafka-producer-network-thread | producer-166] INFO TransactionManager - [Producer clientId=producer-166] ProducerId set to 12363 with epoch 0
13:47:25.842 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.842 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.842 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.842 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045842
13:47:25.842 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-168
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.843 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-168] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.843 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-168] Instantiated an idempotent producer.
13:47:25.843 [kafka-producer-network-thread | producer-167] INFO Metadata - [Producer clientId=producer-167] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.844 [kafka-producer-network-thread | producer-167] INFO TransactionManager - [Producer clientId=producer-167] ProducerId set to 13390 with epoch 0
13:47:25.845 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.845 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.845 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.845 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045845
13:47:25.845 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-169
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.846 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-169] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.846 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-169] Instantiated an idempotent producer.
13:47:25.846 [kafka-producer-network-thread | producer-168] INFO Metadata - [Producer clientId=producer-168] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.847 [kafka-producer-network-thread | producer-168] INFO TransactionManager - [Producer clientId=producer-168] ProducerId set to 12365 with epoch 0
13:47:25.848 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.848 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.848 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.848 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045848
13:47:25.848 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-170
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.849 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-170] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.849 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-170] Instantiated an idempotent producer.
13:47:25.850 [kafka-producer-network-thread | producer-169] INFO Metadata - [Producer clientId=producer-169] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.850 [kafka-producer-network-thread | producer-169] INFO TransactionManager - [Producer clientId=producer-169] ProducerId set to 13392 with epoch 0
13:47:25.851 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.851 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.851 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.851 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045851
13:47:25.852 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-171
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.852 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-171] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.852 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-171] Instantiated an idempotent producer.
13:47:25.853 [kafka-producer-network-thread | producer-170] INFO Metadata - [Producer clientId=producer-170] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.853 [kafka-producer-network-thread | producer-170] INFO TransactionManager - [Producer clientId=producer-170] ProducerId set to 13394 with epoch 0
13:47:25.854 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.854 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.854 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.854 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045854
13:47:25.855 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-172
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.855 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-172] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.855 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-172] Instantiated an idempotent producer.
13:47:25.855 [kafka-producer-network-thread | producer-171] INFO Metadata - [Producer clientId=producer-171] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.855 [kafka-producer-network-thread | producer-171] INFO TransactionManager - [Producer clientId=producer-171] ProducerId set to 14278 with epoch 0
13:47:25.857 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.857 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.857 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.857 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045857
13:47:25.857 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-173
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.858 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-173] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.858 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-173] Instantiated an idempotent producer.
13:47:25.859 [kafka-producer-network-thread | producer-172] INFO Metadata - [Producer clientId=producer-172] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.859 [kafka-producer-network-thread | producer-172] INFO TransactionManager - [Producer clientId=producer-172] ProducerId set to 12369 with epoch 0
13:47:25.861 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.861 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.862 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.862 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045861
13:47:25.862 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-174
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.862 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-174] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.862 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-174] Instantiated an idempotent producer.
13:47:25.865 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.865 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.865 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.865 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045865
13:47:25.865 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-175
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.865 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-175] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.866 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-175] Instantiated an idempotent producer.
13:47:25.866 [kafka-producer-network-thread | producer-174] INFO Metadata - [Producer clientId=producer-174] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.867 [kafka-producer-network-thread | producer-174] INFO TransactionManager - [Producer clientId=producer-174] ProducerId set to 14281 with epoch 0
13:47:25.867 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.868 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.868 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.868 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045868
13:47:25.868 [kafka-producer-network-thread | producer-173] INFO Metadata - [Producer clientId=producer-173] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.868 [kafka-producer-network-thread | producer-173] INFO TransactionManager - [Producer clientId=producer-173] ProducerId set to 12370 with epoch 0
13:47:25.868 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-176
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.869 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-176] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.869 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-176] Instantiated an idempotent producer.
13:47:25.869 [kafka-producer-network-thread | producer-175] INFO Metadata - [Producer clientId=producer-175] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.869 [kafka-producer-network-thread | producer-175] INFO TransactionManager - [Producer clientId=producer-175] ProducerId set to 13399 with epoch 0
13:47:25.871 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.871 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.871 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.871 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045871
13:47:25.871 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-177
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.872 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-177] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.872 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-177] Instantiated an idempotent producer.
13:47:25.873 [kafka-producer-network-thread | producer-176] INFO Metadata - [Producer clientId=producer-176] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.873 [kafka-producer-network-thread | producer-176] INFO TransactionManager - [Producer clientId=producer-176] ProducerId set to 14284 with epoch 0
13:47:25.874 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.874 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.874 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.874 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045874
13:47:25.874 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-178
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.875 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-178] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.875 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-178] Instantiated an idempotent producer.
13:47:25.875 [kafka-producer-network-thread | producer-177] INFO Metadata - [Producer clientId=producer-177] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.876 [kafka-producer-network-thread | producer-177] INFO TransactionManager - [Producer clientId=producer-177] ProducerId set to 12374 with epoch 0
13:47:25.877 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.877 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.877 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.877 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045877
13:47:25.877 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-179
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.878 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-179] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.878 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-179] Instantiated an idempotent producer.
13:47:25.878 [kafka-producer-network-thread | producer-178] INFO Metadata - [Producer clientId=producer-178] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.879 [kafka-producer-network-thread | producer-178] INFO TransactionManager - [Producer clientId=producer-178] ProducerId set to 13401 with epoch 0
13:47:25.880 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.880 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.880 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.880 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045880
13:47:25.880 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-180
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.881 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-180] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.881 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-180] Instantiated an idempotent producer.
13:47:25.881 [kafka-producer-network-thread | producer-179] INFO Metadata - [Producer clientId=producer-179] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.882 [kafka-producer-network-thread | producer-179] INFO TransactionManager - [Producer clientId=producer-179] ProducerId set to 14286 with epoch 0
13:47:25.882 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.883 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.883 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.883 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045883
13:47:25.883 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-181
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.883 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-181] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.884 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-181] Instantiated an idempotent producer.
13:47:25.884 [kafka-producer-network-thread | producer-180] INFO Metadata - [Producer clientId=producer-180] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.885 [kafka-producer-network-thread | producer-180] INFO TransactionManager - [Producer clientId=producer-180] ProducerId set to 14287 with epoch 0
13:47:25.885 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.885 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.885 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.885 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045885
13:47:25.886 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-182
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.886 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-182] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.886 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-182] Instantiated an idempotent producer.
13:47:25.887 [kafka-producer-network-thread | producer-181] INFO Metadata - [Producer clientId=producer-181] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.887 [kafka-producer-network-thread | producer-181] INFO TransactionManager - [Producer clientId=producer-181] ProducerId set to 14288 with epoch 0
13:47:25.888 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.888 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.888 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.888 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045888
13:47:25.888 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-183
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.889 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-183] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.889 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-183] Instantiated an idempotent producer.
13:47:25.890 [kafka-producer-network-thread | producer-182] INFO Metadata - [Producer clientId=producer-182] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.890 [kafka-producer-network-thread | producer-182] INFO TransactionManager - [Producer clientId=producer-182] ProducerId set to 14290 with epoch 0
13:47:25.891 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.891 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.892 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.892 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045891
13:47:25.892 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-184
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.892 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-184] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.892 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-184] Instantiated an idempotent producer.
13:47:25.893 [kafka-producer-network-thread | producer-183] INFO Metadata - [Producer clientId=producer-183] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.893 [kafka-producer-network-thread | producer-183] INFO TransactionManager - [Producer clientId=producer-183] ProducerId set to 12381 with epoch 0
13:47:25.895 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.895 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.895 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.895 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045895
13:47:25.895 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-185
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.896 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-185] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.896 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-185] Instantiated an idempotent producer.
13:47:25.897 [kafka-producer-network-thread | producer-184] INFO Metadata - [Producer clientId=producer-184] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.897 [kafka-producer-network-thread | producer-184] INFO TransactionManager - [Producer clientId=producer-184] ProducerId set to 13406 with epoch 0
13:47:25.898 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.898 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.898 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.898 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045898
13:47:25.898 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-186
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.899 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-186] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.899 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-186] Instantiated an idempotent producer.
13:47:25.900 [kafka-producer-network-thread | producer-185] INFO Metadata - [Producer clientId=producer-185] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.900 [kafka-producer-network-thread | producer-185] INFO TransactionManager - [Producer clientId=producer-185] ProducerId set to 13408 with epoch 0
13:47:25.901 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.901 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.901 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.901 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045901
13:47:25.901 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-187
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.902 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-187] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.902 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-187] Instantiated an idempotent producer.
13:47:25.902 [kafka-producer-network-thread | producer-186] INFO Metadata - [Producer clientId=producer-186] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.903 [kafka-producer-network-thread | producer-186] INFO TransactionManager - [Producer clientId=producer-186] ProducerId set to 13410 with epoch 0
13:47:25.904 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.904 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.904 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.904 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045904
13:47:25.904 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-188
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.905 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-188] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.905 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-188] Instantiated an idempotent producer.
13:47:25.905 [kafka-producer-network-thread | producer-187] INFO Metadata - [Producer clientId=producer-187] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.906 [kafka-producer-network-thread | producer-187] INFO TransactionManager - [Producer clientId=producer-187] ProducerId set to 12384 with epoch 0
13:47:25.907 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.907 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.907 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.907 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045907
13:47:25.907 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-189
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.908 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-189] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.908 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-189] Instantiated an idempotent producer.
13:47:25.908 [kafka-producer-network-thread | producer-188] INFO Metadata - [Producer clientId=producer-188] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.909 [kafka-producer-network-thread | producer-188] INFO TransactionManager - [Producer clientId=producer-188] ProducerId set to 14296 with epoch 0
13:47:25.910 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.911 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.911 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.911 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045911
13:47:25.911 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-190
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.912 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-190] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.912 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-190] Instantiated an idempotent producer.
13:47:25.912 [kafka-producer-network-thread | producer-189] INFO Metadata - [Producer clientId=producer-189] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.912 [kafka-producer-network-thread | producer-189] INFO TransactionManager - [Producer clientId=producer-189] ProducerId set to 12385 with epoch 0
13:47:25.914 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.914 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.914 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.914 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045914
13:47:25.914 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-191
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.915 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-191] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.915 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-191] Instantiated an idempotent producer.
13:47:25.915 [kafka-producer-network-thread | producer-190] INFO Metadata - [Producer clientId=producer-190] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.915 [kafka-producer-network-thread | producer-190] INFO TransactionManager - [Producer clientId=producer-190] ProducerId set to 14299 with epoch 0
13:47:25.916 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.917 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.917 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.917 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045917
13:47:25.917 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-192
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.918 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-192] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.918 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-192] Instantiated an idempotent producer.
13:47:25.918 [kafka-producer-network-thread | producer-191] INFO Metadata - [Producer clientId=producer-191] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.918 [kafka-producer-network-thread | producer-191] INFO TransactionManager - [Producer clientId=producer-191] ProducerId set to 14300 with epoch 0
13:47:25.920 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.920 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.920 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.920 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045920
13:47:25.920 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-193
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.921 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-193] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.921 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-193] Instantiated an idempotent producer.
13:47:25.921 [kafka-producer-network-thread | producer-192] INFO Metadata - [Producer clientId=producer-192] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.922 [kafka-producer-network-thread | producer-192] INFO TransactionManager - [Producer clientId=producer-192] ProducerId set to 12388 with epoch 0
13:47:25.923 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.923 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.923 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.923 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045923
13:47:25.923 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-194
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.924 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-194] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.924 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-194] Instantiated an idempotent producer.
13:47:25.924 [kafka-producer-network-thread | producer-193] INFO Metadata - [Producer clientId=producer-193] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.925 [kafka-producer-network-thread | producer-193] INFO TransactionManager - [Producer clientId=producer-193] ProducerId set to 13415 with epoch 0
13:47:25.926 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.926 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.926 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.926 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045926
13:47:25.926 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-195
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.927 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-195] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.927 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-195] Instantiated an idempotent producer.
13:47:25.928 [kafka-producer-network-thread | producer-194] INFO Metadata - [Producer clientId=producer-194] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.928 [kafka-producer-network-thread | producer-194] INFO TransactionManager - [Producer clientId=producer-194] ProducerId set to 13416 with epoch 0
13:47:25.929 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.929 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.929 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.929 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045929
13:47:25.929 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-196
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.930 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-196] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.930 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-196] Instantiated an idempotent producer.
13:47:25.931 [kafka-producer-network-thread | producer-195] INFO Metadata - [Producer clientId=producer-195] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.931 [kafka-producer-network-thread | producer-195] INFO TransactionManager - [Producer clientId=producer-195] ProducerId set to 12393 with epoch 0
13:47:25.932 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.932 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.932 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.932 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045932
13:47:25.932 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-197
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.933 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-197] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.933 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-197] Instantiated an idempotent producer.
13:47:25.933 [kafka-producer-network-thread | producer-196] INFO Metadata - [Producer clientId=producer-196] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.934 [kafka-producer-network-thread | producer-196] INFO TransactionManager - [Producer clientId=producer-196] ProducerId set to 12394 with epoch 0
13:47:25.935 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.935 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.935 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.935 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045935
13:47:25.935 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-198
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.936 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-198] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.936 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-198] Instantiated an idempotent producer.
13:47:25.937 [kafka-producer-network-thread | producer-197] INFO Metadata - [Producer clientId=producer-197] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.937 [kafka-producer-network-thread | producer-197] INFO TransactionManager - [Producer clientId=producer-197] ProducerId set to 13418 with epoch 0
13:47:25.937 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.938 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.938 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.938 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045937
13:47:25.938 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-199
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.938 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-199] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.938 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-199] Instantiated an idempotent producer.
13:47:25.939 [kafka-producer-network-thread | producer-198] INFO Metadata - [Producer clientId=producer-198] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.939 [kafka-producer-network-thread | producer-198] INFO TransactionManager - [Producer clientId=producer-198] ProducerId set to 14307 with epoch 0
13:47:25.940 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.940 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.940 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.940 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045940
13:47:25.940 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-200
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.941 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-200] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.941 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-200] Instantiated an idempotent producer.
13:47:25.941 [kafka-producer-network-thread | producer-199] INFO Metadata - [Producer clientId=producer-199] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.941 [kafka-producer-network-thread | producer-199] INFO TransactionManager - [Producer clientId=producer-199] ProducerId set to 13420 with epoch 0
13:47:25.942 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.942 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.942 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.942 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045942
13:47:25.942 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-201
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.943 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-201] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.943 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-201] Instantiated an idempotent producer.
13:47:25.943 [kafka-producer-network-thread | producer-200] INFO Metadata - [Producer clientId=producer-200] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.943 [kafka-producer-network-thread | producer-200] INFO TransactionManager - [Producer clientId=producer-200] ProducerId set to 12398 with epoch 0
13:47:25.944 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.944 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.944 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.944 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045944
13:47:25.945 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-202
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.945 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-202] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.945 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-202] Instantiated an idempotent producer.
13:47:25.945 [kafka-producer-network-thread | producer-201] INFO Metadata - [Producer clientId=producer-201] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.946 [kafka-producer-network-thread | producer-201] INFO TransactionManager - [Producer clientId=producer-201] ProducerId set to 12399 with epoch 0
13:47:25.946 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.946 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.946 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.946 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045946
13:47:25.947 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-203
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.947 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-203] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.947 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-203] Instantiated an idempotent producer.
13:47:25.948 [kafka-producer-network-thread | producer-202] INFO Metadata - [Producer clientId=producer-202] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.948 [kafka-producer-network-thread | producer-202] INFO TransactionManager - [Producer clientId=producer-202] ProducerId set to 14311 with epoch 0
13:47:25.949 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.949 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.949 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.949 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045949
13:47:25.949 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-204
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.950 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-204] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.950 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-204] Instantiated an idempotent producer.
13:47:25.950 [kafka-producer-network-thread | producer-203] INFO Metadata - [Producer clientId=producer-203] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.950 [kafka-producer-network-thread | producer-203] INFO TransactionManager - [Producer clientId=producer-203] ProducerId set to 12403 with epoch 0
13:47:25.951 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.951 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.951 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.951 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045951
13:47:25.951 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-205
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.952 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-205] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.952 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-205] Instantiated an idempotent producer.
13:47:25.953 [kafka-producer-network-thread | producer-204] INFO Metadata - [Producer clientId=producer-204] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.953 [kafka-producer-network-thread | producer-204] INFO TransactionManager - [Producer clientId=producer-204] ProducerId set to 13421 with epoch 0
13:47:25.953 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.953 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.953 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.953 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045953
13:47:25.954 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-206
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.954 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-206] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.954 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-206] Instantiated an idempotent producer.
13:47:25.955 [kafka-producer-network-thread | producer-205] INFO Metadata - [Producer clientId=producer-205] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.955 [kafka-producer-network-thread | producer-205] INFO TransactionManager - [Producer clientId=producer-205] ProducerId set to 14314 with epoch 0
13:47:25.955 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.955 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.955 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.956 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045955
13:47:25.956 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-207
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.956 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-207] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.956 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-207] Instantiated an idempotent producer.
13:47:25.957 [kafka-producer-network-thread | producer-206] INFO Metadata - [Producer clientId=producer-206] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.957 [kafka-producer-network-thread | producer-206] INFO TransactionManager - [Producer clientId=producer-206] ProducerId set to 13422 with epoch 0
13:47:25.958 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.958 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.958 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.958 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045958
13:47:25.958 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-208
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.959 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-208] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.959 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-208] Instantiated an idempotent producer.
13:47:25.959 [kafka-producer-network-thread | producer-207] INFO Metadata - [Producer clientId=producer-207] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.959 [kafka-producer-network-thread | producer-207] INFO TransactionManager - [Producer clientId=producer-207] ProducerId set to 13424 with epoch 0
13:47:25.960 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.960 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.960 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.960 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045960
13:47:25.960 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-209
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.961 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-209] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.961 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-209] Instantiated an idempotent producer.
13:47:25.962 [kafka-producer-network-thread | producer-208] INFO Metadata - [Producer clientId=producer-208] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.962 [kafka-producer-network-thread | producer-208] INFO TransactionManager - [Producer clientId=producer-208] ProducerId set to 12406 with epoch 0
13:47:25.962 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.962 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.962 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.962 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045962
13:47:25.963 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-210
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.963 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-210] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.963 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-210] Instantiated an idempotent producer.
13:47:25.964 [kafka-producer-network-thread | producer-209] INFO Metadata - [Producer clientId=producer-209] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.964 [kafka-producer-network-thread | producer-209] INFO TransactionManager - [Producer clientId=producer-209] ProducerId set to 12407 with epoch 0
13:47:25.964 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.965 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.965 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.965 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045964
13:47:25.965 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-211
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.965 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-211] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.965 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-211] Instantiated an idempotent producer.
13:47:25.966 [kafka-producer-network-thread | producer-210] INFO Metadata - [Producer clientId=producer-210] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.966 [kafka-producer-network-thread | producer-210] INFO TransactionManager - [Producer clientId=producer-210] ProducerId set to 14317 with epoch 0
13:47:25.967 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.967 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.967 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.967 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045967
13:47:25.967 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-212
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.967 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-212] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.968 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-212] Instantiated an idempotent producer.
13:47:25.968 [kafka-producer-network-thread | producer-211] INFO Metadata - [Producer clientId=producer-211] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.968 [kafka-producer-network-thread | producer-211] INFO TransactionManager - [Producer clientId=producer-211] ProducerId set to 12409 with epoch 0
13:47:25.969 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.969 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.969 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.969 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045969
13:47:25.969 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-213
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.970 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-213] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.970 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-213] Instantiated an idempotent producer.
13:47:25.971 [kafka-producer-network-thread | producer-212] INFO Metadata - [Producer clientId=producer-212] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.971 [kafka-producer-network-thread | producer-212] INFO TransactionManager - [Producer clientId=producer-212] ProducerId set to 12411 with epoch 0
13:47:25.971 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.971 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.971 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.971 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045971
13:47:25.972 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-214
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.972 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-214] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.972 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-214] Instantiated an idempotent producer.
13:47:25.973 [kafka-producer-network-thread | producer-213] INFO Metadata - [Producer clientId=producer-213] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.973 [kafka-producer-network-thread | producer-213] INFO TransactionManager - [Producer clientId=producer-213] ProducerId set to 13430 with epoch 0
13:47:25.974 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.974 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.974 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.974 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045974
13:47:25.974 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-215
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.974 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-215] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.975 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-215] Instantiated an idempotent producer.
13:47:25.975 [kafka-producer-network-thread | producer-214] INFO Metadata - [Producer clientId=producer-214] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.975 [kafka-producer-network-thread | producer-214] INFO TransactionManager - [Producer clientId=producer-214] ProducerId set to 13431 with epoch 0
13:47:25.976 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.976 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.976 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.976 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045976
13:47:25.976 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-216
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.977 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-216] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.977 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-216] Instantiated an idempotent producer.
13:47:25.977 [kafka-producer-network-thread | producer-215] INFO Metadata - [Producer clientId=producer-215] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.977 [kafka-producer-network-thread | producer-215] INFO TransactionManager - [Producer clientId=producer-215] ProducerId set to 14319 with epoch 0
13:47:25.978 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.978 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.978 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.978 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045978
13:47:25.978 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-217
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.979 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-217] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.979 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-217] Instantiated an idempotent producer.
13:47:25.979 [kafka-producer-network-thread | producer-216] INFO Metadata - [Producer clientId=producer-216] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.980 [kafka-producer-network-thread | producer-216] INFO TransactionManager - [Producer clientId=producer-216] ProducerId set to 14320 with epoch 0
13:47:25.980 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.980 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.980 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.980 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045980
13:47:25.981 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-218
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.981 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-218] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.981 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-218] Instantiated an idempotent producer.
13:47:25.982 [kafka-producer-network-thread | producer-217] INFO Metadata - [Producer clientId=producer-217] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.982 [kafka-producer-network-thread | producer-217] INFO TransactionManager - [Producer clientId=producer-217] ProducerId set to 14323 with epoch 0
13:47:25.982 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.982 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.983 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.983 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045982
13:47:25.983 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-219
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.983 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-219] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.983 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-219] Instantiated an idempotent producer.
13:47:25.984 [kafka-producer-network-thread | producer-218] INFO Metadata - [Producer clientId=producer-218] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.984 [kafka-producer-network-thread | producer-218] INFO TransactionManager - [Producer clientId=producer-218] ProducerId set to 13433 with epoch 0
13:47:25.985 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.985 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.985 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.985 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045985
13:47:25.985 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-220
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.985 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-220] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.985 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-220] Instantiated an idempotent producer.
13:47:25.986 [kafka-producer-network-thread | producer-219] INFO Metadata - [Producer clientId=producer-219] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.986 [kafka-producer-network-thread | producer-219] INFO TransactionManager - [Producer clientId=producer-219] ProducerId set to 14325 with epoch 0
13:47:25.987 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.987 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.987 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.987 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045987
13:47:25.987 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-221
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.988 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-221] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.988 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-221] Instantiated an idempotent producer.
13:47:25.988 [kafka-producer-network-thread | producer-220] INFO Metadata - [Producer clientId=producer-220] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.988 [kafka-producer-network-thread | producer-220] INFO TransactionManager - [Producer clientId=producer-220] ProducerId set to 13437 with epoch 0
13:47:25.989 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.989 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.989 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.989 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045989
13:47:25.989 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-222
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.990 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-222] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.990 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-222] Instantiated an idempotent producer.
13:47:25.990 [kafka-producer-network-thread | producer-221] INFO Metadata - [Producer clientId=producer-221] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.991 [kafka-producer-network-thread | producer-221] INFO TransactionManager - [Producer clientId=producer-221] ProducerId set to 14327 with epoch 0
13:47:25.991 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.991 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.991 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.991 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045991
13:47:25.992 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-223
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.992 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-223] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.992 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-223] Instantiated an idempotent producer.
13:47:25.993 [kafka-producer-network-thread | producer-222] INFO Metadata - [Producer clientId=producer-222] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.993 [kafka-producer-network-thread | producer-222] INFO TransactionManager - [Producer clientId=producer-222] ProducerId set to 12416 with epoch 0
13:47:25.994 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.994 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.994 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.994 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045994
13:47:25.994 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-224
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.994 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-224] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.994 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-224] Instantiated an idempotent producer.
13:47:25.995 [kafka-producer-network-thread | producer-223] INFO Metadata - [Producer clientId=producer-223] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.996 [kafka-producer-network-thread | producer-223] INFO TransactionManager - [Producer clientId=producer-223] ProducerId set to 12419 with epoch 0
13:47:25.996 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.996 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.996 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.996 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045996
13:47:25.996 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-225
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.997 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-225] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.997 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-225] Instantiated an idempotent producer.
13:47:25.997 [kafka-producer-network-thread | producer-224] INFO Metadata - [Producer clientId=producer-224] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:25.997 [kafka-producer-network-thread | producer-224] INFO TransactionManager - [Producer clientId=producer-224] ProducerId set to 12420 with epoch 0
13:47:25.998 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:25.998 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:25.998 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:25.998 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336045998
13:47:25.998 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-226
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:25.999 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-226] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:25.999 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-226] Instantiated an idempotent producer.
13:47:25.999 [kafka-producer-network-thread | producer-225] INFO Metadata - [Producer clientId=producer-225] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.000 [kafka-producer-network-thread | producer-225] INFO TransactionManager - [Producer clientId=producer-225] ProducerId set to 13439 with epoch 0
13:47:26.000 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.000 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.000 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.000 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046000
13:47:26.001 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-227
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.001 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-227] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.001 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-227] Instantiated an idempotent producer.
13:47:26.002 [kafka-producer-network-thread | producer-226] INFO Metadata - [Producer clientId=producer-226] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.002 [kafka-producer-network-thread | producer-226] INFO TransactionManager - [Producer clientId=producer-226] ProducerId set to 12423 with epoch 0
13:47:26.002 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.003 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.003 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.003 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046003
13:47:26.003 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-228
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.003 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-228] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.004 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-228] Instantiated an idempotent producer.
13:47:26.004 [kafka-producer-network-thread | producer-227] INFO Metadata - [Producer clientId=producer-227] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.004 [kafka-producer-network-thread | producer-227] INFO TransactionManager - [Producer clientId=producer-227] ProducerId set to 13440 with epoch 0
13:47:26.005 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.005 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.005 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.005 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046005
13:47:26.005 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-229
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.006 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-229] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.006 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-229] Instantiated an idempotent producer.
13:47:26.006 [kafka-producer-network-thread | producer-228] INFO Metadata - [Producer clientId=producer-228] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.006 [kafka-producer-network-thread | producer-228] INFO TransactionManager - [Producer clientId=producer-228] ProducerId set to 14331 with epoch 0
13:47:26.007 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.007 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.007 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.007 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046007
13:47:26.007 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-230
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.008 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-230] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.008 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-230] Instantiated an idempotent producer.
13:47:26.008 [kafka-producer-network-thread | producer-229] INFO Metadata - [Producer clientId=producer-229] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.009 [kafka-producer-network-thread | producer-229] INFO TransactionManager - [Producer clientId=producer-229] ProducerId set to 12425 with epoch 0
13:47:26.009 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.009 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.009 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.009 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046009
13:47:26.009 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-231
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.010 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-231] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.010 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-231] Instantiated an idempotent producer.
13:47:26.010 [kafka-producer-network-thread | producer-230] INFO Metadata - [Producer clientId=producer-230] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.010 [kafka-producer-network-thread | producer-230] INFO TransactionManager - [Producer clientId=producer-230] ProducerId set to 12426 with epoch 0
13:47:26.011 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.011 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.011 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.011 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046011
13:47:26.012 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-232
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.012 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-232] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.012 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-232] Instantiated an idempotent producer.
13:47:26.013 [kafka-producer-network-thread | producer-231] INFO Metadata - [Producer clientId=producer-231] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.013 [kafka-producer-network-thread | producer-231] INFO TransactionManager - [Producer clientId=producer-231] ProducerId set to 12427 with epoch 0
13:47:26.013 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.013 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.013 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.013 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046013
13:47:26.014 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-233
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.014 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-233] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.014 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-233] Instantiated an idempotent producer.
13:47:26.014 [kafka-producer-network-thread | producer-232] INFO Metadata - [Producer clientId=producer-232] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.015 [kafka-producer-network-thread | producer-232] INFO TransactionManager - [Producer clientId=producer-232] ProducerId set to 13442 with epoch 0
13:47:26.015 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.016 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.016 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.016 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046015
13:47:26.016 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-234
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.016 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-234] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.016 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-234] Instantiated an idempotent producer.
13:47:26.017 [kafka-producer-network-thread | producer-233] INFO Metadata - [Producer clientId=producer-233] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.018 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.018 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.018 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.018 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046018
13:47:26.018 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-235
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.019 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-235] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.019 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-235] Instantiated an idempotent producer.
13:47:26.019 [kafka-producer-network-thread | producer-234] INFO Metadata - [Producer clientId=producer-234] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.019 [kafka-producer-network-thread | producer-234] INFO TransactionManager - [Producer clientId=producer-234] ProducerId set to 14337 with epoch 0
13:47:26.020 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.020 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.020 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.020 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046020
13:47:26.021 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-236
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.021 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-236] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.022 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-236] Instantiated an idempotent producer.
13:47:26.022 [kafka-producer-network-thread | producer-235] INFO Metadata - [Producer clientId=producer-235] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.022 [kafka-producer-network-thread | producer-235] INFO TransactionManager - [Producer clientId=producer-235] ProducerId set to 12430 with epoch 0
13:47:26.023 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.023 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.023 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.023 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046023
13:47:26.023 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-237
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.024 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-237] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.024 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-237] Instantiated an idempotent producer.
13:47:26.025 [kafka-producer-network-thread | producer-236] INFO Metadata - [Producer clientId=producer-236] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.025 [kafka-producer-network-thread | producer-236] INFO TransactionManager - [Producer clientId=producer-236] ProducerId set to 13445 with epoch 0
13:47:26.026 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.026 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.026 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.026 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046026
13:47:26.026 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-238
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.027 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-238] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.027 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-238] Instantiated an idempotent producer.
13:47:26.028 [kafka-producer-network-thread | producer-237] INFO Metadata - [Producer clientId=producer-237] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.028 [kafka-producer-network-thread | producer-237] INFO TransactionManager - [Producer clientId=producer-237] ProducerId set to 12431 with epoch 0
13:47:26.029 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.029 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.029 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.029 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046029
13:47:26.029 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-239
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.029 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-239] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.030 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-239] Instantiated an idempotent producer.
13:47:26.030 [kafka-producer-network-thread | producer-238] INFO Metadata - [Producer clientId=producer-238] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.031 [kafka-producer-network-thread | producer-238] INFO TransactionManager - [Producer clientId=producer-238] ProducerId set to 13446 with epoch 0
13:47:26.031 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.031 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.031 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.031 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046031
13:47:26.032 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-240
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.032 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-240] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.032 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-240] Instantiated an idempotent producer.
13:47:26.033 [kafka-producer-network-thread | producer-239] INFO Metadata - [Producer clientId=producer-239] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.033 [kafka-producer-network-thread | producer-239] INFO TransactionManager - [Producer clientId=producer-239] ProducerId set to 14344 with epoch 0
13:47:26.033 [kafka-producer-network-thread | producer-233] INFO TransactionManager - [Producer clientId=producer-233] ProducerId set to 12433 with epoch 0
13:47:26.034 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.034 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.034 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.034 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046034
13:47:26.034 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-241
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.035 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-241] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.035 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-241] Instantiated an idempotent producer.
13:47:26.036 [kafka-producer-network-thread | producer-240] INFO Metadata - [Producer clientId=producer-240] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.036 [kafka-producer-network-thread | producer-240] INFO TransactionManager - [Producer clientId=producer-240] ProducerId set to 14345 with epoch 0
13:47:26.043 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.043 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.043 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.043 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046043
13:47:26.043 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-242
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.044 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-242] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.044 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-242] Instantiated an idempotent producer.
13:47:26.044 [kafka-producer-network-thread | producer-241] INFO Metadata - [Producer clientId=producer-241] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.044 [kafka-producer-network-thread | producer-241] INFO TransactionManager - [Producer clientId=producer-241] ProducerId set to 12437 with epoch 0
13:47:26.045 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.046 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.046 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.046 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046046
13:47:26.046 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-243
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.046 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-243] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.046 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-243] Instantiated an idempotent producer.
13:47:26.047 [kafka-producer-network-thread | producer-242] INFO Metadata - [Producer clientId=producer-242] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.047 [kafka-producer-network-thread | producer-242] INFO TransactionManager - [Producer clientId=producer-242] ProducerId set to 13449 with epoch 0
13:47:26.048 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.048 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.048 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.048 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046048
13:47:26.048 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-244
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.048 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-244] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.049 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-244] Instantiated an idempotent producer.
13:47:26.049 [kafka-producer-network-thread | producer-243] INFO Metadata - [Producer clientId=producer-243] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.049 [kafka-producer-network-thread | producer-243] INFO TransactionManager - [Producer clientId=producer-243] ProducerId set to 12438 with epoch 0
13:47:26.050 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.050 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.050 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.050 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046050
13:47:26.050 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-245
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.051 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-245] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.051 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-245] Instantiated an idempotent producer.
13:47:26.052 [kafka-producer-network-thread | producer-244] INFO Metadata - [Producer clientId=producer-244] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.052 [kafka-producer-network-thread | producer-244] INFO TransactionManager - [Producer clientId=producer-244] ProducerId set to 14352 with epoch 0
13:47:26.052 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.052 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.052 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.052 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046052
13:47:26.053 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-246
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.053 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-246] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.053 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-246] Instantiated an idempotent producer.
13:47:26.053 [kafka-producer-network-thread | producer-245] INFO Metadata - [Producer clientId=producer-245] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.053 [kafka-producer-network-thread | producer-245] INFO TransactionManager - [Producer clientId=producer-245] ProducerId set to 14354 with epoch 0
13:47:26.054 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.054 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.054 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.054 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046054
13:47:26.055 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-247
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.055 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-247] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.055 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-247] Instantiated an idempotent producer.
13:47:26.056 [kafka-producer-network-thread | producer-246] INFO Metadata - [Producer clientId=producer-246] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.056 [kafka-producer-network-thread | producer-246] INFO TransactionManager - [Producer clientId=producer-246] ProducerId set to 13451 with epoch 0
13:47:26.057 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.057 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.057 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.057 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046057
13:47:26.057 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-248
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.058 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-248] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.058 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-248] Instantiated an idempotent producer.
13:47:26.058 [kafka-producer-network-thread | producer-247] INFO Metadata - [Producer clientId=producer-247] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.058 [kafka-producer-network-thread | producer-247] INFO TransactionManager - [Producer clientId=producer-247] ProducerId set to 12440 with epoch 0
13:47:26.060 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.060 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.060 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.060 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046060
13:47:26.060 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-249
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.061 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-249] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.061 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-249] Instantiated an idempotent producer.
13:47:26.061 [kafka-producer-network-thread | producer-248] INFO Metadata - [Producer clientId=producer-248] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.061 [kafka-producer-network-thread | producer-248] INFO TransactionManager - [Producer clientId=producer-248] ProducerId set to 13453 with epoch 0
13:47:26.062 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.062 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.062 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.062 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046062
13:47:26.063 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-250
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.063 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-250] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.063 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-250] Instantiated an idempotent producer.
13:47:26.064 [kafka-producer-network-thread | producer-249] INFO Metadata - [Producer clientId=producer-249] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.064 [kafka-producer-network-thread | producer-249] INFO TransactionManager - [Producer clientId=producer-249] ProducerId set to 13454 with epoch 0
13:47:26.065 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.065 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.065 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.065 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046065
13:47:26.066 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-251
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.066 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-251] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.066 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-251] Instantiated an idempotent producer.
13:47:26.067 [kafka-producer-network-thread | producer-250] INFO Metadata - [Producer clientId=producer-250] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.067 [kafka-producer-network-thread | producer-250] INFO TransactionManager - [Producer clientId=producer-250] ProducerId set to 14359 with epoch 0
13:47:26.068 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.068 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.068 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.068 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046068
13:47:26.068 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-252
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.069 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-252] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.069 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-252] Instantiated an idempotent producer.
13:47:26.069 [kafka-producer-network-thread | producer-251] INFO Metadata - [Producer clientId=producer-251] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.069 [kafka-producer-network-thread | producer-251] INFO TransactionManager - [Producer clientId=producer-251] ProducerId set to 14360 with epoch 0
13:47:26.070 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.070 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.070 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.070 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046070
13:47:26.071 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-253
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.071 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-253] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.071 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-253] Instantiated an idempotent producer.
13:47:26.072 [kafka-producer-network-thread | producer-252] INFO Metadata - [Producer clientId=producer-252] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.072 [kafka-producer-network-thread | producer-252] INFO TransactionManager - [Producer clientId=producer-252] ProducerId set to 14362 with epoch 0
13:47:26.073 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.073 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.073 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.073 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046073
13:47:26.073 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-254
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.074 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-254] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.074 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-254] Instantiated an idempotent producer.
13:47:26.074 [kafka-producer-network-thread | producer-253] INFO Metadata - [Producer clientId=producer-253] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.074 [kafka-producer-network-thread | producer-253] INFO TransactionManager - [Producer clientId=producer-253] ProducerId set to 13457 with epoch 0
13:47:26.076 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.076 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.077 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.077 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046076
13:47:26.077 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-255
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.077 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-255] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.077 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-255] Instantiated an idempotent producer.
13:47:26.078 [kafka-producer-network-thread | producer-254] INFO Metadata - [Producer clientId=producer-254] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.079 [kafka-producer-network-thread | producer-254] INFO TransactionManager - [Producer clientId=producer-254] ProducerId set to 12445 with epoch 0
13:47:26.079 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.079 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.079 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.079 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046079
13:47:26.080 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-256
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.080 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-256] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.080 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-256] Instantiated an idempotent producer.
13:47:26.081 [kafka-producer-network-thread | producer-255] INFO Metadata - [Producer clientId=producer-255] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.082 [kafka-producer-network-thread | producer-255] INFO TransactionManager - [Producer clientId=producer-255] ProducerId set to 14365 with epoch 0
13:47:26.083 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.084 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.084 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.084 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046084
13:47:26.084 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-257
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.085 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-257] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.085 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-257] Instantiated an idempotent producer.
13:47:26.085 [kafka-producer-network-thread | producer-256] INFO Metadata - [Producer clientId=producer-256] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.085 [kafka-producer-network-thread | producer-256] INFO TransactionManager - [Producer clientId=producer-256] ProducerId set to 14366 with epoch 0
13:47:26.088 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.088 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.088 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.088 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046088
13:47:26.089 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-258
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.089 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-258] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.089 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-258] Instantiated an idempotent producer.
13:47:26.090 [kafka-producer-network-thread | producer-257] INFO Metadata - [Producer clientId=producer-257] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.091 [kafka-producer-network-thread | producer-257] INFO TransactionManager - [Producer clientId=producer-257] ProducerId set to 13460 with epoch 0
13:47:26.091 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.091 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.092 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.092 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046091
13:47:26.092 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-259
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.092 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-259] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.092 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-259] Instantiated an idempotent producer.
13:47:26.094 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.094 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.094 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.094 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046094
13:47:26.095 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-260
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.096 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-260] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.096 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-260] Instantiated an idempotent producer.
13:47:26.097 [kafka-producer-network-thread | producer-259] INFO Metadata - [Producer clientId=producer-259] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.097 [kafka-producer-network-thread | producer-259] INFO TransactionManager - [Producer clientId=producer-259] ProducerId set to 14368 with epoch 0
13:47:26.097 [kafka-producer-network-thread | producer-258] INFO Metadata - [Producer clientId=producer-258] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.097 [kafka-producer-network-thread | producer-258] INFO TransactionManager - [Producer clientId=producer-258] ProducerId set to 12449 with epoch 0
13:47:26.098 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.098 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.098 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.098 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046098
13:47:26.098 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-261
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.098 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-261] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.099 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-261] Instantiated an idempotent producer.
13:47:26.099 [kafka-producer-network-thread | producer-260] INFO Metadata - [Producer clientId=producer-260] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.099 [kafka-producer-network-thread | producer-260] INFO TransactionManager - [Producer clientId=producer-260] ProducerId set to 12450 with epoch 0
13:47:26.100 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.100 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.100 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.100 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046100
13:47:26.100 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-262
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.101 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-262] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.101 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-262] Instantiated an idempotent producer.
13:47:26.102 [kafka-producer-network-thread | producer-261] INFO Metadata - [Producer clientId=producer-261] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.102 [kafka-producer-network-thread | producer-261] INFO TransactionManager - [Producer clientId=producer-261] ProducerId set to 13463 with epoch 0
13:47:26.103 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.103 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.103 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.103 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046103
13:47:26.103 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-263
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.104 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-263] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.104 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-263] Instantiated an idempotent producer.
13:47:26.105 [kafka-producer-network-thread | producer-262] INFO Metadata - [Producer clientId=producer-262] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.105 [kafka-producer-network-thread | producer-262] INFO TransactionManager - [Producer clientId=producer-262] ProducerId set to 12452 with epoch 0
13:47:26.105 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.105 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.106 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.106 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046105
13:47:26.106 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-264
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.106 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-264] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.107 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-264] Instantiated an idempotent producer.
13:47:26.107 [kafka-producer-network-thread | producer-263] INFO Metadata - [Producer clientId=producer-263] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.107 [kafka-producer-network-thread | producer-263] INFO TransactionManager - [Producer clientId=producer-263] ProducerId set to 12454 with epoch 0
13:47:26.108 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.108 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.108 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.108 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046108
13:47:26.108 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-265
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.109 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-265] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.109 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-265] Instantiated an idempotent producer.
13:47:26.111 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.111 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.111 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.111 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046111
13:47:26.111 [kafka-producer-network-thread | producer-264] INFO Metadata - [Producer clientId=producer-264] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.111 [kafka-producer-network-thread | producer-264] INFO TransactionManager - [Producer clientId=producer-264] ProducerId set to 14371 with epoch 0
13:47:26.111 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-266
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.112 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-266] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.112 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-266] Instantiated an idempotent producer.
13:47:26.112 [kafka-producer-network-thread | producer-265] INFO Metadata - [Producer clientId=producer-265] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.113 [kafka-producer-network-thread | producer-265] INFO TransactionManager - [Producer clientId=producer-265] ProducerId set to 14372 with epoch 0
13:47:26.114 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.114 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.114 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.114 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046114
13:47:26.114 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-267
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.115 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-267] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.115 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-267] Instantiated an idempotent producer.
13:47:26.116 [kafka-producer-network-thread | producer-266] INFO Metadata - [Producer clientId=producer-266] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.116 [kafka-producer-network-thread | producer-266] INFO TransactionManager - [Producer clientId=producer-266] ProducerId set to 12456 with epoch 0
13:47:26.117 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.117 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.117 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.117 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046117
13:47:26.117 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-268
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.118 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-268] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.118 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-268] Instantiated an idempotent producer.
13:47:26.118 [kafka-producer-network-thread | producer-267] INFO Metadata - [Producer clientId=producer-267] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.118 [kafka-producer-network-thread | producer-267] INFO TransactionManager - [Producer clientId=producer-267] ProducerId set to 13468 with epoch 0
13:47:26.120 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.120 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.120 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.120 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046120
13:47:26.120 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-269
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.120 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-269] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.121 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-269] Instantiated an idempotent producer.
13:47:26.121 [kafka-producer-network-thread | producer-268] INFO Metadata - [Producer clientId=producer-268] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.121 [kafka-producer-network-thread | producer-268] INFO TransactionManager - [Producer clientId=producer-268] ProducerId set to 14375 with epoch 0
13:47:26.122 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.122 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.122 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.122 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046122
13:47:26.123 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-270
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.123 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-270] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.123 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-270] Instantiated an idempotent producer.
13:47:26.123 [kafka-producer-network-thread | producer-269] INFO Metadata - [Producer clientId=producer-269] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.124 [kafka-producer-network-thread | producer-269] INFO TransactionManager - [Producer clientId=producer-269] ProducerId set to 14376 with epoch 0
13:47:26.125 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.125 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.125 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.125 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046125
13:47:26.126 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-271
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.126 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-271] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.126 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-271] Instantiated an idempotent producer.
13:47:26.127 [kafka-producer-network-thread | producer-270] INFO Metadata - [Producer clientId=producer-270] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.127 [kafka-producer-network-thread | producer-270] INFO TransactionManager - [Producer clientId=producer-270] ProducerId set to 12458 with epoch 0
13:47:26.128 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.128 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.128 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.128 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046128
13:47:26.128 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-272
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.128 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-272] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.129 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-272] Instantiated an idempotent producer.
13:47:26.129 [kafka-producer-network-thread | producer-271] INFO Metadata - [Producer clientId=producer-271] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.129 [kafka-producer-network-thread | producer-271] INFO TransactionManager - [Producer clientId=producer-271] ProducerId set to 14379 with epoch 0
13:47:26.130 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.130 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.130 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.130 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046130
13:47:26.131 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-273
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.131 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-273] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.131 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-273] Instantiated an idempotent producer.
13:47:26.132 [kafka-producer-network-thread | producer-272] INFO Metadata - [Producer clientId=producer-272] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.132 [kafka-producer-network-thread | producer-272] INFO TransactionManager - [Producer clientId=producer-272] ProducerId set to 12461 with epoch 0
13:47:26.141 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.141 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.141 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.141 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046141
13:47:26.141 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-274
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.142 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-274] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.142 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-274] Instantiated an idempotent producer.
13:47:26.142 [kafka-producer-network-thread | producer-273] INFO Metadata - [Producer clientId=producer-273] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.142 [kafka-producer-network-thread | producer-273] INFO TransactionManager - [Producer clientId=producer-273] ProducerId set to 14381 with epoch 0
13:47:26.143 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.143 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.143 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.143 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046143
13:47:26.144 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-275
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.144 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-275] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.144 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-275] Instantiated an idempotent producer.
13:47:26.145 [kafka-producer-network-thread | producer-274] INFO Metadata - [Producer clientId=producer-274] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.145 [kafka-producer-network-thread | producer-274] INFO TransactionManager - [Producer clientId=producer-274] ProducerId set to 12466 with epoch 0
13:47:26.146 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.146 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.146 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.146 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046146
13:47:26.146 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-276
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.147 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-276] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.147 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-276] Instantiated an idempotent producer.
13:47:26.147 [kafka-producer-network-thread | producer-275] INFO Metadata - [Producer clientId=producer-275] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.148 [kafka-producer-network-thread | producer-275] INFO TransactionManager - [Producer clientId=producer-275] ProducerId set to 12468 with epoch 0
13:47:26.148 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.148 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.148 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.148 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046148
13:47:26.149 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-277
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.149 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-277] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.149 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-277] Instantiated an idempotent producer.
13:47:26.150 [kafka-producer-network-thread | producer-276] INFO Metadata - [Producer clientId=producer-276] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.150 [kafka-producer-network-thread | producer-276] INFO TransactionManager - [Producer clientId=producer-276] ProducerId set to 12469 with epoch 0
13:47:26.151 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.151 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.151 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.151 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046151
13:47:26.152 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-278
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.152 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-278] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.152 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-278] Instantiated an idempotent producer.
13:47:26.152 [kafka-producer-network-thread | producer-277] INFO Metadata - [Producer clientId=producer-277] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.153 [kafka-producer-network-thread | producer-277] INFO TransactionManager - [Producer clientId=producer-277] ProducerId set to 14384 with epoch 0
13:47:26.154 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.154 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.154 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.154 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046154
13:47:26.154 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-279
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.155 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-279] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.155 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-279] Instantiated an idempotent producer.
13:47:26.155 [kafka-producer-network-thread | producer-278] INFO Metadata - [Producer clientId=producer-278] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.156 [kafka-producer-network-thread | producer-278] INFO TransactionManager - [Producer clientId=producer-278] ProducerId set to 13473 with epoch 0
13:47:26.157 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.157 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.157 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.157 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046157
13:47:26.157 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-280
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.158 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-280] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.158 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-280] Instantiated an idempotent producer.
13:47:26.158 [kafka-producer-network-thread | producer-279] INFO Metadata - [Producer clientId=producer-279] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.158 [kafka-producer-network-thread | producer-279] INFO TransactionManager - [Producer clientId=producer-279] ProducerId set to 13474 with epoch 0
13:47:26.160 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.160 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.160 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.160 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046160
13:47:26.160 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-281
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.160 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-281] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.160 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-281] Instantiated an idempotent producer.
13:47:26.161 [kafka-producer-network-thread | producer-280] INFO Metadata - [Producer clientId=producer-280] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.161 [kafka-producer-network-thread | producer-280] INFO TransactionManager - [Producer clientId=producer-280] ProducerId set to 13476 with epoch 0
13:47:26.162 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.162 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.162 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.162 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046162
13:47:26.163 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-282
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.163 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-282] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.163 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-282] Instantiated an idempotent producer.
13:47:26.164 [kafka-producer-network-thread | producer-281] INFO Metadata - [Producer clientId=producer-281] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.164 [kafka-producer-network-thread | producer-281] INFO TransactionManager - [Producer clientId=producer-281] ProducerId set to 12471 with epoch 0
13:47:26.165 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.165 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.165 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.165 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046165
13:47:26.166 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-283
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.166 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-283] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.166 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-283] Instantiated an idempotent producer.
13:47:26.169 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.169 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.169 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.169 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046169
13:47:26.169 [kafka-producer-network-thread | producer-282] INFO Metadata - [Producer clientId=producer-282] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.169 [kafka-producer-network-thread | producer-282] INFO TransactionManager - [Producer clientId=producer-282] ProducerId set to 14390 with epoch 0
13:47:26.170 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-284
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.170 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-284] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.170 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-284] Instantiated an idempotent producer.
13:47:26.172 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.173 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.173 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.173 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046172
13:47:26.173 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-285
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.173 [kafka-producer-network-thread | producer-283] INFO Metadata - [Producer clientId=producer-283] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.173 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-285] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.174 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-285] Instantiated an idempotent producer.
13:47:26.174 [kafka-producer-network-thread | producer-283] INFO TransactionManager - [Producer clientId=producer-283] ProducerId set to 12473 with epoch 0
13:47:26.174 [kafka-producer-network-thread | producer-284] INFO Metadata - [Producer clientId=producer-284] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.174 [kafka-producer-network-thread | producer-284] INFO TransactionManager - [Producer clientId=producer-284] ProducerId set to 13479 with epoch 0
13:47:26.175 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.176 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.176 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.176 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046176
13:47:26.176 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-286
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.177 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-286] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.177 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-286] Instantiated an idempotent producer.
13:47:26.177 [kafka-producer-network-thread | producer-285] INFO Metadata - [Producer clientId=producer-285] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.177 [kafka-producer-network-thread | producer-285] INFO TransactionManager - [Producer clientId=producer-285] ProducerId set to 13480 with epoch 0
13:47:26.183 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.183 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.184 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.184 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046183
13:47:26.184 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-287
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.184 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-287] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.184 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-287] Instantiated an idempotent producer.
13:47:26.186 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.186 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.186 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.186 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046186
13:47:26.186 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-288
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.186 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-288] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.186 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-288] Instantiated an idempotent producer.
13:47:26.187 [kafka-producer-network-thread | producer-287] INFO Metadata - [Producer clientId=producer-287] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.187 [kafka-producer-network-thread | producer-287] INFO TransactionManager - [Producer clientId=producer-287] ProducerId set to 14397 with epoch 0
13:47:26.188 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.188 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.188 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.188 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046188
13:47:26.188 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-289
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.188 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-289] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.189 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-289] Instantiated an idempotent producer.
13:47:26.189 [kafka-producer-network-thread | producer-288] INFO Metadata - [Producer clientId=producer-288] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.189 [kafka-producer-network-thread | producer-288] INFO TransactionManager - [Producer clientId=producer-288] ProducerId set to 12478 with epoch 0
13:47:26.190 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.190 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.190 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.190 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046190
13:47:26.190 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-290
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.190 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-290] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.191 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-290] Instantiated an idempotent producer.
13:47:26.191 [kafka-producer-network-thread | producer-289] INFO Metadata - [Producer clientId=producer-289] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.191 [kafka-producer-network-thread | producer-289] INFO TransactionManager - [Producer clientId=producer-289] ProducerId set to 12479 with epoch 0
13:47:26.192 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.192 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.192 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.192 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046192
13:47:26.192 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-291
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.193 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-291] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.193 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-291] Instantiated an idempotent producer.
13:47:26.193 [kafka-producer-network-thread | producer-290] INFO Metadata - [Producer clientId=producer-290] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.193 [kafka-producer-network-thread | producer-290] INFO TransactionManager - [Producer clientId=producer-290] ProducerId set to 12480 with epoch 0
13:47:26.194 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.194 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.194 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.194 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046194
13:47:26.194 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-292
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.194 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-292] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.195 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-292] Instantiated an idempotent producer.
13:47:26.195 [kafka-producer-network-thread | producer-286] INFO Metadata - [Producer clientId=producer-286] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.195 [kafka-producer-network-thread | producer-286] INFO TransactionManager - [Producer clientId=producer-286] ProducerId set to 14400 with epoch 0
13:47:26.195 [kafka-producer-network-thread | producer-291] INFO Metadata - [Producer clientId=producer-291] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.195 [kafka-producer-network-thread | producer-291] INFO TransactionManager - [Producer clientId=producer-291] ProducerId set to 12482 with epoch 0
13:47:26.196 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.196 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.196 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.196 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046196
13:47:26.196 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-293
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.197 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-293] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.197 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-293] Instantiated an idempotent producer.
13:47:26.197 [kafka-producer-network-thread | producer-292] INFO Metadata - [Producer clientId=producer-292] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.197 [kafka-producer-network-thread | producer-292] INFO TransactionManager - [Producer clientId=producer-292] ProducerId set to 14402 with epoch 0
13:47:26.198 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.198 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.198 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.198 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046198
13:47:26.199 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-294
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.199 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-294] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.199 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-294] Instantiated an idempotent producer.
13:47:26.199 [kafka-producer-network-thread | producer-293] INFO Metadata - [Producer clientId=producer-293] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.199 [kafka-producer-network-thread | producer-293] INFO TransactionManager - [Producer clientId=producer-293] ProducerId set to 14404 with epoch 0
13:47:26.200 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.200 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.200 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.200 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046200
13:47:26.200 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-295
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.201 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-295] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.201 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-295] Instantiated an idempotent producer.
13:47:26.201 [kafka-producer-network-thread | producer-294] INFO Metadata - [Producer clientId=producer-294] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.201 [kafka-producer-network-thread | producer-294] INFO TransactionManager - [Producer clientId=producer-294] ProducerId set to 13484 with epoch 0
13:47:26.202 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.202 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.202 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.202 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046202
13:47:26.202 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-296
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.203 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-296] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.203 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-296] Instantiated an idempotent producer.
13:47:26.203 [kafka-producer-network-thread | producer-295] INFO Metadata - [Producer clientId=producer-295] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.203 [kafka-producer-network-thread | producer-295] INFO TransactionManager - [Producer clientId=producer-295] ProducerId set to 12486 with epoch 0
13:47:26.204 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.204 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.204 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.204 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046204
13:47:26.204 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-297
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.205 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-297] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.205 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-297] Instantiated an idempotent producer.
13:47:26.205 [kafka-producer-network-thread | producer-296] INFO Metadata - [Producer clientId=producer-296] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.205 [kafka-producer-network-thread | producer-296] INFO TransactionManager - [Producer clientId=producer-296] ProducerId set to 14406 with epoch 0
13:47:26.206 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.206 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.206 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.206 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046206
13:47:26.206 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-298
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.207 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-298] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.207 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-298] Instantiated an idempotent producer.
13:47:26.207 [kafka-producer-network-thread | producer-297] INFO Metadata - [Producer clientId=producer-297] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.207 [kafka-producer-network-thread | producer-297] INFO TransactionManager - [Producer clientId=producer-297] ProducerId set to 14407 with epoch 0
13:47:26.208 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.208 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.208 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.208 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046208
13:47:26.209 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-299
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.209 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-299] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.209 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-299] Instantiated an idempotent producer.
13:47:26.209 [kafka-producer-network-thread | producer-298] INFO Metadata - [Producer clientId=producer-298] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.209 [kafka-producer-network-thread | producer-298] INFO TransactionManager - [Producer clientId=producer-298] ProducerId set to 13486 with epoch 0
13:47:26.210 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.210 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.210 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.210 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046210
13:47:26.211 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-300
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.211 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-300] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.211 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-300] Instantiated an idempotent producer.
13:47:26.211 [kafka-producer-network-thread | producer-299] INFO Metadata - [Producer clientId=producer-299] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.211 [kafka-producer-network-thread | producer-299] INFO TransactionManager - [Producer clientId=producer-299] ProducerId set to 13487 with epoch 0
13:47:26.212 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.212 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.212 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.212 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046212
13:47:26.213 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-301
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.213 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-301] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.213 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-301] Instantiated an idempotent producer.
13:47:26.213 [kafka-producer-network-thread | producer-300] INFO Metadata - [Producer clientId=producer-300] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.214 [kafka-producer-network-thread | producer-300] INFO TransactionManager - [Producer clientId=producer-300] ProducerId set to 12489 with epoch 0
13:47:26.214 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.214 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.214 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.214 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046214
13:47:26.215 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-302
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.215 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-302] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.215 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-302] Instantiated an idempotent producer.
13:47:26.216 [kafka-producer-network-thread | producer-301] INFO Metadata - [Producer clientId=producer-301] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.216 [kafka-producer-network-thread | producer-301] INFO TransactionManager - [Producer clientId=producer-301] ProducerId set to 12490 with epoch 0
13:47:26.217 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.217 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.217 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.217 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046217
13:47:26.217 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-303
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.218 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-303] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.218 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-303] Instantiated an idempotent producer.
13:47:26.219 [kafka-producer-network-thread | producer-302] INFO Metadata - [Producer clientId=producer-302] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.219 [kafka-producer-network-thread | producer-302] INFO TransactionManager - [Producer clientId=producer-302] ProducerId set to 13492 with epoch 0
13:47:26.219 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.220 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.220 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.220 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046220
13:47:26.220 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-304
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.221 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-304] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.221 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-304] Instantiated an idempotent producer.
13:47:26.221 [kafka-producer-network-thread | producer-303] INFO Metadata - [Producer clientId=producer-303] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.221 [kafka-producer-network-thread | producer-303] INFO TransactionManager - [Producer clientId=producer-303] ProducerId set to 14410 with epoch 0
13:47:26.222 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.222 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.222 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.222 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046222
13:47:26.223 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-305
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.223 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-305] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.223 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-305] Instantiated an idempotent producer.
13:47:26.223 [kafka-producer-network-thread | producer-304] INFO Metadata - [Producer clientId=producer-304] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.223 [kafka-producer-network-thread | producer-304] INFO TransactionManager - [Producer clientId=producer-304] ProducerId set to 14412 with epoch 0
13:47:26.224 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.224 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.224 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.224 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046224
13:47:26.225 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-306
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.225 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-306] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.225 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-306] Instantiated an idempotent producer.
13:47:26.226 [kafka-producer-network-thread | producer-305] INFO Metadata - [Producer clientId=producer-305] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.226 [kafka-producer-network-thread | producer-305] INFO TransactionManager - [Producer clientId=producer-305] ProducerId set to 12493 with epoch 0
13:47:26.227 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.227 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.227 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.227 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046227
13:47:26.227 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-307
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.228 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-307] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.228 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-307] Instantiated an idempotent producer.
13:47:26.228 [kafka-producer-network-thread | producer-306] INFO Metadata - [Producer clientId=producer-306] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.228 [kafka-producer-network-thread | producer-306] INFO TransactionManager - [Producer clientId=producer-306] ProducerId set to 13497 with epoch 0
13:47:26.229 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.229 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.229 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.229 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046229
13:47:26.229 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-308
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.230 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-308] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.230 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-308] Instantiated an idempotent producer.
13:47:26.230 [kafka-producer-network-thread | producer-307] INFO Metadata - [Producer clientId=producer-307] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.231 [kafka-producer-network-thread | producer-307] INFO TransactionManager - [Producer clientId=producer-307] ProducerId set to 14413 with epoch 0
13:47:26.231 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.231 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.231 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.231 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046231
13:47:26.232 [qtp435803541-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.216:9092, 10.0.0.52:9092, 10.0.0.229:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-309
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

13:47:26.232 [qtp435803541-28] WARN KafkaProducer - [Producer clientId=producer-309] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
13:47:26.232 [qtp435803541-28] INFO KafkaProducer - [Producer clientId=producer-309] Instantiated an idempotent producer.
13:47:26.233 [kafka-producer-network-thread | producer-308] INFO Metadata - [Producer clientId=producer-308] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.233 [kafka-producer-network-thread | producer-308] INFO TransactionManager - [Producer clientId=producer-308] ProducerId set to 12496 with epoch 0
13:47:26.233 [qtp435803541-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
13:47:26.233 [qtp435803541-28] INFO AppInfoParser - Kafka version: 3.6.1
13:47:26.234 [qtp435803541-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
13:47:26.234 [qtp435803541-28] INFO AppInfoParser - Kafka startTimeMs: 1717336046233
13:47:26.235 [kafka-producer-network-thread | producer-309] INFO Metadata - [Producer clientId=producer-309] Cluster ID: npFGiqmcThOkfBOsM5z8_g
13:47:26.235 [kafka-producer-network-thread | producer-309] INFO TransactionManager - [Producer clientId=producer-309] ProducerId set to 12498 with epoch 0
13:47:26.238 [qtp435803541-28] INFO LocalWorker - Created 309 producers in 991.847296 ms from {
  "topics" : [ "test-topic-0000000-FGdYwL4", "test-topic-0000001-8XkVdYY", "test-topic-0000002-AnoRVV8", "test-topic-0000003-KFfayTM", "test-topic-0000004-20ZHReU", "test-topic-0000005-z0C2FwA", "test-topic-0000006-c-q-i_g", "test-topic-0000007-0MzD9Ik", "test-topic-0000008-0nz4Z_4", "test-topic-0000009-AqQ2Zlw", "test-topic-0000010-NyjSQ9A", "test-topic-0000011-zxqm4Mw", "test-topic-0000012-YCyXSbE", "test-topic-0000013-FjDWcwQ", "test-topic-0000014-CFLlGHs", "test-topic-0000015-URbXFF4", "test-topic-0000016-sZJ3Jho", "test-topic-0000017--qoxjPU", "test-topic-0000018-o_iMPj4", "test-topic-0000019-KoBZyHg", "test-topic-0000020-M_uOt0w", "test-topic-0000021-g1wDjUE", "test-topic-0000022-SNsKA5U", "test-topic-0000023-UFWJKKU", "test-topic-0000024-G8RFGsk", "test-topic-0000025-6uZz340", "test-topic-0000026-PbTraa0", "test-topic-0000027-Xa_RnUU", "test-topic-0000028-3nLVSQs", "test-topic-0000029-Sq99nJQ", "test-topic-0000030-SxXiKuo", "test-topic-0000031-DjUOkAw", "test-topic-0000032-uNikqf8", "test-topic-0000033-I9YklqI", "test-topic-0000034-P1Rw2WM", "test-topic-0000035-xhp6_oA", "test-topic-0000036-KEdU3IU", "test-topic-0000037-2r-FtRk", "test-topic-0000038-aoczOmE", "test-topic-0000039-DLNOGX4", "test-topic-0000040-ctRrJ_E", "test-topic-0000041-Ni38W-8", "test-topic-0000042-IpLh0uQ", "test-topic-0000043-CI9z7bU", "test-topic-0000044-HLDd740", "test-topic-0000045-5ePkOy4", "test-topic-0000046-P0FMkh4", "test-topic-0000047-Ci_iHCk", "test-topic-0000048-cYfObxU", "test-topic-0000049-9ea7a3Q", "test-topic-0000050-n3f7BfU", "test-topic-0000051-A0OfkLI", "test-topic-0000052-AfpVojk", "test-topic-0000053-Wz-ZTHE", "test-topic-0000054-omow84U", "test-topic-0000055-C3trC3o", "test-topic-0000056-Hx4phh4", "test-topic-0000057-b1ROO2s", "test-topic-0000058-ru5jUZw", "test-topic-0000059-2eeNhoM", "test-topic-0000060-YhVhRN4", "test-topic-0000061-btSl6bw", "test-topic-0000062-rNORlD0", "test-topic-0000063-TutZTB8", "test-topic-0000064-JLHPfAM", "test-topic-0000065-9yyIq1M", "test-topic-0000066-iVHj7R4", "test-topic-0000067-6rhS1nY", "test-topic-0000068-BieU9RA", "test-topic-0000069-j5MG-i8", "test-topic-0000070-toSKqSk", "test-topic-0000071-VWYOjwM", "test-topic-0000072-atXhL_g", "test-topic-0000073-HZ6O7Og", "test-topic-0000074-qfrgGP4", "test-topic-0000075-2Is6uhc", "test-topic-0000076-9xcr8KU", "test-topic-0000077-bmvIbiY", "test-topic-0000078-Wk4biHA", "test-topic-0000079-4XRk71U", "test-topic-0000080-GSwinHI", "test-topic-0000081-slvhhyc", "test-topic-0000082-x9QjlwQ", "test-topic-0000083-g-BmxjQ", "test-topic-0000084-fyVCbbE", "test-topic-0000085-_VhFHj0", "test-topic-0000086-cFlu7XU", "test-topic-0000087-81GfjoE", "test-topic-0000088-m_LR2ic", "test-topic-0000089-x68IQU4", "test-topic-0000090-2-rWqDI", "test-topic-0000091-DPFMLNo", "test-topic-0000092-JXGTSos", "test-topic-0000093-bXeEJlM", "test-topic-0000094-EbfdF94", "test-topic-0000095-zPq6gTM", "test-topic-0000096-mZKQCwo", "test-topic-0000097-rYrnvdk", "test-topic-0000098-H_jRR9A", "test-topic-0000099-1cEYHFU", "test-topic-0000100-tJC42sY", "test-topic-0000101-LhC-54M", "test-topic-0000102-l_C9r5E", "test-topic-0000103-7T4hNlo", "test-topic-0000104--zE_tVI", "test-topic-0000105-9pKxJ4U", "test-topic-0000106-DPglyWA", "test-topic-0000107-fjH0hDM", "test-topic-0000108-NB7wiDg", "test-topic-0000109-8qoD6Cs", "test-topic-0000110-mZfst7E", "test-topic-0000111-F9DCrSI", "test-topic-0000112-6kLoZnM", "test-topic-0000113-cTWFNVA", "test-topic-0000114-W7btOqk", "test-topic-0000115-6QgytUA", "test-topic-0000116-7UdnOfU", "test-topic-0000117-qR0MMec", "test-topic-0000118-8tUi_6Q", "test-topic-0000119-SlKUM_g", "test-topic-0000120-0BOroSI", "test-topic-0000121-MbWpUXY", "test-topic-0000122-BF9iF7A", "test-topic-0000123-NQtdm4o", "test-topic-0000124-amAHj1M", "test-topic-0000125-hZwj-ZY", "test-topic-0000126-uv0Lyw8", "test-topic-0000127-yWtvaYk", "test-topic-0000128-VV-rVFU", "test-topic-0000129-hjtxynQ", "test-topic-0000130-Qg40Jrk", "test-topic-0000131-xgUrqV0", "test-topic-0000132-cm7Hf-c", "test-topic-0000133-98k_qFM", "test-topic-0000134-Sxkgttc", "test-topic-0000135-E9VX0MI", "test-topic-0000136-Y9wEdEA", "test-topic-0000137-Aei-Pwg", "test-topic-0000138-jGAmpUk", "test-topic-0000139-OuBTmUg", "test-topic-0000140-EL2B4IY", "test-topic-0000141-sMY3in0", "test-topic-0000142-PXtC-SI", "test-topic-0000143-6mgkLNE", "test-topic-0000144-I87Cc1c", "test-topic-0000145-c-Awvi4", "test-topic-0000146-mwLxECY", "test-topic-0000147-daxMmRU", "test-topic-0000148-jGtN0UQ", "test-topic-0000149-oEEgv68", "test-topic-0000150-aU4kmlM", "test-topic-0000151-TzSMYyE", "test-topic-0000152-_ZPbr1E", "test-topic-0000153-7WDuOCQ", "test-topic-0000154-akFkJ1U", "test-topic-0000155-lbbml9M", "test-topic-0000156-bv1bM3c", "test-topic-0000157--IfLOsc", "test-topic-0000158-6CVrNxA", "test-topic-0000159-g4aXvWA", "test-topic-0000160-mjkwCiM", "test-topic-0000161-wcsZU2U", "test-topic-0000162-MJrR-xo", "test-topic-0000163-_ZTSuc8", "test-topic-0000164-gepakbQ", "test-topic-0000165-K5Vt5OE", "test-topic-0000166-FI2baz0", "test-topic-0000167-BwF1nXw", "test-topic-0000168-5AaQRwA", "test-topic-0000169-frnmqbA", "test-topic-0000170-Z0q4Nvo", "test-topic-0000171-TTgHNZY", "test-topic-0000172-zC5ZI88", "test-topic-0000173-6CJkJ1w", "test-topic-0000174-hJfH_wE", "test-topic-0000175-nKeyHaA", "test-topic-0000176-BBDA9F8", "test-topic-0000177-9whUEAI", "test-topic-0000178-yN-12bs", "test-topic-0000179-Z_sMFPQ", "test-topic-0000180-mtow198", "test-topic-0000181-ILkihtM", "test-topic-0000182-FHEBZ8A", "test-topic-0000183-Q_DaKzs", "test-topic-0000184-YsWG3PQ", "test-topic-0000185-PO-JbZY", "test-topic-0000186-TMi6IGE", "test-topic-0000187-a7MsovY", "test-topic-0000188-c6J0hjY", "test-topic-0000189-Br5CACQ", "test-topic-0000190-2u2ROx8", "test-topic-0000191-PNN1Bfk", "test-topic-0000192-qIO7V7Q", "test-topic-0000193-ngfcLus", "test-topic-0000194-K-KCWTE", "test-topic-0000195-ur-Cgeo", "test-topic-0000196-IG_hwmw", "test-topic-0000197-CIa3XGw", "test-topic-0000198-MRrztgM", "test-topic-0000199-CtttN8Y", "test-topic-0000200-viNaANQ", "test-topic-0000201-rmNvfr4", "test-topic-0000202-3wtSyrE", "test-topic-0000203-9hn2q10", "test-topic-0000204-qe1T4lQ", "test-topic-0000205-2mMmqQg", "test-topic-0000206-sMqOXZA", "test-topic-0000207-bDTZgNE", "test-topic-0000208-zYqakMk", "test-topic-0000209-PZuErwo", "test-topic-0000210-IbT0AKY", "test-topic-0000211-_2UT4Bs", "test-topic-0000212-WR9CMwQ", "test-topic-0000213-a7hif5U", "test-topic-0000214-MyxBVy0", "test-topic-0000215-Zb4mOoY", "test-topic-0000216-PzoM90k", "test-topic-0000217-XNxlkQ4", "test-topic-0000218-6mkEIxQ", "test-topic-0000219-9wHMOjI", "test-topic-0000220-uOm4gtE", "test-topic-0000221-7QIO4vA", "test-topic-0000222-0FOfLX4", "test-topic-0000223-NBqvIZI", "test-topic-0000224-vd-16Eg", "test-topic-0000225-Xfv4mUc", "test-topic-0000226-cmxwGEA", "test-topic-0000227-PhYZ_-4", "test-topic-0000228-j6bdXE8", "test-topic-0000229-0fBbwTU", "test-topic-0000230-4s4B6Wc", "test-topic-0000231-W7upruI", "test-topic-0000232-L-U4evs", "test-topic-0000233-0IL1GHA", "test-topic-0000234-MztKqbA", "test-topic-0000235-daWCzN0", "test-topic-0000236-5rPzsFQ", "test-topic-0000237-x236eMI", "test-topic-0000238-ATNTxQ8", "test-topic-0000239-m_eFS6M", "test-topic-0000240-vwD5iNc", "test-topic-0000241-hsO-5Ig", "test-topic-0000242-5iXW5yk", "test-topic-0000243-fpyKxcw", "test-topic-0000244-CATmwfU", "test-topic-0000245-wLMd2DQ", "test-topic-0000246-Bq6i99k", "test-topic-0000247-9BaoGEM", "test-topic-0000248-1cRH_ZI", "test-topic-0000249-j-ThMcs", "test-topic-0000250-hNzff68", "test-topic-0000251-eeL7Zsc", "test-topic-0000252-fa1UjIY", "test-topic-0000253-71qwhGg", "test-topic-0000254-CpZ6PWw", "test-topic-0000255-qWOKGG0", "test-topic-0000256-GzCULh8", "test-topic-0000257-P_M3hrc", "test-topic-0000258-Rv9SxIc", "test-topic-0000259-x2gdERw", "test-topic-0000260-DnsmC54", "test-topic-0000261-w2mnyns", "test-topic-0000262-Z_n6Lqs", "test-topic-0000263-OjpC5g8", "test-topic-0000264-eT2e8rU", "test-topic-0000265-JPOr-Ag", "test-topic-0000266-pK4XlDY", "test-topic-0000267-CjvJg1c", "test-topic-0000268-xHueAw8", "test-topic-0000269-7mR6KMk", "test-topic-0000270-tS64jLw", "test-topic-0000271-ZxlpV1c", "test-topic-0000272-GXSuIMg", "test-topic-0000273-EO6kLrs", "test-topic-0000274-WBszb4M", "test-topic-0000275-I49nzkY", "test-topic-0000276-6JL1QfE", "test-topic-0000277-YF-_KfA", "test-topic-0000278-zWRdAgQ", "test-topic-0000279-M7JpqrA", "test-topic-0000280-Y3fRkQ4", "test-topic-0000281-FQQUyA4", "test-topic-0000282-WxYsVXA", "test-topic-0000283-MdXNdPY", "test-topic-0000284-Agh4b5c", "test-topic-0000285-SwrrYM0", "test-topic-0000286-yTITFyk", "test-topic-0000287-3fcwIsk", "test-topic-0000288-AZcX53o", "test-topic-0000289-gnsmK30", "test-topic-0000290-5aCzRUQ", "test-topic-0000291-mMcByrM", "test-topic-0000292-3RYn65c", "test-topic-0000293-H8U0kX0", "test-topic-0000294-ASiqRA4", "test-topic-0000295-5y9DMI4", "test-topic-0000296-217YnkM", "test-topic-0000297-6tCb4MU", "test-topic-0000298-cXyRfIQ", "test-topic-0000299-9nrgwQo", "test-topic-0000300-gX_eTcY", "test-topic-0000301-j62eWV0", "test-topic-0000302-DlyJbtk", "test-topic-0000303-EgI1jiw" ],
  "producerIndex" : 2,
  "isTpcH" : true
}
13:47:27.181 [qtp435803541-29] INFO WorkerHandler - Start load publish-rate: 3333333.3333333335 msg/s -- payload-size: 0 -- producer index: 2
13:47:27.183 [qtp435803541-29] INFO LocalWorker - Number of commands 1666 | Commands per batch 17 | Batches per producer 98
13:47:27.214 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.251 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.253 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-0 after sending 136 messages. Shutting down.
13:47:27.253 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.275 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.277 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-1 after sending 136 messages. Shutting down.
13:47:27.277 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.296 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.297 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-2 after sending 136 messages. Shutting down.
13:47:27.298 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.314 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.316 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-3 after sending 136 messages. Shutting down.
13:47:27.316 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.338 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.340 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-4 after sending 136 messages. Shutting down.
13:47:27.340 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.358 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.360 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-5 after sending 136 messages. Shutting down.
13:47:27.360 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.374 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.376 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-6 after sending 136 messages. Shutting down.
13:47:27.376 [throughput-worker-3-1] INFO LocalWorker - Number of batches 8 | Start 3334 | Max 5000
13:47:27.383 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Launched 136 completable futures. Awaiting...
13:47:27.385 [throughput-worker-3-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 2-7 after sending 136 messages. Shutting down.
13:47:27.563 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-006-aUhexWc-2-ef47cab8-1868-4b2e-812e-6f1dae868b6c', protocol='range'}
13:47:27.563 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-003-0UoWg7A-1-3c859a36-127e-4b0e-ab61-97d6a38913f3', protocol='range'}
13:47:27.570 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-009-cMbbSZU-3-2bca2ea4-85c8-4655-9e82-b57e23cc889c', protocol='range'}
13:47:27.571 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Finished assignment for group at generation 1: {consumer-sub-003-0UoWg7A-1-3c859a36-127e-4b0e-ab61-97d6a38913f3=Assignment(partitions=[test-topic-0000003-KFfayTM-0])}
13:47:27.571 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Finished assignment for group at generation 1: {consumer-sub-009-cMbbSZU-3-2bca2ea4-85c8-4655-9e82-b57e23cc889c=Assignment(partitions=[test-topic-0000009-AqQ2Zlw-0])}
13:47:27.571 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Finished assignment for group at generation 1: {consumer-sub-006-aUhexWc-2-ef47cab8-1868-4b2e-812e-6f1dae868b6c=Assignment(partitions=[test-topic-0000006-c-q-i_g-0])}
13:47:27.576 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-006-aUhexWc-2-ef47cab8-1868-4b2e-812e-6f1dae868b6c', protocol='range'}
13:47:27.576 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-003-0UoWg7A-1-3c859a36-127e-4b0e-ab61-97d6a38913f3', protocol='range'}
13:47:27.576 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-009-cMbbSZU-3-2bca2ea4-85c8-4655-9e82-b57e23cc889c', protocol='range'}
13:47:27.576 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Notifying assignor about the new Assignment(partitions=[test-topic-0000006-c-q-i_g-0])
13:47:27.576 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Notifying assignor about the new Assignment(partitions=[test-topic-0000003-KFfayTM-0])
13:47:27.576 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Notifying assignor about the new Assignment(partitions=[test-topic-0000009-AqQ2Zlw-0])
13:47:27.577 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-012-eu2G-4s-4-233f7c66-1649-410b-9665-d3cfeff50859', protocol='range'}
13:47:27.578 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Finished assignment for group at generation 1: {consumer-sub-012-eu2G-4s-4-233f7c66-1649-410b-9665-d3cfeff50859=Assignment(partitions=[test-topic-0000012-YCyXSbE-0])}
13:47:27.579 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Adding newly assigned partitions: test-topic-0000003-KFfayTM-0
13:47:27.579 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Adding newly assigned partitions: test-topic-0000009-AqQ2Zlw-0
13:47:27.579 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Adding newly assigned partitions: test-topic-0000006-c-q-i_g-0
13:47:27.579 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-012-eu2G-4s-4-233f7c66-1649-410b-9665-d3cfeff50859', protocol='range'}
13:47:27.579 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Notifying assignor about the new Assignment(partitions=[test-topic-0000012-YCyXSbE-0])
13:47:27.579 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Adding newly assigned partitions: test-topic-0000012-YCyXSbE-0
13:47:27.586 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Found no committed offset for partition test-topic-0000009-AqQ2Zlw-0
13:47:27.586 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Found no committed offset for partition test-topic-0000003-KFfayTM-0
13:47:27.586 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Found no committed offset for partition test-topic-0000006-c-q-i_g-0
13:47:27.586 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Found no committed offset for partition test-topic-0000012-YCyXSbE-0
13:47:27.587 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-015-ApWU4ds-5-0a08a230-89b8-4f45-812d-55e97a37c8b1', protocol='range'}
13:47:27.588 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Finished assignment for group at generation 1: {consumer-sub-015-ApWU4ds-5-0a08a230-89b8-4f45-812d-55e97a37c8b1=Assignment(partitions=[test-topic-0000015-URbXFF4-0])}
13:47:27.589 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-015-ApWU4ds-5-0a08a230-89b8-4f45-812d-55e97a37c8b1', protocol='range'}
13:47:27.589 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Notifying assignor about the new Assignment(partitions=[test-topic-0000015-URbXFF4-0])
13:47:27.589 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Adding newly assigned partitions: test-topic-0000015-URbXFF4-0
13:47:27.590 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Found no committed offset for partition test-topic-0000015-URbXFF4-0
13:47:27.596 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-018-OpDGV-0-6-1838bd7b-9c06-465f-9b99-af517319c178', protocol='range'}
13:47:27.597 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Finished assignment for group at generation 1: {consumer-sub-018-OpDGV-0-6-1838bd7b-9c06-465f-9b99-af517319c178=Assignment(partitions=[test-topic-0000018-o_iMPj4-0])}
13:47:27.597 [pool-5-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-003-0UoWg7A-1, groupId=sub-003-0UoWg7A] Resetting offset for partition test-topic-0000003-KFfayTM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.597 [pool-6-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-006-aUhexWc-2, groupId=sub-006-aUhexWc] Resetting offset for partition test-topic-0000006-c-q-i_g-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.597 [pool-8-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-012-eu2G-4s-4, groupId=sub-012-eu2G-4s] Resetting offset for partition test-topic-0000012-YCyXSbE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.597 [pool-9-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-015-ApWU4ds-5, groupId=sub-015-ApWU4ds] Resetting offset for partition test-topic-0000015-URbXFF4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.597 [pool-7-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-009-cMbbSZU-3, groupId=sub-009-cMbbSZU] Resetting offset for partition test-topic-0000009-AqQ2Zlw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.598 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-018-OpDGV-0-6-1838bd7b-9c06-465f-9b99-af517319c178', protocol='range'}
13:47:27.599 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Notifying assignor about the new Assignment(partitions=[test-topic-0000018-o_iMPj4-0])
13:47:27.599 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Adding newly assigned partitions: test-topic-0000018-o_iMPj4-0
13:47:27.599 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Found no committed offset for partition test-topic-0000018-o_iMPj4-0
13:47:27.602 [pool-10-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-018-OpDGV-0-6, groupId=sub-018-OpDGV-0] Resetting offset for partition test-topic-0000018-o_iMPj4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.609 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-021-i3NgyAI-7-f533da0a-68ee-4f5c-aaf6-9f88561e9a6d', protocol='range'}
13:47:27.609 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Finished assignment for group at generation 1: {consumer-sub-021-i3NgyAI-7-f533da0a-68ee-4f5c-aaf6-9f88561e9a6d=Assignment(partitions=[test-topic-0000021-g1wDjUE-0])}
13:47:27.611 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-021-i3NgyAI-7-f533da0a-68ee-4f5c-aaf6-9f88561e9a6d', protocol='range'}
13:47:27.611 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Notifying assignor about the new Assignment(partitions=[test-topic-0000021-g1wDjUE-0])
13:47:27.611 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Adding newly assigned partitions: test-topic-0000021-g1wDjUE-0
13:47:27.612 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Found no committed offset for partition test-topic-0000021-g1wDjUE-0
13:47:27.614 [pool-11-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-021-i3NgyAI-7, groupId=sub-021-i3NgyAI] Resetting offset for partition test-topic-0000021-g1wDjUE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.616 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-024-8BS-0vU-8-123df7d0-537b-4a4a-a052-7ef92b9aab15', protocol='range'}
13:47:27.617 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Finished assignment for group at generation 1: {consumer-sub-024-8BS-0vU-8-123df7d0-537b-4a4a-a052-7ef92b9aab15=Assignment(partitions=[test-topic-0000024-G8RFGsk-0])}
13:47:27.619 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-024-8BS-0vU-8-123df7d0-537b-4a4a-a052-7ef92b9aab15', protocol='range'}
13:47:27.620 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Notifying assignor about the new Assignment(partitions=[test-topic-0000024-G8RFGsk-0])
13:47:27.620 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Adding newly assigned partitions: test-topic-0000024-G8RFGsk-0
13:47:27.621 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Found no committed offset for partition test-topic-0000024-G8RFGsk-0
13:47:27.623 [pool-12-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-024-8BS-0vU-8, groupId=sub-024-8BS-0vU] Resetting offset for partition test-topic-0000024-G8RFGsk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.625 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-027-gbjWpRs-9-d955083d-8990-4e4b-9b0c-bc812cc476c4', protocol='range'}
13:47:27.625 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Finished assignment for group at generation 1: {consumer-sub-027-gbjWpRs-9-d955083d-8990-4e4b-9b0c-bc812cc476c4=Assignment(partitions=[test-topic-0000027-Xa_RnUU-0])}
13:47:27.626 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-027-gbjWpRs-9-d955083d-8990-4e4b-9b0c-bc812cc476c4', protocol='range'}
13:47:27.627 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Notifying assignor about the new Assignment(partitions=[test-topic-0000027-Xa_RnUU-0])
13:47:27.627 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Adding newly assigned partitions: test-topic-0000027-Xa_RnUU-0
13:47:27.627 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Found no committed offset for partition test-topic-0000027-Xa_RnUU-0
13:47:27.629 [pool-13-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-027-gbjWpRs-9, groupId=sub-027-gbjWpRs] Resetting offset for partition test-topic-0000027-Xa_RnUU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.629 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-030-ug8aBAo-10-4d8f2780-5a70-45f7-83c6-fe5248d91679', protocol='range'}
13:47:27.629 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Finished assignment for group at generation 1: {consumer-sub-030-ug8aBAo-10-4d8f2780-5a70-45f7-83c6-fe5248d91679=Assignment(partitions=[test-topic-0000030-SxXiKuo-0])}
13:47:27.631 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-030-ug8aBAo-10-4d8f2780-5a70-45f7-83c6-fe5248d91679', protocol='range'}
13:47:27.631 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Notifying assignor about the new Assignment(partitions=[test-topic-0000030-SxXiKuo-0])
13:47:27.631 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Adding newly assigned partitions: test-topic-0000030-SxXiKuo-0
13:47:27.632 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Found no committed offset for partition test-topic-0000030-SxXiKuo-0
13:47:27.633 [pool-14-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-030-ug8aBAo-10, groupId=sub-030-ug8aBAo] Resetting offset for partition test-topic-0000030-SxXiKuo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.639 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-033-ar1WBTU-11-ebffdaea-1f44-4d4f-adb5-c7774a7ba6f3', protocol='range'}
13:47:27.639 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Finished assignment for group at generation 1: {consumer-sub-033-ar1WBTU-11-ebffdaea-1f44-4d4f-adb5-c7774a7ba6f3=Assignment(partitions=[test-topic-0000033-I9YklqI-0])}
13:47:27.640 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-033-ar1WBTU-11-ebffdaea-1f44-4d4f-adb5-c7774a7ba6f3', protocol='range'}
13:47:27.641 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Notifying assignor about the new Assignment(partitions=[test-topic-0000033-I9YklqI-0])
13:47:27.641 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Adding newly assigned partitions: test-topic-0000033-I9YklqI-0
13:47:27.641 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Found no committed offset for partition test-topic-0000033-I9YklqI-0
13:47:27.643 [pool-15-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-033-ar1WBTU-11, groupId=sub-033-ar1WBTU] Resetting offset for partition test-topic-0000033-I9YklqI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.646 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-036-TUEqcZ8-12-ebc8cb3a-eade-4b95-859b-67ad5248dff3', protocol='range'}
13:47:27.647 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Finished assignment for group at generation 1: {consumer-sub-036-TUEqcZ8-12-ebc8cb3a-eade-4b95-859b-67ad5248dff3=Assignment(partitions=[test-topic-0000036-KEdU3IU-0])}
13:47:27.648 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-036-TUEqcZ8-12-ebc8cb3a-eade-4b95-859b-67ad5248dff3', protocol='range'}
13:47:27.648 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Notifying assignor about the new Assignment(partitions=[test-topic-0000036-KEdU3IU-0])
13:47:27.648 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Adding newly assigned partitions: test-topic-0000036-KEdU3IU-0
13:47:27.649 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Found no committed offset for partition test-topic-0000036-KEdU3IU-0
13:47:27.650 [pool-16-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-036-TUEqcZ8-12, groupId=sub-036-TUEqcZ8] Resetting offset for partition test-topic-0000036-KEdU3IU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.658 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-039-uNVajws-13-b661e1b1-a484-4d0e-96a4-25c49bbddc06', protocol='range'}
13:47:27.658 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Finished assignment for group at generation 1: {consumer-sub-039-uNVajws-13-b661e1b1-a484-4d0e-96a4-25c49bbddc06=Assignment(partitions=[test-topic-0000039-DLNOGX4-0])}
13:47:27.659 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-039-uNVajws-13-b661e1b1-a484-4d0e-96a4-25c49bbddc06', protocol='range'}
13:47:27.660 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Notifying assignor about the new Assignment(partitions=[test-topic-0000039-DLNOGX4-0])
13:47:27.660 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Adding newly assigned partitions: test-topic-0000039-DLNOGX4-0
13:47:27.660 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Found no committed offset for partition test-topic-0000039-DLNOGX4-0
13:47:27.661 [pool-17-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-039-uNVajws-13, groupId=sub-039-uNVajws] Resetting offset for partition test-topic-0000039-DLNOGX4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.670 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-045-5U4Mi-w-15-1530983f-96a9-4c18-805a-5a226e481554', protocol='range'}
13:47:27.670 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Finished assignment for group at generation 1: {consumer-sub-045-5U4Mi-w-15-1530983f-96a9-4c18-805a-5a226e481554=Assignment(partitions=[test-topic-0000045-5ePkOy4-0])}
13:47:27.672 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-045-5U4Mi-w-15-1530983f-96a9-4c18-805a-5a226e481554', protocol='range'}
13:47:27.672 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Notifying assignor about the new Assignment(partitions=[test-topic-0000045-5ePkOy4-0])
13:47:27.672 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Adding newly assigned partitions: test-topic-0000045-5ePkOy4-0
13:47:27.672 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Found no committed offset for partition test-topic-0000045-5ePkOy4-0
13:47:27.674 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-042-7jZZFn4-14-a7e2bc68-fe36-486d-9307-065a24061320', protocol='range'}
13:47:27.674 [pool-19-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-045-5U4Mi-w-15, groupId=sub-045-5U4Mi-w] Resetting offset for partition test-topic-0000045-5ePkOy4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.674 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Finished assignment for group at generation 1: {consumer-sub-042-7jZZFn4-14-a7e2bc68-fe36-486d-9307-065a24061320=Assignment(partitions=[test-topic-0000042-IpLh0uQ-0])}
13:47:27.675 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-042-7jZZFn4-14-a7e2bc68-fe36-486d-9307-065a24061320', protocol='range'}
13:47:27.676 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Notifying assignor about the new Assignment(partitions=[test-topic-0000042-IpLh0uQ-0])
13:47:27.676 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Adding newly assigned partitions: test-topic-0000042-IpLh0uQ-0
13:47:27.676 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Found no committed offset for partition test-topic-0000042-IpLh0uQ-0
13:47:27.679 [pool-18-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-042-7jZZFn4-14, groupId=sub-042-7jZZFn4] Resetting offset for partition test-topic-0000042-IpLh0uQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.680 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-048-sKkuCFk-16-b60cf4a1-e873-4180-8850-0d11e703327a', protocol='range'}
13:47:27.680 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Finished assignment for group at generation 1: {consumer-sub-048-sKkuCFk-16-b60cf4a1-e873-4180-8850-0d11e703327a=Assignment(partitions=[test-topic-0000048-cYfObxU-0])}
13:47:27.682 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-048-sKkuCFk-16-b60cf4a1-e873-4180-8850-0d11e703327a', protocol='range'}
13:47:27.682 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Notifying assignor about the new Assignment(partitions=[test-topic-0000048-cYfObxU-0])
13:47:27.682 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Adding newly assigned partitions: test-topic-0000048-cYfObxU-0
13:47:27.682 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Found no committed offset for partition test-topic-0000048-cYfObxU-0
13:47:27.684 [pool-20-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-048-sKkuCFk-16, groupId=sub-048-sKkuCFk] Resetting offset for partition test-topic-0000048-cYfObxU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.687 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-051-yzXOEeo-17-998cb597-36c9-46e6-b4f6-0e64b22711eb', protocol='range'}
13:47:27.687 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Finished assignment for group at generation 1: {consumer-sub-051-yzXOEeo-17-998cb597-36c9-46e6-b4f6-0e64b22711eb=Assignment(partitions=[test-topic-0000051-A0OfkLI-0])}
13:47:27.688 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-051-yzXOEeo-17-998cb597-36c9-46e6-b4f6-0e64b22711eb', protocol='range'}
13:47:27.688 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Notifying assignor about the new Assignment(partitions=[test-topic-0000051-A0OfkLI-0])
13:47:27.689 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Adding newly assigned partitions: test-topic-0000051-A0OfkLI-0
13:47:27.689 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Found no committed offset for partition test-topic-0000051-A0OfkLI-0
13:47:27.690 [pool-21-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-051-yzXOEeo-17, groupId=sub-051-yzXOEeo] Resetting offset for partition test-topic-0000051-A0OfkLI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.692 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-054-73hEJ48-18-1f4bf7b1-09f5-40f0-98eb-8d59474f6826', protocol='range'}
13:47:27.692 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Finished assignment for group at generation 1: {consumer-sub-054-73hEJ48-18-1f4bf7b1-09f5-40f0-98eb-8d59474f6826=Assignment(partitions=[test-topic-0000054-omow84U-0])}
13:47:27.694 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-054-73hEJ48-18-1f4bf7b1-09f5-40f0-98eb-8d59474f6826', protocol='range'}
13:47:27.694 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Notifying assignor about the new Assignment(partitions=[test-topic-0000054-omow84U-0])
13:47:27.694 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Adding newly assigned partitions: test-topic-0000054-omow84U-0
13:47:27.694 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Found no committed offset for partition test-topic-0000054-omow84U-0
13:47:27.696 [pool-22-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-054-73hEJ48-18, groupId=sub-054-73hEJ48] Resetting offset for partition test-topic-0000054-omow84U-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.698 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-057-Rt1H-Uc-19-c970361d-ff92-4129-9a0d-e30726025902', protocol='range'}
13:47:27.698 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Finished assignment for group at generation 1: {consumer-sub-057-Rt1H-Uc-19-c970361d-ff92-4129-9a0d-e30726025902=Assignment(partitions=[test-topic-0000057-b1ROO2s-0])}
13:47:27.700 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-057-Rt1H-Uc-19-c970361d-ff92-4129-9a0d-e30726025902', protocol='range'}
13:47:27.700 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Notifying assignor about the new Assignment(partitions=[test-topic-0000057-b1ROO2s-0])
13:47:27.700 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Adding newly assigned partitions: test-topic-0000057-b1ROO2s-0
13:47:27.700 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Found no committed offset for partition test-topic-0000057-b1ROO2s-0
13:47:27.702 [pool-23-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-057-Rt1H-Uc-19, groupId=sub-057-Rt1H-Uc] Resetting offset for partition test-topic-0000057-b1ROO2s-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.705 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-060-DVzPiDs-20-e4ff19d8-0daf-4dc9-9fa4-3ee25f29b2de', protocol='range'}
13:47:27.705 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Finished assignment for group at generation 1: {consumer-sub-060-DVzPiDs-20-e4ff19d8-0daf-4dc9-9fa4-3ee25f29b2de=Assignment(partitions=[test-topic-0000060-YhVhRN4-0])}
13:47:27.707 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-060-DVzPiDs-20-e4ff19d8-0daf-4dc9-9fa4-3ee25f29b2de', protocol='range'}
13:47:27.707 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Notifying assignor about the new Assignment(partitions=[test-topic-0000060-YhVhRN4-0])
13:47:27.707 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Adding newly assigned partitions: test-topic-0000060-YhVhRN4-0
13:47:27.708 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Found no committed offset for partition test-topic-0000060-YhVhRN4-0
13:47:27.708 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-063-DWLnvh0-21-5bb12345-d466-4b32-b791-7595cb6632b6', protocol='range'}
13:47:27.708 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Finished assignment for group at generation 1: {consumer-sub-063-DWLnvh0-21-5bb12345-d466-4b32-b791-7595cb6632b6=Assignment(partitions=[test-topic-0000063-TutZTB8-0])}
13:47:27.710 [pool-24-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-060-DVzPiDs-20, groupId=sub-060-DVzPiDs] Resetting offset for partition test-topic-0000060-YhVhRN4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.710 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-063-DWLnvh0-21-5bb12345-d466-4b32-b791-7595cb6632b6', protocol='range'}
13:47:27.710 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Notifying assignor about the new Assignment(partitions=[test-topic-0000063-TutZTB8-0])
13:47:27.710 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Adding newly assigned partitions: test-topic-0000063-TutZTB8-0
13:47:27.710 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Found no committed offset for partition test-topic-0000063-TutZTB8-0
13:47:27.712 [pool-25-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-063-DWLnvh0-21, groupId=sub-063-DWLnvh0] Resetting offset for partition test-topic-0000063-TutZTB8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.714 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-066-badRioQ-22-f5ce6f55-9e20-4a7c-a804-6e04df93cb13', protocol='range'}
13:47:27.714 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Finished assignment for group at generation 1: {consumer-sub-066-badRioQ-22-f5ce6f55-9e20-4a7c-a804-6e04df93cb13=Assignment(partitions=[test-topic-0000066-iVHj7R4-0])}
13:47:27.716 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-066-badRioQ-22-f5ce6f55-9e20-4a7c-a804-6e04df93cb13', protocol='range'}
13:47:27.716 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000066-iVHj7R4-0])
13:47:27.716 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Adding newly assigned partitions: test-topic-0000066-iVHj7R4-0
13:47:27.717 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Found no committed offset for partition test-topic-0000066-iVHj7R4-0
13:47:27.718 [pool-26-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-066-badRioQ-22, groupId=sub-066-badRioQ] Resetting offset for partition test-topic-0000066-iVHj7R4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.718 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-069-zacfn0w-23-0222871c-cd5a-4ce0-aa72-c802d877e237', protocol='range'}
13:47:27.719 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Finished assignment for group at generation 1: {consumer-sub-069-zacfn0w-23-0222871c-cd5a-4ce0-aa72-c802d877e237=Assignment(partitions=[test-topic-0000069-j5MG-i8-0])}
13:47:27.720 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-069-zacfn0w-23-0222871c-cd5a-4ce0-aa72-c802d877e237', protocol='range'}
13:47:27.720 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Notifying assignor about the new Assignment(partitions=[test-topic-0000069-j5MG-i8-0])
13:47:27.720 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Adding newly assigned partitions: test-topic-0000069-j5MG-i8-0
13:47:27.721 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Found no committed offset for partition test-topic-0000069-j5MG-i8-0
13:47:27.722 [pool-27-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-069-zacfn0w-23, groupId=sub-069-zacfn0w] Resetting offset for partition test-topic-0000069-j5MG-i8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.724 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-072-rcD_DSA-24-11939ce4-8de2-4ecc-ae22-8644ed5733a9', protocol='range'}
13:47:27.724 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Finished assignment for group at generation 1: {consumer-sub-072-rcD_DSA-24-11939ce4-8de2-4ecc-ae22-8644ed5733a9=Assignment(partitions=[test-topic-0000072-atXhL_g-0])}
13:47:27.726 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-072-rcD_DSA-24-11939ce4-8de2-4ecc-ae22-8644ed5733a9', protocol='range'}
13:47:27.726 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Notifying assignor about the new Assignment(partitions=[test-topic-0000072-atXhL_g-0])
13:47:27.726 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Adding newly assigned partitions: test-topic-0000072-atXhL_g-0
13:47:27.727 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Found no committed offset for partition test-topic-0000072-atXhL_g-0
13:47:27.728 [pool-28-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-072-rcD_DSA-24, groupId=sub-072-rcD_DSA] Resetting offset for partition test-topic-0000072-atXhL_g-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.730 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-075-h4sM5Kk-25-ff28c2d9-715a-4e01-92f9-966712525214', protocol='range'}
13:47:27.730 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Finished assignment for group at generation 1: {consumer-sub-075-h4sM5Kk-25-ff28c2d9-715a-4e01-92f9-966712525214=Assignment(partitions=[test-topic-0000075-2Is6uhc-0])}
13:47:27.732 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-075-h4sM5Kk-25-ff28c2d9-715a-4e01-92f9-966712525214', protocol='range'}
13:47:27.732 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Notifying assignor about the new Assignment(partitions=[test-topic-0000075-2Is6uhc-0])
13:47:27.732 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Adding newly assigned partitions: test-topic-0000075-2Is6uhc-0
13:47:27.732 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Found no committed offset for partition test-topic-0000075-2Is6uhc-0
13:47:27.733 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-078-KB6LNSk-26-8fef32cf-f9b0-45a4-a5c3-6c3de597249e', protocol='range'}
13:47:27.733 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Finished assignment for group at generation 1: {consumer-sub-078-KB6LNSk-26-8fef32cf-f9b0-45a4-a5c3-6c3de597249e=Assignment(partitions=[test-topic-0000078-Wk4biHA-0])}
13:47:27.734 [pool-29-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-075-h4sM5Kk-25, groupId=sub-075-h4sM5Kk] Resetting offset for partition test-topic-0000075-2Is6uhc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.735 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-078-KB6LNSk-26-8fef32cf-f9b0-45a4-a5c3-6c3de597249e', protocol='range'}
13:47:27.735 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Notifying assignor about the new Assignment(partitions=[test-topic-0000078-Wk4biHA-0])
13:47:27.735 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Adding newly assigned partitions: test-topic-0000078-Wk4biHA-0
13:47:27.736 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Found no committed offset for partition test-topic-0000078-Wk4biHA-0
13:47:27.737 [pool-30-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-078-KB6LNSk-26, groupId=sub-078-KB6LNSk] Resetting offset for partition test-topic-0000078-Wk4biHA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.740 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-081-LEfrf2U-27-32cb27a5-ca1d-4eea-b9c5-904571f55944', protocol='range'}
13:47:27.740 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Finished assignment for group at generation 1: {consumer-sub-081-LEfrf2U-27-32cb27a5-ca1d-4eea-b9c5-904571f55944=Assignment(partitions=[test-topic-0000081-slvhhyc-0])}
13:47:27.742 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-081-LEfrf2U-27-32cb27a5-ca1d-4eea-b9c5-904571f55944', protocol='range'}
13:47:27.742 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Notifying assignor about the new Assignment(partitions=[test-topic-0000081-slvhhyc-0])
13:47:27.742 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Adding newly assigned partitions: test-topic-0000081-slvhhyc-0
13:47:27.742 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-084-q-2xFSQ-28-21e215f5-f272-45cc-8adf-ea758964b392', protocol='range'}
13:47:27.742 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Found no committed offset for partition test-topic-0000081-slvhhyc-0
13:47:27.743 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Finished assignment for group at generation 1: {consumer-sub-084-q-2xFSQ-28-21e215f5-f272-45cc-8adf-ea758964b392=Assignment(partitions=[test-topic-0000084-fyVCbbE-0])}
13:47:27.744 [pool-31-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-081-LEfrf2U-27, groupId=sub-081-LEfrf2U] Resetting offset for partition test-topic-0000081-slvhhyc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.744 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-084-q-2xFSQ-28-21e215f5-f272-45cc-8adf-ea758964b392', protocol='range'}
13:47:27.744 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000084-fyVCbbE-0])
13:47:27.745 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Adding newly assigned partitions: test-topic-0000084-fyVCbbE-0
13:47:27.745 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Found no committed offset for partition test-topic-0000084-fyVCbbE-0
13:47:27.747 [pool-32-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-084-q-2xFSQ-28, groupId=sub-084-q-2xFSQ] Resetting offset for partition test-topic-0000084-fyVCbbE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.758 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-087-d0I0Wbs-29-933d6f8e-c773-4379-9576-d39ec985b295', protocol='range'}
13:47:27.758 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Finished assignment for group at generation 1: {consumer-sub-087-d0I0Wbs-29-933d6f8e-c773-4379-9576-d39ec985b295=Assignment(partitions=[test-topic-0000087-81GfjoE-0])}
13:47:27.760 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-090-d75WZU8-30-8c31ff25-60d9-418a-8df8-8029eca665e5', protocol='range'}
13:47:27.760 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-087-d0I0Wbs-29-933d6f8e-c773-4379-9576-d39ec985b295', protocol='range'}
13:47:27.760 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Finished assignment for group at generation 1: {consumer-sub-090-d75WZU8-30-8c31ff25-60d9-418a-8df8-8029eca665e5=Assignment(partitions=[test-topic-0000090-2-rWqDI-0])}
13:47:27.760 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Notifying assignor about the new Assignment(partitions=[test-topic-0000087-81GfjoE-0])
13:47:27.760 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Adding newly assigned partitions: test-topic-0000087-81GfjoE-0
13:47:27.761 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Found no committed offset for partition test-topic-0000087-81GfjoE-0
13:47:27.762 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-090-d75WZU8-30-8c31ff25-60d9-418a-8df8-8029eca665e5', protocol='range'}
13:47:27.762 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Notifying assignor about the new Assignment(partitions=[test-topic-0000090-2-rWqDI-0])
13:47:27.762 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Adding newly assigned partitions: test-topic-0000090-2-rWqDI-0
13:47:27.762 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Found no committed offset for partition test-topic-0000090-2-rWqDI-0
13:47:27.762 [pool-33-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-087-d0I0Wbs-29, groupId=sub-087-d0I0Wbs] Resetting offset for partition test-topic-0000087-81GfjoE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.766 [pool-34-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-090-d75WZU8-30, groupId=sub-090-d75WZU8] Resetting offset for partition test-topic-0000090-2-rWqDI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.769 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-093-Cs1epd4-31-4ecc8049-8780-41bb-b83c-f4755bd625ba', protocol='range'}
13:47:27.769 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Finished assignment for group at generation 1: {consumer-sub-093-Cs1epd4-31-4ecc8049-8780-41bb-b83c-f4755bd625ba=Assignment(partitions=[test-topic-0000093-bXeEJlM-0])}
13:47:27.770 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-093-Cs1epd4-31-4ecc8049-8780-41bb-b83c-f4755bd625ba', protocol='range'}
13:47:27.771 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Notifying assignor about the new Assignment(partitions=[test-topic-0000093-bXeEJlM-0])
13:47:27.771 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Adding newly assigned partitions: test-topic-0000093-bXeEJlM-0
13:47:27.771 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Found no committed offset for partition test-topic-0000093-bXeEJlM-0
13:47:27.773 [pool-35-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-093-Cs1epd4-31, groupId=sub-093-Cs1epd4] Resetting offset for partition test-topic-0000093-bXeEJlM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.785 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-096-d8pEiis-32-b7eb56a3-53f0-407e-8810-6d8b09d51ef7', protocol='range'}
13:47:27.785 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Finished assignment for group at generation 1: {consumer-sub-096-d8pEiis-32-b7eb56a3-53f0-407e-8810-6d8b09d51ef7=Assignment(partitions=[test-topic-0000096-mZKQCwo-0])}
13:47:27.787 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-096-d8pEiis-32-b7eb56a3-53f0-407e-8810-6d8b09d51ef7', protocol='range'}
13:47:27.787 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Notifying assignor about the new Assignment(partitions=[test-topic-0000096-mZKQCwo-0])
13:47:27.787 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Adding newly assigned partitions: test-topic-0000096-mZKQCwo-0
13:47:27.788 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Found no committed offset for partition test-topic-0000096-mZKQCwo-0
13:47:27.790 [pool-36-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-096-d8pEiis-32, groupId=sub-096-d8pEiis] Resetting offset for partition test-topic-0000096-mZKQCwo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.790 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-099-zH2uJSI-33-3fffd459-1c88-417f-8ccb-13daba620900', protocol='range'}
13:47:27.790 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Finished assignment for group at generation 1: {consumer-sub-099-zH2uJSI-33-3fffd459-1c88-417f-8ccb-13daba620900=Assignment(partitions=[test-topic-0000099-1cEYHFU-0])}
13:47:27.792 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-099-zH2uJSI-33-3fffd459-1c88-417f-8ccb-13daba620900', protocol='range'}
13:47:27.792 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Notifying assignor about the new Assignment(partitions=[test-topic-0000099-1cEYHFU-0])
13:47:27.792 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Adding newly assigned partitions: test-topic-0000099-1cEYHFU-0
13:47:27.792 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Found no committed offset for partition test-topic-0000099-1cEYHFU-0
13:47:27.794 [pool-37-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-099-zH2uJSI-33, groupId=sub-099-zH2uJSI] Resetting offset for partition test-topic-0000099-1cEYHFU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.795 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-102-w7piq0s-34-7395eb1f-8ca4-4add-9ddd-44bec07d5504', protocol='range'}
13:47:27.795 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Finished assignment for group at generation 1: {consumer-sub-102-w7piq0s-34-7395eb1f-8ca4-4add-9ddd-44bec07d5504=Assignment(partitions=[test-topic-0000102-l_C9r5E-0])}
13:47:27.797 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-102-w7piq0s-34-7395eb1f-8ca4-4add-9ddd-44bec07d5504', protocol='range'}
13:47:27.797 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Notifying assignor about the new Assignment(partitions=[test-topic-0000102-l_C9r5E-0])
13:47:27.797 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Adding newly assigned partitions: test-topic-0000102-l_C9r5E-0
13:47:27.798 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Found no committed offset for partition test-topic-0000102-l_C9r5E-0
13:47:27.799 [pool-38-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-102-w7piq0s-34, groupId=sub-102-w7piq0s] Resetting offset for partition test-topic-0000102-l_C9r5E-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.799 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-105-gjMdpGk-35-d21733a5-91d5-4b27-85e4-2f070fa28e41', protocol='range'}
13:47:27.800 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Finished assignment for group at generation 1: {consumer-sub-105-gjMdpGk-35-d21733a5-91d5-4b27-85e4-2f070fa28e41=Assignment(partitions=[test-topic-0000105-9pKxJ4U-0])}
13:47:27.801 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-105-gjMdpGk-35-d21733a5-91d5-4b27-85e4-2f070fa28e41', protocol='range'}
13:47:27.801 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Notifying assignor about the new Assignment(partitions=[test-topic-0000105-9pKxJ4U-0])
13:47:27.801 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Adding newly assigned partitions: test-topic-0000105-9pKxJ4U-0
13:47:27.802 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Found no committed offset for partition test-topic-0000105-9pKxJ4U-0
13:47:27.803 [pool-39-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-105-gjMdpGk-35, groupId=sub-105-gjMdpGk] Resetting offset for partition test-topic-0000105-9pKxJ4U-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.808 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-108-VQMvh1w-36-c1059523-2c6f-4158-9996-6bd47cb8859b', protocol='range'}
13:47:27.808 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Finished assignment for group at generation 1: {consumer-sub-108-VQMvh1w-36-c1059523-2c6f-4158-9996-6bd47cb8859b=Assignment(partitions=[test-topic-0000108-NB7wiDg-0])}
13:47:27.810 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-108-VQMvh1w-36-c1059523-2c6f-4158-9996-6bd47cb8859b', protocol='range'}
13:47:27.810 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Notifying assignor about the new Assignment(partitions=[test-topic-0000108-NB7wiDg-0])
13:47:27.810 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Adding newly assigned partitions: test-topic-0000108-NB7wiDg-0
13:47:27.811 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Found no committed offset for partition test-topic-0000108-NB7wiDg-0
13:47:27.812 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-111-rfLDPtE-37-55f3a809-fdd5-4f2b-aca7-b5790f12abc0', protocol='range'}
13:47:27.812 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Finished assignment for group at generation 1: {consumer-sub-111-rfLDPtE-37-55f3a809-fdd5-4f2b-aca7-b5790f12abc0=Assignment(partitions=[test-topic-0000111-F9DCrSI-0])}
13:47:27.812 [pool-40-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-108-VQMvh1w-36, groupId=sub-108-VQMvh1w] Resetting offset for partition test-topic-0000108-NB7wiDg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.814 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-111-rfLDPtE-37-55f3a809-fdd5-4f2b-aca7-b5790f12abc0', protocol='range'}
13:47:27.814 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Notifying assignor about the new Assignment(partitions=[test-topic-0000111-F9DCrSI-0])
13:47:27.814 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Adding newly assigned partitions: test-topic-0000111-F9DCrSI-0
13:47:27.815 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Found no committed offset for partition test-topic-0000111-F9DCrSI-0
13:47:27.816 [pool-41-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-111-rfLDPtE-37, groupId=sub-111-rfLDPtE] Resetting offset for partition test-topic-0000111-F9DCrSI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.831 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-114-CjI2vXU-38-169fd2d1-b90c-41e3-b102-d7982460bfaf', protocol='range'}
13:47:27.832 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Finished assignment for group at generation 1: {consumer-sub-114-CjI2vXU-38-169fd2d1-b90c-41e3-b102-d7982460bfaf=Assignment(partitions=[test-topic-0000114-W7btOqk-0])}
13:47:27.833 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-114-CjI2vXU-38-169fd2d1-b90c-41e3-b102-d7982460bfaf', protocol='range'}
13:47:27.833 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Notifying assignor about the new Assignment(partitions=[test-topic-0000114-W7btOqk-0])
13:47:27.834 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Adding newly assigned partitions: test-topic-0000114-W7btOqk-0
13:47:27.834 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Found no committed offset for partition test-topic-0000114-W7btOqk-0
13:47:27.836 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-117-oxxQs5w-39-f8465de1-ac7a-4797-b612-960ac6c9a114', protocol='range'}
13:47:27.836 [pool-42-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-114-CjI2vXU-38, groupId=sub-114-CjI2vXU] Resetting offset for partition test-topic-0000114-W7btOqk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.836 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Finished assignment for group at generation 1: {consumer-sub-117-oxxQs5w-39-f8465de1-ac7a-4797-b612-960ac6c9a114=Assignment(partitions=[test-topic-0000117-qR0MMec-0])}
13:47:27.837 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-117-oxxQs5w-39-f8465de1-ac7a-4797-b612-960ac6c9a114', protocol='range'}
13:47:27.838 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Notifying assignor about the new Assignment(partitions=[test-topic-0000117-qR0MMec-0])
13:47:27.838 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Adding newly assigned partitions: test-topic-0000117-qR0MMec-0
13:47:27.838 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Found no committed offset for partition test-topic-0000117-qR0MMec-0
13:47:27.840 [pool-43-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-117-oxxQs5w-39, groupId=sub-117-oxxQs5w] Resetting offset for partition test-topic-0000117-qR0MMec-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.851 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-120-3MwEZaA-40-8aa20cbb-ea75-49b5-b54f-799d35c02c7f', protocol='range'}
13:47:27.852 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Finished assignment for group at generation 1: {consumer-sub-120-3MwEZaA-40-8aa20cbb-ea75-49b5-b54f-799d35c02c7f=Assignment(partitions=[test-topic-0000120-0BOroSI-0])}
13:47:27.853 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-120-3MwEZaA-40-8aa20cbb-ea75-49b5-b54f-799d35c02c7f', protocol='range'}
13:47:27.853 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Notifying assignor about the new Assignment(partitions=[test-topic-0000120-0BOroSI-0])
13:47:27.854 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Adding newly assigned partitions: test-topic-0000120-0BOroSI-0
13:47:27.854 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-123-8btZO2A-41-d00ceeb4-4d66-48c3-829e-4e32b1cd4e7d', protocol='range'}
13:47:27.854 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Finished assignment for group at generation 1: {consumer-sub-123-8btZO2A-41-d00ceeb4-4d66-48c3-829e-4e32b1cd4e7d=Assignment(partitions=[test-topic-0000123-NQtdm4o-0])}
13:47:27.854 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Found no committed offset for partition test-topic-0000120-0BOroSI-0
13:47:27.856 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-123-8btZO2A-41-d00ceeb4-4d66-48c3-829e-4e32b1cd4e7d', protocol='range'}
13:47:27.856 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Notifying assignor about the new Assignment(partitions=[test-topic-0000123-NQtdm4o-0])
13:47:27.856 [pool-44-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-120-3MwEZaA-40, groupId=sub-120-3MwEZaA] Resetting offset for partition test-topic-0000120-0BOroSI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.856 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Adding newly assigned partitions: test-topic-0000123-NQtdm4o-0
13:47:27.856 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Found no committed offset for partition test-topic-0000123-NQtdm4o-0
13:47:27.858 [pool-45-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-123-8btZO2A-41, groupId=sub-123-8btZO2A] Resetting offset for partition test-topic-0000123-NQtdm4o-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.859 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-126-X5sjNKg-42-e5d70a86-52f4-458f-9e40-5b14a59f8cd7', protocol='range'}
13:47:27.859 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Finished assignment for group at generation 1: {consumer-sub-126-X5sjNKg-42-e5d70a86-52f4-458f-9e40-5b14a59f8cd7=Assignment(partitions=[test-topic-0000126-uv0Lyw8-0])}
13:47:27.861 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-126-X5sjNKg-42-e5d70a86-52f4-458f-9e40-5b14a59f8cd7', protocol='range'}
13:47:27.861 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Notifying assignor about the new Assignment(partitions=[test-topic-0000126-uv0Lyw8-0])
13:47:27.861 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Adding newly assigned partitions: test-topic-0000126-uv0Lyw8-0
13:47:27.861 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Found no committed offset for partition test-topic-0000126-uv0Lyw8-0
13:47:27.863 [pool-46-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-126-X5sjNKg-42, groupId=sub-126-X5sjNKg] Resetting offset for partition test-topic-0000126-uv0Lyw8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.864 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-129-8OESq3A-43-9227cf78-3f65-49ce-a476-065e1ad15730', protocol='range'}
13:47:27.865 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Finished assignment for group at generation 1: {consumer-sub-129-8OESq3A-43-9227cf78-3f65-49ce-a476-065e1ad15730=Assignment(partitions=[test-topic-0000129-hjtxynQ-0])}
13:47:27.867 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-129-8OESq3A-43-9227cf78-3f65-49ce-a476-065e1ad15730', protocol='range'}
13:47:27.867 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Notifying assignor about the new Assignment(partitions=[test-topic-0000129-hjtxynQ-0])
13:47:27.867 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Adding newly assigned partitions: test-topic-0000129-hjtxynQ-0
13:47:27.867 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Found no committed offset for partition test-topic-0000129-hjtxynQ-0
13:47:27.869 [pool-47-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-129-8OESq3A-43, groupId=sub-129-8OESq3A] Resetting offset for partition test-topic-0000129-hjtxynQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.873 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-132-eXc28iU-44-cabe07aa-1443-459a-8ce8-73c1e7382e8a', protocol='range'}
13:47:27.873 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Finished assignment for group at generation 1: {consumer-sub-132-eXc28iU-44-cabe07aa-1443-459a-8ce8-73c1e7382e8a=Assignment(partitions=[test-topic-0000132-cm7Hf-c-0])}
13:47:27.875 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-132-eXc28iU-44-cabe07aa-1443-459a-8ce8-73c1e7382e8a', protocol='range'}
13:47:27.875 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Notifying assignor about the new Assignment(partitions=[test-topic-0000132-cm7Hf-c-0])
13:47:27.875 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Adding newly assigned partitions: test-topic-0000132-cm7Hf-c-0
13:47:27.876 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-135-plEHZ4o-45-d33885d7-2cac-4d73-ab95-2ba69391b6ad', protocol='range'}
13:47:27.876 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Found no committed offset for partition test-topic-0000132-cm7Hf-c-0
13:47:27.876 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Finished assignment for group at generation 1: {consumer-sub-135-plEHZ4o-45-d33885d7-2cac-4d73-ab95-2ba69391b6ad=Assignment(partitions=[test-topic-0000135-E9VX0MI-0])}
13:47:27.877 [pool-48-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-132-eXc28iU-44, groupId=sub-132-eXc28iU] Resetting offset for partition test-topic-0000132-cm7Hf-c-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.877 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-135-plEHZ4o-45-d33885d7-2cac-4d73-ab95-2ba69391b6ad', protocol='range'}
13:47:27.878 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Notifying assignor about the new Assignment(partitions=[test-topic-0000135-E9VX0MI-0])
13:47:27.878 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Adding newly assigned partitions: test-topic-0000135-E9VX0MI-0
13:47:27.878 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Found no committed offset for partition test-topic-0000135-E9VX0MI-0
13:47:27.880 [pool-49-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-135-plEHZ4o-45, groupId=sub-135-plEHZ4o] Resetting offset for partition test-topic-0000135-E9VX0MI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.881 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-138-ZgGbhcY-46-dfb4b484-b0e5-4416-9a56-6bae98450193', protocol='range'}
13:47:27.881 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Finished assignment for group at generation 1: {consumer-sub-138-ZgGbhcY-46-dfb4b484-b0e5-4416-9a56-6bae98450193=Assignment(partitions=[test-topic-0000138-jGAmpUk-0])}
13:47:27.884 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-138-ZgGbhcY-46-dfb4b484-b0e5-4416-9a56-6bae98450193', protocol='range'}
13:47:27.884 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Notifying assignor about the new Assignment(partitions=[test-topic-0000138-jGAmpUk-0])
13:47:27.884 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Adding newly assigned partitions: test-topic-0000138-jGAmpUk-0
13:47:27.885 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Found no committed offset for partition test-topic-0000138-jGAmpUk-0
13:47:27.887 [pool-50-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-138-ZgGbhcY-46, groupId=sub-138-ZgGbhcY] Resetting offset for partition test-topic-0000138-jGAmpUk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.889 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-141-3_O-qMI-47-440be29d-f149-48cf-961c-88a149f52206', protocol='range'}
13:47:27.889 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Finished assignment for group at generation 1: {consumer-sub-141-3_O-qMI-47-440be29d-f149-48cf-961c-88a149f52206=Assignment(partitions=[test-topic-0000141-sMY3in0-0])}
13:47:27.892 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-141-3_O-qMI-47-440be29d-f149-48cf-961c-88a149f52206', protocol='range'}
13:47:27.892 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Notifying assignor about the new Assignment(partitions=[test-topic-0000141-sMY3in0-0])
13:47:27.893 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Adding newly assigned partitions: test-topic-0000141-sMY3in0-0
13:47:27.893 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Found no committed offset for partition test-topic-0000141-sMY3in0-0
13:47:27.894 [pool-51-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-141-3_O-qMI-47, groupId=sub-141-3_O-qMI] Resetting offset for partition test-topic-0000141-sMY3in0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.895 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-144-7NIlz98-48-988877ff-e01d-4288-8bcc-dbdde754aad8', protocol='range'}
13:47:27.895 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Finished assignment for group at generation 1: {consumer-sub-144-7NIlz98-48-988877ff-e01d-4288-8bcc-dbdde754aad8=Assignment(partitions=[test-topic-0000144-I87Cc1c-0])}
13:47:27.897 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-144-7NIlz98-48-988877ff-e01d-4288-8bcc-dbdde754aad8', protocol='range'}
13:47:27.897 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Notifying assignor about the new Assignment(partitions=[test-topic-0000144-I87Cc1c-0])
13:47:27.897 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Adding newly assigned partitions: test-topic-0000144-I87Cc1c-0
13:47:27.898 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Found no committed offset for partition test-topic-0000144-I87Cc1c-0
13:47:27.900 [pool-52-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-144-7NIlz98-48, groupId=sub-144-7NIlz98] Resetting offset for partition test-topic-0000144-I87Cc1c-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.908 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-147-jNBMJq4-49-6be70f66-10b7-480b-a6bc-104eb2fa77d7', protocol='range'}
13:47:27.909 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Finished assignment for group at generation 1: {consumer-sub-147-jNBMJq4-49-6be70f66-10b7-480b-a6bc-104eb2fa77d7=Assignment(partitions=[test-topic-0000147-daxMmRU-0])}
13:47:27.910 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-150-2w0ayDQ-50-0f535b83-9ba3-4628-9646-7d4d754ad5b7', protocol='range'}
13:47:27.910 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Finished assignment for group at generation 1: {consumer-sub-150-2w0ayDQ-50-0f535b83-9ba3-4628-9646-7d4d754ad5b7=Assignment(partitions=[test-topic-0000150-aU4kmlM-0])}
13:47:27.910 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-147-jNBMJq4-49-6be70f66-10b7-480b-a6bc-104eb2fa77d7', protocol='range'}
13:47:27.911 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Notifying assignor about the new Assignment(partitions=[test-topic-0000147-daxMmRU-0])
13:47:27.911 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Adding newly assigned partitions: test-topic-0000147-daxMmRU-0
13:47:27.911 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Found no committed offset for partition test-topic-0000147-daxMmRU-0
13:47:27.912 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-150-2w0ayDQ-50-0f535b83-9ba3-4628-9646-7d4d754ad5b7', protocol='range'}
13:47:27.912 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000150-aU4kmlM-0])
13:47:27.912 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Adding newly assigned partitions: test-topic-0000150-aU4kmlM-0
13:47:27.913 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Found no committed offset for partition test-topic-0000150-aU4kmlM-0
13:47:27.913 [pool-53-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-147-jNBMJq4-49, groupId=sub-147-jNBMJq4] Resetting offset for partition test-topic-0000147-daxMmRU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.914 [pool-54-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-150-2w0ayDQ-50, groupId=sub-150-2w0ayDQ] Resetting offset for partition test-topic-0000150-aU4kmlM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.915 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-153-XIln-9M-51-303c719e-ceba-470d-91c4-491207f3c4e8', protocol='range'}
13:47:27.915 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Finished assignment for group at generation 1: {consumer-sub-153-XIln-9M-51-303c719e-ceba-470d-91c4-491207f3c4e8=Assignment(partitions=[test-topic-0000153-7WDuOCQ-0])}
13:47:27.917 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-153-XIln-9M-51-303c719e-ceba-470d-91c4-491207f3c4e8', protocol='range'}
13:47:27.917 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Notifying assignor about the new Assignment(partitions=[test-topic-0000153-7WDuOCQ-0])
13:47:27.917 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Adding newly assigned partitions: test-topic-0000153-7WDuOCQ-0
13:47:27.917 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Found no committed offset for partition test-topic-0000153-7WDuOCQ-0
13:47:27.919 [pool-55-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-153-XIln-9M-51, groupId=sub-153-XIln-9M] Resetting offset for partition test-topic-0000153-7WDuOCQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.920 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-156-yGFwrQQ-52-1bdb7036-9f7a-4c11-bfd5-6783464c427d', protocol='range'}
13:47:27.921 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Finished assignment for group at generation 1: {consumer-sub-156-yGFwrQQ-52-1bdb7036-9f7a-4c11-bfd5-6783464c427d=Assignment(partitions=[test-topic-0000156-bv1bM3c-0])}
13:47:27.922 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-156-yGFwrQQ-52-1bdb7036-9f7a-4c11-bfd5-6783464c427d', protocol='range'}
13:47:27.922 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-159-mZHXHFA-53-b6848800-3036-43b2-b57f-9d1476bb95e9', protocol='range'}
13:47:27.922 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000156-bv1bM3c-0])
13:47:27.923 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Adding newly assigned partitions: test-topic-0000156-bv1bM3c-0
13:47:27.923 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Finished assignment for group at generation 1: {consumer-sub-159-mZHXHFA-53-b6848800-3036-43b2-b57f-9d1476bb95e9=Assignment(partitions=[test-topic-0000159-g4aXvWA-0])}
13:47:27.923 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Found no committed offset for partition test-topic-0000156-bv1bM3c-0
13:47:27.924 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-159-mZHXHFA-53-b6848800-3036-43b2-b57f-9d1476bb95e9', protocol='range'}
13:47:27.925 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Notifying assignor about the new Assignment(partitions=[test-topic-0000159-g4aXvWA-0])
13:47:27.925 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Adding newly assigned partitions: test-topic-0000159-g4aXvWA-0
13:47:27.925 [pool-56-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-156-yGFwrQQ-52, groupId=sub-156-yGFwrQQ] Resetting offset for partition test-topic-0000156-bv1bM3c-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.925 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Found no committed offset for partition test-topic-0000159-g4aXvWA-0
13:47:27.927 [pool-57-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-159-mZHXHFA-53, groupId=sub-159-mZHXHFA] Resetting offset for partition test-topic-0000159-g4aXvWA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.935 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-162-CuU3Xlg-54-3c38cfa1-9a76-401e-837c-06e5905f8196', protocol='range'}
13:47:27.935 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Finished assignment for group at generation 1: {consumer-sub-162-CuU3Xlg-54-3c38cfa1-9a76-401e-837c-06e5905f8196=Assignment(partitions=[test-topic-0000162-MJrR-xo-0])}
13:47:27.936 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-165-Rp8SVso-55-9c0bef42-cee7-486e-ad3b-54423e65e848', protocol='range'}
13:47:27.936 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Finished assignment for group at generation 1: {consumer-sub-165-Rp8SVso-55-9c0bef42-cee7-486e-ad3b-54423e65e848=Assignment(partitions=[test-topic-0000165-K5Vt5OE-0])}
13:47:27.936 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-162-CuU3Xlg-54-3c38cfa1-9a76-401e-837c-06e5905f8196', protocol='range'}
13:47:27.937 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Notifying assignor about the new Assignment(partitions=[test-topic-0000162-MJrR-xo-0])
13:47:27.937 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Adding newly assigned partitions: test-topic-0000162-MJrR-xo-0
13:47:27.937 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Found no committed offset for partition test-topic-0000162-MJrR-xo-0
13:47:27.937 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-165-Rp8SVso-55-9c0bef42-cee7-486e-ad3b-54423e65e848', protocol='range'}
13:47:27.938 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Notifying assignor about the new Assignment(partitions=[test-topic-0000165-K5Vt5OE-0])
13:47:27.938 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Adding newly assigned partitions: test-topic-0000165-K5Vt5OE-0
13:47:27.938 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Found no committed offset for partition test-topic-0000165-K5Vt5OE-0
13:47:27.938 [pool-58-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-162-CuU3Xlg-54, groupId=sub-162-CuU3Xlg] Resetting offset for partition test-topic-0000162-MJrR-xo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.940 [pool-59-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-165-Rp8SVso-55, groupId=sub-165-Rp8SVso] Resetting offset for partition test-topic-0000165-K5Vt5OE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.942 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-168-9VyMs40-56-602ae3f0-f3c5-44a9-a8c9-c56d4b802150', protocol='range'}
13:47:27.942 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Finished assignment for group at generation 1: {consumer-sub-168-9VyMs40-56-602ae3f0-f3c5-44a9-a8c9-c56d4b802150=Assignment(partitions=[test-topic-0000168-5AaQRwA-0])}
13:47:27.944 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-168-9VyMs40-56-602ae3f0-f3c5-44a9-a8c9-c56d4b802150', protocol='range'}
13:47:27.944 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Notifying assignor about the new Assignment(partitions=[test-topic-0000168-5AaQRwA-0])
13:47:27.944 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Adding newly assigned partitions: test-topic-0000168-5AaQRwA-0
13:47:27.945 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Found no committed offset for partition test-topic-0000168-5AaQRwA-0
13:47:27.947 [pool-60-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-168-9VyMs40-56, groupId=sub-168-9VyMs40] Resetting offset for partition test-topic-0000168-5AaQRwA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.951 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-171-dhED_pg-57-eafe6c49-f93a-4b13-8afa-4afa92c14a57', protocol='range'}
13:47:27.951 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Finished assignment for group at generation 1: {consumer-sub-171-dhED_pg-57-eafe6c49-f93a-4b13-8afa-4afa92c14a57=Assignment(partitions=[test-topic-0000171-TTgHNZY-0])}
13:47:27.952 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-171-dhED_pg-57-eafe6c49-f93a-4b13-8afa-4afa92c14a57', protocol='range'}
13:47:27.953 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Notifying assignor about the new Assignment(partitions=[test-topic-0000171-TTgHNZY-0])
13:47:27.953 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Adding newly assigned partitions: test-topic-0000171-TTgHNZY-0
13:47:27.953 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Found no committed offset for partition test-topic-0000171-TTgHNZY-0
13:47:27.955 [pool-61-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-171-dhED_pg-57, groupId=sub-171-dhED_pg] Resetting offset for partition test-topic-0000171-TTgHNZY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.958 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-174-VtGKXiA-58-fa6f4e28-0c32-4358-88ac-e30c64550e53', protocol='range'}
13:47:27.958 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Finished assignment for group at generation 1: {consumer-sub-174-VtGKXiA-58-fa6f4e28-0c32-4358-88ac-e30c64550e53=Assignment(partitions=[test-topic-0000174-hJfH_wE-0])}
13:47:27.959 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-174-VtGKXiA-58-fa6f4e28-0c32-4358-88ac-e30c64550e53', protocol='range'}
13:47:27.960 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Notifying assignor about the new Assignment(partitions=[test-topic-0000174-hJfH_wE-0])
13:47:27.960 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Adding newly assigned partitions: test-topic-0000174-hJfH_wE-0
13:47:27.960 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Found no committed offset for partition test-topic-0000174-hJfH_wE-0
13:47:27.962 [pool-62-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-174-VtGKXiA-58, groupId=sub-174-VtGKXiA] Resetting offset for partition test-topic-0000174-hJfH_wE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.963 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-177-7kd9GC8-59-d8b9a23a-8ae4-45bb-8c84-961397b78c8b', protocol='range'}
13:47:27.963 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Finished assignment for group at generation 1: {consumer-sub-177-7kd9GC8-59-d8b9a23a-8ae4-45bb-8c84-961397b78c8b=Assignment(partitions=[test-topic-0000177-9whUEAI-0])}
13:47:27.965 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-177-7kd9GC8-59-d8b9a23a-8ae4-45bb-8c84-961397b78c8b', protocol='range'}
13:47:27.965 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Notifying assignor about the new Assignment(partitions=[test-topic-0000177-9whUEAI-0])
13:47:27.965 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Adding newly assigned partitions: test-topic-0000177-9whUEAI-0
13:47:27.966 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Found no committed offset for partition test-topic-0000177-9whUEAI-0
13:47:27.967 [pool-63-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-177-7kd9GC8-59, groupId=sub-177-7kd9GC8] Resetting offset for partition test-topic-0000177-9whUEAI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:27.971 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-180-L4cWf7o-60-07b5304c-0494-4620-b7c5-29ed69731108', protocol='range'}
13:47:27.971 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Finished assignment for group at generation 1: {consumer-sub-180-L4cWf7o-60-07b5304c-0494-4620-b7c5-29ed69731108=Assignment(partitions=[test-topic-0000180-mtow198-0])}
13:47:27.973 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-180-L4cWf7o-60-07b5304c-0494-4620-b7c5-29ed69731108', protocol='range'}
13:47:27.973 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Notifying assignor about the new Assignment(partitions=[test-topic-0000180-mtow198-0])
13:47:27.973 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Adding newly assigned partitions: test-topic-0000180-mtow198-0
13:47:27.974 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Found no committed offset for partition test-topic-0000180-mtow198-0
13:47:27.975 [pool-64-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-180-L4cWf7o-60, groupId=sub-180-L4cWf7o] Resetting offset for partition test-topic-0000180-mtow198-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.976 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-183-_icEX9A-61-79dea89a-d5d5-4a7f-bf74-5bdb52626bc2', protocol='range'}
13:47:27.977 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Finished assignment for group at generation 1: {consumer-sub-183-_icEX9A-61-79dea89a-d5d5-4a7f-bf74-5bdb52626bc2=Assignment(partitions=[test-topic-0000183-Q_DaKzs-0])}
13:47:27.978 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-183-_icEX9A-61-79dea89a-d5d5-4a7f-bf74-5bdb52626bc2', protocol='range'}
13:47:27.979 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Notifying assignor about the new Assignment(partitions=[test-topic-0000183-Q_DaKzs-0])
13:47:27.979 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Adding newly assigned partitions: test-topic-0000183-Q_DaKzs-0
13:47:27.979 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Found no committed offset for partition test-topic-0000183-Q_DaKzs-0
13:47:27.981 [pool-65-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-183-_icEX9A-61, groupId=sub-183-_icEX9A] Resetting offset for partition test-topic-0000183-Q_DaKzs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:27.987 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-186-tb5lhHw-62-f50e472c-9ade-4a05-b195-d0acd3a1bb52', protocol='range'}
13:47:27.987 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Finished assignment for group at generation 1: {consumer-sub-186-tb5lhHw-62-f50e472c-9ade-4a05-b195-d0acd3a1bb52=Assignment(partitions=[test-topic-0000186-TMi6IGE-0])}
13:47:27.988 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-189-nUp5ynA-63-39467be7-ff40-451d-9503-ffc23002c911', protocol='range'}
13:47:27.988 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Finished assignment for group at generation 1: {consumer-sub-189-nUp5ynA-63-39467be7-ff40-451d-9503-ffc23002c911=Assignment(partitions=[test-topic-0000189-Br5CACQ-0])}
13:47:27.989 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-186-tb5lhHw-62-f50e472c-9ade-4a05-b195-d0acd3a1bb52', protocol='range'}
13:47:27.989 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Notifying assignor about the new Assignment(partitions=[test-topic-0000186-TMi6IGE-0])
13:47:27.989 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Adding newly assigned partitions: test-topic-0000186-TMi6IGE-0
13:47:27.990 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-189-nUp5ynA-63-39467be7-ff40-451d-9503-ffc23002c911', protocol='range'}
13:47:27.990 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Found no committed offset for partition test-topic-0000186-TMi6IGE-0
13:47:27.990 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Notifying assignor about the new Assignment(partitions=[test-topic-0000189-Br5CACQ-0])
13:47:27.990 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Adding newly assigned partitions: test-topic-0000189-Br5CACQ-0
13:47:27.990 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Found no committed offset for partition test-topic-0000189-Br5CACQ-0
13:47:27.992 [pool-66-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-186-tb5lhHw-62, groupId=sub-186-tb5lhHw] Resetting offset for partition test-topic-0000186-TMi6IGE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.992 [pool-67-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-189-nUp5ynA-63, groupId=sub-189-nUp5ynA] Resetting offset for partition test-topic-0000189-Br5CACQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:27.996 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-192-h9BuMY0-64-b9667911-fec2-430b-a1ff-6379e105729c', protocol='range'}
13:47:27.997 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Finished assignment for group at generation 1: {consumer-sub-192-h9BuMY0-64-b9667911-fec2-430b-a1ff-6379e105729c=Assignment(partitions=[test-topic-0000192-qIO7V7Q-0])}
13:47:27.998 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-192-h9BuMY0-64-b9667911-fec2-430b-a1ff-6379e105729c', protocol='range'}
13:47:27.999 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Notifying assignor about the new Assignment(partitions=[test-topic-0000192-qIO7V7Q-0])
13:47:27.999 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Adding newly assigned partitions: test-topic-0000192-qIO7V7Q-0
13:47:27.999 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Found no committed offset for partition test-topic-0000192-qIO7V7Q-0
13:47:28.001 [pool-68-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-192-h9BuMY0-64, groupId=sub-192-h9BuMY0] Resetting offset for partition test-topic-0000192-qIO7V7Q-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.006 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-195-xI9sSec-65-7b260926-8e34-4ca9-9dfd-1bf4e1d3ea1e', protocol='range'}
13:47:28.006 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Finished assignment for group at generation 1: {consumer-sub-195-xI9sSec-65-7b260926-8e34-4ca9-9dfd-1bf4e1d3ea1e=Assignment(partitions=[test-topic-0000195-ur-Cgeo-0])}
13:47:28.007 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-198-MIarouE-66-94a47337-c16a-4f74-907c-98202220f8cb', protocol='range'}
13:47:28.007 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Finished assignment for group at generation 1: {consumer-sub-198-MIarouE-66-94a47337-c16a-4f74-907c-98202220f8cb=Assignment(partitions=[test-topic-0000198-MRrztgM-0])}
13:47:28.008 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-195-xI9sSec-65-7b260926-8e34-4ca9-9dfd-1bf4e1d3ea1e', protocol='range'}
13:47:28.008 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Notifying assignor about the new Assignment(partitions=[test-topic-0000195-ur-Cgeo-0])
13:47:28.009 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Adding newly assigned partitions: test-topic-0000195-ur-Cgeo-0
13:47:28.009 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-198-MIarouE-66-94a47337-c16a-4f74-907c-98202220f8cb', protocol='range'}
13:47:28.009 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Notifying assignor about the new Assignment(partitions=[test-topic-0000198-MRrztgM-0])
13:47:28.009 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Adding newly assigned partitions: test-topic-0000198-MRrztgM-0
13:47:28.009 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Found no committed offset for partition test-topic-0000195-ur-Cgeo-0
13:47:28.009 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Found no committed offset for partition test-topic-0000198-MRrztgM-0
13:47:28.011 [pool-69-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-195-xI9sSec-65, groupId=sub-195-xI9sSec] Resetting offset for partition test-topic-0000195-ur-Cgeo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.011 [pool-70-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-198-MIarouE-66, groupId=sub-198-MIarouE] Resetting offset for partition test-topic-0000198-MRrztgM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.014 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-201-DRMyqV0-67-89a1dddc-5788-4b11-80e1-ce0fbff26b69', protocol='range'}
13:47:28.015 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Finished assignment for group at generation 1: {consumer-sub-201-DRMyqV0-67-89a1dddc-5788-4b11-80e1-ce0fbff26b69=Assignment(partitions=[test-topic-0000201-rmNvfr4-0])}
13:47:28.016 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-201-DRMyqV0-67-89a1dddc-5788-4b11-80e1-ce0fbff26b69', protocol='range'}
13:47:28.016 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Notifying assignor about the new Assignment(partitions=[test-topic-0000201-rmNvfr4-0])
13:47:28.016 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Adding newly assigned partitions: test-topic-0000201-rmNvfr4-0
13:47:28.017 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Found no committed offset for partition test-topic-0000201-rmNvfr4-0
13:47:28.018 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-204-38mBm0s-68-e9e2db1a-e5da-41cb-a470-d09a49e70034', protocol='range'}
13:47:28.019 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Finished assignment for group at generation 1: {consumer-sub-204-38mBm0s-68-e9e2db1a-e5da-41cb-a470-d09a49e70034=Assignment(partitions=[test-topic-0000204-qe1T4lQ-0])}
13:47:28.019 [pool-71-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-201-DRMyqV0-67, groupId=sub-201-DRMyqV0] Resetting offset for partition test-topic-0000201-rmNvfr4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.020 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-204-38mBm0s-68-e9e2db1a-e5da-41cb-a470-d09a49e70034', protocol='range'}
13:47:28.020 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Notifying assignor about the new Assignment(partitions=[test-topic-0000204-qe1T4lQ-0])
13:47:28.021 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Adding newly assigned partitions: test-topic-0000204-qe1T4lQ-0
13:47:28.021 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Found no committed offset for partition test-topic-0000204-qe1T4lQ-0
13:47:28.023 [pool-72-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-204-38mBm0s-68, groupId=sub-204-38mBm0s] Resetting offset for partition test-topic-0000204-qe1T4lQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.026 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-210-ZQk298Y-70-b972ce9c-7d01-48bc-8bdd-da81f46ff154', protocol='range'}
13:47:28.027 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Finished assignment for group at generation 1: {consumer-sub-210-ZQk298Y-70-b972ce9c-7d01-48bc-8bdd-da81f46ff154=Assignment(partitions=[test-topic-0000210-IbT0AKY-0])}
13:47:28.028 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-210-ZQk298Y-70-b972ce9c-7d01-48bc-8bdd-da81f46ff154', protocol='range'}
13:47:28.028 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Notifying assignor about the new Assignment(partitions=[test-topic-0000210-IbT0AKY-0])
13:47:28.029 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Adding newly assigned partitions: test-topic-0000210-IbT0AKY-0
13:47:28.029 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Found no committed offset for partition test-topic-0000210-IbT0AKY-0
13:47:28.031 [pool-74-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-210-ZQk298Y-70, groupId=sub-210-ZQk298Y] Resetting offset for partition test-topic-0000210-IbT0AKY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.035 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-207-jL30q_M-69-613346be-213a-4e0b-8ce3-23ce63f32abe', protocol='range'}
13:47:28.035 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Finished assignment for group at generation 1: {consumer-sub-207-jL30q_M-69-613346be-213a-4e0b-8ce3-23ce63f32abe=Assignment(partitions=[test-topic-0000207-bDTZgNE-0])}
13:47:28.036 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-207-jL30q_M-69-613346be-213a-4e0b-8ce3-23ce63f32abe', protocol='range'}
13:47:28.036 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Notifying assignor about the new Assignment(partitions=[test-topic-0000207-bDTZgNE-0])
13:47:28.037 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Adding newly assigned partitions: test-topic-0000207-bDTZgNE-0
13:47:28.037 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Found no committed offset for partition test-topic-0000207-bDTZgNE-0
13:47:28.039 [pool-73-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-207-jL30q_M-69, groupId=sub-207-jL30q_M] Resetting offset for partition test-topic-0000207-bDTZgNE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.046 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-213-7fDmYK4-71-952af2b6-14d0-42da-961d-a447919dc420', protocol='range'}
13:47:28.047 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Finished assignment for group at generation 1: {consumer-sub-213-7fDmYK4-71-952af2b6-14d0-42da-961d-a447919dc420=Assignment(partitions=[test-topic-0000213-a7hif5U-0])}
13:47:28.048 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-213-7fDmYK4-71-952af2b6-14d0-42da-961d-a447919dc420', protocol='range'}
13:47:28.049 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Notifying assignor about the new Assignment(partitions=[test-topic-0000213-a7hif5U-0])
13:47:28.049 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Adding newly assigned partitions: test-topic-0000213-a7hif5U-0
13:47:28.049 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Found no committed offset for partition test-topic-0000213-a7hif5U-0
13:47:28.051 [pool-75-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-213-7fDmYK4-71, groupId=sub-213-7fDmYK4] Resetting offset for partition test-topic-0000213-a7hif5U-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.052 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-216-cOjc_gA-72-e8a44d61-03fa-4abd-83db-23e67b6dc98b', protocol='range'}
13:47:28.052 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Finished assignment for group at generation 1: {consumer-sub-216-cOjc_gA-72-e8a44d61-03fa-4abd-83db-23e67b6dc98b=Assignment(partitions=[test-topic-0000216-PzoM90k-0])}
13:47:28.054 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-216-cOjc_gA-72-e8a44d61-03fa-4abd-83db-23e67b6dc98b', protocol='range'}
13:47:28.054 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Notifying assignor about the new Assignment(partitions=[test-topic-0000216-PzoM90k-0])
13:47:28.054 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Adding newly assigned partitions: test-topic-0000216-PzoM90k-0
13:47:28.054 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Found no committed offset for partition test-topic-0000216-PzoM90k-0
13:47:28.055 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-219-zge6Hqg-73-0cc26bfc-4a3c-454c-be74-cf0892b1fefe', protocol='range'}
13:47:28.055 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Finished assignment for group at generation 1: {consumer-sub-219-zge6Hqg-73-0cc26bfc-4a3c-454c-be74-cf0892b1fefe=Assignment(partitions=[test-topic-0000219-9wHMOjI-0])}
13:47:28.056 [pool-76-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-216-cOjc_gA-72, groupId=sub-216-cOjc_gA] Resetting offset for partition test-topic-0000216-PzoM90k-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.057 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-219-zge6Hqg-73-0cc26bfc-4a3c-454c-be74-cf0892b1fefe', protocol='range'}
13:47:28.057 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Notifying assignor about the new Assignment(partitions=[test-topic-0000219-9wHMOjI-0])
13:47:28.057 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Adding newly assigned partitions: test-topic-0000219-9wHMOjI-0
13:47:28.058 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Found no committed offset for partition test-topic-0000219-9wHMOjI-0
13:47:28.059 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-222-Bh6PWik-74-5a119084-a18d-4db1-8887-3981e02e2d8b', protocol='range'}
13:47:28.059 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Finished assignment for group at generation 1: {consumer-sub-222-Bh6PWik-74-5a119084-a18d-4db1-8887-3981e02e2d8b=Assignment(partitions=[test-topic-0000222-0FOfLX4-0])}
13:47:28.059 [pool-77-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-219-zge6Hqg-73, groupId=sub-219-zge6Hqg] Resetting offset for partition test-topic-0000219-9wHMOjI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.061 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-222-Bh6PWik-74-5a119084-a18d-4db1-8887-3981e02e2d8b', protocol='range'}
13:47:28.061 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Notifying assignor about the new Assignment(partitions=[test-topic-0000222-0FOfLX4-0])
13:47:28.061 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Adding newly assigned partitions: test-topic-0000222-0FOfLX4-0
13:47:28.061 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Found no committed offset for partition test-topic-0000222-0FOfLX4-0
13:47:28.063 [pool-78-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-222-Bh6PWik-74, groupId=sub-222-Bh6PWik] Resetting offset for partition test-topic-0000222-0FOfLX4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.066 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-225-X6fowHo-75-e84e15de-c310-4f06-85c2-310444260fef', protocol='range'}
13:47:28.066 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Finished assignment for group at generation 1: {consumer-sub-225-X6fowHo-75-e84e15de-c310-4f06-85c2-310444260fef=Assignment(partitions=[test-topic-0000225-Xfv4mUc-0])}
13:47:28.067 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-225-X6fowHo-75-e84e15de-c310-4f06-85c2-310444260fef', protocol='range'}
13:47:28.068 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Notifying assignor about the new Assignment(partitions=[test-topic-0000225-Xfv4mUc-0])
13:47:28.068 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Adding newly assigned partitions: test-topic-0000225-Xfv4mUc-0
13:47:28.068 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Found no committed offset for partition test-topic-0000225-Xfv4mUc-0
13:47:28.070 [pool-79-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-225-X6fowHo-75, groupId=sub-225-X6fowHo] Resetting offset for partition test-topic-0000225-Xfv4mUc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.072 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-228-RZlr8_o-76-52387017-6147-4a81-b2b3-13da2584bf5b', protocol='range'}
13:47:28.072 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Finished assignment for group at generation 1: {consumer-sub-228-RZlr8_o-76-52387017-6147-4a81-b2b3-13da2584bf5b=Assignment(partitions=[test-topic-0000228-j6bdXE8-0])}
13:47:28.074 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-228-RZlr8_o-76-52387017-6147-4a81-b2b3-13da2584bf5b', protocol='range'}
13:47:28.074 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Notifying assignor about the new Assignment(partitions=[test-topic-0000228-j6bdXE8-0])
13:47:28.074 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Adding newly assigned partitions: test-topic-0000228-j6bdXE8-0
13:47:28.075 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Found no committed offset for partition test-topic-0000228-j6bdXE8-0
13:47:28.076 [pool-80-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-228-RZlr8_o-76, groupId=sub-228-RZlr8_o] Resetting offset for partition test-topic-0000228-j6bdXE8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.080 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-231-OB5fv-Q-77-c6a8b7c4-8ca9-413e-a856-cfc57c6aec32', protocol='range'}
13:47:28.080 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Finished assignment for group at generation 1: {consumer-sub-231-OB5fv-Q-77-c6a8b7c4-8ca9-413e-a856-cfc57c6aec32=Assignment(partitions=[test-topic-0000231-W7upruI-0])}
13:47:28.082 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-231-OB5fv-Q-77-c6a8b7c4-8ca9-413e-a856-cfc57c6aec32', protocol='range'}
13:47:28.082 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Notifying assignor about the new Assignment(partitions=[test-topic-0000231-W7upruI-0])
13:47:28.082 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Adding newly assigned partitions: test-topic-0000231-W7upruI-0
13:47:28.083 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Found no committed offset for partition test-topic-0000231-W7upruI-0
13:47:28.084 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-234-Wkn5HAk-78-a02e5c3c-c25c-4b02-b7b1-89ad15a6b81c', protocol='range'}
13:47:28.084 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Finished assignment for group at generation 1: {consumer-sub-234-Wkn5HAk-78-a02e5c3c-c25c-4b02-b7b1-89ad15a6b81c=Assignment(partitions=[test-topic-0000234-MztKqbA-0])}
13:47:28.085 [pool-81-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-231-OB5fv-Q-77, groupId=sub-231-OB5fv-Q] Resetting offset for partition test-topic-0000231-W7upruI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.086 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-234-Wkn5HAk-78-a02e5c3c-c25c-4b02-b7b1-89ad15a6b81c', protocol='range'}
13:47:28.086 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Notifying assignor about the new Assignment(partitions=[test-topic-0000234-MztKqbA-0])
13:47:28.086 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Adding newly assigned partitions: test-topic-0000234-MztKqbA-0
13:47:28.087 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-237-e0zoYsA-79-f69ec73f-3676-4c5e-b49e-a16e1b6b57b9', protocol='range'}
13:47:28.087 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Finished assignment for group at generation 1: {consumer-sub-237-e0zoYsA-79-f69ec73f-3676-4c5e-b49e-a16e1b6b57b9=Assignment(partitions=[test-topic-0000237-x236eMI-0])}
13:47:28.087 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Found no committed offset for partition test-topic-0000234-MztKqbA-0
13:47:28.089 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-237-e0zoYsA-79-f69ec73f-3676-4c5e-b49e-a16e1b6b57b9', protocol='range'}
13:47:28.089 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Notifying assignor about the new Assignment(partitions=[test-topic-0000237-x236eMI-0])
13:47:28.089 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Adding newly assigned partitions: test-topic-0000237-x236eMI-0
13:47:28.089 [pool-82-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-234-Wkn5HAk-78, groupId=sub-234-Wkn5HAk] Resetting offset for partition test-topic-0000234-MztKqbA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.089 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Found no committed offset for partition test-topic-0000237-x236eMI-0
13:47:28.091 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-240-vyR70kw-80-f67d9901-edf6-45b8-a642-9f7ca45cb235', protocol='range'}
13:47:28.091 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Finished assignment for group at generation 1: {consumer-sub-240-vyR70kw-80-f67d9901-edf6-45b8-a642-9f7ca45cb235=Assignment(partitions=[test-topic-0000240-vwD5iNc-0])}
13:47:28.091 [pool-83-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-237-e0zoYsA-79, groupId=sub-237-e0zoYsA] Resetting offset for partition test-topic-0000237-x236eMI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.093 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-240-vyR70kw-80-f67d9901-edf6-45b8-a642-9f7ca45cb235', protocol='range'}
13:47:28.093 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Notifying assignor about the new Assignment(partitions=[test-topic-0000240-vwD5iNc-0])
13:47:28.093 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Adding newly assigned partitions: test-topic-0000240-vwD5iNc-0
13:47:28.093 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Found no committed offset for partition test-topic-0000240-vwD5iNc-0
13:47:28.095 [pool-84-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-240-vyR70kw-80, groupId=sub-240-vyR70kw] Resetting offset for partition test-topic-0000240-vwD5iNc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.095 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-243-K9G8MCY-81-405831a9-fdf2-492d-b437-fa6b3c7ac77f', protocol='range'}
13:47:28.096 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Finished assignment for group at generation 1: {consumer-sub-243-K9G8MCY-81-405831a9-fdf2-492d-b437-fa6b3c7ac77f=Assignment(partitions=[test-topic-0000243-fpyKxcw-0])}
13:47:28.098 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-243-K9G8MCY-81-405831a9-fdf2-492d-b437-fa6b3c7ac77f', protocol='range'}
13:47:28.098 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Notifying assignor about the new Assignment(partitions=[test-topic-0000243-fpyKxcw-0])
13:47:28.098 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Adding newly assigned partitions: test-topic-0000243-fpyKxcw-0
13:47:28.098 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-246-uUsGb-s-82-3ee0b3bf-c72f-436c-9097-7813dba39529', protocol='range'}
13:47:28.099 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Finished assignment for group at generation 1: {consumer-sub-246-uUsGb-s-82-3ee0b3bf-c72f-436c-9097-7813dba39529=Assignment(partitions=[test-topic-0000246-Bq6i99k-0])}
13:47:28.098 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Found no committed offset for partition test-topic-0000243-fpyKxcw-0
13:47:28.100 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-246-uUsGb-s-82-3ee0b3bf-c72f-436c-9097-7813dba39529', protocol='range'}
13:47:28.100 [pool-85-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-243-K9G8MCY-81, groupId=sub-243-K9G8MCY] Resetting offset for partition test-topic-0000243-fpyKxcw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.100 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Notifying assignor about the new Assignment(partitions=[test-topic-0000246-Bq6i99k-0])
13:47:28.100 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Adding newly assigned partitions: test-topic-0000246-Bq6i99k-0
13:47:28.101 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Found no committed offset for partition test-topic-0000246-Bq6i99k-0
13:47:28.101 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-249-zHjl4eA-83-0b71fa37-0193-467b-8626-aa56c188a577', protocol='range'}
13:47:28.102 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Finished assignment for group at generation 1: {consumer-sub-249-zHjl4eA-83-0b71fa37-0193-467b-8626-aa56c188a577=Assignment(partitions=[test-topic-0000249-j-ThMcs-0])}
13:47:28.103 [pool-86-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-246-uUsGb-s-82, groupId=sub-246-uUsGb-s] Resetting offset for partition test-topic-0000246-Bq6i99k-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.104 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-249-zHjl4eA-83-0b71fa37-0193-467b-8626-aa56c188a577', protocol='range'}
13:47:28.104 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Notifying assignor about the new Assignment(partitions=[test-topic-0000249-j-ThMcs-0])
13:47:28.104 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Adding newly assigned partitions: test-topic-0000249-j-ThMcs-0
13:47:28.105 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Found no committed offset for partition test-topic-0000249-j-ThMcs-0
13:47:28.107 [pool-87-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-249-zHjl4eA-83, groupId=sub-249-zHjl4eA] Resetting offset for partition test-topic-0000249-j-ThMcs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.107 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-252-EmLjkEo-84-49d5ee02-9316-4d0b-aad5-c8c344609d01', protocol='range'}
13:47:28.107 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Finished assignment for group at generation 1: {consumer-sub-252-EmLjkEo-84-49d5ee02-9316-4d0b-aad5-c8c344609d01=Assignment(partitions=[test-topic-0000252-fa1UjIY-0])}
13:47:28.108 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-252-EmLjkEo-84-49d5ee02-9316-4d0b-aad5-c8c344609d01', protocol='range'}
13:47:28.108 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Notifying assignor about the new Assignment(partitions=[test-topic-0000252-fa1UjIY-0])
13:47:28.108 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Adding newly assigned partitions: test-topic-0000252-fa1UjIY-0
13:47:28.109 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Found no committed offset for partition test-topic-0000252-fa1UjIY-0
13:47:28.110 [pool-88-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-252-EmLjkEo-84, groupId=sub-252-EmLjkEo] Resetting offset for partition test-topic-0000252-fa1UjIY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.115 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-255-OykRCRA-85-349f68c8-dff0-4066-8e31-24229486e6cd', protocol='range'}
13:47:28.116 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Finished assignment for group at generation 1: {consumer-sub-255-OykRCRA-85-349f68c8-dff0-4066-8e31-24229486e6cd=Assignment(partitions=[test-topic-0000255-qWOKGG0-0])}
13:47:28.117 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-255-OykRCRA-85-349f68c8-dff0-4066-8e31-24229486e6cd', protocol='range'}
13:47:28.117 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Notifying assignor about the new Assignment(partitions=[test-topic-0000255-qWOKGG0-0])
13:47:28.117 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Adding newly assigned partitions: test-topic-0000255-qWOKGG0-0
13:47:28.118 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Found no committed offset for partition test-topic-0000255-qWOKGG0-0
13:47:28.123 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-261-0MZJWCA-87-268383bc-942b-4358-80da-49d15862c336', protocol='range'}
13:47:28.123 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Finished assignment for group at generation 1: {consumer-sub-261-0MZJWCA-87-268383bc-942b-4358-80da-49d15862c336=Assignment(partitions=[test-topic-0000261-w2mnyns-0])}
13:47:28.124 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-258-E3w5eVc-86-fbc6f10a-bfa6-4ebc-8903-70a35504ce89', protocol='range'}
13:47:28.124 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Finished assignment for group at generation 1: {consumer-sub-258-E3w5eVc-86-fbc6f10a-bfa6-4ebc-8903-70a35504ce89=Assignment(partitions=[test-topic-0000258-Rv9SxIc-0])}
13:47:28.125 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-261-0MZJWCA-87-268383bc-942b-4358-80da-49d15862c336', protocol='range'}
13:47:28.125 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Notifying assignor about the new Assignment(partitions=[test-topic-0000261-w2mnyns-0])
13:47:28.125 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Adding newly assigned partitions: test-topic-0000261-w2mnyns-0
13:47:28.126 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-258-E3w5eVc-86-fbc6f10a-bfa6-4ebc-8903-70a35504ce89', protocol='range'}
13:47:28.126 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Notifying assignor about the new Assignment(partitions=[test-topic-0000258-Rv9SxIc-0])
13:47:28.126 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Adding newly assigned partitions: test-topic-0000258-Rv9SxIc-0
13:47:28.126 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Found no committed offset for partition test-topic-0000258-Rv9SxIc-0
13:47:28.128 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-264-xDpyMxE-88-c2653c93-5f82-4089-9c36-69d70d732f38', protocol='range'}
13:47:28.128 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Finished assignment for group at generation 1: {consumer-sub-264-xDpyMxE-88-c2653c93-5f82-4089-9c36-69d70d732f38=Assignment(partitions=[test-topic-0000264-eT2e8rU-0])}
13:47:28.130 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-267-ss7aMOo-89-b4f09981-8759-4d93-af93-f9826a663476', protocol='range'}
13:47:28.130 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-264-xDpyMxE-88-c2653c93-5f82-4089-9c36-69d70d732f38', protocol='range'}
13:47:28.130 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Notifying assignor about the new Assignment(partitions=[test-topic-0000264-eT2e8rU-0])
13:47:28.130 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Finished assignment for group at generation 1: {consumer-sub-267-ss7aMOo-89-b4f09981-8759-4d93-af93-f9826a663476=Assignment(partitions=[test-topic-0000267-CjvJg1c-0])}
13:47:28.130 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Adding newly assigned partitions: test-topic-0000264-eT2e8rU-0
13:47:28.131 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Found no committed offset for partition test-topic-0000264-eT2e8rU-0
13:47:28.132 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-267-ss7aMOo-89-b4f09981-8759-4d93-af93-f9826a663476', protocol='range'}
13:47:28.131 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Found no committed offset for partition test-topic-0000261-w2mnyns-0
13:47:28.132 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Notifying assignor about the new Assignment(partitions=[test-topic-0000267-CjvJg1c-0])
13:47:28.132 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Adding newly assigned partitions: test-topic-0000267-CjvJg1c-0
13:47:28.132 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Found no committed offset for partition test-topic-0000267-CjvJg1c-0
13:47:28.133 [pool-92-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-264-xDpyMxE-88, groupId=sub-264-xDpyMxE] Resetting offset for partition test-topic-0000264-eT2e8rU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.134 [pool-90-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-258-E3w5eVc-86, groupId=sub-258-E3w5eVc] Resetting offset for partition test-topic-0000258-Rv9SxIc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.134 [pool-91-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-261-0MZJWCA-87, groupId=sub-261-0MZJWCA] Resetting offset for partition test-topic-0000261-w2mnyns-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.134 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-270-aPNzw1o-90-1ada19ec-e32d-48f3-8f0d-648fb91a1bf9', protocol='range'}
13:47:28.134 [pool-93-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-267-ss7aMOo-89, groupId=sub-267-ss7aMOo] Resetting offset for partition test-topic-0000267-CjvJg1c-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.135 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Finished assignment for group at generation 1: {consumer-sub-270-aPNzw1o-90-1ada19ec-e32d-48f3-8f0d-648fb91a1bf9=Assignment(partitions=[test-topic-0000270-tS64jLw-0])}
13:47:28.136 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-270-aPNzw1o-90-1ada19ec-e32d-48f3-8f0d-648fb91a1bf9', protocol='range'}
13:47:28.137 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Notifying assignor about the new Assignment(partitions=[test-topic-0000270-tS64jLw-0])
13:47:28.137 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Adding newly assigned partitions: test-topic-0000270-tS64jLw-0
13:47:28.137 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Found no committed offset for partition test-topic-0000270-tS64jLw-0
13:47:28.138 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-273-eqL_byk-91-9a8ef42b-ec72-44fe-b89c-a032b752fef6', protocol='range'}
13:47:28.138 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Finished assignment for group at generation 1: {consumer-sub-273-eqL_byk-91-9a8ef42b-ec72-44fe-b89c-a032b752fef6=Assignment(partitions=[test-topic-0000273-EO6kLrs-0])}
13:47:28.143 [pool-89-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-255-OykRCRA-85, groupId=sub-255-OykRCRA] Resetting offset for partition test-topic-0000255-qWOKGG0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.143 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-276-M_73Af4-92-eae216e7-6c24-47dc-9815-fa4973f440f0', protocol='range'}
13:47:28.143 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Finished assignment for group at generation 1: {consumer-sub-276-M_73Af4-92-eae216e7-6c24-47dc-9815-fa4973f440f0=Assignment(partitions=[test-topic-0000276-6JL1QfE-0])}
13:47:28.143 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-273-eqL_byk-91-9a8ef42b-ec72-44fe-b89c-a032b752fef6', protocol='range'}
13:47:28.143 [pool-94-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-270-aPNzw1o-90, groupId=sub-270-aPNzw1o] Resetting offset for partition test-topic-0000270-tS64jLw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.143 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Notifying assignor about the new Assignment(partitions=[test-topic-0000273-EO6kLrs-0])
13:47:28.144 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Adding newly assigned partitions: test-topic-0000273-EO6kLrs-0
13:47:28.144 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Found no committed offset for partition test-topic-0000273-EO6kLrs-0
13:47:28.145 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-276-M_73Af4-92-eae216e7-6c24-47dc-9815-fa4973f440f0', protocol='range'}
13:47:28.145 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Notifying assignor about the new Assignment(partitions=[test-topic-0000276-6JL1QfE-0])
13:47:28.145 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Adding newly assigned partitions: test-topic-0000276-6JL1QfE-0
13:47:28.145 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Found no committed offset for partition test-topic-0000276-6JL1QfE-0
13:47:28.151 [pool-95-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-273-eqL_byk-91, groupId=sub-273-eqL_byk] Resetting offset for partition test-topic-0000273-EO6kLrs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.151 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-279-DMHO4yA-93-cbb9ee97-5254-458a-a27f-d15dc521a685', protocol='range'}
13:47:28.151 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Finished assignment for group at generation 1: {consumer-sub-279-DMHO4yA-93-cbb9ee97-5254-458a-a27f-d15dc521a685=Assignment(partitions=[test-topic-0000279-M7JpqrA-0])}
13:47:28.154 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-279-DMHO4yA-93-cbb9ee97-5254-458a-a27f-d15dc521a685', protocol='range'}
13:47:28.154 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Notifying assignor about the new Assignment(partitions=[test-topic-0000279-M7JpqrA-0])
13:47:28.154 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Adding newly assigned partitions: test-topic-0000279-M7JpqrA-0
13:47:28.155 [pool-96-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-276-M_73Af4-92, groupId=sub-276-M_73Af4] Resetting offset for partition test-topic-0000276-6JL1QfE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.155 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-285-smiSWoo-95-bd11f87a-e503-46ea-be59-2e3305bc4cf2', protocol='range'}
13:47:28.155 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Finished assignment for group at generation 1: {consumer-sub-285-smiSWoo-95-bd11f87a-e503-46ea-be59-2e3305bc4cf2=Assignment(partitions=[test-topic-0000285-SwrrYM0-0])}
13:47:28.156 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-282-TogoQgQ-94-e2e92b81-d25b-4370-b3e8-c47c651fd6bd', protocol='range'}
13:47:28.156 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Finished assignment for group at generation 1: {consumer-sub-282-TogoQgQ-94-e2e92b81-d25b-4370-b3e8-c47c651fd6bd=Assignment(partitions=[test-topic-0000282-WxYsVXA-0])}
13:47:28.155 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Found no committed offset for partition test-topic-0000279-M7JpqrA-0
13:47:28.157 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-285-smiSWoo-95-bd11f87a-e503-46ea-be59-2e3305bc4cf2', protocol='range'}
13:47:28.157 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Notifying assignor about the new Assignment(partitions=[test-topic-0000285-SwrrYM0-0])
13:47:28.157 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Adding newly assigned partitions: test-topic-0000285-SwrrYM0-0
13:47:28.159 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-282-TogoQgQ-94-e2e92b81-d25b-4370-b3e8-c47c651fd6bd', protocol='range'}
13:47:28.159 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Found no committed offset for partition test-topic-0000285-SwrrYM0-0
13:47:28.160 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000282-WxYsVXA-0])
13:47:28.160 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Adding newly assigned partitions: test-topic-0000282-WxYsVXA-0
13:47:28.160 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-288-DoWSTjQ-96-b383ccda-9f01-43fd-8e5a-88447d67628c', protocol='range'}
13:47:28.161 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Finished assignment for group at generation 1: {consumer-sub-288-DoWSTjQ-96-b383ccda-9f01-43fd-8e5a-88447d67628c=Assignment(partitions=[test-topic-0000288-AZcX53o-0])}
13:47:28.161 [pool-97-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-279-DMHO4yA-93, groupId=sub-279-DMHO4yA] Resetting offset for partition test-topic-0000279-M7JpqrA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.162 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Found no committed offset for partition test-topic-0000282-WxYsVXA-0
13:47:28.162 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-288-DoWSTjQ-96-b383ccda-9f01-43fd-8e5a-88447d67628c', protocol='range'}
13:47:28.163 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000288-AZcX53o-0])
13:47:28.163 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Adding newly assigned partitions: test-topic-0000288-AZcX53o-0
13:47:28.163 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Found no committed offset for partition test-topic-0000288-AZcX53o-0
13:47:28.163 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-291-el6WLME-97-9d192a98-289e-4792-87f6-5b1320826aa9', protocol='range'}
13:47:28.164 [pool-99-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-285-smiSWoo-95, groupId=sub-285-smiSWoo] Resetting offset for partition test-topic-0000285-SwrrYM0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.164 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Finished assignment for group at generation 1: {consumer-sub-291-el6WLME-97-9d192a98-289e-4792-87f6-5b1320826aa9=Assignment(partitions=[test-topic-0000291-mMcByrM-0])}
13:47:28.166 [pool-98-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-282-TogoQgQ-94, groupId=sub-282-TogoQgQ] Resetting offset for partition test-topic-0000282-WxYsVXA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.166 [pool-100-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-288-DoWSTjQ-96, groupId=sub-288-DoWSTjQ] Resetting offset for partition test-topic-0000288-AZcX53o-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
13:47:28.167 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-294-cJqVTOk-98-16bc701b-0d50-43b5-bb58-867fe423d261', protocol='range'}
13:47:28.167 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Finished assignment for group at generation 1: {consumer-sub-294-cJqVTOk-98-16bc701b-0d50-43b5-bb58-867fe423d261=Assignment(partitions=[test-topic-0000294-ASiqRA4-0])}
13:47:28.168 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-291-el6WLME-97-9d192a98-289e-4792-87f6-5b1320826aa9', protocol='range'}
13:47:28.168 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Notifying assignor about the new Assignment(partitions=[test-topic-0000291-mMcByrM-0])
13:47:28.168 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Adding newly assigned partitions: test-topic-0000291-mMcByrM-0
13:47:28.168 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-297-0dalijI-99-e372742e-da1e-4d1d-b759-eb1e33e33c69', protocol='range'}
13:47:28.169 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Finished assignment for group at generation 1: {consumer-sub-297-0dalijI-99-e372742e-da1e-4d1d-b759-eb1e33e33c69=Assignment(partitions=[test-topic-0000297-6tCb4MU-0])}
13:47:28.169 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Found no committed offset for partition test-topic-0000291-mMcByrM-0
13:47:28.169 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-294-cJqVTOk-98-16bc701b-0d50-43b5-bb58-867fe423d261', protocol='range'}
13:47:28.169 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Notifying assignor about the new Assignment(partitions=[test-topic-0000294-ASiqRA4-0])
13:47:28.169 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Adding newly assigned partitions: test-topic-0000294-ASiqRA4-0
13:47:28.170 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Found no committed offset for partition test-topic-0000294-ASiqRA4-0
13:47:28.170 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-297-0dalijI-99-e372742e-da1e-4d1d-b759-eb1e33e33c69', protocol='range'}
13:47:28.171 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Notifying assignor about the new Assignment(partitions=[test-topic-0000297-6tCb4MU-0])
13:47:28.171 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Adding newly assigned partitions: test-topic-0000297-6tCb4MU-0
13:47:28.170 [pool-101-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-291-el6WLME-97, groupId=sub-291-el6WLME] Resetting offset for partition test-topic-0000291-mMcByrM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.172 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Found no committed offset for partition test-topic-0000297-6tCb4MU-0
13:47:28.172 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-300-2CQVEBk-100-5024f32d-b8ae-466f-8340-00c2b1a32a98', protocol='range'}
13:47:28.172 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Finished assignment for group at generation 1: {consumer-sub-300-2CQVEBk-100-5024f32d-b8ae-466f-8340-00c2b1a32a98=Assignment(partitions=[test-topic-0000300-gX_eTcY-0])}
13:47:28.172 [pool-102-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-294-cJqVTOk-98, groupId=sub-294-cJqVTOk] Resetting offset for partition test-topic-0000294-ASiqRA4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.173 [pool-103-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-297-0dalijI-99, groupId=sub-297-0dalijI] Resetting offset for partition test-topic-0000297-6tCb4MU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.216:9092 (id: 0 rack: null)], epoch=0}}.
13:47:28.174 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-300-2CQVEBk-100-5024f32d-b8ae-466f-8340-00c2b1a32a98', protocol='range'}
13:47:28.174 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Notifying assignor about the new Assignment(partitions=[test-topic-0000300-gX_eTcY-0])
13:47:28.174 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Adding newly assigned partitions: test-topic-0000300-gX_eTcY-0
13:47:28.175 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Found no committed offset for partition test-topic-0000300-gX_eTcY-0
13:47:28.177 [pool-104-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-300-2CQVEBk-100, groupId=sub-300-2CQVEBk] Resetting offset for partition test-topic-0000300-gX_eTcY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.52:9092 (id: 1 rack: null)], epoch=0}}.
13:47:28.179 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-303-YLtD0wE-101-e788eec9-2583-4fff-a6a2-41cd03ee6209', protocol='range'}
13:47:28.179 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Finished assignment for group at generation 1: {consumer-sub-303-YLtD0wE-101-e788eec9-2583-4fff-a6a2-41cd03ee6209=Assignment(partitions=[test-topic-0000303-EgI1jiw-0])}
13:47:28.180 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-303-YLtD0wE-101-e788eec9-2583-4fff-a6a2-41cd03ee6209', protocol='range'}
13:47:28.180 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Notifying assignor about the new Assignment(partitions=[test-topic-0000303-EgI1jiw-0])
13:47:28.180 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Adding newly assigned partitions: test-topic-0000303-EgI1jiw-0
13:47:28.181 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Found no committed offset for partition test-topic-0000303-EgI1jiw-0
13:47:28.183 [pool-105-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-303-YLtD0wE-101, groupId=sub-303-YLtD0wE] Resetting offset for partition test-topic-0000303-EgI1jiw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.229:9092 (id: 2 rack: null)], epoch=0}}.
