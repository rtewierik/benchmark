10:35:06.948 [main] INFO log - Logging initialized @4358ms to org.eclipse.jetty.util.log.Slf4jLog
10:35:07.027 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
10:35:07.057 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@ea27e34{/,null,AVAILABLE}
10:35:07.073 [main] INFO AbstractConnector - Started ServerConnector@1095f122{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
10:35:07.073 [main] INFO Server - Started @4486ms
10:35:07.075 [main] INFO PrometheusMetricsProvider - Started Prometheus stats endpoint at 0.0.0.0:8081
10:35:07.113 [main] INFO BenchmarkWorker - Starting benchmark with config: {
  "httpPort" : 8080,
  "statsPort" : 8081
}
10:35:07.157 [main] INFO Javalin - 
 _________________________________________
|        _                  _ _           |
|       | | __ ___   ____ _| (_)_ __      |
|    _  | |/ _` \ \ / / _` | | | '_ \     |
|   | |_| | (_| |\ V / (_| | | | | | |    |
|    \___/ \__,_| \_/ \__,_|_|_|_| |_|    |
|_________________________________________|
|                                         |
|    https://javalin.io/documentation     |
|_________________________________________|
10:35:07.159 [main] INFO Javalin - Starting Javalin ...
10:35:07.166 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
10:35:07.179 [main] INFO session - DefaultSessionIdManager workerName=node0
10:35:07.179 [main] INFO session - No SessionScavenger set, using defaults
10:35:07.180 [main] INFO session - node0 Scavenging every 660000ms
10:35:07.182 [main] INFO ContextHandler - Started i.j.e.j.@3122b117{/,null,AVAILABLE}
10:35:07.182 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@29a23c3d{/,null,AVAILABLE}
10:35:07.184 [main] INFO AbstractConnector - Started ServerConnector@faa3fed{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
10:35:07.184 [main] INFO Server - Started @4597ms
10:35:07.184 [main] INFO EmbeddedServer - Jetty is listening on: [http://localhost:8080]
10:35:07.184 [main] INFO Javalin - Javalin has started \o/
10:35:07.548 [main] INFO CentralWorkerStats - Central worker stats initialized
10:35:30.025 [main] INFO Benchmark - Using default worker file workers.yaml!
10:35:30.032 [main] INFO Benchmark - Reading workers list from workers.yaml
10:35:30.081 [main] INFO Benchmark - Starting benchmark with config: {
  "drivers" : [ "driver-kafka/kafka-experiment.yaml" ],
  "workers" : [ "http://10.0.0.42:8080", "http://10.0.0.246:8080", "http://10.0.0.175:8080" ],
  "workersFile" : "/opt/benchmark/workers.yaml",
  "tpcHFiles" : [ "workloads/tpc-h-q6-10000-500.yaml", "workloads/tpc-h-q1-10000-800.yaml", "workloads/tpc-h-q6-10000-800.yaml" ],
  "workloads" : [ "workloads/tpc-h-base-long.yaml" ],
  "output" : null
}
10:35:30.096 [main] INFO Benchmark - Workloads: {
  "tpc-h-base-long" : {
    "name" : "tpc-h",
    "topics" : 0,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 0,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 10000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 10,
    "warmupDurationMinutes" : 1
  }
}
10:35:30.108 [main] INFO Benchmark - TPC-H arguments: [ {
  "queryId" : "tpc-h-q6-10000-500",
  "query" : "ForecastingRevenueChange",
  "sourceDataS3FolderUri" : "s3://tpc-h-chunks/chunks-by-file-size/7kb",
  "numberOfChunks" : 10000,
  "numberOfWorkers" : 500
}, {
  "queryId" : "tpc-h-q1-10000-800",
  "query" : "PricingSummaryReport",
  "sourceDataS3FolderUri" : "s3://tpc-h-chunks/chunks-by-file-size/7kb",
  "numberOfChunks" : 10000,
  "numberOfWorkers" : 800
}, {
  "queryId" : "tpc-h-q6-10000-800",
  "query" : "ForecastingRevenueChange",
  "sourceDataS3FolderUri" : "s3://tpc-h-chunks/chunks-by-file-size/7kb",
  "numberOfChunks" : 10000,
  "numberOfWorkers" : 800
} ]
10:35:30.446 [main] INFO CentralWorkerStats - Central worker stats initialized
10:35:30.699 [main] INFO DistributedWorkersEnsemble - Workers list - producers: [http://10.0.0.42:8080,http://10.0.0.246:8080,http://10.0.0.175:8080]
10:35:30.700 [main] INFO DistributedWorkersEnsemble - Workers list - consumers: http://10.0.0.42:8080,http://10.0.0.246:8080,http://10.0.0.175:8080
10:35:30.702 [main] INFO Benchmark - --------------- WORKLOAD : tpc-h --- DRIVER : Kafka---------------
10:35:31.107 [qtp235162442-24] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
10:35:31.140 [qtp235162442-24] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

10:35:31.198 [qtp235162442-24] INFO AppInfoParser - Kafka version: 3.6.1
10:35:31.198 [qtp235162442-24] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:31.198 [qtp235162442-24] INFO AppInfoParser - Kafka startTimeMs: 1716806131196
10:35:31.202 [main] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
10:35:31.225 [main] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

10:35:31.279 [main] INFO AppInfoParser - Kafka version: 3.6.1
10:35:31.279 [main] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:31.279 [main] INFO AppInfoParser - Kafka startTimeMs: 1716806131277
10:35:31.290 [qtp235162442-29] INFO WorkerHandler - Received create topics request for topics: {
  "numberOfTopics" : 507,
  "numberOfPartitionsPerTopic" : 1
}
10:35:34.954 [qtp235162442-29] INFO LocalWorker - Created 507 topics in 3663.164664 ms
10:35:34.967 [main] INFO WorkloadGenerator - Created 507 topics in 3683.22794 ms
10:35:35.010 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-000-veGIiUw-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-000-veGIiUw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.049 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.049 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.049 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135049
10:35:35.050 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Subscribed to topic(s): test-topic-0000000-V_-J4Ns
10:35:35.053 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-001-Sc_ClX8-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-001-Sc_ClX8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.059 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.060 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.060 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135059
10:35:35.060 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Subscribed to topic(s): test-topic-0000001-_L2etTM
10:35:35.061 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-002--gDe5LI-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-002--gDe5LI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.067 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.067 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.067 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135067
10:35:35.067 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Subscribed to topic(s): test-topic-0000002-mWviUz4
10:35:35.068 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-003-nQrvCqU-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-003-nQrvCqU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.069 [pool-3-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.073 [pool-5-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.074 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.075 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.075 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135074
10:35:35.075 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Subscribed to topic(s): test-topic-0000003-uwAasiE
10:35:35.076 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-004-9YDQMtE-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-004-9YDQMtE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.077 [pool-4-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.080 [pool-6-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.082 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.082 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.082 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135082
10:35:35.082 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Subscribed to topic(s): test-topic-0000004-_jh6Paw
10:35:35.083 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-005-O3eWxIY-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-005-O3eWxIY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.088 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.088 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.089 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135088
10:35:35.089 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Subscribed to topic(s): test-topic-0000005-zLcoUuQ
10:35:35.090 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-007-kSb0jfw-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-007-kSb0jfw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.092 [pool-7-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.093 [pool-8-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.095 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.095 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.095 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135095
10:35:35.095 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Subscribed to topic(s): test-topic-0000007-hcTxvVI
10:35:35.096 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-010-qhXZymU-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-010-qhXZymU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.100 [pool-9-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.101 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.101 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.101 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135101
10:35:35.102 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Subscribed to topic(s): test-topic-0000010-U6HXPng
10:35:35.103 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-013-8FJsfOU-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-013-8FJsfOU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.106 [pool-10-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.107 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.107 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.107 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135107
10:35:35.108 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Subscribed to topic(s): test-topic-0000013-upYB7Dk
10:35:35.108 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-016-xxzskEg-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-016-xxzskEg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.112 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.112 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.112 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135112
10:35:35.112 [pool-11-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.112 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Subscribed to topic(s): test-topic-0000016-MLlCoec
10:35:35.113 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-019-MASUH9w-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-019-MASUH9w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.116 [pool-12-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.116 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.117 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.117 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135116
10:35:35.117 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Subscribed to topic(s): test-topic-0000019-aCPUnu8
10:35:35.118 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-022-oQkyCnM-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-022-oQkyCnM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.120 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.121 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.121 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135120
10:35:35.121 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Subscribed to topic(s): test-topic-0000022-adVjIaQ
10:35:35.121 [pool-13-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.121 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-025-5EVGGWg-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-025-5EVGGWg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.125 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.125 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.125 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135125
10:35:35.125 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Subscribed to topic(s): test-topic-0000025-IRIRha0
10:35:35.126 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-028-ICc1E4A-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-028-ICc1E4A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.127 [pool-14-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.129 [pool-15-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.130 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.130 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.130 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135130
10:35:35.130 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Subscribed to topic(s): test-topic-0000028-Uo_eHQg
10:35:35.131 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-031-jsgw8Lw-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-031-jsgw8Lw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.134 [pool-16-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.135 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.135 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.135 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135135
10:35:35.135 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Subscribed to topic(s): test-topic-0000031-_-x9Y-Y
10:35:35.136 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-034-jXfQV4M-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-034-jXfQV4M
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.139 [pool-17-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.149 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.149 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.149 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135149
10:35:35.149 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Subscribed to topic(s): test-topic-0000034-mQDs78Y
10:35:35.150 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-037-EKNVMKY-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-037-EKNVMKY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.152 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.152 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.152 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135152
10:35:35.153 [pool-18-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.153 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Subscribed to topic(s): test-topic-0000037-nN3KNZc
10:35:35.154 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-040-nUpe8ic-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-040-nUpe8ic
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.156 [pool-19-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.156 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.156 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.157 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135156
10:35:35.157 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Subscribed to topic(s): test-topic-0000040-ZPiiadY
10:35:35.158 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-043-VRipANU-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-043-VRipANU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.161 [pool-20-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.162 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.162 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.162 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135162
10:35:35.163 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Subscribed to topic(s): test-topic-0000043-UplvRtE
10:35:35.164 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-046-vrUsMA0-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-046-vrUsMA0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.166 [pool-21-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.167 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.167 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.167 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135167
10:35:35.168 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Subscribed to topic(s): test-topic-0000046-q-UQa6M
10:35:35.172 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-049-QC2A1E8-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-049-QC2A1E8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.175 [pool-22-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.176 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.176 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.176 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135176
10:35:35.176 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Subscribed to topic(s): test-topic-0000049-sFgFDYQ
10:35:35.178 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-052-oVomvmI-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-052-oVomvmI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.181 [pool-23-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.182 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.182 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.182 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135182
10:35:35.182 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Subscribed to topic(s): test-topic-0000052-2HKJDng
10:35:35.183 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-055-1horpzI-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-055-1horpzI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.190 [pool-24-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.190 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.190 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.190 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135190
10:35:35.190 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Subscribed to topic(s): test-topic-0000055-PfazGY4
10:35:35.191 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-058-CCgSZb8-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-058-CCgSZb8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.194 [pool-25-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.195 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.195 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.195 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135195
10:35:35.196 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Subscribed to topic(s): test-topic-0000058-nA5y_Cg
10:35:35.197 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-061-p-joeqs-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-061-p-joeqs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.199 [pool-26-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.200 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.200 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.201 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135200
10:35:35.201 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Subscribed to topic(s): test-topic-0000061-cZAtpwQ
10:35:35.202 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-064-0QANq0Y-26
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-064-0QANq0Y
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.204 [pool-27-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.206 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.206 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.206 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135206
10:35:35.206 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Subscribed to topic(s): test-topic-0000064-Fd6J5P4
10:35:35.207 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-067-gruf-jQ-27
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-067-gruf-jQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.211 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.211 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.212 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135211
10:35:35.212 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Subscribed to topic(s): test-topic-0000067-8UqVjsA
10:35:35.215 [pool-28-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.221 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-070-RHUsvvo-28
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-070-RHUsvvo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.225 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.225 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.225 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135225
10:35:35.225 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Subscribed to topic(s): test-topic-0000070-HtSFP-Q
10:35:35.227 [pool-29-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.228 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-073-WaSvAxI-29
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-073-WaSvAxI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.231 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.231 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.231 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135231
10:35:35.232 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Subscribed to topic(s): test-topic-0000073-CgvL2Cw
10:35:35.233 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-076-mvrRvF8-30
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-076-mvrRvF8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.243 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.243 [pool-31-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.243 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.243 [pool-30-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.243 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135243
10:35:35.244 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Subscribed to topic(s): test-topic-0000076-9ukLbdc
10:35:35.245 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-079-cvsLMw4-31
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-079-cvsLMw4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.248 [pool-32-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.249 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.250 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.250 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135249
10:35:35.250 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Subscribed to topic(s): test-topic-0000079-cEsvck0
10:35:35.251 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-082-zkxa8VI-32
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-082-zkxa8VI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.254 [pool-33-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.254 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.254 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.254 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135254
10:35:35.255 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Subscribed to topic(s): test-topic-0000082-FLXnEIs
10:35:35.256 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-085-0JPJEnM-33
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-085-0JPJEnM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.259 [pool-34-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.261 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.261 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.261 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135261
10:35:35.261 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Subscribed to topic(s): test-topic-0000085-N2NHIBM
10:35:35.263 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-088-qObEwis-34
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-088-qObEwis
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.266 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.266 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.267 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135266
10:35:35.267 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Subscribed to topic(s): test-topic-0000088-Stb9i1o
10:35:35.268 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-091-4lK-O0k-35
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-091-4lK-O0k
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.271 [pool-36-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.272 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.272 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.272 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135272
10:35:35.272 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Subscribed to topic(s): test-topic-0000091-E9z7puA
10:35:35.273 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.275 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-094-BrzruBE-36
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-094-BrzruBE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.275 [pool-35-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.276 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.277 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.278 [pool-37-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.279 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.280 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.280 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.280 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.280 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135279
10:35:35.280 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Subscribed to topic(s): test-topic-0000094-Gf5KW3M
10:35:35.281 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] (Re-)joining group
10:35:35.281 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] (Re-)joining group
10:35:35.281 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.282 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] (Re-)joining group
10:35:35.282 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-097-avjoPdA-37
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-097-avjoPdA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.286 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] (Re-)joining group
10:35:35.286 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.285 [pool-38-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.288 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.290 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.287 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] (Re-)joining group
10:35:35.290 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.290 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.291 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.291 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.291 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135291
10:35:35.291 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Subscribed to topic(s): test-topic-0000097-zLO3jFY
10:35:35.295 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.298 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.299 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.301 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] (Re-)joining group
10:35:35.304 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.304 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] (Re-)joining group
10:35:35.304 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.306 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] (Re-)joining group
10:35:35.307 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] (Re-)joining group
10:35:35.307 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Request joining group due to: need to re-join with the given member-id: consumer-sub-003-nQrvCqU-4-7d3ed392-4827-466f-b22a-a7e27fc26b82
10:35:35.308 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.308 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] (Re-)joining group
10:35:35.309 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Request joining group due to: need to re-join with the given member-id: consumer-sub-049-QC2A1E8-21-c4c234fb-12c4-496e-a180-eb5841f277de
10:35:35.309 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.309 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] (Re-)joining group
10:35:35.309 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] (Re-)joining group
10:35:35.310 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Request joining group due to: need to re-join with the given member-id: consumer-sub-002--gDe5LI-3-42165364-8a79-4795-9dd3-bb0dcc960d7f
10:35:35.310 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.310 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] (Re-)joining group
10:35:35.310 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.311 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] (Re-)joining group
10:35:35.311 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Request joining group due to: need to re-join with the given member-id: consumer-sub-055-1horpzI-23-c87a0144-a022-4fa2-81cd-73a1486ed25c
10:35:35.312 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.312 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] (Re-)joining group
10:35:35.313 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Request joining group due to: need to re-join with the given member-id: consumer-sub-043-VRipANU-19-ff028afa-f38c-4a1a-86c7-082ab365bf54
10:35:35.313 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.313 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] (Re-)joining group
10:35:35.313 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-100-bqIr850-38
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-100-bqIr850
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.313 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Request joining group due to: need to re-join with the given member-id: consumer-sub-013-8FJsfOU-9-2a447fb9-1de0-432c-a0b1-fb86dc5fd606
10:35:35.314 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.314 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] (Re-)joining group
10:35:35.315 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Request joining group due to: need to re-join with the given member-id: consumer-sub-058-CCgSZb8-24-aaab71c1-a76d-4e83-bf3f-03d8b0da3e1a
10:35:35.315 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.315 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.315 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] (Re-)joining group
10:35:35.315 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Request joining group due to: need to re-join with the given member-id: consumer-sub-091-4lK-O0k-35-dfe34f62-ae89-4513-97b7-16c5c0bc7526
10:35:35.315 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Request joining group due to: need to re-join with the given member-id: consumer-sub-004-9YDQMtE-5-70fc8c8e-d3f6-4a37-9178-35555d22a998
10:35:35.316 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] (Re-)joining group
10:35:35.316 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.316 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.316 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] (Re-)joining group
10:35:35.316 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] (Re-)joining group
10:35:35.316 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Request joining group due to: need to re-join with the given member-id: consumer-sub-046-vrUsMA0-20-a4df3078-fd6c-46fa-8666-2037a4c8c207
10:35:35.316 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.317 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] (Re-)joining group
10:35:35.318 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.319 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.319 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Request joining group due to: need to re-join with the given member-id: consumer-sub-094-BrzruBE-36-b1603e9f-7b58-473e-910d-c6150a40603c
10:35:35.319 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.319 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.319 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.319 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] (Re-)joining group
10:35:35.319 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135319
10:35:35.320 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Subscribed to topic(s): test-topic-0000100-U4JejkA
10:35:35.320 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Request joining group due to: need to re-join with the given member-id: consumer-sub-007-kSb0jfw-7-e169bd5f-d90e-4fbc-ae9d-c2aefe365c2c
10:35:35.320 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] (Re-)joining group
10:35:35.320 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.320 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] (Re-)joining group
10:35:35.321 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] (Re-)joining group
10:35:35.322 [pool-39-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.322 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] (Re-)joining group
10:35:35.323 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.323 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Request joining group due to: need to re-join with the given member-id: consumer-sub-052-oVomvmI-22-2d67d8a2-7ed2-48a1-9a6d-1e834e33bf94
10:35:35.323 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.323 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] (Re-)joining group
10:35:35.324 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-103-ryJeykA-39
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-103-ryJeykA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.324 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] (Re-)joining group
10:35:35.325 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Request joining group due to: need to re-join with the given member-id: consumer-sub-005-O3eWxIY-6-ec23536a-0ba0-4b4a-868e-cb46ba0ae817
10:35:35.325 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Request joining group due to: need to re-join with the given member-id: consumer-sub-001-Sc_ClX8-2-1690bdac-c0fe-4257-aa15-68c897f71ce8
10:35:35.325 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.325 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.325 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] (Re-)joining group
10:35:35.325 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] (Re-)joining group
10:35:35.326 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.326 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.327 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Request joining group due to: need to re-join with the given member-id: consumer-sub-019-MASUH9w-11-e29cce5b-9813-4572-b85f-09dd9512b480
10:35:35.327 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.327 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] (Re-)joining group
10:35:35.328 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.328 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.329 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.329 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135328
10:35:35.329 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Subscribed to topic(s): test-topic-0000103-BaW4fGY
10:35:35.330 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] (Re-)joining group
10:35:35.330 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] (Re-)joining group
10:35:35.331 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] (Re-)joining group
10:35:35.331 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.332 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] (Re-)joining group
10:35:35.332 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] (Re-)joining group
10:35:35.333 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Request joining group due to: need to re-join with the given member-id: consumer-sub-064-0QANq0Y-26-1974649a-f45b-4841-a274-2bbbd3eb0b8e
10:35:35.333 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.333 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] (Re-)joining group
10:35:35.333 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Request joining group due to: need to re-join with the given member-id: consumer-sub-010-qhXZymU-8-b504aef7-4334-4c00-b48d-458960123435
10:35:35.334 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.334 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Request joining group due to: need to re-join with the given member-id: consumer-sub-016-xxzskEg-10-771919ca-f496-4aab-8936-7764ec805179
10:35:35.334 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] (Re-)joining group
10:35:35.334 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.334 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] (Re-)joining group
10:35:35.335 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-106-0hMyMrI-40
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-106-0hMyMrI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.335 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.336 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.336 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.336 [pool-40-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.337 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.338 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Request joining group due to: need to re-join with the given member-id: consumer-sub-028-ICc1E4A-14-9814b9d3-66ec-4df1-9d6b-8a0f266ed722
10:35:35.338 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.339 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] (Re-)joining group
10:35:35.339 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.339 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.339 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135339
10:35:35.339 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Request joining group due to: need to re-join with the given member-id: consumer-sub-061-p-joeqs-25-377bf9ad-cad9-4127-b7f1-c0cdc495f72b
10:35:35.339 [pool-41-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.339 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Subscribed to topic(s): test-topic-0000106--MB_6Bg
10:35:35.339 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] (Re-)joining group
10:35:35.340 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.341 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] (Re-)joining group
10:35:35.339 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.341 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] (Re-)joining group
10:35:35.342 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] (Re-)joining group
10:35:35.343 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Request joining group due to: need to re-join with the given member-id: consumer-sub-025-5EVGGWg-13-29821947-204b-400c-981d-9b6e7e9e1054
10:35:35.343 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.343 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] (Re-)joining group
10:35:35.343 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] (Re-)joining group
10:35:35.344 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-067-gruf-jQ-27-408b849a-70a6-4c09-9ca0-50bbe99ee7af
10:35:35.344 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.344 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] (Re-)joining group
10:35:35.345 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Request joining group due to: need to re-join with the given member-id: consumer-sub-022-oQkyCnM-12-d0e2d9fc-bf3a-4a86-bf18-400386646d89
10:35:35.345 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.345 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] (Re-)joining group
10:35:35.346 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Request joining group due to: need to re-join with the given member-id: consumer-sub-097-avjoPdA-37-9c6f2478-0ddc-4729-95b6-412367cb7696
10:35:35.346 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.346 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] (Re-)joining group
10:35:35.347 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] (Re-)joining group
10:35:35.348 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.348 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] (Re-)joining group
10:35:35.348 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-109-59qp1r8-41
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-109-59qp1r8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.349 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] (Re-)joining group
10:35:35.351 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Request joining group due to: need to re-join with the given member-id: consumer-sub-100-bqIr850-38-d2ac2605-6465-47ca-a740-95c2cff5ae03
10:35:35.351 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.351 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] (Re-)joining group
10:35:35.352 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.352 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Request joining group due to: need to re-join with the given member-id: consumer-sub-103-ryJeykA-39-1abeb6d5-4e08-47fb-a575-83a4d6fd81f2
10:35:35.352 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.353 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] (Re-)joining group
10:35:35.352 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] (Re-)joining group
10:35:35.353 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.354 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.354 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135353
10:35:35.354 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.355 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Subscribed to topic(s): test-topic-0000109-LtOlXJY
10:35:35.355 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.355 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Request joining group due to: need to re-join with the given member-id: consumer-sub-031-jsgw8Lw-15-5d732958-b733-4a42-a1bc-2c6e0c621837
10:35:35.356 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.356 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] (Re-)joining group
10:35:35.356 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] (Re-)joining group
10:35:35.356 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] (Re-)joining group
10:35:35.356 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Request joining group due to: need to re-join with the given member-id: consumer-sub-073-WaSvAxI-29-67c8a4c4-1790-4179-ba5a-3b45492ff1e6
10:35:35.357 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.357 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-112-ozdFI5w-42
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-112-ozdFI5w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.358 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.359 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Request joining group due to: need to re-join with the given member-id: consumer-sub-070-RHUsvvo-28-803d1002-d6da-408a-b0f1-eb69ca10a790
10:35:35.359 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.359 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.359 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] (Re-)joining group
10:35:35.359 [pool-42-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.359 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.361 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.361 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.361 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135361
10:35:35.361 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Subscribed to topic(s): test-topic-0000112-SsxIWSY
10:35:35.357 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] (Re-)joining group
10:35:35.363 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.364 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] (Re-)joining group
10:35:35.364 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] (Re-)joining group
10:35:35.365 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.365 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Request joining group due to: need to re-join with the given member-id: consumer-sub-037-EKNVMKY-17-1cf48839-5ba4-4a98-814f-3a0fa82abaa9
10:35:35.366 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.366 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] (Re-)joining group
10:35:35.366 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] (Re-)joining group
10:35:35.365 [pool-43-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.366 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.367 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Request joining group due to: need to re-join with the given member-id: consumer-sub-079-cvsLMw4-31-97e621d8-f74d-405e-bc1e-c46496a03899
10:35:35.367 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] (Re-)joining group
10:35:35.367 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Request joining group due to: need to re-join with the given member-id: consumer-sub-034-jXfQV4M-16-f9361b3e-95cb-432c-80f4-ae8927c8984b
10:35:35.368 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.368 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] (Re-)joining group
10:35:35.369 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Request joining group due to: need to re-join with the given member-id: consumer-sub-076-mvrRvF8-30-2f44c3d6-b3a4-455a-9619-2c00eb87bd77
10:35:35.369 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.369 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] (Re-)joining group
10:35:35.369 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-115-3zUz_KI-43
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-115-3zUz_KI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.370 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Request joining group due to: need to re-join with the given member-id: consumer-sub-040-nUpe8ic-18-fdc8093f-54b8-4d61-9ea0-83a5a51684a4
10:35:35.370 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.370 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] (Re-)joining group
10:35:35.373 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.373 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.374 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135373
10:35:35.374 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Subscribed to topic(s): test-topic-0000115-x3VDmZM
10:35:35.367 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] (Re-)joining group
10:35:35.375 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] (Re-)joining group
10:35:35.375 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.375 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] (Re-)joining group
10:35:35.376 [pool-44-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.377 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.377 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.377 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Request joining group due to: need to re-join with the given member-id: consumer-sub-085-0JPJEnM-33-123c5a31-f57a-4b89-95cb-a2043ebeb525
10:35:35.377 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Request joining group due to: need to re-join with the given member-id: consumer-sub-106-0hMyMrI-40-d79b6ea2-04ab-452d-a68f-de5f05168619
10:35:35.378 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.378 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] (Re-)joining group
10:35:35.378 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.378 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] (Re-)joining group
10:35:35.380 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] (Re-)joining group
10:35:35.380 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] (Re-)joining group
10:35:35.382 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] (Re-)joining group
10:35:35.382 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Request joining group due to: need to re-join with the given member-id: consumer-sub-000-veGIiUw-1-a42b0377-140f-458e-a983-e4386a3c47bb
10:35:35.383 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] (Re-)joining group
10:35:35.383 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.383 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] (Re-)joining group
10:35:35.383 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Request joining group due to: need to re-join with the given member-id: consumer-sub-082-zkxa8VI-32-49836d06-72e4-416f-8745-05a4829e645b
10:35:35.382 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] (Re-)joining group
10:35:35.383 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.383 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] (Re-)joining group
10:35:35.384 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Request joining group due to: need to re-join with the given member-id: consumer-sub-088-qObEwis-34-19161730-c580-45bc-89e0-84cd02c6e32e
10:35:35.384 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.384 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] (Re-)joining group
10:35:35.385 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-118-GV4H62g-44
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-118-GV4H62g
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.385 [pool-45-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.386 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.386 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Request joining group due to: need to re-join with the given member-id: consumer-sub-109-59qp1r8-41-a131679f-f513-46c0-adc7-0d364539ede7
10:35:35.386 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] (Re-)joining group
10:35:35.387 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.387 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] (Re-)joining group
10:35:35.388 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Request joining group due to: need to re-join with the given member-id: consumer-sub-112-ozdFI5w-42-9324967c-3da7-438c-ab9f-213aa34bde93
10:35:35.388 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.388 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] (Re-)joining group
10:35:35.389 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.389 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.389 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135389
10:35:35.389 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Subscribed to topic(s): test-topic-0000118-Mhw4hJk
10:35:35.391 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-121-7dR5cuk-45
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-121-7dR5cuk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.392 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Request joining group due to: need to re-join with the given member-id: consumer-sub-115-3zUz_KI-43-d9d2ab4c-33b5-4725-a77a-926ee2b1127f
10:35:35.392 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.392 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] (Re-)joining group
10:35:35.395 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.395 [pool-46-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.395 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.395 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135395
10:35:35.395 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.395 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Subscribed to topic(s): test-topic-0000121-114XZfc
10:35:35.396 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] (Re-)joining group
10:35:35.396 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-124-wVmvIYQ-46
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-124-wVmvIYQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.398 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Request joining group due to: need to re-join with the given member-id: consumer-sub-118-GV4H62g-44-8a4fcc86-ee12-4d15-b4a3-518495d57fe7
10:35:35.399 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.399 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] (Re-)joining group
10:35:35.400 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.400 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.400 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135400
10:35:35.400 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Subscribed to topic(s): test-topic-0000124-2EDO_w4
10:35:35.401 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-127-GFM7wfU-47
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-127-GFM7wfU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.403 [pool-48-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.404 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.405 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.405 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.405 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135405
10:35:35.406 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Subscribed to topic(s): test-topic-0000127-rXhL7lw
10:35:35.406 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] (Re-)joining group
10:35:35.407 [pool-47-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.407 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.408 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-130-R2MzGZc-48
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-130-R2MzGZc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.408 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-124-wVmvIYQ-46-3c5b5c23-01e1-4576-b3ad-c497d5cc5d52
10:35:35.408 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.409 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] (Re-)joining group
10:35:35.411 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] (Re-)joining group
10:35:35.412 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.412 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.412 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135412
10:35:35.412 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Subscribed to topic(s): test-topic-0000130-fdJ7vTs
10:35:35.413 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-133-herww4w-49
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-133-herww4w
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.414 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Request joining group due to: need to re-join with the given member-id: consumer-sub-121-7dR5cuk-45-a724d78a-3de0-4f47-9f2d-d3d011bbeef8
10:35:35.414 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.414 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] (Re-)joining group
10:35:35.416 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.416 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.416 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135416
10:35:35.416 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Subscribed to topic(s): test-topic-0000133-1ZZQVqE
10:35:35.417 [pool-49-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.417 [pool-50-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.417 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.417 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.420 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] (Re-)joining group
10:35:35.423 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Request joining group due to: need to re-join with the given member-id: consumer-sub-127-GFM7wfU-47-05427824-0a24-4d14-b7b9-a9f38be81146
10:35:35.420 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-136-hnM0maI-50
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-136-hnM0maI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.422 [pool-51-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.424 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.424 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] (Re-)joining group
10:35:35.424 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.427 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.428 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.428 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135427
10:35:35.428 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Subscribed to topic(s): test-topic-0000136-nBov2d0
10:35:35.429 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] (Re-)joining group
10:35:35.429 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-139-Jd7jOg8-51
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-139-Jd7jOg8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.431 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] (Re-)joining group
10:35:35.432 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Request joining group due to: need to re-join with the given member-id: consumer-sub-130-R2MzGZc-48-8688cfce-1470-4429-96fe-1df55f9e79f4
10:35:35.432 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.432 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] (Re-)joining group
10:35:35.433 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Request joining group due to: need to re-join with the given member-id: consumer-sub-133-herww4w-49-fa71df6c-21e2-48c5-b8d8-1e448dee0290
10:35:35.433 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.433 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] (Re-)joining group
10:35:35.434 [pool-52-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.434 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.434 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.434 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.434 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135434
10:35:35.434 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] (Re-)joining group
10:35:35.434 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Subscribed to topic(s): test-topic-0000139-XTb1OHw
10:35:35.435 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-142-zj_UYlg-52
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-142-zj_UYlg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.437 [pool-53-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.438 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.438 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] (Re-)joining group
10:35:35.439 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.439 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.439 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135439
10:35:35.439 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Subscribed to topic(s): test-topic-0000142-QTL4iuM
10:35:35.440 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-145-nXOR4_o-53
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-145-nXOR4_o
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.442 [pool-54-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.442 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.443 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.443 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.444 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135443
10:35:35.444 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Subscribed to topic(s): test-topic-0000145-SgkRMUE
10:35:35.446 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Request joining group due to: need to re-join with the given member-id: consumer-sub-136-hnM0maI-50-8a67a670-0f38-4a67-87d9-3c148cb3c057
10:35:35.447 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.447 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] (Re-)joining group
10:35:35.450 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Request joining group due to: need to re-join with the given member-id: consumer-sub-139-Jd7jOg8-51-4f50d45d-3f54-420c-967b-35c7e9b87972
10:35:35.450 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.450 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] (Re-)joining group
10:35:35.453 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] (Re-)joining group
10:35:35.455 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Request joining group due to: need to re-join with the given member-id: consumer-sub-142-zj_UYlg-52-cf1bd90e-0ffb-4a3f-9634-f06e2de032db
10:35:35.455 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.455 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] (Re-)joining group
10:35:35.457 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-148-dURIGro-54
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-148-dURIGro
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.459 [pool-55-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.459 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.460 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.460 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.460 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135460
10:35:35.460 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Subscribed to topic(s): test-topic-0000148-qpE9hNw
10:35:35.462 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] (Re-)joining group
10:35:35.463 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-151-dol9qp0-55
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-151-dol9qp0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.464 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Request joining group due to: need to re-join with the given member-id: consumer-sub-145-nXOR4_o-53-f1d9e39f-db20-4d96-9716-a869c277d388
10:35:35.464 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.464 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] (Re-)joining group
10:35:35.466 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.467 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.467 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135466
10:35:35.467 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Subscribed to topic(s): test-topic-0000151-VWnPQfI
10:35:35.467 [pool-56-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.467 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.470 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-154-oYkwY_c-56
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-154-oYkwY_c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.473 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.473 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.473 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135473
10:35:35.473 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Subscribed to topic(s): test-topic-0000154-HE2aBZ8
10:35:35.475 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] (Re-)joining group
10:35:35.476 [pool-57-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.476 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.476 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-157-hxUlyBo-57
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-157-hxUlyBo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.479 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Request joining group due to: need to re-join with the given member-id: consumer-sub-148-dURIGro-54-2da45e9c-a8de-402c-a997-c9c62788ff0c
10:35:35.480 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.480 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.480 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135480
10:35:35.480 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Subscribed to topic(s): test-topic-0000157-6w1ItIc
10:35:35.482 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] (Re-)joining group
10:35:35.482 [pool-58-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.482 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.484 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Request joining group due to: need to re-join with the given member-id: consumer-sub-151-dol9qp0-55-823de585-bc89-4c6a-9e45-9f2485a7cd19
10:35:35.484 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.484 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] (Re-)joining group
10:35:35.490 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] (Re-)joining group
10:35:35.490 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-160-VA65eYM-58
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-160-VA65eYM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.492 [pool-59-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.479 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.493 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Request joining group due to: need to re-join with the given member-id: consumer-sub-154-oYkwY_c-56-a5f71378-203c-41b8-afc3-928265aefb57
10:35:35.493 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.493 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.493 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] (Re-)joining group
10:35:35.495 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] (Re-)joining group
10:35:35.497 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Request joining group due to: need to re-join with the given member-id: consumer-sub-157-hxUlyBo-57-16cbca88-9fe9-41a0-bc1f-73cfda0ac225
10:35:35.497 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.497 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.497 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.497 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] (Re-)joining group
10:35:35.493 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] (Re-)joining group
10:35:35.497 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135497
10:35:35.503 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Subscribed to topic(s): test-topic-0000160-B3v6Dzk
10:35:35.504 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-163-nxfAmZ8-59
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-163-nxfAmZ8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.511 [pool-60-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.512 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.512 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.512 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.512 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135512
10:35:35.512 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Subscribed to topic(s): test-topic-0000163-ZKG2hH8
10:35:35.513 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] (Re-)joining group
10:35:35.513 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-166-uAWZs3Y-60
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-166-uAWZs3Y
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.516 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.516 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.516 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135516
10:35:35.516 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Subscribed to topic(s): test-topic-0000166-Xn8hVBw
10:35:35.519 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Request joining group due to: need to re-join with the given member-id: consumer-sub-160-VA65eYM-58-2e206900-33a9-42ce-a449-5176ea44827a
10:35:35.519 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.519 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] (Re-)joining group
10:35:35.522 [pool-61-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.522 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.523 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-169-dswsaeQ-61
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-169-dswsaeQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.523 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] (Re-)joining group
10:35:35.524 [pool-62-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.525 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.525 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] (Re-)joining group
10:35:35.525 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Request joining group due to: need to re-join with the given member-id: consumer-sub-163-nxfAmZ8-59-aceece95-3d0c-44db-a0eb-817a68e8dad5
10:35:35.526 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.526 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] (Re-)joining group
10:35:35.527 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.527 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.527 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135526
10:35:35.527 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Subscribed to topic(s): test-topic-0000169-ghF_OKc
10:35:35.527 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Request joining group due to: need to re-join with the given member-id: consumer-sub-166-uAWZs3Y-60-83ffa56a-7cbd-4f4c-8aa8-b879a1097287
10:35:35.527 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.527 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] (Re-)joining group
10:35:35.530 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-172-rVJbmyc-62
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-172-rVJbmyc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.533 [pool-63-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.533 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.533 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.533 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.533 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135533
10:35:35.534 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Subscribed to topic(s): test-topic-0000172-MDi5xIU
10:35:35.537 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] (Re-)joining group
10:35:35.537 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-175-1iz0jec-63
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-175-1iz0jec
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.540 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.541 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.541 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135540
10:35:35.541 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Subscribed to topic(s): test-topic-0000175-LbeFESo
10:35:35.542 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-178-ke0_tAk-64
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-178-ke0_tAk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.545 [pool-65-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.545 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.545 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.545 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135545
10:35:35.545 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.545 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Subscribed to topic(s): test-topic-0000178-i0eYwS4
10:35:35.546 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] (Re-)joining group
10:35:35.547 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-169-dswsaeQ-61-1b2d1a2c-986b-4fbf-9794-af81eeb13a9d
10:35:35.547 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.547 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] (Re-)joining group
10:35:35.548 [pool-64-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.548 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.548 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Request joining group due to: need to re-join with the given member-id: consumer-sub-175-1iz0jec-63-54160100-12b3-4a89-b60b-4cb48e0730bc
10:35:35.549 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.549 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] (Re-)joining group
10:35:35.549 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-181-BgUa2Oc-65
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-181-BgUa2Oc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.549 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] (Re-)joining group
10:35:35.551 [pool-66-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.551 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.551 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Request joining group due to: need to re-join with the given member-id: consumer-sub-172-rVJbmyc-62-fb6a65f9-9ba0-45d4-b53d-bc96c51fde2a
10:35:35.551 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.551 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] (Re-)joining group
10:35:35.552 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.552 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.552 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135552
10:35:35.553 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Subscribed to topic(s): test-topic-0000181-brF3U9o
10:35:35.553 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] (Re-)joining group
10:35:35.553 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-184-UCC2_8Y-66
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-184-UCC2_8Y
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.555 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Request joining group due to: need to re-join with the given member-id: consumer-sub-178-ke0_tAk-64-6e505a05-f5d4-4882-97cf-a79cde20bdf7
10:35:35.556 [pool-67-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.556 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.556 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.556 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] (Re-)joining group
10:35:35.558 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] (Re-)joining group
10:35:35.559 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.559 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.559 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135559
10:35:35.559 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Subscribed to topic(s): test-topic-0000184-k_ZYxDY
10:35:35.560 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Request joining group due to: need to re-join with the given member-id: consumer-sub-181-BgUa2Oc-65-95ab5b8e-487d-413e-be6c-32cd7a2f010d
10:35:35.560 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-187-dzCZ1J8-67
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-187-dzCZ1J8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.560 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.560 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] (Re-)joining group
10:35:35.562 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.562 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.562 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135562
10:35:35.563 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Subscribed to topic(s): test-topic-0000187-qg-xV74
10:35:35.564 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-190-rMQrnZo-68
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-190-rMQrnZo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.565 [pool-69-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.566 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.569 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.569 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.569 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135569
10:35:35.569 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Subscribed to topic(s): test-topic-0000190-3m3hz00
10:35:35.571 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] (Re-)joining group
10:35:35.571 [pool-68-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.571 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.572 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-193-s8VGh8U-69
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-193-s8VGh8U
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.574 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Request joining group due to: need to re-join with the given member-id: consumer-sub-187-dzCZ1J8-67-2807b9f8-f8d0-45bb-ab84-cfe8c8fb5006
10:35:35.574 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.574 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] (Re-)joining group
10:35:35.574 [pool-70-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.575 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.575 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.575 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.575 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135575
10:35:35.575 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Subscribed to topic(s): test-topic-0000193-IKe7u9w
10:35:35.576 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] (Re-)joining group
10:35:35.578 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Request joining group due to: need to re-join with the given member-id: consumer-sub-184-UCC2_8Y-66-dcb1583c-b79f-4796-880f-f0dba4328f28
10:35:35.578 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.578 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] (Re-)joining group
10:35:35.580 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] (Re-)joining group
10:35:35.580 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-196-zfD1A_I-70
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-196-zfD1A_I
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.583 [pool-71-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.583 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Request joining group due to: need to re-join with the given member-id: consumer-sub-190-rMQrnZo-68-dde23cb7-001d-414b-9c5d-3a5e13e56327
10:35:35.583 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.583 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.583 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] (Re-)joining group
10:35:35.583 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] (Re-)joining group
10:35:35.584 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.584 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.584 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135584
10:35:35.584 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Subscribed to topic(s): test-topic-0000196-Ej9h6yQ
10:35:35.586 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Request joining group due to: need to re-join with the given member-id: consumer-sub-193-s8VGh8U-69-317de2be-8012-4e8e-a661-fa4bef4761ca
10:35:35.586 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.586 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] (Re-)joining group
10:35:35.586 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-199-gj6dzsM-71
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-199-gj6dzsM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.589 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.589 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.589 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135589
10:35:35.589 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Subscribed to topic(s): test-topic-0000199-pa8qKEk
10:35:35.592 [pool-72-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.592 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.594 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] (Re-)joining group
10:35:35.594 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-202-DL6rg0U-72
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-202-DL6rg0U
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.596 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Request joining group due to: need to re-join with the given member-id: consumer-sub-196-zfD1A_I-70-a5dbae94-61d6-4b64-b550-43de2f0b8b2c
10:35:35.596 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.596 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] (Re-)joining group
10:35:35.597 [pool-73-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.597 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.597 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.597 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135597
10:35:35.597 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.597 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Subscribed to topic(s): test-topic-0000202-wnvH5hQ
10:35:35.598 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-205-Xuji97M-73
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-205-Xuji97M
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.600 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] (Re-)joining group
10:35:35.600 [pool-74-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.600 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.601 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.601 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.601 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135601
10:35:35.601 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Subscribed to topic(s): test-topic-0000205-noMcOW4
10:35:35.601 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] (Re-)joining group
10:35:35.602 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Request joining group due to: need to re-join with the given member-id: consumer-sub-199-gj6dzsM-71-f0d3225b-4c94-4154-96c9-a7ae80d3358a
10:35:35.602 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.602 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] (Re-)joining group
10:35:35.603 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Request joining group due to: need to re-join with the given member-id: consumer-sub-202-DL6rg0U-72-8b568640-82a2-4205-b244-ab0a1a6ef10f
10:35:35.604 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.604 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] (Re-)joining group
10:35:35.605 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-208-_BWsszI-74
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-208-_BWsszI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.608 [pool-75-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.608 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.608 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.608 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135608
10:35:35.608 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.608 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Subscribed to topic(s): test-topic-0000208-hdUPCA4
10:35:35.611 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] (Re-)joining group
10:35:35.612 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-211-Gil9jaE-75
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-211-Gil9jaE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.613 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Request joining group due to: need to re-join with the given member-id: consumer-sub-205-Xuji97M-73-6a278020-6305-4c7a-ac4f-c5d31cdc069a
10:35:35.613 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.613 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] (Re-)joining group
10:35:35.613 [pool-76-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.614 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.614 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] (Re-)joining group
10:35:35.615 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.615 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.615 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135615
10:35:35.615 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Subscribed to topic(s): test-topic-0000211-Ph8tip0
10:35:35.616 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Request joining group due to: need to re-join with the given member-id: consumer-sub-208-_BWsszI-74-75758e82-4145-4055-b0d0-e4ba0ada9700
10:35:35.616 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.616 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] (Re-)joining group
10:35:35.617 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-214-u7Hz_Ns-76
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-214-u7Hz_Ns
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.620 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.620 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.620 [pool-77-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.620 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135620
10:35:35.620 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.620 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Subscribed to topic(s): test-topic-0000214-WIM8B8M
10:35:35.621 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-217-zmNMIvw-77
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-217-zmNMIvw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.623 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] (Re-)joining group
10:35:35.624 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.624 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.624 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135624
10:35:35.624 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Subscribed to topic(s): test-topic-0000217-Ajth_NQ
10:35:35.624 [pool-78-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.624 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Request joining group due to: need to re-join with the given member-id: consumer-sub-211-Gil9jaE-75-ace90156-d0ee-4340-9b7d-e4b792e0fc6b
10:35:35.625 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.625 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] (Re-)joining group
10:35:35.625 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.626 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] (Re-)joining group
10:35:35.627 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-220-eLcgVIE-78
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-220-eLcgVIE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.629 [pool-79-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.630 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.630 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.630 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.630 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135630
10:35:35.630 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] (Re-)joining group
10:35:35.630 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Request joining group due to: need to re-join with the given member-id: consumer-sub-214-u7Hz_Ns-76-858b4e25-8c50-446e-9dd3-ecfed657d7f9
10:35:35.631 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Subscribed to topic(s): test-topic-0000220-N-ilnxQ
10:35:35.631 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.631 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] (Re-)joining group
10:35:35.633 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Request joining group due to: need to re-join with the given member-id: consumer-sub-217-zmNMIvw-77-97baa124-ada5-4ac4-9ead-dbea2d97ecd9
10:35:35.633 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.633 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] (Re-)joining group
10:35:35.638 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-223-Borim14-79
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-223-Borim14
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.640 [pool-80-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.640 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.641 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] (Re-)joining group
10:35:35.641 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.641 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.641 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135641
10:35:35.641 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Subscribed to topic(s): test-topic-0000223-ah3LCNA
10:35:35.643 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-226-RKLF2mE-80
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-226-RKLF2mE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.643 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Request joining group due to: need to re-join with the given member-id: consumer-sub-220-eLcgVIE-78-b972007e-a148-4d31-bf8f-b759f019658f
10:35:35.643 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.643 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] (Re-)joining group
10:35:35.646 [pool-81-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.646 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.646 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] (Re-)joining group
10:35:35.646 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.646 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.646 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135646
10:35:35.647 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Subscribed to topic(s): test-topic-0000226-9ja4qbw
10:35:35.648 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Request joining group due to: need to re-join with the given member-id: consumer-sub-223-Borim14-79-50dbd4ea-b713-432f-8b37-b551a173928f
10:35:35.649 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.649 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] (Re-)joining group
10:35:35.651 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-229-K6WIHn0-81
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-229-K6WIHn0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.655 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.655 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.655 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135655
10:35:35.655 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Subscribed to topic(s): test-topic-0000229--X-ffVY
10:35:35.656 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-232-HWA9cc4-82
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-232-HWA9cc4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.659 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.659 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.659 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135659
10:35:35.660 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Subscribed to topic(s): test-topic-0000232-Zo-CFTw
10:35:35.660 [pool-82-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.661 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.663 [pool-83-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.664 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.666 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-235-MeSVaXE-83
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-235-MeSVaXE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.669 [pool-84-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.669 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.669 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.669 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.669 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135669
10:35:35.670 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Subscribed to topic(s): test-topic-0000235-cCNi4L4
10:35:35.673 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] (Re-)joining group
10:35:35.675 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Request joining group due to: need to re-join with the given member-id: consumer-sub-229-K6WIHn0-81-72101873-8e72-4076-b8f8-55064d9ef265
10:35:35.675 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.675 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] (Re-)joining group
10:35:35.676 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] (Re-)joining group
10:35:35.678 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Request joining group due to: need to re-join with the given member-id: consumer-sub-226-RKLF2mE-80-fa4f0f54-fa1f-43c2-9370-75e0c0e806a0
10:35:35.678 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.678 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] (Re-)joining group
10:35:35.681 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-238-ONJOK5A-84
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-238-ONJOK5A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.682 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] (Re-)joining group
10:35:35.684 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Request joining group due to: need to re-join with the given member-id: consumer-sub-232-HWA9cc4-82-d8e2cb3a-b101-41e8-9119-3b458fd9e777
10:35:35.684 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.684 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] (Re-)joining group
10:35:35.684 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.684 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.685 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135684
10:35:35.685 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Subscribed to topic(s): test-topic-0000238-pVDipQg
10:35:35.686 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-241-gvnU3Ck-85
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-241-gvnU3Ck
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.687 [pool-86-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.688 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.688 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] (Re-)joining group
10:35:35.688 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.689 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.689 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135688
10:35:35.689 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Subscribed to topic(s): test-topic-0000241-R-_-_cA
10:35:35.689 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-244-jxtWLHw-86
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-244-jxtWLHw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.690 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Request joining group due to: need to re-join with the given member-id: consumer-sub-238-ONJOK5A-84-8ffc0de2-5043-4497-96f1-8c0d893ed98f
10:35:35.690 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.690 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] (Re-)joining group
10:35:35.692 [pool-87-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.692 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.692 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] (Re-)joining group
10:35:35.693 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.693 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.693 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135693
10:35:35.693 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Subscribed to topic(s): test-topic-0000244-xZzYGvA
10:35:35.694 [pool-85-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.694 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.694 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] (Re-)joining group
10:35:35.695 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Request joining group due to: need to re-join with the given member-id: consumer-sub-241-gvnU3Ck-85-ffeddb23-aa10-480f-8000-fed292d501c1
10:35:35.695 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.695 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] (Re-)joining group
10:35:35.695 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-247-K9XaCCg-87
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-247-K9XaCCg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.697 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Request joining group due to: need to re-join with the given member-id: consumer-sub-235-MeSVaXE-83-d3d2c7bb-daec-474f-98d4-049616041ca5
10:35:35.697 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.697 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] (Re-)joining group
10:35:35.697 [pool-88-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.697 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.698 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] (Re-)joining group
10:35:35.698 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.698 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.698 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135698
10:35:35.698 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Subscribed to topic(s): test-topic-0000247-bLhN7IM
10:35:35.699 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-250-rGmeKVQ-88
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-250-rGmeKVQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.699 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Request joining group due to: need to re-join with the given member-id: consumer-sub-244-jxtWLHw-86-be807ba6-7713-4537-8725-653c390f8539
10:35:35.700 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.700 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] (Re-)joining group
10:35:35.701 [pool-89-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.701 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.701 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] (Re-)joining group
10:35:35.702 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.702 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.702 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135702
10:35:35.702 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Subscribed to topic(s): test-topic-0000250-oUn3sNE
10:35:35.703 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-253-RgeEIIQ-89
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-253-RgeEIIQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.703 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Request joining group due to: need to re-join with the given member-id: consumer-sub-247-K9XaCCg-87-4baccfb4-1b21-4de9-92b0-d41dbb639a31
10:35:35.703 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.704 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] (Re-)joining group
10:35:35.704 [pool-90-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.705 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.706 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.706 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.706 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135706
10:35:35.706 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Subscribed to topic(s): test-topic-0000253-QAvk_uQ
10:35:35.706 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] (Re-)joining group
10:35:35.707 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-256-tSNX3eE-90
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-256-tSNX3eE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.708 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-250-rGmeKVQ-88-1abc8c25-e855-4205-b44f-f33265cfbb8c
10:35:35.708 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.708 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] (Re-)joining group
10:35:35.710 [pool-91-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.710 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.710 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.710 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.710 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135710
10:35:35.711 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Subscribed to topic(s): test-topic-0000256--7oN2X0
10:35:35.712 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] (Re-)joining group
10:35:35.713 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-259-qFaMuSA-91
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-259-qFaMuSA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.713 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-253-RgeEIIQ-89-898266f5-2e8c-4b0e-b26d-d3b383299c6f
10:35:35.714 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.714 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] (Re-)joining group
10:35:35.715 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.715 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.715 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135715
10:35:35.716 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Subscribed to topic(s): test-topic-0000259-zpR5ZgQ
10:35:35.718 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-262-t6tbKE8-92
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-262-t6tbKE8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.720 [pool-93-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.720 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.721 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.721 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.721 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135720
10:35:35.721 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Subscribed to topic(s): test-topic-0000262-2mGVp-c
10:35:35.722 [pool-92-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.722 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.724 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] (Re-)joining group
10:35:35.724 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] (Re-)joining group
10:35:35.726 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Request joining group due to: need to re-join with the given member-id: consumer-sub-259-qFaMuSA-91-81038daa-0bf3-4ce2-949d-3b635a694bf8
10:35:35.726 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.726 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] (Re-)joining group
10:35:35.726 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Request joining group due to: need to re-join with the given member-id: consumer-sub-256-tSNX3eE-90-3dd1cbee-d0b6-4f30-8b43-bc0191ca1b79
10:35:35.726 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.727 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] (Re-)joining group
10:35:35.727 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-265-y1eeaSk-93
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-265-y1eeaSk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.729 [pool-94-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.729 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.730 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.730 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.730 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135730
10:35:35.730 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Subscribed to topic(s): test-topic-0000265-TgfBbRU
10:35:35.731 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] (Re-)joining group
10:35:35.732 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Request joining group due to: need to re-join with the given member-id: consumer-sub-262-t6tbKE8-92-b66ddf5d-0783-489e-b3c0-bc0a40c009d4
10:35:35.732 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.732 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] (Re-)joining group
10:35:35.734 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-268-Nx4dv8k-94
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-268-Nx4dv8k
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.736 [pool-95-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.736 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.737 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.737 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.737 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135737
10:35:35.738 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Subscribed to topic(s): test-topic-0000268-JN0QTJM
10:35:35.738 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] (Re-)joining group
10:35:35.739 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-271-_g-PJNA-95
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-271-_g-PJNA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.740 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Request joining group due to: need to re-join with the given member-id: consumer-sub-265-y1eeaSk-93-950a37e4-c623-4368-82f6-1c64e6f7db28
10:35:35.740 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.740 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] (Re-)joining group
10:35:35.742 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.742 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.742 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135742
10:35:35.742 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Subscribed to topic(s): test-topic-0000271-2pWwc2U
10:35:35.744 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-274-97uhtFY-96
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-274-97uhtFY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.745 [pool-96-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.746 [pool-97-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.747 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.747 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.747 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.747 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135747
10:35:35.747 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Subscribed to topic(s): test-topic-0000274-d_ffdj4
10:35:35.749 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.752 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] (Re-)joining group
10:35:35.754 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Request joining group due to: need to re-join with the given member-id: consumer-sub-271-_g-PJNA-95-66f1e284-2bc1-4f22-a89a-0f94949eec7d
10:35:35.754 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.754 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] (Re-)joining group
10:35:35.759 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] (Re-)joining group
10:35:35.759 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-277-zPD7C0Y-97
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-277-zPD7C0Y
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.761 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Request joining group due to: need to re-join with the given member-id: consumer-sub-268-Nx4dv8k-94-6432603c-6fb3-42b7-b287-cdef399856db
10:35:35.761 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.761 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] (Re-)joining group
10:35:35.762 [pool-98-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.762 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.763 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.763 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.763 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135763
10:35:35.763 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Subscribed to topic(s): test-topic-0000277-cGMK6aw
10:35:35.763 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] (Re-)joining group
10:35:35.764 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-280-Bur9X_M-98
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-280-Bur9X_M
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.766 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Request joining group due to: need to re-join with the given member-id: consumer-sub-274-97uhtFY-96-ccae2a18-32c8-4e34-94a5-d3d99f51026c
10:35:35.766 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.766 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] (Re-)joining group
10:35:35.766 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.766 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.766 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135766
10:35:35.767 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Subscribed to topic(s): test-topic-0000280-Tf41vck
10:35:35.768 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-283-qrdvKP0-99
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-283-qrdvKP0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.769 [pool-99-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.769 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.769 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] (Re-)joining group
10:35:35.770 [pool-100-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.770 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.770 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] (Re-)joining group
10:35:35.771 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Request joining group due to: need to re-join with the given member-id: consumer-sub-277-zPD7C0Y-97-d35f9e28-5562-43e2-8f02-275e606dc320
10:35:35.771 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.771 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] (Re-)joining group
10:35:35.771 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.771 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.772 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135771
10:35:35.772 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Subscribed to topic(s): test-topic-0000283-KIHGGJM
10:35:35.772 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Request joining group due to: need to re-join with the given member-id: consumer-sub-280-Bur9X_M-98-da531213-0b50-427b-b528-4926bcaa5b81
10:35:35.772 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.772 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] (Re-)joining group
10:35:35.772 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-286-C_QmO_E-100
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-286-C_QmO_E
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.775 [pool-101-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.775 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.775 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.775 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.775 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135775
10:35:35.775 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Subscribed to topic(s): test-topic-0000286-UC4nEGw
10:35:35.777 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] (Re-)joining group
10:35:35.778 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-289-5P3MXB0-101
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-289-5P3MXB0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.779 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Request joining group due to: need to re-join with the given member-id: consumer-sub-283-qrdvKP0-99-79401b3a-32bc-4ef8-9ec1-e925cef5e3b0
10:35:35.779 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.779 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] (Re-)joining group
10:35:35.785 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.785 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.785 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135785
10:35:35.785 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Subscribed to topic(s): test-topic-0000289-tlcNYIU
10:35:35.786 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-292-0_zH55A-102
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-292-0_zH55A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.786 [pool-102-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.786 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.788 [pool-103-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.788 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.789 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.789 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.789 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135789
10:35:35.789 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Subscribed to topic(s): test-topic-0000292--jBlQhg
10:35:35.789 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] (Re-)joining group
10:35:35.790 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] (Re-)joining group
10:35:35.791 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-295-yYRDrkU-103
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-295-yYRDrkU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.793 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Request joining group due to: need to re-join with the given member-id: consumer-sub-289-5P3MXB0-101-5433975c-2eb5-41ce-bb37-0bab613a8885
10:35:35.793 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.793 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] (Re-)joining group
10:35:35.793 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.793 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.793 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135793
10:35:35.794 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Subscribed to topic(s): test-topic-0000295-I5j6jbk
10:35:35.794 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-298-GMkVXt0-104
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-298-GMkVXt0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.796 [pool-104-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.796 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.797 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.797 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.797 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135797
10:35:35.797 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Request joining group due to: need to re-join with the given member-id: consumer-sub-286-C_QmO_E-100-18e41f9b-de38-4a50-8a96-67c3bf5290ad
10:35:35.797 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.798 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] (Re-)joining group
10:35:35.802 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Subscribed to topic(s): test-topic-0000298-ceeBYS0
10:35:35.804 [pool-105-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.804 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.807 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] (Re-)joining group
10:35:35.807 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] (Re-)joining group
10:35:35.808 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-301-ForHoYM-105
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-301-ForHoYM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.808 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Request joining group due to: need to re-join with the given member-id: consumer-sub-292-0_zH55A-102-77247aae-3898-445e-8d47-1cc25e2e9a44
10:35:35.809 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.809 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] (Re-)joining group
10:35:35.809 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Request joining group due to: need to re-join with the given member-id: consumer-sub-295-yYRDrkU-103-1be972a8-eb9f-4320-93be-bdfab0e0239e
10:35:35.809 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.809 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] (Re-)joining group
10:35:35.810 [pool-106-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.810 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.811 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.811 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] (Re-)joining group
10:35:35.811 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.811 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135811
10:35:35.811 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Subscribed to topic(s): test-topic-0000301-yA-mZIA
10:35:35.812 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-304-lFC-9Mk-106
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-304-lFC-9Mk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.813 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Request joining group due to: need to re-join with the given member-id: consumer-sub-298-GMkVXt0-104-609a9f17-e6d8-4445-8c1d-a90748f721b8
10:35:35.813 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.813 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] (Re-)joining group
10:35:35.814 [pool-107-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.814 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.814 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.814 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.814 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135814
10:35:35.815 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Subscribed to topic(s): test-topic-0000304-ov6qkF0
10:35:35.815 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] (Re-)joining group
10:35:35.816 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-307-obAgLJY-107
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-307-obAgLJY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.816 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Request joining group due to: need to re-join with the given member-id: consumer-sub-301-ForHoYM-105-c6edf2b8-ad3a-419b-932e-c7b72d1e9410
10:35:35.816 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.816 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] (Re-)joining group
10:35:35.819 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.819 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.819 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135819
10:35:35.819 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Subscribed to topic(s): test-topic-0000307-jPsw980
10:35:35.820 [pool-108-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.820 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.822 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-310-R0E95os-108
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-310-R0E95os
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.825 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] (Re-)joining group
10:35:35.825 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.825 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.825 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135825
10:35:35.825 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Subscribed to topic(s): test-topic-0000310-nAgI1eA
10:35:35.827 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Request joining group due to: need to re-join with the given member-id: consumer-sub-304-lFC-9Mk-106-a274a443-45b4-49f6-9f22-fbe91f4db1cb
10:35:35.827 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.827 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] (Re-)joining group
10:35:35.829 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-313-R0lwR2M-109
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-313-R0lwR2M
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.829 [pool-109-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.829 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.833 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] (Re-)joining group
10:35:35.833 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.833 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.833 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135833
10:35:35.833 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Subscribed to topic(s): test-topic-0000313-X7YT0wM
10:35:35.834 [pool-110-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.834 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.835 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Request joining group due to: need to re-join with the given member-id: consumer-sub-307-obAgLJY-107-a4fb027d-b94c-46f0-9edb-417d5912784a
10:35:35.835 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.835 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] (Re-)joining group
10:35:35.836 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] (Re-)joining group
10:35:35.837 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-316-BeFW2Tg-110
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-316-BeFW2Tg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.838 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Request joining group due to: need to re-join with the given member-id: consumer-sub-310-R0E95os-108-89a83861-c1a0-4c00-9ab3-c7891d7aaa3e
10:35:35.838 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.838 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] (Re-)joining group
10:35:35.838 [pool-111-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.838 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.839 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.839 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.839 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135839
10:35:35.839 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Subscribed to topic(s): test-topic-0000316-Lxd4VNo
10:35:35.840 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] (Re-)joining group
10:35:35.840 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-319-GAjFQLU-111
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-319-GAjFQLU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.841 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Request joining group due to: need to re-join with the given member-id: consumer-sub-313-R0lwR2M-109-f5e1e96f-dde4-4d8d-b2e9-9fc1ee9f0731
10:35:35.841 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.841 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] (Re-)joining group
10:35:35.843 [pool-112-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.843 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.843 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.843 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.843 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135843
10:35:35.843 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Subscribed to topic(s): test-topic-0000319-9t7gUAI
10:35:35.843 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] (Re-)joining group
10:35:35.845 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Request joining group due to: need to re-join with the given member-id: consumer-sub-316-BeFW2Tg-110-cc7f741d-c66a-4be6-8c76-29ad6f189395
10:35:35.845 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.845 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] (Re-)joining group
10:35:35.846 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-322-Q_l-zqA-112
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-322-Q_l-zqA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.849 [pool-113-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.849 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.849 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.849 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.849 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135849
10:35:35.849 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] (Re-)joining group
10:35:35.849 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Subscribed to topic(s): test-topic-0000322-xRObVwo
10:35:35.850 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-325-wXE01jo-113
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-325-wXE01jo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.850 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Request joining group due to: need to re-join with the given member-id: consumer-sub-319-GAjFQLU-111-1425e678-b56d-449e-ae82-cbc4b7ae4cf3
10:35:35.851 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.851 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] (Re-)joining group
10:35:35.852 [pool-114-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.852 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.852 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.852 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.852 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135852
10:35:35.852 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Subscribed to topic(s): test-topic-0000325-yVBo-XQ
10:35:35.853 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] (Re-)joining group
10:35:35.854 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-328-IrnBZGs-114
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-328-IrnBZGs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.854 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Request joining group due to: need to re-join with the given member-id: consumer-sub-322-Q_l-zqA-112-a575abb0-64d6-4ca0-897a-fd5b2aa2fe99
10:35:35.854 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.854 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] (Re-)joining group
10:35:35.856 [pool-115-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.856 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.856 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.856 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.856 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135856
10:35:35.856 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Subscribed to topic(s): test-topic-0000328-gFAenbQ
10:35:35.859 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] (Re-)joining group
10:35:35.861 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Request joining group due to: need to re-join with the given member-id: consumer-sub-325-wXE01jo-113-ef21c79d-29e6-41ef-b4bd-6c6a56fe2ec2
10:35:35.861 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.861 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] (Re-)joining group
10:35:35.861 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-331-OY1AMrs-115
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-331-OY1AMrs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.863 [pool-116-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.863 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.864 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.864 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.864 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] (Re-)joining group
10:35:35.864 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135864
10:35:35.864 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Subscribed to topic(s): test-topic-0000331-SozV4lU
10:35:35.865 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-334-vbmgVHU-116
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-334-vbmgVHU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.867 [pool-117-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.867 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.867 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] (Re-)joining group
10:35:35.867 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.868 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.868 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135867
10:35:35.868 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Request joining group due to: need to re-join with the given member-id: consumer-sub-328-IrnBZGs-114-71307c36-04e7-4213-a03d-d3c31cf0d39e
10:35:35.868 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Subscribed to topic(s): test-topic-0000334-lg5rX9A
10:35:35.868 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.868 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] (Re-)joining group
10:35:35.868 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-337-sKVKKJo-117
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-337-sKVKKJo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.869 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Request joining group due to: need to re-join with the given member-id: consumer-sub-331-OY1AMrs-115-7cc71e94-13d6-44b3-987d-09938f1de11c
10:35:35.869 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.869 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] (Re-)joining group
10:35:35.874 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.874 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.874 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135874
10:35:35.874 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Subscribed to topic(s): test-topic-0000337-Z2pSJcI
10:35:35.875 [pool-118-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.875 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-340-sJB-GGc-118
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-340-sJB-GGc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.875 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.875 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] (Re-)joining group
10:35:35.877 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Request joining group due to: need to re-join with the given member-id: consumer-sub-334-vbmgVHU-116-e98b5212-d2e6-4f1d-bf2f-605757253042
10:35:35.877 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.877 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] (Re-)joining group
10:35:35.878 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.878 [pool-119-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.878 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.878 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135878
10:35:35.878 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.878 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Subscribed to topic(s): test-topic-0000340-6fVYvHQ
10:35:35.878 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] (Re-)joining group
10:35:35.880 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Request joining group due to: need to re-join with the given member-id: consumer-sub-337-sKVKKJo-117-946f75c5-777f-413b-9c1e-9b74ed1b13b2
10:35:35.880 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.880 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] (Re-)joining group
10:35:35.880 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-343-tCi6D5E-119
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-343-tCi6D5E
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.882 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.882 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.882 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135882
10:35:35.882 [pool-120-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.882 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Subscribed to topic(s): test-topic-0000343-QjcgwwM
10:35:35.882 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.884 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-346-6ZznPpc-120
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-346-6ZznPpc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.884 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] (Re-)joining group
10:35:35.886 [pool-121-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.886 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.886 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] (Re-)joining group
10:35:35.887 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.887 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Request joining group due to: need to re-join with the given member-id: consumer-sub-340-sJB-GGc-118-d2346536-70e9-4de6-8d09-c852d3827518
10:35:35.887 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.887 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135887
10:35:35.887 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.887 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] (Re-)joining group
10:35:35.887 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Subscribed to topic(s): test-topic-0000346-67ml2YA
10:35:35.888 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-349-puyQhKk-121
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-349-puyQhKk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.888 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Request joining group due to: need to re-join with the given member-id: consumer-sub-343-tCi6D5E-119-c83ba2ca-452f-47dd-b274-ff861b66007a
10:35:35.888 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.888 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] (Re-)joining group
10:35:35.889 [pool-122-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.890 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.890 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] (Re-)joining group
10:35:35.890 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.890 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.890 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135890
10:35:35.890 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Subscribed to topic(s): test-topic-0000349-MJA-dNs
10:35:35.892 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-352-tPmGvSE-122
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-352-tPmGvSE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.894 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Request joining group due to: need to re-join with the given member-id: consumer-sub-346-6ZznPpc-120-bfbda878-3d45-4e0f-9b71-a5f3deeea35f
10:35:35.894 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.894 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] (Re-)joining group
10:35:35.894 [pool-123-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.894 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.895 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] (Re-)joining group
10:35:35.895 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.895 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.895 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135895
10:35:35.895 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Subscribed to topic(s): test-topic-0000352-sGfuRYg
10:35:35.896 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-355-XWukxHo-123
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-355-XWukxHo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.896 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Request joining group due to: need to re-join with the given member-id: consumer-sub-349-puyQhKk-121-537bd1f5-797d-47dc-b325-2cb968d84043
10:35:35.896 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.897 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] (Re-)joining group
10:35:35.898 [pool-124-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.898 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.899 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.899 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.899 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135899
10:35:35.899 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Subscribed to topic(s): test-topic-0000355-8KDY5A8
10:35:35.900 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] (Re-)joining group
10:35:35.901 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Request joining group due to: need to re-join with the given member-id: consumer-sub-352-tPmGvSE-122-6f6b8759-01ba-4f80-a60b-a55e43012241
10:35:35.901 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.901 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] (Re-)joining group
10:35:35.902 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-358-AcQiokY-124
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-358-AcQiokY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.904 [pool-125-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.905 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.905 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.905 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.905 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135905
10:35:35.905 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Subscribed to topic(s): test-topic-0000358-VRn-TQc
10:35:35.905 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] (Re-)joining group
10:35:35.906 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-361-Gb3dfKI-125
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-361-Gb3dfKI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.907 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Request joining group due to: need to re-join with the given member-id: consumer-sub-355-XWukxHo-123-9dbe8adb-d45e-444b-94da-2478cc2a206b
10:35:35.907 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.907 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] (Re-)joining group
10:35:35.908 [pool-126-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.908 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.909 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] (Re-)joining group
10:35:35.909 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.909 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.909 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135909
10:35:35.909 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Subscribed to topic(s): test-topic-0000361-LZwO7zU
10:35:35.910 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Request joining group due to: need to re-join with the given member-id: consumer-sub-358-AcQiokY-124-52b6ec66-a41c-4c69-a0b0-035c7f098e27
10:35:35.910 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.910 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] (Re-)joining group
10:35:35.911 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-364--B3TswQ-126
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-364--B3TswQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.912 [pool-127-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.912 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.912 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] (Re-)joining group
10:35:35.914 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.914 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.914 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Request joining group due to: need to re-join with the given member-id: consumer-sub-361-Gb3dfKI-125-1bad7ba4-ed26-4acb-979f-cba307a9415b
10:35:35.914 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135914
10:35:35.914 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.914 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] (Re-)joining group
10:35:35.914 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Subscribed to topic(s): test-topic-0000364-kAq5nsI
10:35:35.915 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-367-ql_4kYc-127
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-367-ql_4kYc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.917 [pool-128-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.917 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.918 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.918 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.918 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135918
10:35:35.918 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Subscribed to topic(s): test-topic-0000367-NouK178
10:35:35.919 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] (Re-)joining group
10:35:35.920 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-364--B3TswQ-126-97ac7737-92d9-48de-a41b-b7b9ee9bfc6a
10:35:35.920 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.920 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] (Re-)joining group
10:35:35.921 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-370-v5wLaPc-128
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-370-v5wLaPc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.923 [pool-129-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.923 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.924 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] (Re-)joining group
10:35:35.924 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.924 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.924 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135924
10:35:35.924 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Subscribed to topic(s): test-topic-0000370-mEr65Xk
10:35:35.925 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-373-4hV6wFE-129
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-373-4hV6wFE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.926 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Request joining group due to: need to re-join with the given member-id: consumer-sub-367-ql_4kYc-127-bada1af4-9b48-4af0-895d-174651bfa242
10:35:35.926 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.926 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] (Re-)joining group
10:35:35.926 [pool-130-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.927 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.927 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] (Re-)joining group
10:35:35.928 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.928 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.928 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135928
10:35:35.928 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Subscribed to topic(s): test-topic-0000373-_NDkX0c
10:35:35.929 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-376-igw_F3A-130
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-376-igw_F3A
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.929 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Request joining group due to: need to re-join with the given member-id: consumer-sub-370-v5wLaPc-128-548de164-e564-4272-b293-b36ed7828710
10:35:35.929 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.929 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] (Re-)joining group
10:35:35.930 [pool-131-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.931 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.931 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.931 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.931 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135931
10:35:35.931 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Subscribed to topic(s): test-topic-0000376-OIelxdU
10:35:35.931 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] (Re-)joining group
10:35:35.932 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-379-OGtMICI-131
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-379-OGtMICI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.933 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Request joining group due to: need to re-join with the given member-id: consumer-sub-373-4hV6wFE-129-08a1e9eb-6997-49d4-b916-e7a6be4a3326
10:35:35.933 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.933 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] (Re-)joining group
10:35:35.934 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.935 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.935 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135934
10:35:35.935 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Subscribed to topic(s): test-topic-0000379-TfxtvR0
10:35:35.936 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-382-5bYhotQ-132
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-382-5bYhotQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.937 [pool-132-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.937 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.938 [pool-133-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.938 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] (Re-)joining group
10:35:35.938 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.938 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.938 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.938 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135938
10:35:35.939 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Subscribed to topic(s): test-topic-0000382-L601XY4
10:35:35.939 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] (Re-)joining group
10:35:35.939 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-385-vae6fZg-133
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-385-vae6fZg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.940 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Request joining group due to: need to re-join with the given member-id: consumer-sub-376-igw_F3A-130-ff958076-5daf-4ef9-a3f0-20871e9d8dc1
10:35:35.940 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.940 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] (Re-)joining group
10:35:35.941 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Request joining group due to: need to re-join with the given member-id: consumer-sub-379-OGtMICI-131-f1e10ad5-6366-4772-9b68-e28ea3db908f
10:35:35.941 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.941 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] (Re-)joining group
10:35:35.942 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.942 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.942 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135942
10:35:35.942 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Subscribed to topic(s): test-topic-0000385-UMXA7Q8
10:35:35.942 [pool-134-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.942 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.943 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-388-P5cW7Tg-134
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-388-P5cW7Tg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.943 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] (Re-)joining group
10:35:35.945 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-382-5bYhotQ-132-fa08d952-979a-4212-9456-f2611f673495
10:35:35.945 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.945 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] (Re-)joining group
10:35:35.945 [pool-135-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.945 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.945 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.945 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.945 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135945
10:35:35.946 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Subscribed to topic(s): test-topic-0000388-y1l0tN0
10:35:35.946 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] (Re-)joining group
10:35:35.946 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-391-RUDds4Y-135
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-391-RUDds4Y
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.947 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Request joining group due to: need to re-join with the given member-id: consumer-sub-385-vae6fZg-133-38203741-818d-492f-9d32-edf057ad12e9
10:35:35.947 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.948 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] (Re-)joining group
10:35:35.949 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.949 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.949 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135949
10:35:35.949 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Subscribed to topic(s): test-topic-0000391-QVLIF3k
10:35:35.949 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-394-tyloWTo-136
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-394-tyloWTo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.951 [pool-136-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.951 [pool-137-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.951 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.952 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.952 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] (Re-)joining group
10:35:35.952 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.952 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.952 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135952
10:35:35.952 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Subscribed to topic(s): test-topic-0000394-xlkFLyI
10:35:35.953 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Request joining group due to: need to re-join with the given member-id: consumer-sub-388-P5cW7Tg-134-1b32509e-9473-4521-98ad-aa35ee6eaa4b
10:35:35.954 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.954 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] (Re-)joining group
10:35:35.954 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] (Re-)joining group
10:35:35.954 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-397-zg7ub-4-137
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-397-zg7ub-4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.956 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Request joining group due to: need to re-join with the given member-id: consumer-sub-391-RUDds4Y-135-d3019b5e-8534-49bc-b853-d3c0d9a867cf
10:35:35.956 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.956 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] (Re-)joining group
10:35:35.956 [pool-138-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.956 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.957 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] (Re-)joining group
10:35:35.957 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.957 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.957 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135957
10:35:35.957 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Subscribed to topic(s): test-topic-0000397-bh_sXo0
10:35:35.959 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Request joining group due to: need to re-join with the given member-id: consumer-sub-394-tyloWTo-136-e9fc70cf-e16d-4053-a49c-daac33d7904f
10:35:35.959 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.959 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] (Re-)joining group
10:35:35.961 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-400-KsDN_SE-138
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-400-KsDN_SE
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.963 [pool-139-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.963 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.964 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.964 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] (Re-)joining group
10:35:35.964 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.964 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135964
10:35:35.964 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Subscribed to topic(s): test-topic-0000400-X7FM4dU
10:35:35.965 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-403-NN_e-UM-139
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-403-NN_e-UM
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.967 [pool-140-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.967 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.967 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.967 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.967 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135967
10:35:35.967 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Subscribed to topic(s): test-topic-0000403-cSYU2uM
10:35:35.970 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Request joining group due to: need to re-join with the given member-id: consumer-sub-397-zg7ub-4-137-4174d177-e964-4955-9901-066928aee244
10:35:35.970 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.970 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] (Re-)joining group
10:35:35.972 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] (Re-)joining group
10:35:35.973 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Request joining group due to: need to re-join with the given member-id: consumer-sub-400-KsDN_SE-138-a50dbd55-6d38-426c-921a-b28b437dc3f8
10:35:35.973 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.973 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] (Re-)joining group
10:35:35.975 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-406-fYmqBzg-140
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-406-fYmqBzg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.977 [pool-141-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.977 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:35.977 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.977 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.977 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135977
10:35:35.977 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Subscribed to topic(s): test-topic-0000406-veksnbI
10:35:35.978 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] (Re-)joining group
10:35:35.979 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Request joining group due to: need to re-join with the given member-id: consumer-sub-403-NN_e-UM-139-42367471-f51f-43fb-a9f1-fd2a61198725
10:35:35.980 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.980 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] (Re-)joining group
10:35:35.988 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-409-GRwWUd0-141
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-409-GRwWUd0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.990 [pool-142-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.991 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:35.991 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.991 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.991 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135991
10:35:35.991 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Subscribed to topic(s): test-topic-0000409-sCB18EQ
10:35:35.991 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] (Re-)joining group
10:35:35.993 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Request joining group due to: need to re-join with the given member-id: consumer-sub-406-fYmqBzg-140-ffd6987b-6002-475e-9888-c0f04f7077c2
10:35:35.993 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:35.993 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] (Re-)joining group
10:35:35.995 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-412-KLerxmg-142
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-412-KLerxmg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:35.997 [pool-143-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:35.997 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:35.998 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:35.998 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:35.998 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806135998
10:35:35.998 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] (Re-)joining group
10:35:35.998 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Subscribed to topic(s): test-topic-0000412-gJ9uDSE
10:35:35.999 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-415-DqirbL0-143
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-415-DqirbL0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.002 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.002 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.002 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136002
10:35:36.002 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Subscribed to topic(s): test-topic-0000415-EgHOvbM
10:35:36.003 [pool-144-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.003 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-418-BG0vOxQ-144
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-418-BG0vOxQ
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.003 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.003 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] (Re-)joining group
10:35:36.003 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Request joining group due to: need to re-join with the given member-id: consumer-sub-409-GRwWUd0-141-c8d5cf57-8542-4fe1-a772-b8d2446a5b30
10:35:36.003 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.003 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] (Re-)joining group
10:35:36.005 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Request joining group due to: need to re-join with the given member-id: consumer-sub-412-KLerxmg-142-6e086eaa-8161-49b1-9569-ce0606965e02
10:35:36.005 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.005 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] (Re-)joining group
10:35:36.006 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.006 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.006 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136006
10:35:36.006 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Subscribed to topic(s): test-topic-0000418-qY6RauQ
10:35:36.007 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-421-By8iGYI-145
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-421-By8iGYI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.008 [pool-145-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.008 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.008 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] (Re-)joining group
10:35:36.010 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Request joining group due to: need to re-join with the given member-id: consumer-sub-415-DqirbL0-143-f8fe638f-c59a-4202-93aa-239a11191bb9
10:35:36.010 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.010 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.010 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.010 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136010
10:35:36.010 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] (Re-)joining group
10:35:36.010 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Subscribed to topic(s): test-topic-0000421-AwE19r0
10:35:36.011 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-424-VmduDzo-146
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-424-VmduDzo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.013 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.013 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.013 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136013
10:35:36.013 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Subscribed to topic(s): test-topic-0000424-rZeSqAQ
10:35:36.014 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-427-_nunaqs-147
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-427-_nunaqs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.016 [pool-147-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.016 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.016 [pool-148-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.016 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.016 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.016 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.016 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136016
10:35:36.016 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] (Re-)joining group
10:35:36.016 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Subscribed to topic(s): test-topic-0000427-q9wDEgM
10:35:36.017 [pool-146-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.018 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.018 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Request joining group due to: need to re-join with the given member-id: consumer-sub-421-By8iGYI-145-6d7190be-74ba-48d6-aa90-38c8f3cc0a57
10:35:36.018 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.018 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] (Re-)joining group
10:35:36.019 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] (Re-)joining group
10:35:36.020 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] (Re-)joining group
10:35:36.020 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Request joining group due to: need to re-join with the given member-id: consumer-sub-424-VmduDzo-146-daf58349-dabd-4ff8-b983-136d6353ef1a
10:35:36.021 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.021 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] (Re-)joining group
10:35:36.021 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Request joining group due to: need to re-join with the given member-id: consumer-sub-418-BG0vOxQ-144-d83790f0-2e55-4bc5-bcf3-765044c564a9
10:35:36.021 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.021 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] (Re-)joining group
10:35:36.028 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-430-HIP-Ecc-148
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-430-HIP-Ecc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.030 [pool-149-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.030 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.030 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.030 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.030 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136030
10:35:36.031 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Subscribed to topic(s): test-topic-0000430-1HkZXP0
10:35:36.036 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] (Re-)joining group
10:35:36.036 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-433-5Z6gPg8-149
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-433-5Z6gPg8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.038 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Request joining group due to: need to re-join with the given member-id: consumer-sub-427-_nunaqs-147-d79526e0-4c10-409a-8e41-83cf768bb428
10:35:36.038 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.038 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] (Re-)joining group
10:35:36.038 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.038 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.038 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136038
10:35:36.038 [pool-150-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.038 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Subscribed to topic(s): test-topic-0000433-ahog9AU
10:35:36.038 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.039 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] (Re-)joining group
10:35:36.039 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-436-l5QsKDs-150
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-436-l5QsKDs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.041 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Request joining group due to: need to re-join with the given member-id: consumer-sub-430-HIP-Ecc-148-aeaf283d-6744-421f-8447-932a6732df5b
10:35:36.041 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.041 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] (Re-)joining group
10:35:36.041 [pool-151-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.041 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.041 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.041 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.041 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136041
10:35:36.042 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Subscribed to topic(s): test-topic-0000436-1z7Eoyk
10:35:36.043 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] (Re-)joining group
10:35:36.044 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-439-0u7s0Zo-151
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-439-0u7s0Zo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.045 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Request joining group due to: need to re-join with the given member-id: consumer-sub-433-5Z6gPg8-149-9a960151-dec6-46ab-b396-a6a0d37429ff
10:35:36.045 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.045 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] (Re-)joining group
10:35:36.046 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.046 [pool-152-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.046 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.046 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136046
10:35:36.046 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.046 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Subscribed to topic(s): test-topic-0000439-mHkFOzE
10:35:36.050 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-442-GTggPn4-152
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-442-GTggPn4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.052 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.052 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.052 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136052
10:35:36.052 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Subscribed to topic(s): test-topic-0000442-upMlwWs
10:35:36.058 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] (Re-)joining group
10:35:36.059 [pool-153-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.059 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.059 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Request joining group due to: need to re-join with the given member-id: consumer-sub-436-l5QsKDs-150-d71d1b89-8a4c-4d9a-9fa9-704d39eb93a8
10:35:36.059 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.059 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] (Re-)joining group
10:35:36.063 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] (Re-)joining group
10:35:36.063 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-445-ZjQdD0o-153
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-445-ZjQdD0o
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.065 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Request joining group due to: need to re-join with the given member-id: consumer-sub-439-0u7s0Zo-151-6f6de5ab-714d-4b03-9b85-c60a3913515d
10:35:36.065 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.065 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] (Re-)joining group
10:35:36.065 [pool-154-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.066 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.066 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.066 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.066 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136066
10:35:36.067 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Subscribed to topic(s): test-topic-0000445-e-Tdli0
10:35:36.071 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] (Re-)joining group
10:35:36.072 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Request joining group due to: need to re-join with the given member-id: consumer-sub-442-GTggPn4-152-e878d4d0-5443-4046-958f-50bab84bcca8
10:35:36.073 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.073 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] (Re-)joining group
10:35:36.075 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-448-EYn8owI-154
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-448-EYn8owI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.081 [pool-155-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.081 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.081 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.081 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.081 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136081
10:35:36.082 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Subscribed to topic(s): test-topic-0000448-54rGmRw
10:35:36.082 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] (Re-)joining group
10:35:36.082 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-451-f4gaQWo-155
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-451-f4gaQWo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.084 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Request joining group due to: need to re-join with the given member-id: consumer-sub-445-ZjQdD0o-153-af4ba00b-a55e-43bf-98db-41931d38d375
10:35:36.084 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.084 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] (Re-)joining group
10:35:36.085 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.085 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.085 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136085
10:35:36.085 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Subscribed to topic(s): test-topic-0000451-iYHTx2A
10:35:36.086 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-454-VOt8IBo-156
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-454-VOt8IBo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.088 [pool-157-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.089 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.089 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.089 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.089 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136089
10:35:36.090 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Subscribed to topic(s): test-topic-0000454-jINTbDs
10:35:36.090 [pool-156-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.090 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.092 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] (Re-)joining group
10:35:36.093 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] (Re-)joining group
10:35:36.093 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Request joining group due to: need to re-join with the given member-id: consumer-sub-451-f4gaQWo-155-d7cb18f9-426f-4b03-8aef-749da5027c57
10:35:36.093 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.093 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] (Re-)joining group
10:35:36.093 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-457-HrOiLw0-157
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-457-HrOiLw0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.094 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Request joining group due to: need to re-join with the given member-id: consumer-sub-448-EYn8owI-154-0ae8c1f4-24f5-4a5d-8caa-fd1801ddef7f
10:35:36.094 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.094 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] (Re-)joining group
10:35:36.096 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.096 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.096 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136096
10:35:36.096 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Subscribed to topic(s): test-topic-0000457-37_m3sc
10:35:36.096 [pool-158-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.096 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.097 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] (Re-)joining group
10:35:36.097 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-460-rlIljZk-158
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-460-rlIljZk
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.099 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Request joining group due to: need to re-join with the given member-id: consumer-sub-454-VOt8IBo-156-cce8af2a-086c-4d80-b5b0-11d10d9e2bcd
10:35:36.099 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.099 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] (Re-)joining group
10:35:36.100 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.100 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.100 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136100
10:35:36.100 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Subscribed to topic(s): test-topic-0000460-NzJPttA
10:35:36.100 [pool-159-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.100 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.102 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-463-mxbWA84-159
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-463-mxbWA84
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.104 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] (Re-)joining group
10:35:36.107 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.107 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.107 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136107
10:35:36.107 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Subscribed to topic(s): test-topic-0000463-AnsrbPc
10:35:36.107 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-466-qbRBPK4-160
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-466-qbRBPK4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.107 [pool-160-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.108 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.108 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Request joining group due to: need to re-join with the given member-id: consumer-sub-457-HrOiLw0-157-79837063-8780-454c-81cd-b21c75c2f00d
10:35:36.108 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.108 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] (Re-)joining group
10:35:36.109 [pool-161-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.109 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.114 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] (Re-)joining group
10:35:36.115 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Request joining group due to: need to re-join with the given member-id: consumer-sub-460-rlIljZk-158-3ace56a8-bfcc-47e4-a2d6-d6e439dc95c6
10:35:36.115 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.115 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] (Re-)joining group
10:35:36.117 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] (Re-)joining group
10:35:36.118 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.118 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.118 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136118
10:35:36.118 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Subscribed to topic(s): test-topic-0000466-rwZ2pKE
10:35:36.119 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Request joining group due to: need to re-join with the given member-id: consumer-sub-463-mxbWA84-159-ce25485c-1f27-4a56-9903-5ce0da6c09df
10:35:36.119 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.119 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] (Re-)joining group
10:35:36.119 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-469-CHMVaMY-161
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-469-CHMVaMY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.121 [pool-162-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.121 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.121 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.121 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.121 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136121
10:35:36.121 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Subscribed to topic(s): test-topic-0000469-1ZGl9m0
10:35:36.124 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] (Re-)joining group
10:35:36.124 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-472-nZDgjwA-162
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-472-nZDgjwA
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.126 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Request joining group due to: need to re-join with the given member-id: consumer-sub-466-qbRBPK4-160-173529e3-aee4-4a0e-89c1-da0cc1c4aa5b
10:35:36.126 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.126 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] (Re-)joining group
10:35:36.126 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.126 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.126 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136126
10:35:36.130 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Subscribed to topic(s): test-topic-0000472-FWunwBk
10:35:36.130 [pool-163-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.130 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-475-4g3cL84-163
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-475-4g3cL84
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.130 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.133 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.133 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.133 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136133
10:35:36.133 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Subscribed to topic(s): test-topic-0000475-2oxOTx4
10:35:36.136 [pool-164-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.136 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.137 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] (Re-)joining group
10:35:36.138 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] (Re-)joining group
10:35:36.138 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Request joining group due to: need to re-join with the given member-id: consumer-sub-469-CHMVaMY-161-3af04603-bd18-4d91-b216-e85c38165e55
10:35:36.138 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.138 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-478--bnw0AY-164
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-478--bnw0AY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.138 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] (Re-)joining group
10:35:36.139 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Request joining group due to: need to re-join with the given member-id: consumer-sub-472-nZDgjwA-162-b4481d95-8ca9-41bd-8716-9492555fa718
10:35:36.140 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.140 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] (Re-)joining group
10:35:36.140 [pool-165-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.141 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.141 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] (Re-)joining group
10:35:36.141 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.141 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.141 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136141
10:35:36.142 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Subscribed to topic(s): test-topic-0000478-PJjxrHU
10:35:36.143 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Request joining group due to: need to re-join with the given member-id: consumer-sub-475-4g3cL84-163-0b684e4f-06e1-4b36-8135-af6b74916c85
10:35:36.143 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.143 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] (Re-)joining group
10:35:36.143 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-481-_wldBvc-165
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-481-_wldBvc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.144 [pool-166-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.145 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.145 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.145 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.146 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136145
10:35:36.146 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] (Re-)joining group
10:35:36.146 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Subscribed to topic(s): test-topic-0000481-rS9biTw
10:35:36.147 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-484-0dDycKg-166
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-484-0dDycKg
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.148 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Request joining group due to: need to re-join with the given member-id: consumer-sub-478--bnw0AY-164-8dbf987e-c319-4221-b745-31a685a2aa28
10:35:36.148 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.148 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] (Re-)joining group
10:35:36.150 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.150 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.150 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136150
10:35:36.150 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Subscribed to topic(s): test-topic-0000484-Rft_ITE
10:35:36.151 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-487-tPuwjUY-167
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-487-tPuwjUY
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.152 [pool-167-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.152 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.153 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] (Re-)joining group
10:35:36.154 [pool-168-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.154 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.154 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.154 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136154
10:35:36.154 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Discovered group coordinator 10.0.0.91:9092 (id: 2147483645 rack: null)
10:35:36.154 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Subscribed to topic(s): test-topic-0000487-vhHh-EY
10:35:36.155 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-490-qBSDzRw-168
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-490-qBSDzRw
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.155 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Request joining group due to: need to re-join with the given member-id: consumer-sub-481-_wldBvc-165-a253e4d3-a3f1-4aa3-abec-cb2023dbe482
10:35:36.155 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.155 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] (Re-)joining group
10:35:36.156 [pool-169-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.157 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.157 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.157 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.157 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136157
10:35:36.158 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Subscribed to topic(s): test-topic-0000490-f2jrk7M
10:35:36.159 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] (Re-)joining group
10:35:36.160 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Request joining group due to: need to re-join with the given member-id: consumer-sub-484-0dDycKg-166-8d72fcdc-85ee-456d-903a-cef871f75f0c
10:35:36.160 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.160 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] (Re-)joining group
10:35:36.164 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-493-RgWTaLU-169
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-493-RgWTaLU
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.166 [pool-170-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.166 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.168 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.168 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.168 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136168
10:35:36.168 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Subscribed to topic(s): test-topic-0000493-T5rBBVM
10:35:36.164 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] (Re-)joining group
10:35:36.169 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] (Re-)joining group
10:35:36.170 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Request joining group due to: need to re-join with the given member-id: consumer-sub-487-tPuwjUY-167-487d5482-900a-4987-b7b0-a5eacebd5d81
10:35:36.170 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.170 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] (Re-)joining group
10:35:36.170 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Request joining group due to: need to re-join with the given member-id: consumer-sub-490-qBSDzRw-168-4aa52690-67af-49f6-899a-35225c3c1c37
10:35:36.171 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.171 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] (Re-)joining group
10:35:36.175 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-496-f32gVfs-170
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-496-f32gVfs
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.177 [pool-171-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.177 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.178 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.178 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.178 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136178
10:35:36.178 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Subscribed to topic(s): test-topic-0000496-f5cGpzY
10:35:36.180 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] (Re-)joining group
10:35:36.181 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Request joining group due to: need to re-join with the given member-id: consumer-sub-493-RgWTaLU-169-ecd31458-473b-4724-af6e-01240f24773b
10:35:36.181 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.181 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] (Re-)joining group
10:35:36.183 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-499-lAdLlmc-171
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-499-lAdLlmc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.185 [pool-172-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.185 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.186 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.186 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.186 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136186
10:35:36.186 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Subscribed to topic(s): test-topic-0000499-rvuAtqA
10:35:36.188 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] (Re-)joining group
10:35:36.188 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-502-HkdCi6I-172
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-502-HkdCi6I
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.189 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Request joining group due to: need to re-join with the given member-id: consumer-sub-496-f32gVfs-170-76a17a69-132d-4136-80ea-b4c32824cabc
10:35:36.189 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.189 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] (Re-)joining group
10:35:36.191 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.191 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.191 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136191
10:35:36.191 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Subscribed to topic(s): test-topic-0000502-e6T4-_g
10:35:36.193 [pool-173-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.193 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Discovered group coordinator 10.0.0.162:9092 (id: 2147483647 rack: null)
10:35:36.196 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] (Re-)joining group
10:35:36.196 [qtp235162442-28] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-505-ArOslyo-173
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-505-ArOslyo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:36.197 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Request joining group due to: need to re-join with the given member-id: consumer-sub-499-lAdLlmc-171-10ab314e-d909-41cc-952d-4a200c3299bf
10:35:36.198 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.198 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] (Re-)joining group
10:35:36.198 [pool-174-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.198 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.198 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
10:35:36.198 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:36.198 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716806136198
10:35:36.199 [qtp235162442-28] INFO KafkaConsumer - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Subscribed to topic(s): test-topic-0000505-tAmtBFc
10:35:36.199 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] (Re-)joining group
10:35:36.201 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Request joining group due to: need to re-join with the given member-id: consumer-sub-502-HkdCi6I-172-42275854-4a66-4a13-befa-20b1e4028262
10:35:36.201 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.201 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] (Re-)joining group
10:35:36.203 [qtp235162442-28] INFO LocalWorker - Created 173 consumers in 1203.982953 ms
10:35:36.204 [pool-175-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:36.204 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:36.212 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] (Re-)joining group
10:35:36.214 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Request joining group due to: need to re-join with the given member-id: consumer-sub-505-ArOslyo-173-4c357d76-0f23-47ad-8a99-77d73c932e66
10:35:36.214 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:36.214 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] (Re-)joining group
10:35:38.324 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-055-1horpzI-23-c87a0144-a022-4fa2-81cd-73a1486ed25c', protocol='range'}
10:35:38.325 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-052-oVomvmI-22-2d67d8a2-7ed2-48a1-9a6d-1e834e33bf94', protocol='range'}
10:35:38.326 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-013-8FJsfOU-9-2a447fb9-1de0-432c-a0b1-fb86dc5fd606', protocol='range'}
10:35:38.327 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-043-VRipANU-19-ff028afa-f38c-4a1a-86c7-082ab365bf54', protocol='range'}
10:35:38.328 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-049-QC2A1E8-21-c4c234fb-12c4-496e-a180-eb5841f277de', protocol='range'}
10:35:38.328 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-019-MASUH9w-11-e29cce5b-9813-4572-b85f-09dd9512b480', protocol='range'}
10:35:38.328 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-091-4lK-O0k-35-dfe34f62-ae89-4513-97b7-16c5c0bc7526', protocol='range'}
10:35:38.333 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Finished assignment for group at generation 1: {consumer-sub-049-QC2A1E8-21-c4c234fb-12c4-496e-a180-eb5841f277de=Assignment(partitions=[test-topic-0000049-sFgFDYQ-0])}
10:35:38.333 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Finished assignment for group at generation 1: {consumer-sub-043-VRipANU-19-ff028afa-f38c-4a1a-86c7-082ab365bf54=Assignment(partitions=[test-topic-0000043-UplvRtE-0])}
10:35:38.333 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Finished assignment for group at generation 1: {consumer-sub-013-8FJsfOU-9-2a447fb9-1de0-432c-a0b1-fb86dc5fd606=Assignment(partitions=[test-topic-0000013-upYB7Dk-0])}
10:35:38.333 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Finished assignment for group at generation 1: {consumer-sub-055-1horpzI-23-c87a0144-a022-4fa2-81cd-73a1486ed25c=Assignment(partitions=[test-topic-0000055-PfazGY4-0])}
10:35:38.333 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Finished assignment for group at generation 1: {consumer-sub-052-oVomvmI-22-2d67d8a2-7ed2-48a1-9a6d-1e834e33bf94=Assignment(partitions=[test-topic-0000052-2HKJDng-0])}
10:35:38.333 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Finished assignment for group at generation 1: {consumer-sub-019-MASUH9w-11-e29cce5b-9813-4572-b85f-09dd9512b480=Assignment(partitions=[test-topic-0000019-aCPUnu8-0])}
10:35:38.333 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Finished assignment for group at generation 1: {consumer-sub-091-4lK-O0k-35-dfe34f62-ae89-4513-97b7-16c5c0bc7526=Assignment(partitions=[test-topic-0000091-E9z7puA-0])}
10:35:38.335 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-058-CCgSZb8-24-aaab71c1-a76d-4e83-bf3f-03d8b0da3e1a', protocol='range'}
10:35:38.335 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Finished assignment for group at generation 1: {consumer-sub-058-CCgSZb8-24-aaab71c1-a76d-4e83-bf3f-03d8b0da3e1a=Assignment(partitions=[test-topic-0000058-nA5y_Cg-0])}
10:35:38.336 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-016-xxzskEg-10-771919ca-f496-4aab-8936-7764ec805179', protocol='range'}
10:35:38.336 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Finished assignment for group at generation 1: {consumer-sub-016-xxzskEg-10-771919ca-f496-4aab-8936-7764ec805179=Assignment(partitions=[test-topic-0000016-MLlCoec-0])}
10:35:38.336 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-007-kSb0jfw-7-e169bd5f-d90e-4fbc-ae9d-c2aefe365c2c', protocol='range'}
10:35:38.337 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Finished assignment for group at generation 1: {consumer-sub-007-kSb0jfw-7-e169bd5f-d90e-4fbc-ae9d-c2aefe365c2c=Assignment(partitions=[test-topic-0000007-hcTxvVI-0])}
10:35:38.337 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-046-vrUsMA0-20-a4df3078-fd6c-46fa-8666-2037a4c8c207', protocol='range'}
10:35:38.337 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-094-BrzruBE-36-b1603e9f-7b58-473e-910d-c6150a40603c', protocol='range'}
10:35:38.337 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-064-0QANq0Y-26-1974649a-f45b-4841-a274-2bbbd3eb0b8e', protocol='range'}
10:35:38.337 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Finished assignment for group at generation 1: {consumer-sub-046-vrUsMA0-20-a4df3078-fd6c-46fa-8666-2037a4c8c207=Assignment(partitions=[test-topic-0000046-q-UQa6M-0])}
10:35:38.337 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Finished assignment for group at generation 1: {consumer-sub-094-BrzruBE-36-b1603e9f-7b58-473e-910d-c6150a40603c=Assignment(partitions=[test-topic-0000094-Gf5KW3M-0])}
10:35:38.337 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Finished assignment for group at generation 1: {consumer-sub-064-0QANq0Y-26-1974649a-f45b-4841-a274-2bbbd3eb0b8e=Assignment(partitions=[test-topic-0000064-Fd6J5P4-0])}
10:35:38.337 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-010-qhXZymU-8-b504aef7-4334-4c00-b48d-458960123435', protocol='range'}
10:35:38.338 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Finished assignment for group at generation 1: {consumer-sub-010-qhXZymU-8-b504aef7-4334-4c00-b48d-458960123435=Assignment(partitions=[test-topic-0000010-U6HXPng-0])}
10:35:38.339 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-028-ICc1E4A-14-9814b9d3-66ec-4df1-9d6b-8a0f266ed722', protocol='range'}
10:35:38.339 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Finished assignment for group at generation 1: {consumer-sub-028-ICc1E4A-14-9814b9d3-66ec-4df1-9d6b-8a0f266ed722=Assignment(partitions=[test-topic-0000028-Uo_eHQg-0])}
10:35:38.343 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-061-p-joeqs-25-377bf9ad-cad9-4127-b7f1-c0cdc495f72b', protocol='range'}
10:35:38.343 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Finished assignment for group at generation 1: {consumer-sub-061-p-joeqs-25-377bf9ad-cad9-4127-b7f1-c0cdc495f72b=Assignment(partitions=[test-topic-0000061-cZAtpwQ-0])}
10:35:38.345 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-025-5EVGGWg-13-29821947-204b-400c-981d-9b6e7e9e1054', protocol='range'}
10:35:38.345 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Finished assignment for group at generation 1: {consumer-sub-025-5EVGGWg-13-29821947-204b-400c-981d-9b6e7e9e1054=Assignment(partitions=[test-topic-0000025-IRIRha0-0])}
10:35:38.346 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-067-gruf-jQ-27-408b849a-70a6-4c09-9ca0-50bbe99ee7af', protocol='range'}
10:35:38.346 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-022-oQkyCnM-12-d0e2d9fc-bf3a-4a86-bf18-400386646d89', protocol='range'}
10:35:38.346 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Finished assignment for group at generation 1: {consumer-sub-067-gruf-jQ-27-408b849a-70a6-4c09-9ca0-50bbe99ee7af=Assignment(partitions=[test-topic-0000067-8UqVjsA-0])}
10:35:38.346 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Finished assignment for group at generation 1: {consumer-sub-022-oQkyCnM-12-d0e2d9fc-bf3a-4a86-bf18-400386646d89=Assignment(partitions=[test-topic-0000022-adVjIaQ-0])}
10:35:38.348 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-097-avjoPdA-37-9c6f2478-0ddc-4729-95b6-412367cb7696', protocol='range'}
10:35:38.349 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Finished assignment for group at generation 1: {consumer-sub-097-avjoPdA-37-9c6f2478-0ddc-4729-95b6-412367cb7696=Assignment(partitions=[test-topic-0000097-zLO3jFY-0])}
10:35:38.352 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-100-bqIr850-38-d2ac2605-6465-47ca-a740-95c2cff5ae03', protocol='range'}
10:35:38.352 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Finished assignment for group at generation 1: {consumer-sub-100-bqIr850-38-d2ac2605-6465-47ca-a740-95c2cff5ae03=Assignment(partitions=[test-topic-0000100-U4JejkA-0])}
10:35:38.354 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-103-ryJeykA-39-1abeb6d5-4e08-47fb-a575-83a4d6fd81f2', protocol='range'}
10:35:38.354 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Finished assignment for group at generation 1: {consumer-sub-103-ryJeykA-39-1abeb6d5-4e08-47fb-a575-83a4d6fd81f2=Assignment(partitions=[test-topic-0000103-BaW4fGY-0])}
10:35:38.357 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-031-jsgw8Lw-15-5d732958-b733-4a42-a1bc-2c6e0c621837', protocol='range'}
10:35:38.357 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Finished assignment for group at generation 1: {consumer-sub-031-jsgw8Lw-15-5d732958-b733-4a42-a1bc-2c6e0c621837=Assignment(partitions=[test-topic-0000031-_-x9Y-Y-0])}
10:35:38.360 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-070-RHUsvvo-28-803d1002-d6da-408a-b0f1-eb69ca10a790', protocol='range'}
10:35:38.361 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Finished assignment for group at generation 1: {consumer-sub-070-RHUsvvo-28-803d1002-d6da-408a-b0f1-eb69ca10a790=Assignment(partitions=[test-topic-0000070-HtSFP-Q-0])}
10:35:38.364 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-073-WaSvAxI-29-67c8a4c4-1790-4179-ba5a-3b45492ff1e6', protocol='range'}
10:35:38.364 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Finished assignment for group at generation 1: {consumer-sub-073-WaSvAxI-29-67c8a4c4-1790-4179-ba5a-3b45492ff1e6=Assignment(partitions=[test-topic-0000073-CgvL2Cw-0])}
10:35:38.368 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-037-EKNVMKY-17-1cf48839-5ba4-4a98-814f-3a0fa82abaa9', protocol='range'}
10:35:38.368 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Finished assignment for group at generation 1: {consumer-sub-037-EKNVMKY-17-1cf48839-5ba4-4a98-814f-3a0fa82abaa9=Assignment(partitions=[test-topic-0000037-nN3KNZc-0])}
10:35:38.370 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-034-jXfQV4M-16-f9361b3e-95cb-432c-80f4-ae8927c8984b', protocol='range'}
10:35:38.370 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Finished assignment for group at generation 1: {consumer-sub-034-jXfQV4M-16-f9361b3e-95cb-432c-80f4-ae8927c8984b=Assignment(partitions=[test-topic-0000034-mQDs78Y-0])}
10:35:38.371 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-076-mvrRvF8-30-2f44c3d6-b3a4-455a-9619-2c00eb87bd77', protocol='range'}
10:35:38.371 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Finished assignment for group at generation 1: {consumer-sub-076-mvrRvF8-30-2f44c3d6-b3a4-455a-9619-2c00eb87bd77=Assignment(partitions=[test-topic-0000076-9ukLbdc-0])}
10:35:38.372 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-040-nUpe8ic-18-fdc8093f-54b8-4d61-9ea0-83a5a51684a4', protocol='range'}
10:35:38.372 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Finished assignment for group at generation 1: {consumer-sub-040-nUpe8ic-18-fdc8093f-54b8-4d61-9ea0-83a5a51684a4=Assignment(partitions=[test-topic-0000040-ZPiiadY-0])}
10:35:38.377 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-079-cvsLMw4-31-97e621d8-f74d-405e-bc1e-c46496a03899', protocol='range'}
10:35:38.377 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Finished assignment for group at generation 1: {consumer-sub-079-cvsLMw4-31-97e621d8-f74d-405e-bc1e-c46496a03899=Assignment(partitions=[test-topic-0000079-cEsvck0-0])}
10:35:38.380 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-106-0hMyMrI-40-d79b6ea2-04ab-452d-a68f-de5f05168619', protocol='range'}
10:35:38.380 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Finished assignment for group at generation 1: {consumer-sub-106-0hMyMrI-40-d79b6ea2-04ab-452d-a68f-de5f05168619=Assignment(partitions=[test-topic-0000106--MB_6Bg-0])}
10:35:38.383 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-028-ICc1E4A-14-9814b9d3-66ec-4df1-9d6b-8a0f266ed722', protocol='range'}
10:35:38.383 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-055-1horpzI-23-c87a0144-a022-4fa2-81cd-73a1486ed25c', protocol='range'}
10:35:38.383 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-031-jsgw8Lw-15-5d732958-b733-4a42-a1bc-2c6e0c621837', protocol='range'}
10:35:38.383 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-052-oVomvmI-22-2d67d8a2-7ed2-48a1-9a6d-1e834e33bf94', protocol='range'}
10:35:38.383 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-019-MASUH9w-11-e29cce5b-9813-4572-b85f-09dd9512b480', protocol='range'}
10:35:38.383 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-070-RHUsvvo-28-803d1002-d6da-408a-b0f1-eb69ca10a790', protocol='range'}
10:35:38.383 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Notifying assignor about the new Assignment(partitions=[test-topic-0000019-aCPUnu8-0])
10:35:38.383 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Notifying assignor about the new Assignment(partitions=[test-topic-0000028-Uo_eHQg-0])
10:35:38.383 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Notifying assignor about the new Assignment(partitions=[test-topic-0000070-HtSFP-Q-0])
10:35:38.383 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Notifying assignor about the new Assignment(partitions=[test-topic-0000031-_-x9Y-Y-0])
10:35:38.383 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Notifying assignor about the new Assignment(partitions=[test-topic-0000055-PfazGY4-0])
10:35:38.383 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Notifying assignor about the new Assignment(partitions=[test-topic-0000052-2HKJDng-0])
10:35:38.384 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-085-0JPJEnM-33-123c5a31-f57a-4b89-95cb-a2043ebeb525', protocol='range'}
10:35:38.384 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Finished assignment for group at generation 1: {consumer-sub-085-0JPJEnM-33-123c5a31-f57a-4b89-95cb-a2043ebeb525=Assignment(partitions=[test-topic-0000085-N2NHIBM-0])}
10:35:38.386 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Adding newly assigned partitions: test-topic-0000052-2HKJDng-0
10:35:38.386 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Adding newly assigned partitions: test-topic-0000028-Uo_eHQg-0
10:35:38.386 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Adding newly assigned partitions: test-topic-0000070-HtSFP-Q-0
10:35:38.386 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Adding newly assigned partitions: test-topic-0000031-_-x9Y-Y-0
10:35:38.386 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Adding newly assigned partitions: test-topic-0000055-PfazGY4-0
10:35:38.386 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Adding newly assigned partitions: test-topic-0000019-aCPUnu8-0
10:35:38.387 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-082-zkxa8VI-32-49836d06-72e4-416f-8745-05a4829e645b', protocol='range'}
10:35:38.388 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Finished assignment for group at generation 1: {consumer-sub-082-zkxa8VI-32-49836d06-72e4-416f-8745-05a4829e645b=Assignment(partitions=[test-topic-0000082-FLXnEIs-0])}
10:35:38.393 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-025-5EVGGWg-13-29821947-204b-400c-981d-9b6e7e9e1054', protocol='range'}
10:35:38.393 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Notifying assignor about the new Assignment(partitions=[test-topic-0000025-IRIRha0-0])
10:35:38.393 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Adding newly assigned partitions: test-topic-0000025-IRIRha0-0
10:35:38.393 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-067-gruf-jQ-27-408b849a-70a6-4c09-9ca0-50bbe99ee7af', protocol='range'}
10:35:38.393 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-016-xxzskEg-10-771919ca-f496-4aab-8936-7764ec805179', protocol='range'}
10:35:38.393 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-049-QC2A1E8-21-c4c234fb-12c4-496e-a180-eb5841f277de', protocol='range'}
10:35:38.393 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000067-8UqVjsA-0])
10:35:38.393 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Notifying assignor about the new Assignment(partitions=[test-topic-0000016-MLlCoec-0])
10:35:38.393 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Adding newly assigned partitions: test-topic-0000067-8UqVjsA-0
10:35:38.393 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Notifying assignor about the new Assignment(partitions=[test-topic-0000049-sFgFDYQ-0])
10:35:38.393 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Adding newly assigned partitions: test-topic-0000016-MLlCoec-0
10:35:38.393 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Adding newly assigned partitions: test-topic-0000049-sFgFDYQ-0
10:35:38.393 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-088-qObEwis-34-19161730-c580-45bc-89e0-84cd02c6e32e', protocol='range'}
10:35:38.393 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-112-ozdFI5w-42-9324967c-3da7-438c-ab9f-213aa34bde93', protocol='range'}
10:35:38.393 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Finished assignment for group at generation 1: {consumer-sub-112-ozdFI5w-42-9324967c-3da7-438c-ab9f-213aa34bde93=Assignment(partitions=[test-topic-0000112-SsxIWSY-0])}
10:35:38.393 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-061-p-joeqs-25-377bf9ad-cad9-4127-b7f1-c0cdc495f72b', protocol='range'}
10:35:38.393 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Finished assignment for group at generation 1: {consumer-sub-088-qObEwis-34-19161730-c580-45bc-89e0-84cd02c6e32e=Assignment(partitions=[test-topic-0000088-Stb9i1o-0])}
10:35:38.394 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-109-59qp1r8-41-a131679f-f513-46c0-adc7-0d364539ede7', protocol='range'}
10:35:38.394 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Notifying assignor about the new Assignment(partitions=[test-topic-0000061-cZAtpwQ-0])
10:35:38.394 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-043-VRipANU-19-ff028afa-f38c-4a1a-86c7-082ab365bf54', protocol='range'}
10:35:38.394 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Adding newly assigned partitions: test-topic-0000061-cZAtpwQ-0
10:35:38.394 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Notifying assignor about the new Assignment(partitions=[test-topic-0000043-UplvRtE-0])
10:35:38.394 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Finished assignment for group at generation 1: {consumer-sub-109-59qp1r8-41-a131679f-f513-46c0-adc7-0d364539ede7=Assignment(partitions=[test-topic-0000109-LtOlXJY-0])}
10:35:38.394 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Adding newly assigned partitions: test-topic-0000043-UplvRtE-0
10:35:38.394 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-091-4lK-O0k-35-dfe34f62-ae89-4513-97b7-16c5c0bc7526', protocol='range'}
10:35:38.394 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Notifying assignor about the new Assignment(partitions=[test-topic-0000091-E9z7puA-0])
10:35:38.394 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Adding newly assigned partitions: test-topic-0000091-E9z7puA-0
10:35:38.395 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-115-3zUz_KI-43-d9d2ab4c-33b5-4725-a77a-926ee2b1127f', protocol='range'}
10:35:38.395 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Finished assignment for group at generation 1: {consumer-sub-115-3zUz_KI-43-d9d2ab4c-33b5-4725-a77a-926ee2b1127f=Assignment(partitions=[test-topic-0000115-x3VDmZM-0])}
10:35:38.396 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-040-nUpe8ic-18-fdc8093f-54b8-4d61-9ea0-83a5a51684a4', protocol='range'}
10:35:38.396 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Notifying assignor about the new Assignment(partitions=[test-topic-0000040-ZPiiadY-0])
10:35:38.396 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Adding newly assigned partitions: test-topic-0000040-ZPiiadY-0
10:35:38.397 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-085-0JPJEnM-33-123c5a31-f57a-4b89-95cb-a2043ebeb525', protocol='range'}
10:35:38.397 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Notifying assignor about the new Assignment(partitions=[test-topic-0000085-N2NHIBM-0])
10:35:38.397 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Adding newly assigned partitions: test-topic-0000085-N2NHIBM-0
10:35:38.399 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-013-8FJsfOU-9-2a447fb9-1de0-432c-a0b1-fb86dc5fd606', protocol='range'}
10:35:38.399 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-022-oQkyCnM-12-d0e2d9fc-bf3a-4a86-bf18-400386646d89', protocol='range'}
10:35:38.399 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Notifying assignor about the new Assignment(partitions=[test-topic-0000013-upYB7Dk-0])
10:35:38.399 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Adding newly assigned partitions: test-topic-0000013-upYB7Dk-0
10:35:38.399 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Notifying assignor about the new Assignment(partitions=[test-topic-0000022-adVjIaQ-0])
10:35:38.399 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Adding newly assigned partitions: test-topic-0000022-adVjIaQ-0
10:35:38.401 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-118-GV4H62g-44-8a4fcc86-ee12-4d15-b4a3-518495d57fe7', protocol='range'}
10:35:38.401 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Finished assignment for group at generation 1: {consumer-sub-118-GV4H62g-44-8a4fcc86-ee12-4d15-b4a3-518495d57fe7=Assignment(partitions=[test-topic-0000118-Mhw4hJk-0])}
10:35:38.402 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-010-qhXZymU-8-b504aef7-4334-4c00-b48d-458960123435', protocol='range'}
10:35:38.402 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-034-jXfQV4M-16-f9361b3e-95cb-432c-80f4-ae8927c8984b', protocol='range'}
10:35:38.402 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Notifying assignor about the new Assignment(partitions=[test-topic-0000010-U6HXPng-0])
10:35:38.402 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Notifying assignor about the new Assignment(partitions=[test-topic-0000034-mQDs78Y-0])
10:35:38.402 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Adding newly assigned partitions: test-topic-0000010-U6HXPng-0
10:35:38.402 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Adding newly assigned partitions: test-topic-0000034-mQDs78Y-0
10:35:38.402 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-100-bqIr850-38-d2ac2605-6465-47ca-a740-95c2cff5ae03', protocol='range'}
10:35:38.402 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Notifying assignor about the new Assignment(partitions=[test-topic-0000100-U4JejkA-0])
10:35:38.402 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-064-0QANq0Y-26-1974649a-f45b-4841-a274-2bbbd3eb0b8e', protocol='range'}
10:35:38.402 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Adding newly assigned partitions: test-topic-0000100-U4JejkA-0
10:35:38.402 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Notifying assignor about the new Assignment(partitions=[test-topic-0000064-Fd6J5P4-0])
10:35:38.402 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Adding newly assigned partitions: test-topic-0000064-Fd6J5P4-0
10:35:38.403 [pool-16-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Found no committed offset for partition test-topic-0000028-Uo_eHQg-0
10:35:38.403 [pool-24-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Found no committed offset for partition test-topic-0000052-2HKJDng-0
10:35:38.403 [pool-25-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Found no committed offset for partition test-topic-0000055-PfazGY4-0
10:35:38.403 [pool-17-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Found no committed offset for partition test-topic-0000031-_-x9Y-Y-0
10:35:38.403 [pool-30-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Found no committed offset for partition test-topic-0000070-HtSFP-Q-0
10:35:38.403 [pool-13-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Found no committed offset for partition test-topic-0000019-aCPUnu8-0
10:35:38.404 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-007-kSb0jfw-7-e169bd5f-d90e-4fbc-ae9d-c2aefe365c2c', protocol='range'}
10:35:38.404 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Notifying assignor about the new Assignment(partitions=[test-topic-0000007-hcTxvVI-0])
10:35:38.404 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Adding newly assigned partitions: test-topic-0000007-hcTxvVI-0
10:35:38.404 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-046-vrUsMA0-20-a4df3078-fd6c-46fa-8666-2037a4c8c207', protocol='range'}
10:35:38.404 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Notifying assignor about the new Assignment(partitions=[test-topic-0000046-q-UQa6M-0])
10:35:38.404 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-076-mvrRvF8-30-2f44c3d6-b3a4-455a-9619-2c00eb87bd77', protocol='range'}
10:35:38.404 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Adding newly assigned partitions: test-topic-0000046-q-UQa6M-0
10:35:38.404 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Notifying assignor about the new Assignment(partitions=[test-topic-0000076-9ukLbdc-0])
10:35:38.404 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Adding newly assigned partitions: test-topic-0000076-9ukLbdc-0
10:35:38.405 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-097-avjoPdA-37-9c6f2478-0ddc-4729-95b6-412367cb7696', protocol='range'}
10:35:38.405 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Notifying assignor about the new Assignment(partitions=[test-topic-0000097-zLO3jFY-0])
10:35:38.405 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Adding newly assigned partitions: test-topic-0000097-zLO3jFY-0
10:35:38.406 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-058-CCgSZb8-24-aaab71c1-a76d-4e83-bf3f-03d8b0da3e1a', protocol='range'}
10:35:38.406 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-094-BrzruBE-36-b1603e9f-7b58-473e-910d-c6150a40603c', protocol='range'}
10:35:38.406 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Notifying assignor about the new Assignment(partitions=[test-topic-0000058-nA5y_Cg-0])
10:35:38.406 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Notifying assignor about the new Assignment(partitions=[test-topic-0000094-Gf5KW3M-0])
10:35:38.406 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Adding newly assigned partitions: test-topic-0000058-nA5y_Cg-0
10:35:38.406 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Adding newly assigned partitions: test-topic-0000094-Gf5KW3M-0
10:35:38.406 [pool-27-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Found no committed offset for partition test-topic-0000061-cZAtpwQ-0
10:35:38.406 [pool-29-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Found no committed offset for partition test-topic-0000067-8UqVjsA-0
10:35:38.406 [pool-20-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Found no committed offset for partition test-topic-0000040-ZPiiadY-0
10:35:38.406 [pool-12-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Found no committed offset for partition test-topic-0000016-MLlCoec-0
10:35:38.406 [pool-11-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Found no committed offset for partition test-topic-0000013-upYB7Dk-0
10:35:38.407 [pool-35-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Found no committed offset for partition test-topic-0000085-N2NHIBM-0
10:35:38.406 [pool-23-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Found no committed offset for partition test-topic-0000049-sFgFDYQ-0
10:35:38.407 [pool-14-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Found no committed offset for partition test-topic-0000022-adVjIaQ-0
10:35:38.407 [pool-21-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Found no committed offset for partition test-topic-0000043-UplvRtE-0
10:35:38.407 [pool-40-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Found no committed offset for partition test-topic-0000100-U4JejkA-0
10:35:38.407 [pool-15-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Found no committed offset for partition test-topic-0000025-IRIRha0-0
10:35:38.408 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-106-0hMyMrI-40-d79b6ea2-04ab-452d-a68f-de5f05168619', protocol='range'}
10:35:38.408 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Notifying assignor about the new Assignment(partitions=[test-topic-0000106--MB_6Bg-0])
10:35:38.408 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Adding newly assigned partitions: test-topic-0000106--MB_6Bg-0
10:35:38.408 [pool-37-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Found no committed offset for partition test-topic-0000091-E9z7puA-0
10:35:38.408 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-082-zkxa8VI-32-49836d06-72e4-416f-8745-05a4829e645b', protocol='range'}
10:35:38.408 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Notifying assignor about the new Assignment(partitions=[test-topic-0000082-FLXnEIs-0])
10:35:38.408 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Adding newly assigned partitions: test-topic-0000082-FLXnEIs-0
10:35:38.408 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-073-WaSvAxI-29-67c8a4c4-1790-4179-ba5a-3b45492ff1e6', protocol='range'}
10:35:38.409 [pool-42-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Found no committed offset for partition test-topic-0000106--MB_6Bg-0
10:35:38.409 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Notifying assignor about the new Assignment(partitions=[test-topic-0000073-CgvL2Cw-0])
10:35:38.409 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Adding newly assigned partitions: test-topic-0000073-CgvL2Cw-0
10:35:38.409 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-103-ryJeykA-39-1abeb6d5-4e08-47fb-a575-83a4d6fd81f2', protocol='range'}
10:35:38.409 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Notifying assignor about the new Assignment(partitions=[test-topic-0000103-BaW4fGY-0])
10:35:38.409 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Adding newly assigned partitions: test-topic-0000103-BaW4fGY-0
10:35:38.409 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-037-EKNVMKY-17-1cf48839-5ba4-4a98-814f-3a0fa82abaa9', protocol='range'}
10:35:38.409 [pool-34-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Found no committed offset for partition test-topic-0000082-FLXnEIs-0
10:35:38.409 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Notifying assignor about the new Assignment(partitions=[test-topic-0000037-nN3KNZc-0])
10:35:38.409 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Adding newly assigned partitions: test-topic-0000037-nN3KNZc-0
10:35:38.409 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-115-3zUz_KI-43-d9d2ab4c-33b5-4725-a77a-926ee2b1127f', protocol='range'}
10:35:38.410 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Notifying assignor about the new Assignment(partitions=[test-topic-0000115-x3VDmZM-0])
10:35:38.410 [pool-31-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Found no committed offset for partition test-topic-0000073-CgvL2Cw-0
10:35:38.410 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Adding newly assigned partitions: test-topic-0000115-x3VDmZM-0
10:35:38.410 [pool-19-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Found no committed offset for partition test-topic-0000037-nN3KNZc-0
10:35:38.410 [pool-45-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Found no committed offset for partition test-topic-0000115-x3VDmZM-0
10:35:38.410 [pool-41-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Found no committed offset for partition test-topic-0000103-BaW4fGY-0
10:35:38.411 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-112-ozdFI5w-42-9324967c-3da7-438c-ab9f-213aa34bde93', protocol='range'}
10:35:38.411 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-109-59qp1r8-41-a131679f-f513-46c0-adc7-0d364539ede7', protocol='range'}
10:35:38.411 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Notifying assignor about the new Assignment(partitions=[test-topic-0000109-LtOlXJY-0])
10:35:38.411 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Adding newly assigned partitions: test-topic-0000109-LtOlXJY-0
10:35:38.411 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Notifying assignor about the new Assignment(partitions=[test-topic-0000112-SsxIWSY-0])
10:35:38.411 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Adding newly assigned partitions: test-topic-0000112-SsxIWSY-0
10:35:38.412 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-079-cvsLMw4-31-97e621d8-f74d-405e-bc1e-c46496a03899', protocol='range'}
10:35:38.412 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Notifying assignor about the new Assignment(partitions=[test-topic-0000079-cEsvck0-0])
10:35:38.412 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Adding newly assigned partitions: test-topic-0000079-cEsvck0-0
10:35:38.413 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-124-wVmvIYQ-46-3c5b5c23-01e1-4576-b3ad-c497d5cc5d52', protocol='range'}
10:35:38.413 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-088-qObEwis-34-19161730-c580-45bc-89e0-84cd02c6e32e', protocol='range'}
10:35:38.413 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Finished assignment for group at generation 1: {consumer-sub-124-wVmvIYQ-46-3c5b5c23-01e1-4576-b3ad-c497d5cc5d52=Assignment(partitions=[test-topic-0000124-2EDO_w4-0])}
10:35:38.413 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Notifying assignor about the new Assignment(partitions=[test-topic-0000088-Stb9i1o-0])
10:35:38.413 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Adding newly assigned partitions: test-topic-0000088-Stb9i1o-0
10:35:38.416 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-121-7dR5cuk-45-a724d78a-3de0-4f47-9f2d-d3d011bbeef8', protocol='range'}
10:35:38.416 [pool-28-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Found no committed offset for partition test-topic-0000064-Fd6J5P4-0
10:35:38.416 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Finished assignment for group at generation 1: {consumer-sub-121-7dR5cuk-45-a724d78a-3de0-4f47-9f2d-d3d011bbeef8=Assignment(partitions=[test-topic-0000121-114XZfc-0])}
10:35:38.416 [pool-22-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Found no committed offset for partition test-topic-0000046-q-UQa6M-0
10:35:38.417 [pool-38-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Found no committed offset for partition test-topic-0000094-Gf5KW3M-0
10:35:38.416 [pool-9-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Found no committed offset for partition test-topic-0000007-hcTxvVI-0
10:35:38.417 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-118-GV4H62g-44-8a4fcc86-ee12-4d15-b4a3-518495d57fe7', protocol='range'}
10:35:38.417 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Notifying assignor about the new Assignment(partitions=[test-topic-0000118-Mhw4hJk-0])
10:35:38.417 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Adding newly assigned partitions: test-topic-0000118-Mhw4hJk-0
10:35:38.418 [pool-10-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Found no committed offset for partition test-topic-0000010-U6HXPng-0
10:35:38.418 [pool-26-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Found no committed offset for partition test-topic-0000058-nA5y_Cg-0
10:35:38.418 [pool-44-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Found no committed offset for partition test-topic-0000112-SsxIWSY-0
10:35:38.418 [pool-36-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Found no committed offset for partition test-topic-0000088-Stb9i1o-0
10:35:38.419 [pool-32-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Found no committed offset for partition test-topic-0000076-9ukLbdc-0
10:35:38.419 [pool-43-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Found no committed offset for partition test-topic-0000109-LtOlXJY-0
10:35:38.419 [pool-33-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Found no committed offset for partition test-topic-0000079-cEsvck0-0
10:35:38.419 [pool-46-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Found no committed offset for partition test-topic-0000118-Mhw4hJk-0
10:35:38.420 [pool-39-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Found no committed offset for partition test-topic-0000097-zLO3jFY-0
10:35:38.422 [pool-18-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Found no committed offset for partition test-topic-0000034-mQDs78Y-0
10:35:38.423 [pool-22-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Resetting offset for partition test-topic-0000046-q-UQa6M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.423 [pool-38-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Resetting offset for partition test-topic-0000094-Gf5KW3M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.423 [pool-15-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Resetting offset for partition test-topic-0000025-IRIRha0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.424 [pool-16-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Resetting offset for partition test-topic-0000028-Uo_eHQg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.424 [pool-40-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Resetting offset for partition test-topic-0000100-U4JejkA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.423 [pool-10-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Resetting offset for partition test-topic-0000010-U6HXPng-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.423 [pool-26-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Resetting offset for partition test-topic-0000058-nA5y_Cg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.424 [pool-35-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Resetting offset for partition test-topic-0000085-N2NHIBM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.424 [pool-18-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Resetting offset for partition test-topic-0000034-mQDs78Y-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.424 [pool-42-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Resetting offset for partition test-topic-0000106--MB_6Bg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.424 [pool-20-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Resetting offset for partition test-topic-0000040-ZPiiadY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.425 [pool-19-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Resetting offset for partition test-topic-0000037-nN3KNZc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.425 [pool-29-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Resetting offset for partition test-topic-0000067-8UqVjsA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.425 [pool-14-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Resetting offset for partition test-topic-0000022-adVjIaQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.425 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-121-7dR5cuk-45-a724d78a-3de0-4f47-9f2d-d3d011bbeef8', protocol='range'}
10:35:38.425 [pool-32-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Resetting offset for partition test-topic-0000076-9ukLbdc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.425 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Notifying assignor about the new Assignment(partitions=[test-topic-0000121-114XZfc-0])
10:35:38.426 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Adding newly assigned partitions: test-topic-0000121-114XZfc-0
10:35:38.426 [pool-46-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Resetting offset for partition test-topic-0000118-Mhw4hJk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.426 [pool-39-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Resetting offset for partition test-topic-0000097-zLO3jFY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.425 [pool-11-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Resetting offset for partition test-topic-0000013-upYB7Dk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.426 [pool-36-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Resetting offset for partition test-topic-0000088-Stb9i1o-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.426 [pool-21-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Resetting offset for partition test-topic-0000043-UplvRtE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.425 [pool-25-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Resetting offset for partition test-topic-0000055-PfazGY4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.426 [pool-33-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Resetting offset for partition test-topic-0000079-cEsvck0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.426 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-127-GFM7wfU-47-05427824-0a24-4d14-b7b9-a9f38be81146', protocol='range'}
10:35:38.426 [pool-31-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Resetting offset for partition test-topic-0000073-CgvL2Cw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.426 [pool-34-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Resetting offset for partition test-topic-0000082-FLXnEIs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.426 [pool-27-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Resetting offset for partition test-topic-0000061-cZAtpwQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.426 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Finished assignment for group at generation 1: {consumer-sub-127-GFM7wfU-47-05427824-0a24-4d14-b7b9-a9f38be81146=Assignment(partitions=[test-topic-0000127-rXhL7lw-0])}
10:35:38.427 [pool-12-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Resetting offset for partition test-topic-0000016-MLlCoec-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.427 [pool-45-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Resetting offset for partition test-topic-0000115-x3VDmZM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.427 [pool-23-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Resetting offset for partition test-topic-0000049-sFgFDYQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.426 [pool-44-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Resetting offset for partition test-topic-0000112-SsxIWSY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.427 [pool-37-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Resetting offset for partition test-topic-0000091-E9z7puA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.427 [pool-43-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Resetting offset for partition test-topic-0000109-LtOlXJY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.427 [pool-9-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Resetting offset for partition test-topic-0000007-hcTxvVI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.425 [pool-24-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Resetting offset for partition test-topic-0000052-2HKJDng-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.427 [pool-28-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Resetting offset for partition test-topic-0000064-Fd6J5P4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.427 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-124-wVmvIYQ-46-3c5b5c23-01e1-4576-b3ad-c497d5cc5d52', protocol='range'}
10:35:38.428 [pool-47-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Found no committed offset for partition test-topic-0000121-114XZfc-0
10:35:38.428 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000124-2EDO_w4-0])
10:35:38.428 [pool-30-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Resetting offset for partition test-topic-0000070-HtSFP-Q-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.428 [pool-13-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Resetting offset for partition test-topic-0000019-aCPUnu8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.428 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Adding newly assigned partitions: test-topic-0000124-2EDO_w4-0
10:35:38.428 [pool-41-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Resetting offset for partition test-topic-0000103-BaW4fGY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.429 [pool-17-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Resetting offset for partition test-topic-0000031-_-x9Y-Y-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.429 [pool-48-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Found no committed offset for partition test-topic-0000124-2EDO_w4-0
10:35:38.430 [pool-47-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Resetting offset for partition test-topic-0000121-114XZfc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.431 [pool-48-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Resetting offset for partition test-topic-0000124-2EDO_w4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.432 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-127-GFM7wfU-47-05427824-0a24-4d14-b7b9-a9f38be81146', protocol='range'}
10:35:38.432 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Notifying assignor about the new Assignment(partitions=[test-topic-0000127-rXhL7lw-0])
10:35:38.432 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Adding newly assigned partitions: test-topic-0000127-rXhL7lw-0
10:35:38.435 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-133-herww4w-49-fa71df6c-21e2-48c5-b8d8-1e448dee0290', protocol='range'}
10:35:38.435 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Finished assignment for group at generation 1: {consumer-sub-133-herww4w-49-fa71df6c-21e2-48c5-b8d8-1e448dee0290=Assignment(partitions=[test-topic-0000133-1ZZQVqE-0])}
10:35:38.435 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-130-R2MzGZc-48-8688cfce-1470-4429-96fe-1df55f9e79f4', protocol='range'}
10:35:38.436 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Finished assignment for group at generation 1: {consumer-sub-130-R2MzGZc-48-8688cfce-1470-4429-96fe-1df55f9e79f4=Assignment(partitions=[test-topic-0000130-fdJ7vTs-0])}
10:35:38.437 [pool-49-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Found no committed offset for partition test-topic-0000127-rXhL7lw-0
10:35:38.439 [pool-49-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Resetting offset for partition test-topic-0000127-rXhL7lw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.440 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-133-herww4w-49-fa71df6c-21e2-48c5-b8d8-1e448dee0290', protocol='range'}
10:35:38.440 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Notifying assignor about the new Assignment(partitions=[test-topic-0000133-1ZZQVqE-0])
10:35:38.440 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Adding newly assigned partitions: test-topic-0000133-1ZZQVqE-0
10:35:38.441 [pool-51-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Found no committed offset for partition test-topic-0000133-1ZZQVqE-0
10:35:38.441 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-130-R2MzGZc-48-8688cfce-1470-4429-96fe-1df55f9e79f4', protocol='range'}
10:35:38.441 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Notifying assignor about the new Assignment(partitions=[test-topic-0000130-fdJ7vTs-0])
10:35:38.441 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Adding newly assigned partitions: test-topic-0000130-fdJ7vTs-0
10:35:38.442 [pool-50-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Found no committed offset for partition test-topic-0000130-fdJ7vTs-0
10:35:38.443 [pool-51-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Resetting offset for partition test-topic-0000133-1ZZQVqE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.444 [pool-50-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Resetting offset for partition test-topic-0000130-fdJ7vTs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.448 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-136-hnM0maI-50-8a67a670-0f38-4a67-87d9-3c148cb3c057', protocol='range'}
10:35:38.448 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Finished assignment for group at generation 1: {consumer-sub-136-hnM0maI-50-8a67a670-0f38-4a67-87d9-3c148cb3c057=Assignment(partitions=[test-topic-0000136-nBov2d0-0])}
10:35:38.451 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-139-Jd7jOg8-51-4f50d45d-3f54-420c-967b-35c7e9b87972', protocol='range'}
10:35:38.451 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Finished assignment for group at generation 1: {consumer-sub-139-Jd7jOg8-51-4f50d45d-3f54-420c-967b-35c7e9b87972=Assignment(partitions=[test-topic-0000139-XTb1OHw-0])}
10:35:38.452 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-136-hnM0maI-50-8a67a670-0f38-4a67-87d9-3c148cb3c057', protocol='range'}
10:35:38.452 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Notifying assignor about the new Assignment(partitions=[test-topic-0000136-nBov2d0-0])
10:35:38.452 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Adding newly assigned partitions: test-topic-0000136-nBov2d0-0
10:35:38.453 [pool-52-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Found no committed offset for partition test-topic-0000136-nBov2d0-0
10:35:38.455 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-139-Jd7jOg8-51-4f50d45d-3f54-420c-967b-35c7e9b87972', protocol='range'}
10:35:38.455 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Notifying assignor about the new Assignment(partitions=[test-topic-0000139-XTb1OHw-0])
10:35:38.455 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Adding newly assigned partitions: test-topic-0000139-XTb1OHw-0
10:35:38.455 [pool-52-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Resetting offset for partition test-topic-0000136-nBov2d0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.456 [pool-53-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Found no committed offset for partition test-topic-0000139-XTb1OHw-0
10:35:38.457 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-142-zj_UYlg-52-cf1bd90e-0ffb-4a3f-9634-f06e2de032db', protocol='range'}
10:35:38.457 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Finished assignment for group at generation 1: {consumer-sub-142-zj_UYlg-52-cf1bd90e-0ffb-4a3f-9634-f06e2de032db=Assignment(partitions=[test-topic-0000142-QTL4iuM-0])}
10:35:38.458 [pool-53-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Resetting offset for partition test-topic-0000139-XTb1OHw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.462 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-142-zj_UYlg-52-cf1bd90e-0ffb-4a3f-9634-f06e2de032db', protocol='range'}
10:35:38.462 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Notifying assignor about the new Assignment(partitions=[test-topic-0000142-QTL4iuM-0])
10:35:38.462 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Adding newly assigned partitions: test-topic-0000142-QTL4iuM-0
10:35:38.463 [pool-54-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Found no committed offset for partition test-topic-0000142-QTL4iuM-0
10:35:38.465 [pool-54-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Resetting offset for partition test-topic-0000142-QTL4iuM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.465 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-145-nXOR4_o-53-f1d9e39f-db20-4d96-9716-a869c277d388', protocol='range'}
10:35:38.466 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Finished assignment for group at generation 1: {consumer-sub-145-nXOR4_o-53-f1d9e39f-db20-4d96-9716-a869c277d388=Assignment(partitions=[test-topic-0000145-SgkRMUE-0])}
10:35:38.469 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-145-nXOR4_o-53-f1d9e39f-db20-4d96-9716-a869c277d388', protocol='range'}
10:35:38.470 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Notifying assignor about the new Assignment(partitions=[test-topic-0000145-SgkRMUE-0])
10:35:38.470 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Adding newly assigned partitions: test-topic-0000145-SgkRMUE-0
10:35:38.470 [pool-55-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Found no committed offset for partition test-topic-0000145-SgkRMUE-0
10:35:38.473 [pool-55-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Resetting offset for partition test-topic-0000145-SgkRMUE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.485 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-151-dol9qp0-55-823de585-bc89-4c6a-9e45-9f2485a7cd19', protocol='range'}
10:35:38.486 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Finished assignment for group at generation 1: {consumer-sub-151-dol9qp0-55-823de585-bc89-4c6a-9e45-9f2485a7cd19=Assignment(partitions=[test-topic-0000151-VWnPQfI-0])}
10:35:38.491 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-151-dol9qp0-55-823de585-bc89-4c6a-9e45-9f2485a7cd19', protocol='range'}
10:35:38.491 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Notifying assignor about the new Assignment(partitions=[test-topic-0000151-VWnPQfI-0])
10:35:38.491 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Adding newly assigned partitions: test-topic-0000151-VWnPQfI-0
10:35:38.492 [pool-57-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Found no committed offset for partition test-topic-0000151-VWnPQfI-0
10:35:38.494 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-154-oYkwY_c-56-a5f71378-203c-41b8-afc3-928265aefb57', protocol='range'}
10:35:38.494 [pool-57-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Resetting offset for partition test-topic-0000151-VWnPQfI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.494 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Finished assignment for group at generation 1: {consumer-sub-154-oYkwY_c-56-a5f71378-203c-41b8-afc3-928265aefb57=Assignment(partitions=[test-topic-0000154-HE2aBZ8-0])}
10:35:38.498 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-154-oYkwY_c-56-a5f71378-203c-41b8-afc3-928265aefb57', protocol='range'}
10:35:38.498 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Notifying assignor about the new Assignment(partitions=[test-topic-0000154-HE2aBZ8-0])
10:35:38.498 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Adding newly assigned partitions: test-topic-0000154-HE2aBZ8-0
10:35:38.499 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-157-hxUlyBo-57-16cbca88-9fe9-41a0-bc1f-73cfda0ac225', protocol='range'}
10:35:38.499 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Finished assignment for group at generation 1: {consumer-sub-157-hxUlyBo-57-16cbca88-9fe9-41a0-bc1f-73cfda0ac225=Assignment(partitions=[test-topic-0000157-6w1ItIc-0])}
10:35:38.499 [pool-58-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Found no committed offset for partition test-topic-0000154-HE2aBZ8-0
10:35:38.501 [pool-58-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Resetting offset for partition test-topic-0000154-HE2aBZ8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.502 [main] INFO WorkloadGenerator - Created 507 external consumers in 3516.792 ms
10:35:38.504 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-157-hxUlyBo-57-16cbca88-9fe9-41a0-bc1f-73cfda0ac225', protocol='range'}
10:35:38.504 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Notifying assignor about the new Assignment(partitions=[test-topic-0000157-6w1ItIc-0])
10:35:38.504 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Adding newly assigned partitions: test-topic-0000157-6w1ItIc-0
10:35:38.504 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-148-dURIGro-54-2da45e9c-a8de-402c-a997-c9c62788ff0c', protocol='range'}
10:35:38.504 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Finished assignment for group at generation 1: {consumer-sub-148-dURIGro-54-2da45e9c-a8de-402c-a997-c9c62788ff0c=Assignment(partitions=[test-topic-0000148-qpE9hNw-0])}
10:35:38.505 [pool-59-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Found no committed offset for partition test-topic-0000157-6w1ItIc-0
10:35:38.507 [pool-59-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Resetting offset for partition test-topic-0000157-6w1ItIc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.508 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-148-dURIGro-54-2da45e9c-a8de-402c-a997-c9c62788ff0c', protocol='range'}
10:35:38.508 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Notifying assignor about the new Assignment(partitions=[test-topic-0000148-qpE9hNw-0])
10:35:38.508 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Adding newly assigned partitions: test-topic-0000148-qpE9hNw-0
10:35:38.509 [pool-56-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Found no committed offset for partition test-topic-0000148-qpE9hNw-0
10:35:38.511 [pool-56-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Resetting offset for partition test-topic-0000148-qpE9hNw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.516 [main] INFO ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-sub-006-tfQv-qI-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 1200000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sub-006-tfQv-qI
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

10:35:38.521 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-160-VA65eYM-58-2e206900-33a9-42ce-a449-5176ea44827a', protocol='range'}
10:35:38.521 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Finished assignment for group at generation 1: {consumer-sub-160-VA65eYM-58-2e206900-33a9-42ce-a449-5176ea44827a=Assignment(partitions=[test-topic-0000160-B3v6Dzk-0])}
10:35:38.526 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-160-VA65eYM-58-2e206900-33a9-42ce-a449-5176ea44827a', protocol='range'}
10:35:38.526 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Notifying assignor about the new Assignment(partitions=[test-topic-0000160-B3v6Dzk-0])
10:35:38.526 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Adding newly assigned partitions: test-topic-0000160-B3v6Dzk-0
10:35:38.527 [pool-60-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Found no committed offset for partition test-topic-0000160-B3v6Dzk-0
10:35:38.528 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-163-nxfAmZ8-59-aceece95-3d0c-44db-a0eb-817a68e8dad5', protocol='range'}
10:35:38.528 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Finished assignment for group at generation 1: {consumer-sub-163-nxfAmZ8-59-aceece95-3d0c-44db-a0eb-817a68e8dad5=Assignment(partitions=[test-topic-0000163-ZKG2hH8-0])}
10:35:38.528 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-166-uAWZs3Y-60-83ffa56a-7cbd-4f4c-8aa8-b879a1097287', protocol='range'}
10:35:38.528 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Finished assignment for group at generation 1: {consumer-sub-166-uAWZs3Y-60-83ffa56a-7cbd-4f4c-8aa8-b879a1097287=Assignment(partitions=[test-topic-0000166-Xn8hVBw-0])}
10:35:38.529 [pool-60-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Resetting offset for partition test-topic-0000160-B3v6Dzk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.532 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-166-uAWZs3Y-60-83ffa56a-7cbd-4f4c-8aa8-b879a1097287', protocol='range'}
10:35:38.532 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Notifying assignor about the new Assignment(partitions=[test-topic-0000166-Xn8hVBw-0])
10:35:38.532 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Adding newly assigned partitions: test-topic-0000166-Xn8hVBw-0
10:35:38.532 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-163-nxfAmZ8-59-aceece95-3d0c-44db-a0eb-817a68e8dad5', protocol='range'}
10:35:38.532 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Notifying assignor about the new Assignment(partitions=[test-topic-0000163-ZKG2hH8-0])
10:35:38.532 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Adding newly assigned partitions: test-topic-0000163-ZKG2hH8-0
10:35:38.533 [pool-62-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Found no committed offset for partition test-topic-0000166-Xn8hVBw-0
10:35:38.533 [pool-61-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Found no committed offset for partition test-topic-0000163-ZKG2hH8-0
10:35:38.535 [pool-62-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Resetting offset for partition test-topic-0000166-Xn8hVBw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.535 [pool-61-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Resetting offset for partition test-topic-0000163-ZKG2hH8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.548 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-169-dswsaeQ-61-1b2d1a2c-986b-4fbf-9794-af81eeb13a9d', protocol='range'}
10:35:38.549 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Finished assignment for group at generation 1: {consumer-sub-169-dswsaeQ-61-1b2d1a2c-986b-4fbf-9794-af81eeb13a9d=Assignment(partitions=[test-topic-0000169-ghF_OKc-0])}
10:35:38.551 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-175-1iz0jec-63-54160100-12b3-4a89-b60b-4cb48e0730bc', protocol='range'}
10:35:38.551 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Finished assignment for group at generation 1: {consumer-sub-175-1iz0jec-63-54160100-12b3-4a89-b60b-4cb48e0730bc=Assignment(partitions=[test-topic-0000175-LbeFESo-0])}
10:35:38.553 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-169-dswsaeQ-61-1b2d1a2c-986b-4fbf-9794-af81eeb13a9d', protocol='range'}
10:35:38.553 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000169-ghF_OKc-0])
10:35:38.553 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Adding newly assigned partitions: test-topic-0000169-ghF_OKc-0
10:35:38.553 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-172-rVJbmyc-62-fb6a65f9-9ba0-45d4-b53d-bc96c51fde2a', protocol='range'}
10:35:38.554 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Finished assignment for group at generation 1: {consumer-sub-172-rVJbmyc-62-fb6a65f9-9ba0-45d4-b53d-bc96c51fde2a=Assignment(partitions=[test-topic-0000172-MDi5xIU-0])}
10:35:38.554 [pool-63-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Found no committed offset for partition test-topic-0000169-ghF_OKc-0
10:35:38.555 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-175-1iz0jec-63-54160100-12b3-4a89-b60b-4cb48e0730bc', protocol='range'}
10:35:38.555 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Notifying assignor about the new Assignment(partitions=[test-topic-0000175-LbeFESo-0])
10:35:38.555 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Adding newly assigned partitions: test-topic-0000175-LbeFESo-0
10:35:38.556 [pool-65-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Found no committed offset for partition test-topic-0000175-LbeFESo-0
10:35:38.557 [pool-63-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Resetting offset for partition test-topic-0000169-ghF_OKc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.558 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-178-ke0_tAk-64-6e505a05-f5d4-4882-97cf-a79cde20bdf7', protocol='range'}
10:35:38.558 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-172-rVJbmyc-62-fb6a65f9-9ba0-45d4-b53d-bc96c51fde2a', protocol='range'}
10:35:38.558 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Finished assignment for group at generation 1: {consumer-sub-178-ke0_tAk-64-6e505a05-f5d4-4882-97cf-a79cde20bdf7=Assignment(partitions=[test-topic-0000178-i0eYwS4-0])}
10:35:38.558 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Notifying assignor about the new Assignment(partitions=[test-topic-0000172-MDi5xIU-0])
10:35:38.558 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Adding newly assigned partitions: test-topic-0000172-MDi5xIU-0
10:35:38.558 [pool-65-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Resetting offset for partition test-topic-0000175-LbeFESo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.559 [pool-64-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Found no committed offset for partition test-topic-0000172-MDi5xIU-0
10:35:38.561 [pool-64-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Resetting offset for partition test-topic-0000172-MDi5xIU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.561 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-178-ke0_tAk-64-6e505a05-f5d4-4882-97cf-a79cde20bdf7', protocol='range'}
10:35:38.561 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Notifying assignor about the new Assignment(partitions=[test-topic-0000178-i0eYwS4-0])
10:35:38.561 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Adding newly assigned partitions: test-topic-0000178-i0eYwS4-0
10:35:38.562 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-181-BgUa2Oc-65-95ab5b8e-487d-413e-be6c-32cd7a2f010d', protocol='range'}
10:35:38.562 [pool-66-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Found no committed offset for partition test-topic-0000178-i0eYwS4-0
10:35:38.562 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Finished assignment for group at generation 1: {consumer-sub-181-BgUa2Oc-65-95ab5b8e-487d-413e-be6c-32cd7a2f010d=Assignment(partitions=[test-topic-0000181-brF3U9o-0])}
10:35:38.564 [pool-66-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Resetting offset for partition test-topic-0000178-i0eYwS4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.566 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-181-BgUa2Oc-65-95ab5b8e-487d-413e-be6c-32cd7a2f010d', protocol='range'}
10:35:38.567 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Notifying assignor about the new Assignment(partitions=[test-topic-0000181-brF3U9o-0])
10:35:38.567 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Adding newly assigned partitions: test-topic-0000181-brF3U9o-0
10:35:38.567 [pool-67-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Found no committed offset for partition test-topic-0000181-brF3U9o-0
10:35:38.569 [pool-67-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Resetting offset for partition test-topic-0000181-brF3U9o-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.572 [main] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.572 [main] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.572 [main] INFO AppInfoParser - Kafka startTimeMs: 1716806138572
10:35:38.574 [main] INFO KafkaConsumer - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Subscribed to topic(s): test-topic-0000006-TuXPgEs
10:35:38.576 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-187-dzCZ1J8-67-2807b9f8-f8d0-45bb-ab84-cfe8c8fb5006', protocol='range'}
10:35:38.577 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Finished assignment for group at generation 1: {consumer-sub-187-dzCZ1J8-67-2807b9f8-f8d0-45bb-ab84-cfe8c8fb5006=Assignment(partitions=[test-topic-0000187-qg-xV74-0])}
10:35:38.580 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-184-UCC2_8Y-66-dcb1583c-b79f-4796-880f-f0dba4328f28', protocol='range'}
10:35:38.580 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Finished assignment for group at generation 1: {consumer-sub-184-UCC2_8Y-66-dcb1583c-b79f-4796-880f-f0dba4328f28=Assignment(partitions=[test-topic-0000184-k_ZYxDY-0])}
10:35:38.581 [main] INFO LocalWorker - Created 1 consumers in 77.901987 ms
10:35:38.581 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-187-dzCZ1J8-67-2807b9f8-f8d0-45bb-ab84-cfe8c8fb5006', protocol='range'}
10:35:38.581 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Notifying assignor about the new Assignment(partitions=[test-topic-0000187-qg-xV74-0])
10:35:38.581 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Adding newly assigned partitions: test-topic-0000187-qg-xV74-0
10:35:38.582 [pool-69-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Found no committed offset for partition test-topic-0000187-qg-xV74-0
10:35:38.584 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-190-rMQrnZo-68-dde23cb7-001d-414b-9c5d-3a5e13e56327', protocol='range'}
10:35:38.584 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Finished assignment for group at generation 1: {consumer-sub-190-rMQrnZo-68-dde23cb7-001d-414b-9c5d-3a5e13e56327=Assignment(partitions=[test-topic-0000190-3m3hz00-0])}
10:35:38.584 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-184-UCC2_8Y-66-dcb1583c-b79f-4796-880f-f0dba4328f28', protocol='range'}
10:35:38.584 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Notifying assignor about the new Assignment(partitions=[test-topic-0000184-k_ZYxDY-0])
10:35:38.585 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Adding newly assigned partitions: test-topic-0000184-k_ZYxDY-0
10:35:38.586 [pool-68-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Found no committed offset for partition test-topic-0000184-k_ZYxDY-0
10:35:38.586 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-193-s8VGh8U-69-317de2be-8012-4e8e-a661-fa4bef4761ca', protocol='range'}
10:35:38.586 [pool-69-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Resetting offset for partition test-topic-0000187-qg-xV74-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.586 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Finished assignment for group at generation 1: {consumer-sub-193-s8VGh8U-69-317de2be-8012-4e8e-a661-fa4bef4761ca=Assignment(partitions=[test-topic-0000193-IKe7u9w-0])}
10:35:38.588 [pool-68-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Resetting offset for partition test-topic-0000184-k_ZYxDY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.590 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-190-rMQrnZo-68-dde23cb7-001d-414b-9c5d-3a5e13e56327', protocol='range'}
10:35:38.590 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-193-s8VGh8U-69-317de2be-8012-4e8e-a661-fa4bef4761ca', protocol='range'}
10:35:38.590 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Notifying assignor about the new Assignment(partitions=[test-topic-0000190-3m3hz00-0])
10:35:38.590 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Notifying assignor about the new Assignment(partitions=[test-topic-0000193-IKe7u9w-0])
10:35:38.590 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Adding newly assigned partitions: test-topic-0000190-3m3hz00-0
10:35:38.590 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Adding newly assigned partitions: test-topic-0000193-IKe7u9w-0
10:35:38.591 [pool-70-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Found no committed offset for partition test-topic-0000190-3m3hz00-0
10:35:38.591 [pool-71-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Found no committed offset for partition test-topic-0000193-IKe7u9w-0
10:35:38.593 [pool-70-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Resetting offset for partition test-topic-0000190-3m3hz00-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.593 [pool-71-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Resetting offset for partition test-topic-0000193-IKe7u9w-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.597 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-196-zfD1A_I-70-a5dbae94-61d6-4b64-b550-43de2f0b8b2c', protocol='range'}
10:35:38.597 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Finished assignment for group at generation 1: {consumer-sub-196-zfD1A_I-70-a5dbae94-61d6-4b64-b550-43de2f0b8b2c=Assignment(partitions=[test-topic-0000196-Ej9h6yQ-0])}
10:35:38.597 [pool-2-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.599 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Discovered group coordinator 10.0.0.131:9092 (id: 2147483646 rack: null)
10:35:38.601 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-196-zfD1A_I-70-a5dbae94-61d6-4b64-b550-43de2f0b8b2c', protocol='range'}
10:35:38.601 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Notifying assignor about the new Assignment(partitions=[test-topic-0000196-Ej9h6yQ-0])
10:35:38.601 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Adding newly assigned partitions: test-topic-0000196-Ej9h6yQ-0
10:35:38.602 [pool-72-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Found no committed offset for partition test-topic-0000196-Ej9h6yQ-0
10:35:38.603 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-199-gj6dzsM-71-f0d3225b-4c94-4154-96c9-a7ae80d3358a', protocol='range'}
10:35:38.603 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] (Re-)joining group
10:35:38.603 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Finished assignment for group at generation 1: {consumer-sub-199-gj6dzsM-71-f0d3225b-4c94-4154-96c9-a7ae80d3358a=Assignment(partitions=[test-topic-0000199-pa8qKEk-0])}
10:35:38.605 [pool-72-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Resetting offset for partition test-topic-0000196-Ej9h6yQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.606 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.607 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-202-DL6rg0U-72-8b568640-82a2-4205-b244-ab0a1a6ef10f', protocol='range'}
10:35:38.607 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-199-gj6dzsM-71-f0d3225b-4c94-4154-96c9-a7ae80d3358a', protocol='range'}
10:35:38.607 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Notifying assignor about the new Assignment(partitions=[test-topic-0000199-pa8qKEk-0])
10:35:38.607 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Adding newly assigned partitions: test-topic-0000199-pa8qKEk-0
10:35:38.607 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Finished assignment for group at generation 1: {consumer-sub-202-DL6rg0U-72-8b568640-82a2-4205-b244-ab0a1a6ef10f=Assignment(partitions=[test-topic-0000202-wnvH5hQ-0])}
10:35:38.608 [pool-73-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Found no committed offset for partition test-topic-0000199-pa8qKEk-0
10:35:38.610 [pool-73-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Resetting offset for partition test-topic-0000199-pa8qKEk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.610 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.611 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-202-DL6rg0U-72-8b568640-82a2-4205-b244-ab0a1a6ef10f', protocol='range'}
10:35:38.611 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Notifying assignor about the new Assignment(partitions=[test-topic-0000202-wnvH5hQ-0])
10:35:38.611 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Adding newly assigned partitions: test-topic-0000202-wnvH5hQ-0
10:35:38.612 [pool-74-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Found no committed offset for partition test-topic-0000202-wnvH5hQ-0
10:35:38.615 [pool-74-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Resetting offset for partition test-topic-0000202-wnvH5hQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.617 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-205-Xuji97M-73-6a278020-6305-4c7a-ac4f-c5d31cdc069a', protocol='range'}
10:35:38.617 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Finished assignment for group at generation 1: {consumer-sub-205-Xuji97M-73-6a278020-6305-4c7a-ac4f-c5d31cdc069a=Assignment(partitions=[test-topic-0000205-noMcOW4-0])}
10:35:38.617 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-208-_BWsszI-74-75758e82-4145-4055-b0d0-e4ba0ada9700', protocol='range'}
10:35:38.618 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Finished assignment for group at generation 1: {consumer-sub-208-_BWsszI-74-75758e82-4145-4055-b0d0-e4ba0ada9700=Assignment(partitions=[test-topic-0000208-hdUPCA4-0])}
10:35:38.619 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
10:35:38.621 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-205-Xuji97M-73-6a278020-6305-4c7a-ac4f-c5d31cdc069a', protocol='range'}
10:35:38.621 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Notifying assignor about the new Assignment(partitions=[test-topic-0000205-noMcOW4-0])
10:35:38.622 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Adding newly assigned partitions: test-topic-0000205-noMcOW4-0
10:35:38.622 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Request joining group due to: need to re-join with the given member-id: consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3
10:35:38.623 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
10:35:38.623 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] (Re-)joining group
10:35:38.624 [pool-75-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Found no committed offset for partition test-topic-0000205-noMcOW4-0
10:35:38.625 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-211-Gil9jaE-75-ace90156-d0ee-4340-9b7d-e4b792e0fc6b', protocol='range'}
10:35:38.625 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Finished assignment for group at generation 1: {consumer-sub-211-Gil9jaE-75-ace90156-d0ee-4340-9b7d-e4b792e0fc6b=Assignment(partitions=[test-topic-0000211-Ph8tip0-0])}
10:35:38.626 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-208-_BWsszI-74-75758e82-4145-4055-b0d0-e4ba0ada9700', protocol='range'}
10:35:38.626 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Notifying assignor about the new Assignment(partitions=[test-topic-0000208-hdUPCA4-0])
10:35:38.626 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Adding newly assigned partitions: test-topic-0000208-hdUPCA4-0
10:35:38.626 [pool-75-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Resetting offset for partition test-topic-0000205-noMcOW4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.627 [pool-76-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Found no committed offset for partition test-topic-0000208-hdUPCA4-0
10:35:38.628 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-211-Gil9jaE-75-ace90156-d0ee-4340-9b7d-e4b792e0fc6b', protocol='range'}
10:35:38.628 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Notifying assignor about the new Assignment(partitions=[test-topic-0000211-Ph8tip0-0])
10:35:38.628 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Adding newly assigned partitions: test-topic-0000211-Ph8tip0-0
10:35:38.628 [pool-76-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Resetting offset for partition test-topic-0000208-hdUPCA4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.629 [pool-77-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Found no committed offset for partition test-topic-0000211-Ph8tip0-0
10:35:38.630 [pool-77-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Resetting offset for partition test-topic-0000211-Ph8tip0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.633 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-214-u7Hz_Ns-76-858b4e25-8c50-446e-9dd3-ecfed657d7f9', protocol='range'}
10:35:38.633 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Finished assignment for group at generation 1: {consumer-sub-214-u7Hz_Ns-76-858b4e25-8c50-446e-9dd3-ecfed657d7f9=Assignment(partitions=[test-topic-0000214-WIM8B8M-0])}
10:35:38.634 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.635 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.635 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.635 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-217-zmNMIvw-77-97baa124-ada5-4ac4-9ead-dbea2d97ecd9', protocol='range'}
10:35:38.635 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138635
10:35:38.635 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Finished assignment for group at generation 1: {consumer-sub-217-zmNMIvw-77-97baa124-ada5-4ac4-9ead-dbea2d97ecd9=Assignment(partitions=[test-topic-0000217-Ajth_NQ-0])}
10:35:38.636 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.636 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-2] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.636 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
10:35:38.638 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-214-u7Hz_Ns-76-858b4e25-8c50-446e-9dd3-ecfed657d7f9', protocol='range'}
10:35:38.638 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Notifying assignor about the new Assignment(partitions=[test-topic-0000214-WIM8B8M-0])
10:35:38.638 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Adding newly assigned partitions: test-topic-0000214-WIM8B8M-0
10:35:38.639 [pool-78-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Found no committed offset for partition test-topic-0000214-WIM8B8M-0
10:35:38.639 [kafka-producer-network-thread | producer-1] INFO Metadata - [Producer clientId=producer-1] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.639 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.639 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-217-zmNMIvw-77-97baa124-ada5-4ac4-9ead-dbea2d97ecd9', protocol='range'}
10:35:38.640 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.640 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.640 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138639
10:35:38.640 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Notifying assignor about the new Assignment(partitions=[test-topic-0000217-Ajth_NQ-0])
10:35:38.640 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Adding newly assigned partitions: test-topic-0000217-Ajth_NQ-0
10:35:38.640 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.640 [pool-79-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Found no committed offset for partition test-topic-0000217-Ajth_NQ-0
10:35:38.641 [pool-78-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Resetting offset for partition test-topic-0000214-WIM8B8M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.641 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-3] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.641 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
10:35:38.641 [kafka-producer-network-thread | producer-2] INFO Metadata - [Producer clientId=producer-2] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.642 [pool-79-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Resetting offset for partition test-topic-0000217-Ajth_NQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.643 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.643 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.643 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.643 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138643
10:35:38.644 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.644 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-4] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.644 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-4] Instantiated an idempotent producer.
10:35:38.644 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-220-eLcgVIE-78-b972007e-a148-4d31-bf8f-b759f019658f', protocol='range'}
10:35:38.644 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Finished assignment for group at generation 1: {consumer-sub-220-eLcgVIE-78-b972007e-a148-4d31-bf8f-b759f019658f=Assignment(partitions=[test-topic-0000220-N-ilnxQ-0])}
10:35:38.645 [kafka-producer-network-thread | producer-3] INFO Metadata - [Producer clientId=producer-3] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.646 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.647 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.647 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.647 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138647
10:35:38.647 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.647 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-5] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.648 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-5] Instantiated an idempotent producer.
10:35:38.648 [kafka-producer-network-thread | producer-4] INFO Metadata - [Producer clientId=producer-4] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.648 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-220-eLcgVIE-78-b972007e-a148-4d31-bf8f-b759f019658f', protocol='range'}
10:35:38.649 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Notifying assignor about the new Assignment(partitions=[test-topic-0000220-N-ilnxQ-0])
10:35:38.649 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Adding newly assigned partitions: test-topic-0000220-N-ilnxQ-0
10:35:38.649 [pool-80-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Found no committed offset for partition test-topic-0000220-N-ilnxQ-0
10:35:38.650 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.650 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.650 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.650 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138650
10:35:38.650 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.651 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-6] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.651 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-6] Instantiated an idempotent producer.
10:35:38.651 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-223-Borim14-79-50dbd4ea-b713-432f-8b37-b551a173928f', protocol='range'}
10:35:38.651 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Finished assignment for group at generation 1: {consumer-sub-223-Borim14-79-50dbd4ea-b713-432f-8b37-b551a173928f=Assignment(partitions=[test-topic-0000223-ah3LCNA-0])}
10:35:38.651 [pool-80-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Resetting offset for partition test-topic-0000220-N-ilnxQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.652 [kafka-producer-network-thread | producer-5] INFO Metadata - [Producer clientId=producer-5] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.652 [kafka-producer-network-thread | producer-5] INFO TransactionManager - [Producer clientId=producer-5] ProducerId set to 1000 with epoch 0
10:35:38.653 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.653 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.653 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.653 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138653
10:35:38.653 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.654 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-7] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.654 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-7] Instantiated an idempotent producer.
10:35:38.654 [kafka-producer-network-thread | producer-6] INFO Metadata - [Producer clientId=producer-6] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.655 [kafka-producer-network-thread | producer-6] INFO TransactionManager - [Producer clientId=producer-6] ProducerId set to 1002 with epoch 0
10:35:38.656 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-223-Borim14-79-50dbd4ea-b713-432f-8b37-b551a173928f', protocol='range'}
10:35:38.656 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Notifying assignor about the new Assignment(partitions=[test-topic-0000223-ah3LCNA-0])
10:35:38.656 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Adding newly assigned partitions: test-topic-0000223-ah3LCNA-0
10:35:38.656 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.656 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.656 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.656 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138656
10:35:38.657 [pool-81-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Found no committed offset for partition test-topic-0000223-ah3LCNA-0
10:35:38.656 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.657 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-8] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.657 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-8] Instantiated an idempotent producer.
10:35:38.658 [kafka-producer-network-thread | producer-7] INFO Metadata - [Producer clientId=producer-7] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.658 [kafka-producer-network-thread | producer-7] INFO TransactionManager - [Producer clientId=producer-7] ProducerId set to 2005 with epoch 0
10:35:38.658 [pool-81-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Resetting offset for partition test-topic-0000223-ah3LCNA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.659 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.659 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.659 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.659 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138659
10:35:38.660 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.660 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-9] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.660 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-9] Instantiated an idempotent producer.
10:35:38.661 [kafka-producer-network-thread | producer-8] INFO Metadata - [Producer clientId=producer-8] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.661 [kafka-producer-network-thread | producer-8] INFO TransactionManager - [Producer clientId=producer-8] ProducerId set to 3 with epoch 0
10:35:38.662 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.662 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.662 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.662 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138662
10:35:38.662 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.663 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-10] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.663 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-10] Instantiated an idempotent producer.
10:35:38.663 [kafka-producer-network-thread | producer-9] INFO Metadata - [Producer clientId=producer-9] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.664 [kafka-producer-network-thread | producer-9] INFO TransactionManager - [Producer clientId=producer-9] ProducerId set to 4 with epoch 0
10:35:38.665 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.665 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.665 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.665 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138665
10:35:38.665 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.666 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-11] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.666 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-11] Instantiated an idempotent producer.
10:35:38.666 [kafka-producer-network-thread | producer-10] INFO Metadata - [Producer clientId=producer-10] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.667 [kafka-producer-network-thread | producer-10] INFO TransactionManager - [Producer clientId=producer-10] ProducerId set to 1005 with epoch 0
10:35:38.668 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.668 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.668 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.668 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138668
10:35:38.668 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.669 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-12] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.669 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-12] Instantiated an idempotent producer.
10:35:38.670 [kafka-producer-network-thread | producer-11] INFO Metadata - [Producer clientId=producer-11] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.670 [kafka-producer-network-thread | producer-11] INFO TransactionManager - [Producer clientId=producer-11] ProducerId set to 5 with epoch 0
10:35:38.671 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.671 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.671 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.671 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138671
10:35:38.672 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.672 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-13] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.672 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-13] Instantiated an idempotent producer.
10:35:38.673 [kafka-producer-network-thread | producer-12] INFO Metadata - [Producer clientId=producer-12] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.673 [kafka-producer-network-thread | producer-12] INFO TransactionManager - [Producer clientId=producer-12] ProducerId set to 1009 with epoch 0
10:35:38.674 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.674 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.674 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.674 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138674
10:35:38.674 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.675 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-14] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.675 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-14] Instantiated an idempotent producer.
10:35:38.675 [kafka-producer-network-thread | producer-13] INFO Metadata - [Producer clientId=producer-13] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.676 [kafka-producer-network-thread | producer-13] INFO TransactionManager - [Producer clientId=producer-13] ProducerId set to 2008 with epoch 0
10:35:38.677 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-229-K6WIHn0-81-72101873-8e72-4076-b8f8-55064d9ef265', protocol='range'}
10:35:38.677 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.677 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.677 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Finished assignment for group at generation 1: {consumer-sub-229-K6WIHn0-81-72101873-8e72-4076-b8f8-55064d9ef265=Assignment(partitions=[test-topic-0000229--X-ffVY-0])}
10:35:38.677 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.677 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138677
10:35:38.677 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.678 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-15] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.678 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-15] Instantiated an idempotent producer.
10:35:38.678 [kafka-producer-network-thread | producer-14] INFO Metadata - [Producer clientId=producer-14] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.679 [kafka-producer-network-thread | producer-14] INFO TransactionManager - [Producer clientId=producer-14] ProducerId set to 2010 with epoch 0
10:35:38.679 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-226-RKLF2mE-80-fa4f0f54-fa1f-43c2-9370-75e0c0e806a0', protocol='range'}
10:35:38.679 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Finished assignment for group at generation 1: {consumer-sub-226-RKLF2mE-80-fa4f0f54-fa1f-43c2-9370-75e0c0e806a0=Assignment(partitions=[test-topic-0000226-9ja4qbw-0])}
10:35:38.680 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.680 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.680 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.680 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138680
10:35:38.681 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.681 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-229-K6WIHn0-81-72101873-8e72-4076-b8f8-55064d9ef265', protocol='range'}
10:35:38.681 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Notifying assignor about the new Assignment(partitions=[test-topic-0000229--X-ffVY-0])
10:35:38.681 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Adding newly assigned partitions: test-topic-0000229--X-ffVY-0
10:35:38.682 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-16] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.682 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-16] Instantiated an idempotent producer.
10:35:38.682 [kafka-producer-network-thread | producer-15] INFO TransactionManager - [Producer clientId=producer-15] ProducerId set to 2012 with epoch 0
10:35:38.682 [pool-83-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Found no committed offset for partition test-topic-0000229--X-ffVY-0
10:35:38.682 [kafka-producer-network-thread | producer-15] INFO Metadata - [Producer clientId=producer-15] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.684 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-226-RKLF2mE-80-fa4f0f54-fa1f-43c2-9370-75e0c0e806a0', protocol='range'}
10:35:38.684 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.684 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.684 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.684 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Notifying assignor about the new Assignment(partitions=[test-topic-0000226-9ja4qbw-0])
10:35:38.684 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138684
10:35:38.684 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Adding newly assigned partitions: test-topic-0000226-9ja4qbw-0
10:35:38.684 [pool-83-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Resetting offset for partition test-topic-0000229--X-ffVY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.684 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.685 [pool-82-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Found no committed offset for partition test-topic-0000226-9ja4qbw-0
10:35:38.685 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-17] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.685 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-232-HWA9cc4-82-d8e2cb3a-b101-41e8-9119-3b458fd9e777', protocol='range'}
10:35:38.685 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-17] Instantiated an idempotent producer.
10:35:38.685 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Finished assignment for group at generation 1: {consumer-sub-232-HWA9cc4-82-d8e2cb3a-b101-41e8-9119-3b458fd9e777=Assignment(partitions=[test-topic-0000232-Zo-CFTw-0])}
10:35:38.686 [kafka-producer-network-thread | producer-16] INFO Metadata - [Producer clientId=producer-16] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.686 [kafka-producer-network-thread | producer-16] INFO TransactionManager - [Producer clientId=producer-16] ProducerId set to 2014 with epoch 0
10:35:38.687 [pool-82-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Resetting offset for partition test-topic-0000226-9ja4qbw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.687 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.687 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.687 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.687 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138687
10:35:38.687 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.688 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-18] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.688 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-18] Instantiated an idempotent producer.
10:35:38.688 [kafka-producer-network-thread | producer-17] INFO TransactionManager - [Producer clientId=producer-17] ProducerId set to 2015 with epoch 0
10:35:38.688 [kafka-producer-network-thread | producer-17] INFO Metadata - [Producer clientId=producer-17] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.689 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-232-HWA9cc4-82-d8e2cb3a-b101-41e8-9119-3b458fd9e777', protocol='range'}
10:35:38.689 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Notifying assignor about the new Assignment(partitions=[test-topic-0000232-Zo-CFTw-0])
10:35:38.689 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Adding newly assigned partitions: test-topic-0000232-Zo-CFTw-0
10:35:38.689 [pool-84-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Found no committed offset for partition test-topic-0000232-Zo-CFTw-0
10:35:38.690 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.690 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.690 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.690 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138690
10:35:38.690 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.691 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-19] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.691 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-19] Instantiated an idempotent producer.
10:35:38.691 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-238-ONJOK5A-84-8ffc0de2-5043-4497-96f1-8c0d893ed98f', protocol='range'}
10:35:38.691 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Finished assignment for group at generation 1: {consumer-sub-238-ONJOK5A-84-8ffc0de2-5043-4497-96f1-8c0d893ed98f=Assignment(partitions=[test-topic-0000238-pVDipQg-0])}
10:35:38.694 [pool-84-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Resetting offset for partition test-topic-0000232-Zo-CFTw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.694 [kafka-producer-network-thread | producer-18] INFO Metadata - [Producer clientId=producer-18] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.694 [kafka-producer-network-thread | producer-18] INFO TransactionManager - [Producer clientId=producer-18] ProducerId set to 2017 with epoch 0
10:35:38.695 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.695 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.695 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.695 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138695
10:35:38.695 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-238-ONJOK5A-84-8ffc0de2-5043-4497-96f1-8c0d893ed98f', protocol='range'}
10:35:38.695 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Notifying assignor about the new Assignment(partitions=[test-topic-0000238-pVDipQg-0])
10:35:38.695 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Adding newly assigned partitions: test-topic-0000238-pVDipQg-0
10:35:38.695 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.695 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-20] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.696 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-20] Instantiated an idempotent producer.
10:35:38.696 [pool-86-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Found no committed offset for partition test-topic-0000238-pVDipQg-0
10:35:38.696 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-241-gvnU3Ck-85-ffeddb23-aa10-480f-8000-fed292d501c1', protocol='range'}
10:35:38.696 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Finished assignment for group at generation 1: {consumer-sub-241-gvnU3Ck-85-ffeddb23-aa10-480f-8000-fed292d501c1=Assignment(partitions=[test-topic-0000241-R-_-_cA-0])}
10:35:38.697 [kafka-producer-network-thread | producer-19] INFO Metadata - [Producer clientId=producer-19] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.697 [kafka-producer-network-thread | producer-19] INFO TransactionManager - [Producer clientId=producer-19] ProducerId set to 13 with epoch 0
10:35:38.698 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.698 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.698 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.698 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138698
10:35:38.698 [pool-86-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Resetting offset for partition test-topic-0000238-pVDipQg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.698 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.699 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-235-MeSVaXE-83-d3d2c7bb-daec-474f-98d4-049616041ca5', protocol='range'}
10:35:38.699 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Finished assignment for group at generation 1: {consumer-sub-235-MeSVaXE-83-d3d2c7bb-daec-474f-98d4-049616041ca5=Assignment(partitions=[test-topic-0000235-cCNi4L4-0])}
10:35:38.699 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-21] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.699 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-21] Instantiated an idempotent producer.
10:35:38.700 [kafka-producer-network-thread | producer-20] INFO Metadata - [Producer clientId=producer-20] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.700 [kafka-producer-network-thread | producer-20] INFO TransactionManager - [Producer clientId=producer-20] ProducerId set to 14 with epoch 0
10:35:38.700 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.700 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.700 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.700 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138700
10:35:38.701 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.701 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-241-gvnU3Ck-85-ffeddb23-aa10-480f-8000-fed292d501c1', protocol='range'}
10:35:38.701 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Notifying assignor about the new Assignment(partitions=[test-topic-0000241-R-_-_cA-0])
10:35:38.701 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Adding newly assigned partitions: test-topic-0000241-R-_-_cA-0
10:35:38.701 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-22] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.701 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-22] Instantiated an idempotent producer.
10:35:38.702 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-244-jxtWLHw-86-be807ba6-7713-4537-8725-653c390f8539', protocol='range'}
10:35:38.702 [pool-87-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Found no committed offset for partition test-topic-0000241-R-_-_cA-0
10:35:38.702 [kafka-producer-network-thread | producer-21] INFO Metadata - [Producer clientId=producer-21] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.702 [kafka-producer-network-thread | producer-21] INFO TransactionManager - [Producer clientId=producer-21] ProducerId set to 1014 with epoch 0
10:35:38.702 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Finished assignment for group at generation 1: {consumer-sub-244-jxtWLHw-86-be807ba6-7713-4537-8725-653c390f8539=Assignment(partitions=[test-topic-0000244-xZzYGvA-0])}
10:35:38.703 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-235-MeSVaXE-83-d3d2c7bb-daec-474f-98d4-049616041ca5', protocol='range'}
10:35:38.703 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Notifying assignor about the new Assignment(partitions=[test-topic-0000235-cCNi4L4-0])
10:35:38.703 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Adding newly assigned partitions: test-topic-0000235-cCNi4L4-0
10:35:38.704 [pool-85-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Found no committed offset for partition test-topic-0000235-cCNi4L4-0
10:35:38.704 [pool-87-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Resetting offset for partition test-topic-0000241-R-_-_cA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.705 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-247-K9XaCCg-87-4baccfb4-1b21-4de9-92b0-d41dbb639a31', protocol='range'}
10:35:38.705 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Finished assignment for group at generation 1: {consumer-sub-247-K9XaCCg-87-4baccfb4-1b21-4de9-92b0-d41dbb639a31=Assignment(partitions=[test-topic-0000247-bLhN7IM-0])}
10:35:38.705 [pool-85-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Resetting offset for partition test-topic-0000235-cCNi4L4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.706 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.706 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.706 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.706 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138706
10:35:38.706 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-244-jxtWLHw-86-be807ba6-7713-4537-8725-653c390f8539', protocol='range'}
10:35:38.706 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.706 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Notifying assignor about the new Assignment(partitions=[test-topic-0000244-xZzYGvA-0])
10:35:38.706 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Adding newly assigned partitions: test-topic-0000244-xZzYGvA-0
10:35:38.707 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-23] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.707 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-23] Instantiated an idempotent producer.
10:35:38.707 [pool-88-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Found no committed offset for partition test-topic-0000244-xZzYGvA-0
10:35:38.708 [kafka-producer-network-thread | producer-22] INFO Metadata - [Producer clientId=producer-22] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.708 [kafka-producer-network-thread | producer-22] INFO TransactionManager - [Producer clientId=producer-22] ProducerId set to 2023 with epoch 0
10:35:38.709 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.709 [pool-88-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Resetting offset for partition test-topic-0000244-xZzYGvA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.709 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.709 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.709 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138709
10:35:38.709 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.710 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-24] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.710 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-24] Instantiated an idempotent producer.
10:35:38.710 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-247-K9XaCCg-87-4baccfb4-1b21-4de9-92b0-d41dbb639a31', protocol='range'}
10:35:38.710 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Notifying assignor about the new Assignment(partitions=[test-topic-0000247-bLhN7IM-0])
10:35:38.710 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Adding newly assigned partitions: test-topic-0000247-bLhN7IM-0
10:35:38.710 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-250-rGmeKVQ-88-1abc8c25-e855-4205-b44f-f33265cfbb8c', protocol='range'}
10:35:38.710 [kafka-producer-network-thread | producer-23] INFO Metadata - [Producer clientId=producer-23] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.710 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Finished assignment for group at generation 1: {consumer-sub-250-rGmeKVQ-88-1abc8c25-e855-4205-b44f-f33265cfbb8c=Assignment(partitions=[test-topic-0000250-oUn3sNE-0])}
10:35:38.711 [kafka-producer-network-thread | producer-23] INFO TransactionManager - [Producer clientId=producer-23] ProducerId set to 17 with epoch 0
10:35:38.711 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.711 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.711 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.711 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138711
10:35:38.712 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-25
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.712 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-25] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.712 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-25] Instantiated an idempotent producer.
10:35:38.713 [pool-89-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Found no committed offset for partition test-topic-0000247-bLhN7IM-0
10:35:38.713 [kafka-producer-network-thread | producer-24] INFO Metadata - [Producer clientId=producer-24] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.714 [kafka-producer-network-thread | producer-24] INFO TransactionManager - [Producer clientId=producer-24] ProducerId set to 18 with epoch 0
10:35:38.714 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.714 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.714 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.714 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138714
10:35:38.715 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-26
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.715 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-250-rGmeKVQ-88-1abc8c25-e855-4205-b44f-f33265cfbb8c', protocol='range'}
10:35:38.715 [pool-89-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Resetting offset for partition test-topic-0000247-bLhN7IM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.715 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000250-oUn3sNE-0])
10:35:38.715 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Adding newly assigned partitions: test-topic-0000250-oUn3sNE-0
10:35:38.715 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-253-RgeEIIQ-89-898266f5-2e8c-4b0e-b26d-d3b383299c6f', protocol='range'}
10:35:38.715 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-26] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.715 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-26] Instantiated an idempotent producer.
10:35:38.715 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Finished assignment for group at generation 1: {consumer-sub-253-RgeEIIQ-89-898266f5-2e8c-4b0e-b26d-d3b383299c6f=Assignment(partitions=[test-topic-0000253-QAvk_uQ-0])}
10:35:38.716 [pool-90-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Found no committed offset for partition test-topic-0000250-oUn3sNE-0
10:35:38.716 [kafka-producer-network-thread | producer-25] INFO Metadata - [Producer clientId=producer-25] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.716 [kafka-producer-network-thread | producer-25] INFO TransactionManager - [Producer clientId=producer-25] ProducerId set to 20 with epoch 0
10:35:38.717 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.717 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.717 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.717 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138717
10:35:38.717 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-27
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.717 [pool-90-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Resetting offset for partition test-topic-0000250-oUn3sNE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.717 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-27] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.718 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-27] Instantiated an idempotent producer.
10:35:38.719 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-253-RgeEIIQ-89-898266f5-2e8c-4b0e-b26d-d3b383299c6f', protocol='range'}
10:35:38.719 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000253-QAvk_uQ-0])
10:35:38.719 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Adding newly assigned partitions: test-topic-0000253-QAvk_uQ-0
10:35:38.720 [kafka-producer-network-thread | producer-26] INFO Metadata - [Producer clientId=producer-26] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.720 [pool-91-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Found no committed offset for partition test-topic-0000253-QAvk_uQ-0
10:35:38.720 [kafka-producer-network-thread | producer-26] INFO TransactionManager - [Producer clientId=producer-26] ProducerId set to 22 with epoch 0
10:35:38.721 [pool-91-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Resetting offset for partition test-topic-0000253-QAvk_uQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.724 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.724 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.724 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.724 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138724
10:35:38.724 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-28
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.724 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-28] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.725 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-28] Instantiated an idempotent producer.
10:35:38.725 [kafka-producer-network-thread | producer-27] INFO Metadata - [Producer clientId=producer-27] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.725 [kafka-producer-network-thread | producer-27] INFO TransactionManager - [Producer clientId=producer-27] ProducerId set to 1019 with epoch 0
10:35:38.726 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.726 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.726 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.726 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138726
10:35:38.727 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-259-qFaMuSA-91-81038daa-0bf3-4ce2-949d-3b635a694bf8', protocol='range'}
10:35:38.727 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-29
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.727 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Finished assignment for group at generation 1: {consumer-sub-259-qFaMuSA-91-81038daa-0bf3-4ce2-949d-3b635a694bf8=Assignment(partitions=[test-topic-0000259-zpR5ZgQ-0])}
10:35:38.727 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-29] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.727 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-29] Instantiated an idempotent producer.
10:35:38.728 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-256-tSNX3eE-90-3dd1cbee-d0b6-4f30-8b43-bc0191ca1b79', protocol='range'}
10:35:38.728 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Finished assignment for group at generation 1: {consumer-sub-256-tSNX3eE-90-3dd1cbee-d0b6-4f30-8b43-bc0191ca1b79=Assignment(partitions=[test-topic-0000256--7oN2X0-0])}
10:35:38.728 [kafka-producer-network-thread | producer-28] INFO Metadata - [Producer clientId=producer-28] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.728 [kafka-producer-network-thread | producer-28] INFO TransactionManager - [Producer clientId=producer-28] ProducerId set to 26 with epoch 0
10:35:38.729 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.729 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.729 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.729 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138729
10:35:38.730 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-30
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.730 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-30] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.730 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-30] Instantiated an idempotent producer.
10:35:38.731 [kafka-producer-network-thread | producer-29] INFO Metadata - [Producer clientId=producer-29] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.731 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-259-qFaMuSA-91-81038daa-0bf3-4ce2-949d-3b635a694bf8', protocol='range'}
10:35:38.731 [kafka-producer-network-thread | producer-29] INFO TransactionManager - [Producer clientId=producer-29] ProducerId set to 28 with epoch 0
10:35:38.731 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Notifying assignor about the new Assignment(partitions=[test-topic-0000259-zpR5ZgQ-0])
10:35:38.731 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Adding newly assigned partitions: test-topic-0000259-zpR5ZgQ-0
10:35:38.732 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-256-tSNX3eE-90-3dd1cbee-d0b6-4f30-8b43-bc0191ca1b79', protocol='range'}
10:35:38.732 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Notifying assignor about the new Assignment(partitions=[test-topic-0000256--7oN2X0-0])
10:35:38.732 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Adding newly assigned partitions: test-topic-0000256--7oN2X0-0
10:35:38.732 [pool-93-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Found no committed offset for partition test-topic-0000259-zpR5ZgQ-0
10:35:38.733 [pool-92-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Found no committed offset for partition test-topic-0000256--7oN2X0-0
10:35:38.733 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.733 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-262-t6tbKE8-92-b66ddf5d-0783-489e-b3c0-bc0a40c009d4', protocol='range'}
10:35:38.733 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.733 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.733 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138733
10:35:38.733 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Finished assignment for group at generation 1: {consumer-sub-262-t6tbKE8-92-b66ddf5d-0783-489e-b3c0-bc0a40c009d4=Assignment(partitions=[test-topic-0000262-2mGVp-c-0])}
10:35:38.733 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-31
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.734 [pool-93-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Resetting offset for partition test-topic-0000259-zpR5ZgQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.734 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-31] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.734 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-31] Instantiated an idempotent producer.
10:35:38.734 [pool-92-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Resetting offset for partition test-topic-0000256--7oN2X0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.735 [kafka-producer-network-thread | producer-30] INFO Metadata - [Producer clientId=producer-30] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.735 [kafka-producer-network-thread | producer-30] INFO TransactionManager - [Producer clientId=producer-30] ProducerId set to 1021 with epoch 0
10:35:38.736 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.736 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.736 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.736 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138736
10:35:38.736 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-32
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.737 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-262-t6tbKE8-92-b66ddf5d-0783-489e-b3c0-bc0a40c009d4', protocol='range'}
10:35:38.737 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Notifying assignor about the new Assignment(partitions=[test-topic-0000262-2mGVp-c-0])
10:35:38.737 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-32] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.737 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Adding newly assigned partitions: test-topic-0000262-2mGVp-c-0
10:35:38.737 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-32] Instantiated an idempotent producer.
10:35:38.737 [kafka-producer-network-thread | producer-31] INFO Metadata - [Producer clientId=producer-31] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.737 [kafka-producer-network-thread | producer-31] INFO TransactionManager - [Producer clientId=producer-31] ProducerId set to 31 with epoch 0
10:35:38.737 [pool-94-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Found no committed offset for partition test-topic-0000262-2mGVp-c-0
10:35:38.739 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.739 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.739 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.739 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138739
10:35:38.739 [pool-94-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Resetting offset for partition test-topic-0000262-2mGVp-c-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.739 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-33
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.740 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-33] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.740 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-33] Instantiated an idempotent producer.
10:35:38.740 [kafka-producer-network-thread | producer-32] INFO Metadata - [Producer clientId=producer-32] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.740 [kafka-producer-network-thread | producer-32] INFO TransactionManager - [Producer clientId=producer-32] ProducerId set to 33 with epoch 0
10:35:38.741 [kafka-producer-network-thread | producer-1] INFO TransactionManager - [Producer clientId=producer-1] ProducerId set to 34 with epoch 0
10:35:38.742 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-265-y1eeaSk-93-950a37e4-c623-4368-82f6-1c64e6f7db28', protocol='range'}
10:35:38.742 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Finished assignment for group at generation 1: {consumer-sub-265-y1eeaSk-93-950a37e4-c623-4368-82f6-1c64e6f7db28=Assignment(partitions=[test-topic-0000265-TgfBbRU-0])}
10:35:38.742 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.742 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.742 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.742 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138742
10:35:38.743 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-34
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.743 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-34] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.743 [kafka-producer-network-thread | producer-2] INFO TransactionManager - [Producer clientId=producer-2] ProducerId set to 35 with epoch 0
10:35:38.743 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-34] Instantiated an idempotent producer.
10:35:38.744 [kafka-producer-network-thread | producer-33] INFO Metadata - [Producer clientId=producer-33] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.744 [kafka-producer-network-thread | producer-33] INFO TransactionManager - [Producer clientId=producer-33] ProducerId set to 1028 with epoch 0
10:35:38.745 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.745 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.745 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.745 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138745
10:35:38.746 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-35
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.746 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-265-y1eeaSk-93-950a37e4-c623-4368-82f6-1c64e6f7db28', protocol='range'}
10:35:38.746 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-35] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.746 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Notifying assignor about the new Assignment(partitions=[test-topic-0000265-TgfBbRU-0])
10:35:38.746 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-35] Instantiated an idempotent producer.
10:35:38.746 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Adding newly assigned partitions: test-topic-0000265-TgfBbRU-0
10:35:38.747 [pool-95-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Found no committed offset for partition test-topic-0000265-TgfBbRU-0
10:35:38.747 [kafka-producer-network-thread | producer-34] INFO Metadata - [Producer clientId=producer-34] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.747 [kafka-producer-network-thread | producer-34] INFO TransactionManager - [Producer clientId=producer-34] ProducerId set to 1029 with epoch 0
10:35:38.747 [kafka-producer-network-thread | producer-3] INFO TransactionManager - [Producer clientId=producer-3] ProducerId set to 2035 with epoch 0
10:35:38.748 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.748 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.748 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.748 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138748
10:35:38.749 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-36
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.749 [pool-95-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Resetting offset for partition test-topic-0000265-TgfBbRU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.749 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-36] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.749 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-36] Instantiated an idempotent producer.
10:35:38.750 [kafka-producer-network-thread | producer-35] INFO Metadata - [Producer clientId=producer-35] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.750 [kafka-producer-network-thread | producer-4] INFO TransactionManager - [Producer clientId=producer-4] ProducerId set to 2037 with epoch 0
10:35:38.750 [kafka-producer-network-thread | producer-35] INFO TransactionManager - [Producer clientId=producer-35] ProducerId set to 40 with epoch 0
10:35:38.751 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.751 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.751 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.751 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138751
10:35:38.751 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-37
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.752 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-37] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.752 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-37] Instantiated an idempotent producer.
10:35:38.753 [kafka-producer-network-thread | producer-36] INFO Metadata - [Producer clientId=producer-36] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.753 [kafka-producer-network-thread | producer-36] INFO TransactionManager - [Producer clientId=producer-36] ProducerId set to 1033 with epoch 0
10:35:38.754 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.754 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.754 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.754 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138754
10:35:38.755 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-38
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.755 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-38] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.755 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-38] Instantiated an idempotent producer.
10:35:38.756 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-271-_g-PJNA-95-66f1e284-2bc1-4f22-a89a-0f94949eec7d', protocol='range'}
10:35:38.756 [kafka-producer-network-thread | producer-37] INFO Metadata - [Producer clientId=producer-37] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.756 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Finished assignment for group at generation 1: {consumer-sub-271-_g-PJNA-95-66f1e284-2bc1-4f22-a89a-0f94949eec7d=Assignment(partitions=[test-topic-0000271-2pWwc2U-0])}
10:35:38.756 [kafka-producer-network-thread | producer-37] INFO TransactionManager - [Producer clientId=producer-37] ProducerId set to 44 with epoch 0
10:35:38.757 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.757 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.757 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.757 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138757
10:35:38.758 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-39
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.758 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-39] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.758 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-39] Instantiated an idempotent producer.
10:35:38.759 [kafka-producer-network-thread | producer-38] INFO Metadata - [Producer clientId=producer-38] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.759 [kafka-producer-network-thread | producer-38] INFO TransactionManager - [Producer clientId=producer-38] ProducerId set to 1035 with epoch 0
10:35:38.760 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.760 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.760 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.760 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138760
10:35:38.761 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-40
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.761 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-40] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.761 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-271-_g-PJNA-95-66f1e284-2bc1-4f22-a89a-0f94949eec7d', protocol='range'}
10:35:38.761 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-40] Instantiated an idempotent producer.
10:35:38.761 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Notifying assignor about the new Assignment(partitions=[test-topic-0000271-2pWwc2U-0])
10:35:38.762 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Adding newly assigned partitions: test-topic-0000271-2pWwc2U-0
10:35:38.762 [kafka-producer-network-thread | producer-39] INFO Metadata - [Producer clientId=producer-39] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.762 [kafka-producer-network-thread | producer-39] INFO TransactionManager - [Producer clientId=producer-39] ProducerId set to 2039 with epoch 0
10:35:38.762 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-268-Nx4dv8k-94-6432603c-6fb3-42b7-b287-cdef399856db', protocol='range'}
10:35:38.762 [pool-97-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Found no committed offset for partition test-topic-0000271-2pWwc2U-0
10:35:38.762 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Finished assignment for group at generation 1: {consumer-sub-268-Nx4dv8k-94-6432603c-6fb3-42b7-b287-cdef399856db=Assignment(partitions=[test-topic-0000268-JN0QTJM-0])}
10:35:38.763 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.763 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.763 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.763 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138763
10:35:38.764 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-41
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.764 [pool-97-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Resetting offset for partition test-topic-0000271-2pWwc2U-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.764 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-41] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.764 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-41] Instantiated an idempotent producer.
10:35:38.765 [kafka-producer-network-thread | producer-40] INFO Metadata - [Producer clientId=producer-40] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.765 [kafka-producer-network-thread | producer-40] INFO TransactionManager - [Producer clientId=producer-40] ProducerId set to 47 with epoch 0
10:35:38.766 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.766 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.766 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.766 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138766
10:35:38.767 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-268-Nx4dv8k-94-6432603c-6fb3-42b7-b287-cdef399856db', protocol='range'}
10:35:38.767 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Notifying assignor about the new Assignment(partitions=[test-topic-0000268-JN0QTJM-0])
10:35:38.767 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Adding newly assigned partitions: test-topic-0000268-JN0QTJM-0
10:35:38.767 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-42
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.767 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-42] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.767 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-42] Instantiated an idempotent producer.
10:35:38.768 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-274-97uhtFY-96-ccae2a18-32c8-4e34-94a5-d3d99f51026c', protocol='range'}
10:35:38.768 [pool-96-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Found no committed offset for partition test-topic-0000268-JN0QTJM-0
10:35:38.768 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Finished assignment for group at generation 1: {consumer-sub-274-97uhtFY-96-ccae2a18-32c8-4e34-94a5-d3d99f51026c=Assignment(partitions=[test-topic-0000274-d_ffdj4-0])}
10:35:38.768 [kafka-producer-network-thread | producer-41] INFO Metadata - [Producer clientId=producer-41] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.768 [kafka-producer-network-thread | producer-41] INFO TransactionManager - [Producer clientId=producer-41] ProducerId set to 50 with epoch 0
10:35:38.770 [pool-96-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Resetting offset for partition test-topic-0000268-JN0QTJM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.770 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.770 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.770 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.770 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138770
10:35:38.771 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-43
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.771 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-43] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.771 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-43] Instantiated an idempotent producer.
10:35:38.771 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-274-97uhtFY-96-ccae2a18-32c8-4e34-94a5-d3d99f51026c', protocol='range'}
10:35:38.771 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Notifying assignor about the new Assignment(partitions=[test-topic-0000274-d_ffdj4-0])
10:35:38.771 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Adding newly assigned partitions: test-topic-0000274-d_ffdj4-0
10:35:38.771 [kafka-producer-network-thread | producer-42] INFO Metadata - [Producer clientId=producer-42] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.772 [kafka-producer-network-thread | producer-42] INFO TransactionManager - [Producer clientId=producer-42] ProducerId set to 2041 with epoch 0
10:35:38.772 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-277-zPD7C0Y-97-d35f9e28-5562-43e2-8f02-275e606dc320', protocol='range'}
10:35:38.772 [pool-98-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Found no committed offset for partition test-topic-0000274-d_ffdj4-0
10:35:38.772 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Finished assignment for group at generation 1: {consumer-sub-277-zPD7C0Y-97-d35f9e28-5562-43e2-8f02-275e606dc320=Assignment(partitions=[test-topic-0000277-cGMK6aw-0])}
10:35:38.773 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.773 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.773 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.773 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138773
10:35:38.774 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-280-Bur9X_M-98-da531213-0b50-427b-b528-4926bcaa5b81', protocol='range'}
10:35:38.774 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Finished assignment for group at generation 1: {consumer-sub-280-Bur9X_M-98-da531213-0b50-427b-b528-4926bcaa5b81=Assignment(partitions=[test-topic-0000280-Tf41vck-0])}
10:35:38.774 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-44
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.774 [pool-98-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Resetting offset for partition test-topic-0000274-d_ffdj4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.774 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-44] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.775 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-44] Instantiated an idempotent producer.
10:35:38.775 [kafka-producer-network-thread | producer-43] INFO Metadata - [Producer clientId=producer-43] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.775 [kafka-producer-network-thread | producer-43] INFO TransactionManager - [Producer clientId=producer-43] ProducerId set to 54 with epoch 0
10:35:38.775 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-277-zPD7C0Y-97-d35f9e28-5562-43e2-8f02-275e606dc320', protocol='range'}
10:35:38.775 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Notifying assignor about the new Assignment(partitions=[test-topic-0000277-cGMK6aw-0])
10:35:38.775 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Adding newly assigned partitions: test-topic-0000277-cGMK6aw-0
10:35:38.776 [pool-99-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Found no committed offset for partition test-topic-0000277-cGMK6aw-0
10:35:38.777 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.777 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.777 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.777 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138777
10:35:38.777 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-45
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.778 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-45] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.778 [pool-99-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Resetting offset for partition test-topic-0000277-cGMK6aw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.778 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-45] Instantiated an idempotent producer.
10:35:38.778 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-280-Bur9X_M-98-da531213-0b50-427b-b528-4926bcaa5b81', protocol='range'}
10:35:38.778 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Notifying assignor about the new Assignment(partitions=[test-topic-0000280-Tf41vck-0])
10:35:38.778 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Adding newly assigned partitions: test-topic-0000280-Tf41vck-0
10:35:38.778 [kafka-producer-network-thread | producer-44] INFO Metadata - [Producer clientId=producer-44] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.778 [kafka-producer-network-thread | producer-44] INFO TransactionManager - [Producer clientId=producer-44] ProducerId set to 56 with epoch 0
10:35:38.779 [pool-100-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Found no committed offset for partition test-topic-0000280-Tf41vck-0
10:35:38.780 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.780 [pool-100-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Resetting offset for partition test-topic-0000280-Tf41vck-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.781 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.781 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.781 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138780
10:35:38.781 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-283-qrdvKP0-99-79401b3a-32bc-4ef8-9ec1-e925cef5e3b0', protocol='range'}
10:35:38.781 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Finished assignment for group at generation 1: {consumer-sub-283-qrdvKP0-99-79401b3a-32bc-4ef8-9ec1-e925cef5e3b0=Assignment(partitions=[test-topic-0000283-KIHGGJM-0])}
10:35:38.781 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-46
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.782 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-46] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.782 [kafka-producer-network-thread | producer-45] INFO Metadata - [Producer clientId=producer-45] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.782 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-46] Instantiated an idempotent producer.
10:35:38.782 [kafka-producer-network-thread | producer-45] INFO TransactionManager - [Producer clientId=producer-45] ProducerId set to 1041 with epoch 0
10:35:38.783 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.784 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.784 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.784 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138784
10:35:38.784 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-47
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.785 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-47] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.785 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-47] Instantiated an idempotent producer.
10:35:38.785 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-283-qrdvKP0-99-79401b3a-32bc-4ef8-9ec1-e925cef5e3b0', protocol='range'}
10:35:38.785 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Notifying assignor about the new Assignment(partitions=[test-topic-0000283-KIHGGJM-0])
10:35:38.785 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Adding newly assigned partitions: test-topic-0000283-KIHGGJM-0
10:35:38.785 [kafka-producer-network-thread | producer-46] INFO Metadata - [Producer clientId=producer-46] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.785 [kafka-producer-network-thread | producer-46] INFO TransactionManager - [Producer clientId=producer-46] ProducerId set to 2046 with epoch 0
10:35:38.786 [pool-101-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Found no committed offset for partition test-topic-0000283-KIHGGJM-0
10:35:38.787 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.787 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.787 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.787 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138787
10:35:38.788 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-48
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.788 [pool-101-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Resetting offset for partition test-topic-0000283-KIHGGJM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.788 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-48] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.788 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-48] Instantiated an idempotent producer.
10:35:38.788 [kafka-producer-network-thread | producer-47] INFO Metadata - [Producer clientId=producer-47] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.789 [kafka-producer-network-thread | producer-47] INFO TransactionManager - [Producer clientId=producer-47] ProducerId set to 57 with epoch 0
10:35:38.790 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.790 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.790 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.790 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138790
10:35:38.790 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-49
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.791 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-49] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.791 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-49] Instantiated an idempotent producer.
10:35:38.791 [kafka-producer-network-thread | producer-48] INFO Metadata - [Producer clientId=producer-48] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.792 [kafka-producer-network-thread | producer-48] INFO TransactionManager - [Producer clientId=producer-48] ProducerId set to 60 with epoch 0
10:35:38.793 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.793 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.793 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.793 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138793
10:35:38.793 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-50
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.794 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-50] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.794 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-50] Instantiated an idempotent producer.
10:35:38.794 [kafka-producer-network-thread | producer-49] INFO Metadata - [Producer clientId=producer-49] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.794 [kafka-producer-network-thread | producer-49] INFO TransactionManager - [Producer clientId=producer-49] ProducerId set to 61 with epoch 0
10:35:38.795 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-289-5P3MXB0-101-5433975c-2eb5-41ce-bb37-0bab613a8885', protocol='range'}
10:35:38.795 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Finished assignment for group at generation 1: {consumer-sub-289-5P3MXB0-101-5433975c-2eb5-41ce-bb37-0bab613a8885=Assignment(partitions=[test-topic-0000289-tlcNYIU-0])}
10:35:38.796 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.796 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.796 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.796 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138796
10:35:38.796 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-51
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.797 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-51] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.797 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-51] Instantiated an idempotent producer.
10:35:38.797 [kafka-producer-network-thread | producer-50] INFO Metadata - [Producer clientId=producer-50] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.797 [kafka-producer-network-thread | producer-50] INFO TransactionManager - [Producer clientId=producer-50] ProducerId set to 62 with epoch 0
10:35:38.798 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-286-C_QmO_E-100-18e41f9b-de38-4a50-8a96-67c3bf5290ad', protocol='range'}
10:35:38.799 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Finished assignment for group at generation 1: {consumer-sub-286-C_QmO_E-100-18e41f9b-de38-4a50-8a96-67c3bf5290ad=Assignment(partitions=[test-topic-0000286-UC4nEGw-0])}
10:35:38.799 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.799 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.799 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.799 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138799
10:35:38.799 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-52
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.800 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-289-5P3MXB0-101-5433975c-2eb5-41ce-bb37-0bab613a8885', protocol='range'}
10:35:38.800 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Notifying assignor about the new Assignment(partitions=[test-topic-0000289-tlcNYIU-0])
10:35:38.800 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Adding newly assigned partitions: test-topic-0000289-tlcNYIU-0
10:35:38.800 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-52] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.800 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-52] Instantiated an idempotent producer.
10:35:38.800 [pool-103-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Found no committed offset for partition test-topic-0000289-tlcNYIU-0
10:35:38.801 [kafka-producer-network-thread | producer-51] INFO Metadata - [Producer clientId=producer-51] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.801 [kafka-producer-network-thread | producer-51] INFO TransactionManager - [Producer clientId=producer-51] ProducerId set to 65 with epoch 0
10:35:38.802 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.802 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.802 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.802 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138802
10:35:38.802 [pool-103-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Resetting offset for partition test-topic-0000289-tlcNYIU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.802 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-53
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.803 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-53] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.803 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-53] Instantiated an idempotent producer.
10:35:38.804 [kafka-producer-network-thread | producer-52] INFO Metadata - [Producer clientId=producer-52] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.804 [kafka-producer-network-thread | producer-52] INFO TransactionManager - [Producer clientId=producer-52] ProducerId set to 2050 with epoch 0
10:35:38.805 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-286-C_QmO_E-100-18e41f9b-de38-4a50-8a96-67c3bf5290ad', protocol='range'}
10:35:38.805 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Notifying assignor about the new Assignment(partitions=[test-topic-0000286-UC4nEGw-0])
10:35:38.805 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Adding newly assigned partitions: test-topic-0000286-UC4nEGw-0
10:35:38.806 [pool-102-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Found no committed offset for partition test-topic-0000286-UC4nEGw-0
10:35:38.807 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.807 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.807 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.807 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138807
10:35:38.807 [pool-102-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Resetting offset for partition test-topic-0000286-UC4nEGw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.808 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-54
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.808 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-54] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.808 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-54] Instantiated an idempotent producer.
10:35:38.809 [kafka-producer-network-thread | producer-53] INFO Metadata - [Producer clientId=producer-53] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.809 [kafka-producer-network-thread | producer-53] INFO TransactionManager - [Producer clientId=producer-53] ProducerId set to 2051 with epoch 0
10:35:38.809 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-292-0_zH55A-102-77247aae-3898-445e-8d47-1cc25e2e9a44', protocol='range'}
10:35:38.810 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Finished assignment for group at generation 1: {consumer-sub-292-0_zH55A-102-77247aae-3898-445e-8d47-1cc25e2e9a44=Assignment(partitions=[test-topic-0000292--jBlQhg-0])}
10:35:38.810 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.810 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.810 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.810 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138810
10:35:38.811 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-295-yYRDrkU-103-1be972a8-eb9f-4320-93be-bdfab0e0239e', protocol='range'}
10:35:38.811 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-55
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.811 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Finished assignment for group at generation 1: {consumer-sub-295-yYRDrkU-103-1be972a8-eb9f-4320-93be-bdfab0e0239e=Assignment(partitions=[test-topic-0000295-I5j6jbk-0])}
10:35:38.811 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-55] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.811 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-55] Instantiated an idempotent producer.
10:35:38.812 [kafka-producer-network-thread | producer-54] INFO Metadata - [Producer clientId=producer-54] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.812 [kafka-producer-network-thread | producer-54] INFO TransactionManager - [Producer clientId=producer-54] ProducerId set to 69 with epoch 0
10:35:38.813 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.813 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.813 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-292-0_zH55A-102-77247aae-3898-445e-8d47-1cc25e2e9a44', protocol='range'}
10:35:38.813 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.813 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138813
10:35:38.813 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Notifying assignor about the new Assignment(partitions=[test-topic-0000292--jBlQhg-0])
10:35:38.813 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Adding newly assigned partitions: test-topic-0000292--jBlQhg-0
10:35:38.814 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-56
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.814 [pool-104-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Found no committed offset for partition test-topic-0000292--jBlQhg-0
10:35:38.814 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-56] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.814 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-56] Instantiated an idempotent producer.
10:35:38.815 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-295-yYRDrkU-103-1be972a8-eb9f-4320-93be-bdfab0e0239e', protocol='range'}
10:35:38.815 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Notifying assignor about the new Assignment(partitions=[test-topic-0000295-I5j6jbk-0])
10:35:38.815 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Adding newly assigned partitions: test-topic-0000295-I5j6jbk-0
10:35:38.815 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-298-GMkVXt0-104-609a9f17-e6d8-4445-8c1d-a90748f721b8', protocol='range'}
10:35:38.815 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Finished assignment for group at generation 1: {consumer-sub-298-GMkVXt0-104-609a9f17-e6d8-4445-8c1d-a90748f721b8=Assignment(partitions=[test-topic-0000298-ceeBYS0-0])}
10:35:38.816 [pool-105-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Found no committed offset for partition test-topic-0000295-I5j6jbk-0
10:35:38.816 [pool-104-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Resetting offset for partition test-topic-0000292--jBlQhg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.817 [kafka-producer-network-thread | producer-55] INFO Metadata - [Producer clientId=producer-55] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.817 [kafka-producer-network-thread | producer-55] INFO TransactionManager - [Producer clientId=producer-55] ProducerId set to 71 with epoch 0
10:35:38.817 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.817 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.817 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.817 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138817
10:35:38.817 [pool-105-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Resetting offset for partition test-topic-0000295-I5j6jbk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.817 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-301-ForHoYM-105-c6edf2b8-ad3a-419b-932e-c7b72d1e9410', protocol='range'}
10:35:38.818 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Finished assignment for group at generation 1: {consumer-sub-301-ForHoYM-105-c6edf2b8-ad3a-419b-932e-c7b72d1e9410=Assignment(partitions=[test-topic-0000301-yA-mZIA-0])}
10:35:38.818 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-57
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.818 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-57] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.818 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-57] Instantiated an idempotent producer.
10:35:38.819 [kafka-producer-network-thread | producer-56] INFO Metadata - [Producer clientId=producer-56] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.819 [kafka-producer-network-thread | producer-56] INFO TransactionManager - [Producer clientId=producer-56] ProducerId set to 72 with epoch 0
10:35:38.820 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-298-GMkVXt0-104-609a9f17-e6d8-4445-8c1d-a90748f721b8', protocol='range'}
10:35:38.820 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Notifying assignor about the new Assignment(partitions=[test-topic-0000298-ceeBYS0-0])
10:35:38.820 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Adding newly assigned partitions: test-topic-0000298-ceeBYS0-0
10:35:38.820 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.820 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.820 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.820 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138820
10:35:38.821 [pool-106-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Found no committed offset for partition test-topic-0000298-ceeBYS0-0
10:35:38.821 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-301-ForHoYM-105-c6edf2b8-ad3a-419b-932e-c7b72d1e9410', protocol='range'}
10:35:38.821 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-58
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.821 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Notifying assignor about the new Assignment(partitions=[test-topic-0000301-yA-mZIA-0])
10:35:38.821 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Adding newly assigned partitions: test-topic-0000301-yA-mZIA-0
10:35:38.821 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-58] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.821 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-58] Instantiated an idempotent producer.
10:35:38.821 [pool-107-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Found no committed offset for partition test-topic-0000301-yA-mZIA-0
10:35:38.822 [pool-106-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Resetting offset for partition test-topic-0000298-ceeBYS0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.823 [pool-107-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Resetting offset for partition test-topic-0000301-yA-mZIA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.824 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.824 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.824 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.824 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138824
10:35:38.825 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-59
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.825 [kafka-producer-network-thread | producer-57] INFO TransactionManager - [Producer clientId=producer-57] ProducerId set to 2055 with epoch 0
10:35:38.825 [kafka-producer-network-thread | producer-57] INFO Metadata - [Producer clientId=producer-57] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.825 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-59] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.826 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-59] Instantiated an idempotent producer.
10:35:38.827 [kafka-producer-network-thread | producer-58] INFO Metadata - [Producer clientId=producer-58] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.827 [kafka-producer-network-thread | producer-58] INFO TransactionManager - [Producer clientId=producer-58] ProducerId set to 2057 with epoch 0
10:35:38.828 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.828 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.828 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.828 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138828
10:35:38.829 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-60
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.829 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-304-lFC-9Mk-106-a274a443-45b4-49f6-9f22-fbe91f4db1cb', protocol='range'}
10:35:38.829 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-60] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.829 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-60] Instantiated an idempotent producer.
10:35:38.829 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Finished assignment for group at generation 1: {consumer-sub-304-lFC-9Mk-106-a274a443-45b4-49f6-9f22-fbe91f4db1cb=Assignment(partitions=[test-topic-0000304-ov6qkF0-0])}
10:35:38.830 [kafka-producer-network-thread | producer-59] INFO Metadata - [Producer clientId=producer-59] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.830 [kafka-producer-network-thread | producer-59] INFO TransactionManager - [Producer clientId=producer-59] ProducerId set to 1054 with epoch 0
10:35:38.833 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.833 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.833 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.833 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138833
10:35:38.833 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-304-lFC-9Mk-106-a274a443-45b4-49f6-9f22-fbe91f4db1cb', protocol='range'}
10:35:38.833 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Notifying assignor about the new Assignment(partitions=[test-topic-0000304-ov6qkF0-0])
10:35:38.833 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Adding newly assigned partitions: test-topic-0000304-ov6qkF0-0
10:35:38.833 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-61
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.834 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-61] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.834 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-61] Instantiated an idempotent producer.
10:35:38.834 [pool-108-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Found no committed offset for partition test-topic-0000304-ov6qkF0-0
10:35:38.835 [kafka-producer-network-thread | producer-60] INFO Metadata - [Producer clientId=producer-60] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.836 [kafka-producer-network-thread | producer-60] INFO TransactionManager - [Producer clientId=producer-60] ProducerId set to 1057 with epoch 0
10:35:38.836 [pool-108-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Resetting offset for partition test-topic-0000304-ov6qkF0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.837 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-307-obAgLJY-107-a4fb027d-b94c-46f0-9edb-417d5912784a', protocol='range'}
10:35:38.837 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Finished assignment for group at generation 1: {consumer-sub-307-obAgLJY-107-a4fb027d-b94c-46f0-9edb-417d5912784a=Assignment(partitions=[test-topic-0000307-jPsw980-0])}
10:35:38.840 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-310-R0E95os-108-89a83861-c1a0-4c00-9ab3-c7891d7aaa3e', protocol='range'}
10:35:38.840 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Finished assignment for group at generation 1: {consumer-sub-310-R0E95os-108-89a83861-c1a0-4c00-9ab3-c7891d7aaa3e=Assignment(partitions=[test-topic-0000310-nAgI1eA-0])}
10:35:38.842 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-313-R0lwR2M-109-f5e1e96f-dde4-4d8d-b2e9-9fc1ee9f0731', protocol='range'}
10:35:38.842 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.842 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.842 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.842 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138842
10:35:38.842 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Finished assignment for group at generation 1: {consumer-sub-313-R0lwR2M-109-f5e1e96f-dde4-4d8d-b2e9-9fc1ee9f0731=Assignment(partitions=[test-topic-0000313-X7YT0wM-0])}
10:35:38.842 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-307-obAgLJY-107-a4fb027d-b94c-46f0-9edb-417d5912784a', protocol='range'}
10:35:38.842 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Notifying assignor about the new Assignment(partitions=[test-topic-0000307-jPsw980-0])
10:35:38.842 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Adding newly assigned partitions: test-topic-0000307-jPsw980-0
10:35:38.842 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-62
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.843 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-62] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.843 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-62] Instantiated an idempotent producer.
10:35:38.843 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-310-R0E95os-108-89a83861-c1a0-4c00-9ab3-c7891d7aaa3e', protocol='range'}
10:35:38.843 [pool-109-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Found no committed offset for partition test-topic-0000307-jPsw980-0
10:35:38.843 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Notifying assignor about the new Assignment(partitions=[test-topic-0000310-nAgI1eA-0])
10:35:38.843 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Adding newly assigned partitions: test-topic-0000310-nAgI1eA-0
10:35:38.844 [pool-110-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Found no committed offset for partition test-topic-0000310-nAgI1eA-0
10:35:38.845 [kafka-producer-network-thread | producer-61] INFO Metadata - [Producer clientId=producer-61] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.845 [kafka-producer-network-thread | producer-61] INFO TransactionManager - [Producer clientId=producer-61] ProducerId set to 1062 with epoch 0
10:35:38.845 [pool-109-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Resetting offset for partition test-topic-0000307-jPsw980-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.845 [pool-110-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Resetting offset for partition test-topic-0000310-nAgI1eA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.846 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-313-R0lwR2M-109-f5e1e96f-dde4-4d8d-b2e9-9fc1ee9f0731', protocol='range'}
10:35:38.846 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Notifying assignor about the new Assignment(partitions=[test-topic-0000313-X7YT0wM-0])
10:35:38.846 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Adding newly assigned partitions: test-topic-0000313-X7YT0wM-0
10:35:38.846 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-316-BeFW2Tg-110-cc7f741d-c66a-4be6-8c76-29ad6f189395', protocol='range'}
10:35:38.846 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Finished assignment for group at generation 1: {consumer-sub-316-BeFW2Tg-110-cc7f741d-c66a-4be6-8c76-29ad6f189395=Assignment(partitions=[test-topic-0000316-Lxd4VNo-0])}
10:35:38.846 [pool-111-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Found no committed offset for partition test-topic-0000313-X7YT0wM-0
10:35:38.848 [pool-111-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Resetting offset for partition test-topic-0000313-X7YT0wM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.849 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.849 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.849 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.849 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138849
10:35:38.849 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-63
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.850 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-63] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.850 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-63] Instantiated an idempotent producer.
10:35:38.850 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-316-BeFW2Tg-110-cc7f741d-c66a-4be6-8c76-29ad6f189395', protocol='range'}
10:35:38.850 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Notifying assignor about the new Assignment(partitions=[test-topic-0000316-Lxd4VNo-0])
10:35:38.850 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Adding newly assigned partitions: test-topic-0000316-Lxd4VNo-0
10:35:38.850 [kafka-producer-network-thread | producer-62] INFO Metadata - [Producer clientId=producer-62] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.851 [kafka-producer-network-thread | producer-62] INFO TransactionManager - [Producer clientId=producer-62] ProducerId set to 1064 with epoch 0
10:35:38.851 [pool-112-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Found no committed offset for partition test-topic-0000316-Lxd4VNo-0
10:35:38.851 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-319-GAjFQLU-111-1425e678-b56d-449e-ae82-cbc4b7ae4cf3', protocol='range'}
10:35:38.851 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Finished assignment for group at generation 1: {consumer-sub-319-GAjFQLU-111-1425e678-b56d-449e-ae82-cbc4b7ae4cf3=Assignment(partitions=[test-topic-0000319-9t7gUAI-0])}
10:35:38.852 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.853 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.853 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.853 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138853
10:35:38.853 [pool-112-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Resetting offset for partition test-topic-0000316-Lxd4VNo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.853 [kafka-producer-network-thread | producer-63] INFO Metadata - [Producer clientId=producer-63] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.853 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-64
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.853 [kafka-producer-network-thread | producer-63] INFO TransactionManager - [Producer clientId=producer-63] ProducerId set to 82 with epoch 0
10:35:38.854 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-64] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.854 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-64] Instantiated an idempotent producer.
10:35:38.854 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-319-GAjFQLU-111-1425e678-b56d-449e-ae82-cbc4b7ae4cf3', protocol='range'}
10:35:38.855 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Notifying assignor about the new Assignment(partitions=[test-topic-0000319-9t7gUAI-0])
10:35:38.855 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Adding newly assigned partitions: test-topic-0000319-9t7gUAI-0
10:35:38.855 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-322-Q_l-zqA-112-a575abb0-64d6-4ca0-897a-fd5b2aa2fe99', protocol='range'}
10:35:38.855 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Finished assignment for group at generation 1: {consumer-sub-322-Q_l-zqA-112-a575abb0-64d6-4ca0-897a-fd5b2aa2fe99=Assignment(partitions=[test-topic-0000322-xRObVwo-0])}
10:35:38.855 [pool-113-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Found no committed offset for partition test-topic-0000319-9t7gUAI-0
10:35:38.856 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.856 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.856 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.856 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138856
10:35:38.857 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-65
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.857 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-65] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.857 [pool-113-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Resetting offset for partition test-topic-0000319-9t7gUAI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.857 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-65] Instantiated an idempotent producer.
10:35:38.859 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-322-Q_l-zqA-112-a575abb0-64d6-4ca0-897a-fd5b2aa2fe99', protocol='range'}
10:35:38.859 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Notifying assignor about the new Assignment(partitions=[test-topic-0000322-xRObVwo-0])
10:35:38.859 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Adding newly assigned partitions: test-topic-0000322-xRObVwo-0
10:35:38.859 [kafka-producer-network-thread | producer-64] INFO Metadata - [Producer clientId=producer-64] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.859 [pool-114-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Found no committed offset for partition test-topic-0000322-xRObVwo-0
10:35:38.859 [kafka-producer-network-thread | producer-64] INFO TransactionManager - [Producer clientId=producer-64] ProducerId set to 1066 with epoch 0
10:35:38.860 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.860 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.860 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.860 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138860
10:35:38.860 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-66
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.861 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-66] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.861 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-66] Instantiated an idempotent producer.
10:35:38.862 [pool-114-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Resetting offset for partition test-topic-0000322-xRObVwo-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.862 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-325-wXE01jo-113-ef21c79d-29e6-41ef-b4bd-6c6a56fe2ec2', protocol='range'}
10:35:38.863 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Finished assignment for group at generation 1: {consumer-sub-325-wXE01jo-113-ef21c79d-29e6-41ef-b4bd-6c6a56fe2ec2=Assignment(partitions=[test-topic-0000325-yVBo-XQ-0])}
10:35:38.864 [kafka-producer-network-thread | producer-65] INFO Metadata - [Producer clientId=producer-65] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.864 [kafka-producer-network-thread | producer-65] INFO TransactionManager - [Producer clientId=producer-65] ProducerId set to 2063 with epoch 0
10:35:38.866 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-325-wXE01jo-113-ef21c79d-29e6-41ef-b4bd-6c6a56fe2ec2', protocol='range'}
10:35:38.866 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Notifying assignor about the new Assignment(partitions=[test-topic-0000325-yVBo-XQ-0])
10:35:38.866 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Adding newly assigned partitions: test-topic-0000325-yVBo-XQ-0
10:35:38.867 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.867 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.867 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.867 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138867
10:35:38.867 [pool-115-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Found no committed offset for partition test-topic-0000325-yVBo-XQ-0
10:35:38.867 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-67
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.868 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-67] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.868 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-67] Instantiated an idempotent producer.
10:35:38.869 [pool-115-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Resetting offset for partition test-topic-0000325-yVBo-XQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.869 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-328-IrnBZGs-114-71307c36-04e7-4213-a03d-d3c31cf0d39e', protocol='range'}
10:35:38.869 [kafka-producer-network-thread | producer-66] INFO Metadata - [Producer clientId=producer-66] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.869 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Finished assignment for group at generation 1: {consumer-sub-328-IrnBZGs-114-71307c36-04e7-4213-a03d-d3c31cf0d39e=Assignment(partitions=[test-topic-0000328-gFAenbQ-0])}
10:35:38.870 [kafka-producer-network-thread | producer-66] INFO TransactionManager - [Producer clientId=producer-66] ProducerId set to 2065 with epoch 0
10:35:38.870 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.870 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.870 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.870 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138870
10:35:38.870 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-68
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.871 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-68] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.871 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-68] Instantiated an idempotent producer.
10:35:38.872 [kafka-producer-network-thread | producer-67] INFO Metadata - [Producer clientId=producer-67] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.872 [kafka-producer-network-thread | producer-67] INFO TransactionManager - [Producer clientId=producer-67] ProducerId set to 2066 with epoch 0
10:35:38.872 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.872 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.872 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.872 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138872
10:35:38.873 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-69
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.873 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-328-IrnBZGs-114-71307c36-04e7-4213-a03d-d3c31cf0d39e', protocol='range'}
10:35:38.873 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Notifying assignor about the new Assignment(partitions=[test-topic-0000328-gFAenbQ-0])
10:35:38.873 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-69] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.873 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Adding newly assigned partitions: test-topic-0000328-gFAenbQ-0
10:35:38.873 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-331-OY1AMrs-115-7cc71e94-13d6-44b3-987d-09938f1de11c', protocol='range'}
10:35:38.874 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Finished assignment for group at generation 1: {consumer-sub-331-OY1AMrs-115-7cc71e94-13d6-44b3-987d-09938f1de11c=Assignment(partitions=[test-topic-0000331-SozV4lU-0])}
10:35:38.874 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-69] Instantiated an idempotent producer.
10:35:38.874 [kafka-producer-network-thread | producer-68] INFO Metadata - [Producer clientId=producer-68] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.874 [pool-116-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Found no committed offset for partition test-topic-0000328-gFAenbQ-0
10:35:38.874 [kafka-producer-network-thread | producer-68] INFO TransactionManager - [Producer clientId=producer-68] ProducerId set to 1074 with epoch 0
10:35:38.876 [pool-116-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Resetting offset for partition test-topic-0000328-gFAenbQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.877 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-331-OY1AMrs-115-7cc71e94-13d6-44b3-987d-09938f1de11c', protocol='range'}
10:35:38.877 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Notifying assignor about the new Assignment(partitions=[test-topic-0000331-SozV4lU-0])
10:35:38.877 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Adding newly assigned partitions: test-topic-0000331-SozV4lU-0
10:35:38.878 [pool-117-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Found no committed offset for partition test-topic-0000331-SozV4lU-0
10:35:38.878 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-334-vbmgVHU-116-e98b5212-d2e6-4f1d-bf2f-605757253042', protocol='range'}
10:35:38.878 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Finished assignment for group at generation 1: {consumer-sub-334-vbmgVHU-116-e98b5212-d2e6-4f1d-bf2f-605757253042=Assignment(partitions=[test-topic-0000334-lg5rX9A-0])}
10:35:38.880 [pool-117-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Resetting offset for partition test-topic-0000331-SozV4lU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.881 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.881 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.881 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.881 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138881
10:35:38.881 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-70
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.881 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-337-sKVKKJo-117-946f75c5-777f-413b-9c1e-9b74ed1b13b2', protocol='range'}
10:35:38.881 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Finished assignment for group at generation 1: {consumer-sub-337-sKVKKJo-117-946f75c5-777f-413b-9c1e-9b74ed1b13b2=Assignment(partitions=[test-topic-0000337-Z2pSJcI-0])}
10:35:38.882 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-70] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.882 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-70] Instantiated an idempotent producer.
10:35:38.882 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-334-vbmgVHU-116-e98b5212-d2e6-4f1d-bf2f-605757253042', protocol='range'}
10:35:38.882 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Notifying assignor about the new Assignment(partitions=[test-topic-0000334-lg5rX9A-0])
10:35:38.882 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Adding newly assigned partitions: test-topic-0000334-lg5rX9A-0
10:35:38.883 [kafka-producer-network-thread | producer-69] INFO Metadata - [Producer clientId=producer-69] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.883 [pool-118-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Found no committed offset for partition test-topic-0000334-lg5rX9A-0
10:35:38.883 [kafka-producer-network-thread | producer-69] INFO TransactionManager - [Producer clientId=producer-69] ProducerId set to 2072 with epoch 0
10:35:38.885 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-337-sKVKKJo-117-946f75c5-777f-413b-9c1e-9b74ed1b13b2', protocol='range'}
10:35:38.885 [pool-118-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Resetting offset for partition test-topic-0000334-lg5rX9A-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.885 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Notifying assignor about the new Assignment(partitions=[test-topic-0000337-Z2pSJcI-0])
10:35:38.885 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Adding newly assigned partitions: test-topic-0000337-Z2pSJcI-0
10:35:38.886 [pool-119-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Found no committed offset for partition test-topic-0000337-Z2pSJcI-0
10:35:38.887 [pool-119-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Resetting offset for partition test-topic-0000337-Z2pSJcI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.889 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.889 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.889 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.889 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138889
10:35:38.889 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-340-sJB-GGc-118-d2346536-70e9-4de6-8d09-c852d3827518', protocol='range'}
10:35:38.889 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Finished assignment for group at generation 1: {consumer-sub-340-sJB-GGc-118-d2346536-70e9-4de6-8d09-c852d3827518=Assignment(partitions=[test-topic-0000340-6fVYvHQ-0])}
10:35:38.889 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-71
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.890 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-71] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.890 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-71] Instantiated an idempotent producer.
10:35:38.891 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-343-tCi6D5E-119-c83ba2ca-452f-47dd-b274-ff861b66007a', protocol='range'}
10:35:38.891 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Finished assignment for group at generation 1: {consumer-sub-343-tCi6D5E-119-c83ba2ca-452f-47dd-b274-ff861b66007a=Assignment(partitions=[test-topic-0000343-QjcgwwM-0])}
10:35:38.892 [kafka-producer-network-thread | producer-70] INFO Metadata - [Producer clientId=producer-70] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.892 [kafka-producer-network-thread | producer-70] INFO TransactionManager - [Producer clientId=producer-70] ProducerId set to 2075 with epoch 0
10:35:38.892 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.892 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.892 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.892 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138892
10:35:38.893 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-72
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.893 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-72] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.893 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-72] Instantiated an idempotent producer.
10:35:38.893 [kafka-producer-network-thread | producer-71] INFO Metadata - [Producer clientId=producer-71] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.894 [kafka-producer-network-thread | producer-71] INFO TransactionManager - [Producer clientId=producer-71] ProducerId set to 88 with epoch 0
10:35:38.894 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-340-sJB-GGc-118-d2346536-70e9-4de6-8d09-c852d3827518', protocol='range'}
10:35:38.894 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Notifying assignor about the new Assignment(partitions=[test-topic-0000340-6fVYvHQ-0])
10:35:38.894 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Adding newly assigned partitions: test-topic-0000340-6fVYvHQ-0
10:35:38.895 [pool-120-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Found no committed offset for partition test-topic-0000340-6fVYvHQ-0
10:35:38.895 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.895 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.895 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.895 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138895
10:35:38.896 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-346-6ZznPpc-120-bfbda878-3d45-4e0f-9b71-a5f3deeea35f', protocol='range'}
10:35:38.896 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Finished assignment for group at generation 1: {consumer-sub-346-6ZznPpc-120-bfbda878-3d45-4e0f-9b71-a5f3deeea35f=Assignment(partitions=[test-topic-0000346-67ml2YA-0])}
10:35:38.896 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-73
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.896 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-73] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.896 [kafka-producer-network-thread | producer-72] INFO Metadata - [Producer clientId=producer-72] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.896 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-73] Instantiated an idempotent producer.
10:35:38.896 [kafka-producer-network-thread | producer-72] INFO TransactionManager - [Producer clientId=producer-72] ProducerId set to 1080 with epoch 0
10:35:38.897 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-349-puyQhKk-121-537bd1f5-797d-47dc-b325-2cb968d84043', protocol='range'}
10:35:38.898 [pool-120-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Resetting offset for partition test-topic-0000340-6fVYvHQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.898 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Finished assignment for group at generation 1: {consumer-sub-349-puyQhKk-121-537bd1f5-797d-47dc-b325-2cb968d84043=Assignment(partitions=[test-topic-0000349-MJA-dNs-0])}
10:35:38.898 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-343-tCi6D5E-119-c83ba2ca-452f-47dd-b274-ff861b66007a', protocol='range'}
10:35:38.898 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Notifying assignor about the new Assignment(partitions=[test-topic-0000343-QjcgwwM-0])
10:35:38.898 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Adding newly assigned partitions: test-topic-0000343-QjcgwwM-0
10:35:38.898 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.898 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.898 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.898 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138898
10:35:38.899 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-74
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.899 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-346-6ZznPpc-120-bfbda878-3d45-4e0f-9b71-a5f3deeea35f', protocol='range'}
10:35:38.899 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Notifying assignor about the new Assignment(partitions=[test-topic-0000346-67ml2YA-0])
10:35:38.899 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Adding newly assigned partitions: test-topic-0000346-67ml2YA-0
10:35:38.899 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-74] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.899 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-74] Instantiated an idempotent producer.
10:35:38.900 [kafka-producer-network-thread | producer-73] INFO Metadata - [Producer clientId=producer-73] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.900 [kafka-producer-network-thread | producer-73] INFO TransactionManager - [Producer clientId=producer-73] ProducerId set to 1081 with epoch 0
10:35:38.901 [pool-122-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Found no committed offset for partition test-topic-0000346-67ml2YA-0
10:35:38.901 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-349-puyQhKk-121-537bd1f5-797d-47dc-b325-2cb968d84043', protocol='range'}
10:35:38.901 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Notifying assignor about the new Assignment(partitions=[test-topic-0000349-MJA-dNs-0])
10:35:38.901 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Adding newly assigned partitions: test-topic-0000349-MJA-dNs-0
10:35:38.902 [pool-121-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Found no committed offset for partition test-topic-0000343-QjcgwwM-0
10:35:38.902 [pool-123-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Found no committed offset for partition test-topic-0000349-MJA-dNs-0
10:35:38.902 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-352-tPmGvSE-122-6f6b8759-01ba-4f80-a60b-a55e43012241', protocol='range'}
10:35:38.902 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Finished assignment for group at generation 1: {consumer-sub-352-tPmGvSE-122-6f6b8759-01ba-4f80-a60b-a55e43012241=Assignment(partitions=[test-topic-0000352-sGfuRYg-0])}
10:35:38.903 [pool-122-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Resetting offset for partition test-topic-0000346-67ml2YA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.903 [pool-121-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Resetting offset for partition test-topic-0000343-QjcgwwM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.904 [pool-123-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Resetting offset for partition test-topic-0000349-MJA-dNs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.905 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.905 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.905 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.905 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138905
10:35:38.905 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-75
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.905 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-352-tPmGvSE-122-6f6b8759-01ba-4f80-a60b-a55e43012241', protocol='range'}
10:35:38.905 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Notifying assignor about the new Assignment(partitions=[test-topic-0000352-sGfuRYg-0])
10:35:38.905 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Adding newly assigned partitions: test-topic-0000352-sGfuRYg-0
10:35:38.906 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-75] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.906 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-75] Instantiated an idempotent producer.
10:35:38.906 [pool-124-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Found no committed offset for partition test-topic-0000352-sGfuRYg-0
10:35:38.907 [kafka-producer-network-thread | producer-74] INFO Metadata - [Producer clientId=producer-74] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.907 [kafka-producer-network-thread | producer-74] INFO TransactionManager - [Producer clientId=producer-74] ProducerId set to 91 with epoch 0
10:35:38.908 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.908 [pool-124-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Resetting offset for partition test-topic-0000352-sGfuRYg-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.908 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.908 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.908 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138908
10:35:38.908 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-76
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.909 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-355-XWukxHo-123-9dbe8adb-d45e-444b-94da-2478cc2a206b', protocol='range'}
10:35:38.909 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-76] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.909 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-76] Instantiated an idempotent producer.
10:35:38.909 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Finished assignment for group at generation 1: {consumer-sub-355-XWukxHo-123-9dbe8adb-d45e-444b-94da-2478cc2a206b=Assignment(partitions=[test-topic-0000355-8KDY5A8-0])}
10:35:38.910 [kafka-producer-network-thread | producer-75] INFO Metadata - [Producer clientId=producer-75] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.911 [kafka-producer-network-thread | producer-75] INFO TransactionManager - [Producer clientId=producer-75] ProducerId set to 1083 with epoch 0
10:35:38.911 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.911 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.911 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.911 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138911
10:35:38.912 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-77
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.912 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-77] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.912 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-77] Instantiated an idempotent producer.
10:35:38.913 [kafka-producer-network-thread | producer-76] INFO Metadata - [Producer clientId=producer-76] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.913 [kafka-producer-network-thread | producer-76] INFO TransactionManager - [Producer clientId=producer-76] ProducerId set to 2078 with epoch 0
10:35:38.914 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-355-XWukxHo-123-9dbe8adb-d45e-444b-94da-2478cc2a206b', protocol='range'}
10:35:38.914 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Notifying assignor about the new Assignment(partitions=[test-topic-0000355-8KDY5A8-0])
10:35:38.914 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Adding newly assigned partitions: test-topic-0000355-8KDY5A8-0
10:35:38.915 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-358-AcQiokY-124-52b6ec66-a41c-4c69-a0b0-035c7f098e27', protocol='range'}
10:35:38.915 [pool-125-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Found no committed offset for partition test-topic-0000355-8KDY5A8-0
10:35:38.915 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Finished assignment for group at generation 1: {consumer-sub-358-AcQiokY-124-52b6ec66-a41c-4c69-a0b0-035c7f098e27=Assignment(partitions=[test-topic-0000358-VRn-TQc-0])}
10:35:38.916 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-361-Gb3dfKI-125-1bad7ba4-ed26-4acb-979f-cba307a9415b', protocol='range'}
10:35:38.916 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Finished assignment for group at generation 1: {consumer-sub-361-Gb3dfKI-125-1bad7ba4-ed26-4acb-979f-cba307a9415b=Assignment(partitions=[test-topic-0000361-LZwO7zU-0])}
10:35:38.917 [pool-125-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Resetting offset for partition test-topic-0000355-8KDY5A8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.918 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-358-AcQiokY-124-52b6ec66-a41c-4c69-a0b0-035c7f098e27', protocol='range'}
10:35:38.918 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Notifying assignor about the new Assignment(partitions=[test-topic-0000358-VRn-TQc-0])
10:35:38.919 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Adding newly assigned partitions: test-topic-0000358-VRn-TQc-0
10:35:38.919 [pool-126-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Found no committed offset for partition test-topic-0000358-VRn-TQc-0
10:35:38.920 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-361-Gb3dfKI-125-1bad7ba4-ed26-4acb-979f-cba307a9415b', protocol='range'}
10:35:38.920 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Notifying assignor about the new Assignment(partitions=[test-topic-0000361-LZwO7zU-0])
10:35:38.920 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Adding newly assigned partitions: test-topic-0000361-LZwO7zU-0
10:35:38.920 [pool-127-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Found no committed offset for partition test-topic-0000361-LZwO7zU-0
10:35:38.921 [pool-126-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Resetting offset for partition test-topic-0000358-VRn-TQc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.922 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-364--B3TswQ-126-97ac7737-92d9-48de-a41b-b7b9ee9bfc6a', protocol='range'}
10:35:38.922 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Finished assignment for group at generation 1: {consumer-sub-364--B3TswQ-126-97ac7737-92d9-48de-a41b-b7b9ee9bfc6a=Assignment(partitions=[test-topic-0000364-kAq5nsI-0])}
10:35:38.922 [pool-127-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Resetting offset for partition test-topic-0000361-LZwO7zU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.923 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.923 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.923 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.923 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138923
10:35:38.923 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-78
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.924 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-78] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.924 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-78] Instantiated an idempotent producer.
10:35:38.924 [kafka-producer-network-thread | producer-77] INFO Metadata - [Producer clientId=producer-77] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.925 [kafka-producer-network-thread | producer-77] INFO TransactionManager - [Producer clientId=producer-77] ProducerId set to 95 with epoch 0
10:35:38.925 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-364--B3TswQ-126-97ac7737-92d9-48de-a41b-b7b9ee9bfc6a', protocol='range'}
10:35:38.925 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000364-kAq5nsI-0])
10:35:38.925 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Adding newly assigned partitions: test-topic-0000364-kAq5nsI-0
10:35:38.926 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.926 [pool-128-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Found no committed offset for partition test-topic-0000364-kAq5nsI-0
10:35:38.926 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.926 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.926 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138926
10:35:38.927 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-79
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.927 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-79] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.927 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-79] Instantiated an idempotent producer.
10:35:38.927 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-367-ql_4kYc-127-bada1af4-9b48-4af0-895d-174651bfa242', protocol='range'}
10:35:38.928 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Finished assignment for group at generation 1: {consumer-sub-367-ql_4kYc-127-bada1af4-9b48-4af0-895d-174651bfa242=Assignment(partitions=[test-topic-0000367-NouK178-0])}
10:35:38.928 [pool-128-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Resetting offset for partition test-topic-0000364-kAq5nsI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.928 [kafka-producer-network-thread | producer-78] INFO Metadata - [Producer clientId=producer-78] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.928 [kafka-producer-network-thread | producer-78] INFO TransactionManager - [Producer clientId=producer-78] ProducerId set to 1085 with epoch 0
10:35:38.930 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.930 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.930 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.930 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138930
10:35:38.930 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-80
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.931 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-80] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.931 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-80] Instantiated an idempotent producer.
10:35:38.931 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-367-ql_4kYc-127-bada1af4-9b48-4af0-895d-174651bfa242', protocol='range'}
10:35:38.931 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Notifying assignor about the new Assignment(partitions=[test-topic-0000367-NouK178-0])
10:35:38.931 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Adding newly assigned partitions: test-topic-0000367-NouK178-0
10:35:38.931 [kafka-producer-network-thread | producer-79] INFO Metadata - [Producer clientId=producer-79] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.932 [kafka-producer-network-thread | producer-79] INFO TransactionManager - [Producer clientId=producer-79] ProducerId set to 100 with epoch 0
10:35:38.932 [pool-129-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Found no committed offset for partition test-topic-0000367-NouK178-0
10:35:38.932 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-370-v5wLaPc-128-548de164-e564-4272-b293-b36ed7828710', protocol='range'}
10:35:38.932 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Finished assignment for group at generation 1: {consumer-sub-370-v5wLaPc-128-548de164-e564-4272-b293-b36ed7828710=Assignment(partitions=[test-topic-0000370-mEr65Xk-0])}
10:35:38.934 [pool-129-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Resetting offset for partition test-topic-0000367-NouK178-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.934 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-373-4hV6wFE-129-08a1e9eb-6997-49d4-b916-e7a6be4a3326', protocol='range'}
10:35:38.934 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Finished assignment for group at generation 1: {consumer-sub-373-4hV6wFE-129-08a1e9eb-6997-49d4-b916-e7a6be4a3326=Assignment(partitions=[test-topic-0000373-_NDkX0c-0])}
10:35:38.936 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-370-v5wLaPc-128-548de164-e564-4272-b293-b36ed7828710', protocol='range'}
10:35:38.936 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Notifying assignor about the new Assignment(partitions=[test-topic-0000370-mEr65Xk-0])
10:35:38.936 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Adding newly assigned partitions: test-topic-0000370-mEr65Xk-0
10:35:38.937 [pool-130-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Found no committed offset for partition test-topic-0000370-mEr65Xk-0
10:35:38.938 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.938 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.938 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.938 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138938
10:35:38.938 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-81
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.939 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-81] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.939 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-81] Instantiated an idempotent producer.
10:35:38.939 [kafka-producer-network-thread | producer-80] INFO Metadata - [Producer clientId=producer-80] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.939 [kafka-producer-network-thread | producer-80] INFO TransactionManager - [Producer clientId=producer-80] ProducerId set to 2082 with epoch 0
10:35:38.940 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-373-4hV6wFE-129-08a1e9eb-6997-49d4-b916-e7a6be4a3326', protocol='range'}
10:35:38.940 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Notifying assignor about the new Assignment(partitions=[test-topic-0000373-_NDkX0c-0])
10:35:38.940 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Adding newly assigned partitions: test-topic-0000373-_NDkX0c-0
10:35:38.941 [pool-131-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Found no committed offset for partition test-topic-0000373-_NDkX0c-0
10:35:38.941 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-376-igw_F3A-130-ff958076-5daf-4ef9-a3f0-20871e9d8dc1', protocol='range'}
10:35:38.942 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Finished assignment for group at generation 1: {consumer-sub-376-igw_F3A-130-ff958076-5daf-4ef9-a3f0-20871e9d8dc1=Assignment(partitions=[test-topic-0000376-OIelxdU-0])}
10:35:38.942 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.942 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.942 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.942 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138942
10:35:38.942 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-379-OGtMICI-131-f1e10ad5-6366-4772-9b68-e28ea3db908f', protocol='range'}
10:35:38.943 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-82
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.943 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Finished assignment for group at generation 1: {consumer-sub-379-OGtMICI-131-f1e10ad5-6366-4772-9b68-e28ea3db908f=Assignment(partitions=[test-topic-0000379-TfxtvR0-0])}
10:35:38.943 [pool-131-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Resetting offset for partition test-topic-0000373-_NDkX0c-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.944 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-82] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.944 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-82] Instantiated an idempotent producer.
10:35:38.945 [kafka-producer-network-thread | producer-81] INFO Metadata - [Producer clientId=producer-81] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.945 [kafka-producer-network-thread | producer-81] INFO TransactionManager - [Producer clientId=producer-81] ProducerId set to 2085 with epoch 0
10:35:38.945 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-376-igw_F3A-130-ff958076-5daf-4ef9-a3f0-20871e9d8dc1', protocol='range'}
10:35:38.945 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Notifying assignor about the new Assignment(partitions=[test-topic-0000376-OIelxdU-0])
10:35:38.945 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Adding newly assigned partitions: test-topic-0000376-OIelxdU-0
10:35:38.946 [pool-132-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Found no committed offset for partition test-topic-0000376-OIelxdU-0
10:35:38.946 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-382-5bYhotQ-132-fa08d952-979a-4212-9456-f2611f673495', protocol='range'}
10:35:38.947 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Finished assignment for group at generation 1: {consumer-sub-382-5bYhotQ-132-fa08d952-979a-4212-9456-f2611f673495=Assignment(partitions=[test-topic-0000382-L601XY4-0])}
10:35:38.947 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-379-OGtMICI-131-f1e10ad5-6366-4772-9b68-e28ea3db908f', protocol='range'}
10:35:38.947 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Notifying assignor about the new Assignment(partitions=[test-topic-0000379-TfxtvR0-0])
10:35:38.947 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Adding newly assigned partitions: test-topic-0000379-TfxtvR0-0
10:35:38.948 [pool-133-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Found no committed offset for partition test-topic-0000379-TfxtvR0-0
10:35:38.948 [pool-132-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Resetting offset for partition test-topic-0000376-OIelxdU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.948 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-385-vae6fZg-133-38203741-818d-492f-9d32-edf057ad12e9', protocol='range'}
10:35:38.949 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Finished assignment for group at generation 1: {consumer-sub-385-vae6fZg-133-38203741-818d-492f-9d32-edf057ad12e9=Assignment(partitions=[test-topic-0000385-UMXA7Q8-0])}
10:35:38.951 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-382-5bYhotQ-132-fa08d952-979a-4212-9456-f2611f673495', protocol='range'}
10:35:38.951 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000382-L601XY4-0])
10:35:38.951 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Adding newly assigned partitions: test-topic-0000382-L601XY4-0
10:35:38.953 [pool-133-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Resetting offset for partition test-topic-0000379-TfxtvR0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:38.954 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.954 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.954 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.954 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138954
10:35:38.954 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-83
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.955 [pool-130-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Resetting offset for partition test-topic-0000370-mEr65Xk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.955 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-385-vae6fZg-133-38203741-818d-492f-9d32-edf057ad12e9', protocol='range'}
10:35:38.955 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Notifying assignor about the new Assignment(partitions=[test-topic-0000385-UMXA7Q8-0])
10:35:38.955 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Adding newly assigned partitions: test-topic-0000385-UMXA7Q8-0
10:35:38.955 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-388-P5cW7Tg-134-1b32509e-9473-4521-98ad-aa35ee6eaa4b', protocol='range'}
10:35:38.956 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Finished assignment for group at generation 1: {consumer-sub-388-P5cW7Tg-134-1b32509e-9473-4521-98ad-aa35ee6eaa4b=Assignment(partitions=[test-topic-0000388-y1l0tN0-0])}
10:35:38.956 [pool-135-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Found no committed offset for partition test-topic-0000385-UMXA7Q8-0
10:35:38.956 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-83] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.956 [pool-134-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Found no committed offset for partition test-topic-0000382-L601XY4-0
10:35:38.957 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-83] Instantiated an idempotent producer.
10:35:38.957 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-391-RUDds4Y-135-d3019b5e-8534-49bc-b853-d3c0d9a867cf', protocol='range'}
10:35:38.958 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Finished assignment for group at generation 1: {consumer-sub-391-RUDds4Y-135-d3019b5e-8534-49bc-b853-d3c0d9a867cf=Assignment(partitions=[test-topic-0000391-QVLIF3k-0])}
10:35:38.960 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-388-P5cW7Tg-134-1b32509e-9473-4521-98ad-aa35ee6eaa4b', protocol='range'}
10:35:38.960 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Notifying assignor about the new Assignment(partitions=[test-topic-0000388-y1l0tN0-0])
10:35:38.960 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Adding newly assigned partitions: test-topic-0000388-y1l0tN0-0
10:35:38.961 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-394-tyloWTo-136-e9fc70cf-e16d-4053-a49c-daac33d7904f', protocol='range'}
10:35:38.961 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Finished assignment for group at generation 1: {consumer-sub-394-tyloWTo-136-e9fc70cf-e16d-4053-a49c-daac33d7904f=Assignment(partitions=[test-topic-0000394-xlkFLyI-0])}
10:35:38.961 [pool-136-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Found no committed offset for partition test-topic-0000388-y1l0tN0-0
10:35:38.962 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-391-RUDds4Y-135-d3019b5e-8534-49bc-b853-d3c0d9a867cf', protocol='range'}
10:35:38.962 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Notifying assignor about the new Assignment(partitions=[test-topic-0000391-QVLIF3k-0])
10:35:38.962 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Adding newly assigned partitions: test-topic-0000391-QVLIF3k-0
10:35:38.963 [pool-137-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Found no committed offset for partition test-topic-0000391-QVLIF3k-0
10:35:38.964 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-394-tyloWTo-136-e9fc70cf-e16d-4053-a49c-daac33d7904f', protocol='range'}
10:35:38.965 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Notifying assignor about the new Assignment(partitions=[test-topic-0000394-xlkFLyI-0])
10:35:38.965 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Adding newly assigned partitions: test-topic-0000394-xlkFLyI-0
10:35:38.965 [pool-138-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Found no committed offset for partition test-topic-0000394-xlkFLyI-0
10:35:38.967 [pool-135-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Resetting offset for partition test-topic-0000385-UMXA7Q8-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.968 [pool-137-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Resetting offset for partition test-topic-0000391-QVLIF3k-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.972 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-397-zg7ub-4-137-4174d177-e964-4955-9901-066928aee244', protocol='range'}
10:35:38.972 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Finished assignment for group at generation 1: {consumer-sub-397-zg7ub-4-137-4174d177-e964-4955-9901-066928aee244=Assignment(partitions=[test-topic-0000397-bh_sXo0-0])}
10:35:38.974 [pool-134-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Resetting offset for partition test-topic-0000382-L601XY4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.975 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-400-KsDN_SE-138-a50dbd55-6d38-426c-921a-b28b437dc3f8', protocol='range'}
10:35:38.975 [kafka-producer-network-thread | producer-82] INFO TransactionManager - [Producer clientId=producer-82] ProducerId set to 2094 with epoch 0
10:35:38.975 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Finished assignment for group at generation 1: {consumer-sub-400-KsDN_SE-138-a50dbd55-6d38-426c-921a-b28b437dc3f8=Assignment(partitions=[test-topic-0000400-X7FM4dU-0])}
10:35:38.975 [kafka-producer-network-thread | producer-82] INFO Metadata - [Producer clientId=producer-82] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.975 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-397-zg7ub-4-137-4174d177-e964-4955-9901-066928aee244', protocol='range'}
10:35:38.976 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Notifying assignor about the new Assignment(partitions=[test-topic-0000397-bh_sXo0-0])
10:35:38.976 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Adding newly assigned partitions: test-topic-0000397-bh_sXo0-0
10:35:38.976 [pool-139-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Found no committed offset for partition test-topic-0000397-bh_sXo0-0
10:35:38.978 [pool-136-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Resetting offset for partition test-topic-0000388-y1l0tN0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.979 [pool-138-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Resetting offset for partition test-topic-0000394-xlkFLyI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:38.980 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-400-KsDN_SE-138-a50dbd55-6d38-426c-921a-b28b437dc3f8', protocol='range'}
10:35:38.980 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Notifying assignor about the new Assignment(partitions=[test-topic-0000400-X7FM4dU-0])
10:35:38.980 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Adding newly assigned partitions: test-topic-0000400-X7FM4dU-0
10:35:38.980 [pool-139-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Resetting offset for partition test-topic-0000397-bh_sXo0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.981 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-403-NN_e-UM-139-42367471-f51f-43fb-a9f1-fd2a61198725', protocol='range'}
10:35:38.981 [pool-140-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Found no committed offset for partition test-topic-0000400-X7FM4dU-0
10:35:38.981 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Finished assignment for group at generation 1: {consumer-sub-403-NN_e-UM-139-42367471-f51f-43fb-a9f1-fd2a61198725=Assignment(partitions=[test-topic-0000403-cSYU2uM-0])}
10:35:38.982 [pool-140-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Resetting offset for partition test-topic-0000400-X7FM4dU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.984 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-403-NN_e-UM-139-42367471-f51f-43fb-a9f1-fd2a61198725', protocol='range'}
10:35:38.984 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Notifying assignor about the new Assignment(partitions=[test-topic-0000403-cSYU2uM-0])
10:35:38.984 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Adding newly assigned partitions: test-topic-0000403-cSYU2uM-0
10:35:38.984 [pool-141-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Found no committed offset for partition test-topic-0000403-cSYU2uM-0
10:35:38.986 [pool-141-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Resetting offset for partition test-topic-0000403-cSYU2uM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:38.986 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.987 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.987 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.987 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138986
10:35:38.988 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-84
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.989 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-84] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.989 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-84] Instantiated an idempotent producer.
10:35:38.990 [kafka-producer-network-thread | producer-83] INFO Metadata - [Producer clientId=producer-83] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.990 [kafka-producer-network-thread | producer-83] INFO TransactionManager - [Producer clientId=producer-83] ProducerId set to 2097 with epoch 0
10:35:38.994 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.994 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.994 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.994 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138994
10:35:38.994 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-85
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.995 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-85] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.995 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-85] Instantiated an idempotent producer.
10:35:38.997 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-406-fYmqBzg-140-ffd6987b-6002-475e-9888-c0f04f7077c2', protocol='range'}
10:35:38.997 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Finished assignment for group at generation 1: {consumer-sub-406-fYmqBzg-140-ffd6987b-6002-475e-9888-c0f04f7077c2=Assignment(partitions=[test-topic-0000406-veksnbI-0])}
10:35:38.998 [kafka-producer-network-thread | producer-84] INFO Metadata - [Producer clientId=producer-84] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:38.998 [kafka-producer-network-thread | producer-84] INFO TransactionManager - [Producer clientId=producer-84] ProducerId set to 1096 with epoch 0
10:35:38.998 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:38.998 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:38.998 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:38.998 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806138998
10:35:38.999 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-86
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:38.999 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-86] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:38.999 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-86] Instantiated an idempotent producer.
10:35:38.999 [kafka-producer-network-thread | producer-85] INFO Metadata - [Producer clientId=producer-85] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.000 [kafka-producer-network-thread | producer-85] INFO TransactionManager - [Producer clientId=producer-85] ProducerId set to 117 with epoch 0
10:35:39.000 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.000 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.000 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.000 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139000
10:35:39.001 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-406-fYmqBzg-140-ffd6987b-6002-475e-9888-c0f04f7077c2', protocol='range'}
10:35:39.001 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-87
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.001 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Notifying assignor about the new Assignment(partitions=[test-topic-0000406-veksnbI-0])
10:35:39.001 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Adding newly assigned partitions: test-topic-0000406-veksnbI-0
10:35:39.001 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-87] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.001 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-87] Instantiated an idempotent producer.
10:35:39.002 [pool-142-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Found no committed offset for partition test-topic-0000406-veksnbI-0
10:35:39.002 [kafka-producer-network-thread | producer-86] INFO Metadata - [Producer clientId=producer-86] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.003 [kafka-producer-network-thread | producer-86] INFO TransactionManager - [Producer clientId=producer-86] ProducerId set to 1099 with epoch 0
10:35:39.004 [pool-142-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Resetting offset for partition test-topic-0000406-veksnbI-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.005 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-409-GRwWUd0-141-c8d5cf57-8542-4fe1-a772-b8d2446a5b30', protocol='range'}
10:35:39.005 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Finished assignment for group at generation 1: {consumer-sub-409-GRwWUd0-141-c8d5cf57-8542-4fe1-a772-b8d2446a5b30=Assignment(partitions=[test-topic-0000409-sCB18EQ-0])}
10:35:39.006 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.006 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.006 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.006 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139006
10:35:39.006 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-88
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.007 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-88] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.007 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-88] Instantiated an idempotent producer.
10:35:39.007 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-412-KLerxmg-142-6e086eaa-8161-49b1-9569-ce0606965e02', protocol='range'}
10:35:39.007 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Finished assignment for group at generation 1: {consumer-sub-412-KLerxmg-142-6e086eaa-8161-49b1-9569-ce0606965e02=Assignment(partitions=[test-topic-0000412-gJ9uDSE-0])}
10:35:39.007 [kafka-producer-network-thread | producer-87] INFO Metadata - [Producer clientId=producer-87] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.007 [kafka-producer-network-thread | producer-87] INFO TransactionManager - [Producer clientId=producer-87] ProducerId set to 2104 with epoch 0
10:35:39.009 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-409-GRwWUd0-141-c8d5cf57-8542-4fe1-a772-b8d2446a5b30', protocol='range'}
10:35:39.009 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Notifying assignor about the new Assignment(partitions=[test-topic-0000409-sCB18EQ-0])
10:35:39.009 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Adding newly assigned partitions: test-topic-0000409-sCB18EQ-0
10:35:39.010 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.010 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.010 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.010 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139010
10:35:39.010 [pool-143-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Found no committed offset for partition test-topic-0000409-sCB18EQ-0
10:35:39.011 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-412-KLerxmg-142-6e086eaa-8161-49b1-9569-ce0606965e02', protocol='range'}
10:35:39.011 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Notifying assignor about the new Assignment(partitions=[test-topic-0000412-gJ9uDSE-0])
10:35:39.011 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Adding newly assigned partitions: test-topic-0000412-gJ9uDSE-0
10:35:39.011 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-415-DqirbL0-143-f8fe638f-c59a-4202-93aa-239a11191bb9', protocol='range'}
10:35:39.011 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Finished assignment for group at generation 1: {consumer-sub-415-DqirbL0-143-f8fe638f-c59a-4202-93aa-239a11191bb9=Assignment(partitions=[test-topic-0000415-EgHOvbM-0])}
10:35:39.011 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-89
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.012 [pool-144-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Found no committed offset for partition test-topic-0000412-gJ9uDSE-0
10:35:39.012 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-89] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.012 [pool-143-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Resetting offset for partition test-topic-0000409-sCB18EQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:39.012 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-89] Instantiated an idempotent producer.
10:35:39.013 [pool-144-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Resetting offset for partition test-topic-0000412-gJ9uDSE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.014 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.014 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.014 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.014 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139014
10:35:39.014 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-415-DqirbL0-143-f8fe638f-c59a-4202-93aa-239a11191bb9', protocol='range'}
10:35:39.014 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-90
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.014 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Notifying assignor about the new Assignment(partitions=[test-topic-0000415-EgHOvbM-0])
10:35:39.014 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Adding newly assigned partitions: test-topic-0000415-EgHOvbM-0
10:35:39.015 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-90] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.015 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-90] Instantiated an idempotent producer.
10:35:39.015 [pool-145-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Found no committed offset for partition test-topic-0000415-EgHOvbM-0
10:35:39.016 [kafka-producer-network-thread | producer-89] INFO Metadata - [Producer clientId=producer-89] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.016 [kafka-producer-network-thread | producer-89] INFO TransactionManager - [Producer clientId=producer-89] ProducerId set to 2106 with epoch 0
10:35:39.017 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.017 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.017 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.017 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139017
10:35:39.017 [pool-145-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Resetting offset for partition test-topic-0000415-EgHOvbM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.017 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-91
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.018 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-91] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.018 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-91] Instantiated an idempotent producer.
10:35:39.018 [kafka-producer-network-thread | producer-90] INFO Metadata - [Producer clientId=producer-90] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.019 [kafka-producer-network-thread | producer-90] INFO TransactionManager - [Producer clientId=producer-90] ProducerId set to 124 with epoch 0
10:35:39.019 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-421-By8iGYI-145-6d7190be-74ba-48d6-aa90-38c8f3cc0a57', protocol='range'}
10:35:39.019 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Finished assignment for group at generation 1: {consumer-sub-421-By8iGYI-145-6d7190be-74ba-48d6-aa90-38c8f3cc0a57=Assignment(partitions=[test-topic-0000421-AwE19r0-0])}
10:35:39.020 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.020 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.020 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.020 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139020
10:35:39.020 [kafka-producer-network-thread | producer-88] INFO Metadata - [Producer clientId=producer-88] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.020 [kafka-producer-network-thread | producer-88] INFO TransactionManager - [Producer clientId=producer-88] ProducerId set to 119 with epoch 0
10:35:39.020 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-92
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.021 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-92] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.021 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-92] Instantiated an idempotent producer.
10:35:39.021 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-424-VmduDzo-146-daf58349-dabd-4ff8-b983-136d6353ef1a', protocol='range'}
10:35:39.021 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Finished assignment for group at generation 1: {consumer-sub-424-VmduDzo-146-daf58349-dabd-4ff8-b983-136d6353ef1a=Assignment(partitions=[test-topic-0000424-rZeSqAQ-0])}
10:35:39.022 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-421-By8iGYI-145-6d7190be-74ba-48d6-aa90-38c8f3cc0a57', protocol='range'}
10:35:39.022 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Notifying assignor about the new Assignment(partitions=[test-topic-0000421-AwE19r0-0])
10:35:39.022 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Adding newly assigned partitions: test-topic-0000421-AwE19r0-0
10:35:39.022 [kafka-producer-network-thread | producer-91] INFO Metadata - [Producer clientId=producer-91] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.022 [kafka-producer-network-thread | producer-91] INFO TransactionManager - [Producer clientId=producer-91] ProducerId set to 1102 with epoch 0
10:35:39.023 [pool-147-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Found no committed offset for partition test-topic-0000421-AwE19r0-0
10:35:39.023 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-418-BG0vOxQ-144-d83790f0-2e55-4bc5-bcf3-765044c564a9', protocol='range'}
10:35:39.023 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Finished assignment for group at generation 1: {consumer-sub-418-BG0vOxQ-144-d83790f0-2e55-4bc5-bcf3-765044c564a9=Assignment(partitions=[test-topic-0000418-qY6RauQ-0])}
10:35:39.024 [pool-147-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Resetting offset for partition test-topic-0000421-AwE19r0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:39.025 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-424-VmduDzo-146-daf58349-dabd-4ff8-b983-136d6353ef1a', protocol='range'}
10:35:39.025 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Notifying assignor about the new Assignment(partitions=[test-topic-0000424-rZeSqAQ-0])
10:35:39.025 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Adding newly assigned partitions: test-topic-0000424-rZeSqAQ-0
10:35:39.026 [pool-148-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Found no committed offset for partition test-topic-0000424-rZeSqAQ-0
10:35:39.027 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-418-BG0vOxQ-144-d83790f0-2e55-4bc5-bcf3-765044c564a9', protocol='range'}
10:35:39.027 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Notifying assignor about the new Assignment(partitions=[test-topic-0000418-qY6RauQ-0])
10:35:39.027 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Adding newly assigned partitions: test-topic-0000418-qY6RauQ-0
10:35:39.027 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.027 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.027 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.027 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139027
10:35:39.027 [pool-146-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Found no committed offset for partition test-topic-0000418-qY6RauQ-0
10:35:39.027 [pool-148-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Resetting offset for partition test-topic-0000424-rZeSqAQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.027 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-93
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.028 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-93] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.028 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-93] Instantiated an idempotent producer.
10:35:39.029 [pool-146-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Resetting offset for partition test-topic-0000418-qY6RauQ-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.031 [kafka-producer-network-thread | producer-92] INFO TransactionManager - [Producer clientId=producer-92] ProducerId set to 127 with epoch 0
10:35:39.031 [kafka-producer-network-thread | producer-92] INFO Metadata - [Producer clientId=producer-92] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.035 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.035 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.035 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.035 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139035
10:35:39.035 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-94
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.035 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-94] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.036 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-94] Instantiated an idempotent producer.
10:35:39.036 [kafka-producer-network-thread | producer-93] INFO Metadata - [Producer clientId=producer-93] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.037 [kafka-producer-network-thread | producer-93] INFO TransactionManager - [Producer clientId=producer-93] ProducerId set to 128 with epoch 0
10:35:39.039 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-427-_nunaqs-147-d79526e0-4c10-409a-8e41-83cf768bb428', protocol='range'}
10:35:39.039 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Finished assignment for group at generation 1: {consumer-sub-427-_nunaqs-147-d79526e0-4c10-409a-8e41-83cf768bb428=Assignment(partitions=[test-topic-0000427-q9wDEgM-0])}
10:35:39.042 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-427-_nunaqs-147-d79526e0-4c10-409a-8e41-83cf768bb428', protocol='range'}
10:35:39.042 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-430-HIP-Ecc-148-aeaf283d-6744-421f-8447-932a6732df5b', protocol='range'}
10:35:39.043 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Notifying assignor about the new Assignment(partitions=[test-topic-0000427-q9wDEgM-0])
10:35:39.043 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Finished assignment for group at generation 1: {consumer-sub-430-HIP-Ecc-148-aeaf283d-6744-421f-8447-932a6732df5b=Assignment(partitions=[test-topic-0000430-1HkZXP0-0])}
10:35:39.043 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Adding newly assigned partitions: test-topic-0000427-q9wDEgM-0
10:35:39.043 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.043 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.043 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.043 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139043
10:35:39.043 [pool-149-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Found no committed offset for partition test-topic-0000427-q9wDEgM-0
10:35:39.043 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-95
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.044 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-95] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.044 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-95] Instantiated an idempotent producer.
10:35:39.045 [kafka-producer-network-thread | producer-94] INFO Metadata - [Producer clientId=producer-94] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.045 [kafka-producer-network-thread | producer-94] INFO TransactionManager - [Producer clientId=producer-94] ProducerId set to 131 with epoch 0
10:35:39.045 [pool-149-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Resetting offset for partition test-topic-0000427-q9wDEgM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.045 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-433-5Z6gPg8-149-9a960151-dec6-46ab-b396-a6a0d37429ff', protocol='range'}
10:35:39.046 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Finished assignment for group at generation 1: {consumer-sub-433-5Z6gPg8-149-9a960151-dec6-46ab-b396-a6a0d37429ff=Assignment(partitions=[test-topic-0000433-ahog9AU-0])}
10:35:39.046 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-430-HIP-Ecc-148-aeaf283d-6744-421f-8447-932a6732df5b', protocol='range'}
10:35:39.046 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Notifying assignor about the new Assignment(partitions=[test-topic-0000430-1HkZXP0-0])
10:35:39.047 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Adding newly assigned partitions: test-topic-0000430-1HkZXP0-0
10:35:39.047 [pool-150-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Found no committed offset for partition test-topic-0000430-1HkZXP0-0
10:35:39.048 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.048 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.048 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.048 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139048
10:35:39.048 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-96
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.049 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-96] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.049 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-96] Instantiated an idempotent producer.
10:35:39.049 [pool-150-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Resetting offset for partition test-topic-0000430-1HkZXP0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.049 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-433-5Z6gPg8-149-9a960151-dec6-46ab-b396-a6a0d37429ff', protocol='range'}
10:35:39.049 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Notifying assignor about the new Assignment(partitions=[test-topic-0000433-ahog9AU-0])
10:35:39.049 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Adding newly assigned partitions: test-topic-0000433-ahog9AU-0
10:35:39.050 [kafka-producer-network-thread | producer-95] INFO Metadata - [Producer clientId=producer-95] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.050 [kafka-producer-network-thread | producer-95] INFO TransactionManager - [Producer clientId=producer-95] ProducerId set to 132 with epoch 0
10:35:39.050 [pool-151-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Found no committed offset for partition test-topic-0000433-ahog9AU-0
10:35:39.050 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.051 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.051 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.051 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139051
10:35:39.052 [pool-151-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Resetting offset for partition test-topic-0000433-ahog9AU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:39.052 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-97
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.052 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-97] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.052 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-97] Instantiated an idempotent producer.
10:35:39.053 [kafka-producer-network-thread | producer-96] INFO Metadata - [Producer clientId=producer-96] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.053 [kafka-producer-network-thread | producer-96] INFO TransactionManager - [Producer clientId=producer-96] ProducerId set to 1109 with epoch 0
10:35:39.054 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.054 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.054 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.054 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139054
10:35:39.055 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-98
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.055 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-98] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.055 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-98] Instantiated an idempotent producer.
10:35:39.056 [kafka-producer-network-thread | producer-97] INFO Metadata - [Producer clientId=producer-97] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.056 [kafka-producer-network-thread | producer-97] INFO TransactionManager - [Producer clientId=producer-97] ProducerId set to 2116 with epoch 0
10:35:39.057 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.057 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.057 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.057 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139057
10:35:39.058 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-99
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.058 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-99] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.058 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-99] Instantiated an idempotent producer.
10:35:39.060 [kafka-producer-network-thread | producer-98] INFO Metadata - [Producer clientId=producer-98] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.060 [kafka-producer-network-thread | producer-98] INFO TransactionManager - [Producer clientId=producer-98] ProducerId set to 1112 with epoch 0
10:35:39.060 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-436-l5QsKDs-150-d71d1b89-8a4c-4d9a-9fa9-704d39eb93a8', protocol='range'}
10:35:39.060 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Finished assignment for group at generation 1: {consumer-sub-436-l5QsKDs-150-d71d1b89-8a4c-4d9a-9fa9-704d39eb93a8=Assignment(partitions=[test-topic-0000436-1z7Eoyk-0])}
10:35:39.061 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.061 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.061 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.061 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139061
10:35:39.061 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-100
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.062 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-100] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.062 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-100] Instantiated an idempotent producer.
10:35:39.063 [kafka-producer-network-thread | producer-99] INFO Metadata - [Producer clientId=producer-99] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.063 [kafka-producer-network-thread | producer-99] INFO TransactionManager - [Producer clientId=producer-99] ProducerId set to 134 with epoch 0
10:35:39.063 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-436-l5QsKDs-150-d71d1b89-8a4c-4d9a-9fa9-704d39eb93a8', protocol='range'}
10:35:39.064 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Notifying assignor about the new Assignment(partitions=[test-topic-0000436-1z7Eoyk-0])
10:35:39.064 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Adding newly assigned partitions: test-topic-0000436-1z7Eoyk-0
10:35:39.064 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.064 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.064 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.064 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139064
10:35:39.064 [pool-152-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Found no committed offset for partition test-topic-0000436-1z7Eoyk-0
10:35:39.064 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-101
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.065 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-101] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.065 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-439-0u7s0Zo-151-6f6de5ab-714d-4b03-9b85-c60a3913515d', protocol='range'}
10:35:39.066 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Finished assignment for group at generation 1: {consumer-sub-439-0u7s0Zo-151-6f6de5ab-714d-4b03-9b85-c60a3913515d=Assignment(partitions=[test-topic-0000439-mHkFOzE-0])}
10:35:39.066 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-101] Instantiated an idempotent producer.
10:35:39.066 [pool-152-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Resetting offset for partition test-topic-0000436-1z7Eoyk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:39.067 [kafka-producer-network-thread | producer-100] INFO Metadata - [Producer clientId=producer-100] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.067 [kafka-producer-network-thread | producer-100] INFO TransactionManager - [Producer clientId=producer-100] ProducerId set to 138 with epoch 0
10:35:39.068 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.068 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.068 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.068 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139068
10:35:39.069 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-102
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.069 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-102] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.069 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-102] Instantiated an idempotent producer.
10:35:39.069 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-439-0u7s0Zo-151-6f6de5ab-714d-4b03-9b85-c60a3913515d', protocol='range'}
10:35:39.070 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Notifying assignor about the new Assignment(partitions=[test-topic-0000439-mHkFOzE-0])
10:35:39.070 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Adding newly assigned partitions: test-topic-0000439-mHkFOzE-0
10:35:39.070 [kafka-producer-network-thread | producer-101] INFO Metadata - [Producer clientId=producer-101] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.070 [kafka-producer-network-thread | producer-101] INFO TransactionManager - [Producer clientId=producer-101] ProducerId set to 140 with epoch 0
10:35:39.070 [pool-153-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Found no committed offset for partition test-topic-0000439-mHkFOzE-0
10:35:39.073 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.073 [pool-153-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Resetting offset for partition test-topic-0000439-mHkFOzE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.073 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.073 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.073 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139073
10:35:39.073 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-103
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.074 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-442-GTggPn4-152-e878d4d0-5443-4046-958f-50bab84bcca8', protocol='range'}
10:35:39.074 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-103] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.074 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-103] Instantiated an idempotent producer.
10:35:39.074 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Finished assignment for group at generation 1: {consumer-sub-442-GTggPn4-152-e878d4d0-5443-4046-958f-50bab84bcca8=Assignment(partitions=[test-topic-0000442-upMlwWs-0])}
10:35:39.075 [kafka-producer-network-thread | producer-102] INFO Metadata - [Producer clientId=producer-102] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.075 [kafka-producer-network-thread | producer-102] INFO TransactionManager - [Producer clientId=producer-102] ProducerId set to 1116 with epoch 0
10:35:39.076 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.076 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.076 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.076 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139076
10:35:39.076 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-104
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.077 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-104] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.077 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-104] Instantiated an idempotent producer.
10:35:39.077 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-442-GTggPn4-152-e878d4d0-5443-4046-958f-50bab84bcca8', protocol='range'}
10:35:39.077 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Notifying assignor about the new Assignment(partitions=[test-topic-0000442-upMlwWs-0])
10:35:39.077 [kafka-producer-network-thread | producer-103] INFO Metadata - [Producer clientId=producer-103] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.077 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Adding newly assigned partitions: test-topic-0000442-upMlwWs-0
10:35:39.077 [kafka-producer-network-thread | producer-103] INFO TransactionManager - [Producer clientId=producer-103] ProducerId set to 1117 with epoch 0
10:35:39.078 [pool-154-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Found no committed offset for partition test-topic-0000442-upMlwWs-0
10:35:39.080 [pool-154-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Resetting offset for partition test-topic-0000442-upMlwWs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:39.085 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-445-ZjQdD0o-153-af4ba00b-a55e-43bf-98db-41931d38d375', protocol='range'}
10:35:39.085 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Finished assignment for group at generation 1: {consumer-sub-445-ZjQdD0o-153-af4ba00b-a55e-43bf-98db-41931d38d375=Assignment(partitions=[test-topic-0000445-e-Tdli0-0])}
10:35:39.088 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.088 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.088 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.088 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139088
10:35:39.088 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-105
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.089 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-105] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.089 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-105] Instantiated an idempotent producer.
10:35:39.089 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-445-ZjQdD0o-153-af4ba00b-a55e-43bf-98db-41931d38d375', protocol='range'}
10:35:39.089 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Notifying assignor about the new Assignment(partitions=[test-topic-0000445-e-Tdli0-0])
10:35:39.089 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Adding newly assigned partitions: test-topic-0000445-e-Tdli0-0
10:35:39.090 [kafka-producer-network-thread | producer-104] INFO Metadata - [Producer clientId=producer-104] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.090 [kafka-producer-network-thread | producer-104] INFO TransactionManager - [Producer clientId=producer-104] ProducerId set to 2124 with epoch 0
10:35:39.090 [pool-155-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Found no committed offset for partition test-topic-0000445-e-Tdli0-0
10:35:39.092 [pool-155-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Resetting offset for partition test-topic-0000445-e-Tdli0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.094 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.094 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.094 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.094 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139094
10:35:39.094 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-106
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.094 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-451-f4gaQWo-155-d7cb18f9-426f-4b03-8aef-749da5027c57', protocol='range'}
10:35:39.095 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Finished assignment for group at generation 1: {consumer-sub-451-f4gaQWo-155-d7cb18f9-426f-4b03-8aef-749da5027c57=Assignment(partitions=[test-topic-0000451-iYHTx2A-0])}
10:35:39.095 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-448-EYn8owI-154-0ae8c1f4-24f5-4a5d-8caa-fd1801ddef7f', protocol='range'}
10:35:39.096 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Finished assignment for group at generation 1: {consumer-sub-448-EYn8owI-154-0ae8c1f4-24f5-4a5d-8caa-fd1801ddef7f=Assignment(partitions=[test-topic-0000448-54rGmRw-0])}
10:35:39.095 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-106] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.096 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-106] Instantiated an idempotent producer.
10:35:39.097 [kafka-producer-network-thread | producer-105] INFO Metadata - [Producer clientId=producer-105] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.097 [kafka-producer-network-thread | producer-105] INFO TransactionManager - [Producer clientId=producer-105] ProducerId set to 146 with epoch 0
10:35:39.098 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.098 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.098 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.098 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139098
10:35:39.098 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-107
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.099 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-451-f4gaQWo-155-d7cb18f9-426f-4b03-8aef-749da5027c57', protocol='range'}
10:35:39.099 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Notifying assignor about the new Assignment(partitions=[test-topic-0000451-iYHTx2A-0])
10:35:39.099 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Adding newly assigned partitions: test-topic-0000451-iYHTx2A-0
10:35:39.099 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-107] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.099 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-448-EYn8owI-154-0ae8c1f4-24f5-4a5d-8caa-fd1801ddef7f', protocol='range'}
10:35:39.099 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Notifying assignor about the new Assignment(partitions=[test-topic-0000448-54rGmRw-0])
10:35:39.099 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Adding newly assigned partitions: test-topic-0000448-54rGmRw-0
10:35:39.099 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-107] Instantiated an idempotent producer.
10:35:39.100 [pool-157-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Found no committed offset for partition test-topic-0000451-iYHTx2A-0
10:35:39.100 [pool-156-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Found no committed offset for partition test-topic-0000448-54rGmRw-0
10:35:39.101 [kafka-producer-network-thread | producer-106] INFO Metadata - [Producer clientId=producer-106] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.101 [kafka-producer-network-thread | producer-106] INFO TransactionManager - [Producer clientId=producer-106] ProducerId set to 2127 with epoch 0
10:35:39.101 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-454-VOt8IBo-156-cce8af2a-086c-4d80-b5b0-11d10d9e2bcd', protocol='range'}
10:35:39.101 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Finished assignment for group at generation 1: {consumer-sub-454-VOt8IBo-156-cce8af2a-086c-4d80-b5b0-11d10d9e2bcd=Assignment(partitions=[test-topic-0000454-jINTbDs-0])}
10:35:39.102 [pool-157-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Resetting offset for partition test-topic-0000451-iYHTx2A-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.102 [pool-156-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Resetting offset for partition test-topic-0000448-54rGmRw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.103 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.103 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.103 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.103 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139103
10:35:39.103 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-108
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.104 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-108] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.104 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-108] Instantiated an idempotent producer.
10:35:39.105 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-454-VOt8IBo-156-cce8af2a-086c-4d80-b5b0-11d10d9e2bcd', protocol='range'}
10:35:39.105 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Notifying assignor about the new Assignment(partitions=[test-topic-0000454-jINTbDs-0])
10:35:39.105 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Adding newly assigned partitions: test-topic-0000454-jINTbDs-0
10:35:39.105 [kafka-producer-network-thread | producer-107] INFO Metadata - [Producer clientId=producer-107] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.105 [kafka-producer-network-thread | producer-107] INFO TransactionManager - [Producer clientId=producer-107] ProducerId set to 148 with epoch 0
10:35:39.105 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.106 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.106 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.106 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139106
10:35:39.106 [pool-158-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Found no committed offset for partition test-topic-0000454-jINTbDs-0
10:35:39.106 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-109
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.107 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-109] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.107 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-109] Instantiated an idempotent producer.
10:35:39.108 [pool-158-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Resetting offset for partition test-topic-0000454-jINTbDs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.109 [kafka-producer-network-thread | producer-108] INFO Metadata - [Producer clientId=producer-108] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.109 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.109 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.109 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.109 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139109
10:35:39.109 [kafka-producer-network-thread | producer-108] INFO TransactionManager - [Producer clientId=producer-108] ProducerId set to 1124 with epoch 0
10:35:39.110 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-110
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.110 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-457-HrOiLw0-157-79837063-8780-454c-81cd-b21c75c2f00d', protocol='range'}
10:35:39.110 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Finished assignment for group at generation 1: {consumer-sub-457-HrOiLw0-157-79837063-8780-454c-81cd-b21c75c2f00d=Assignment(partitions=[test-topic-0000457-37_m3sc-0])}
10:35:39.111 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-110] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.111 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-110] Instantiated an idempotent producer.
10:35:39.111 [kafka-producer-network-thread | producer-109] INFO Metadata - [Producer clientId=producer-109] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.111 [kafka-producer-network-thread | producer-109] INFO TransactionManager - [Producer clientId=producer-109] ProducerId set to 1125 with epoch 0
10:35:39.113 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.113 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.113 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.113 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139113
10:35:39.113 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-111
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.113 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-457-HrOiLw0-157-79837063-8780-454c-81cd-b21c75c2f00d', protocol='range'}
10:35:39.113 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Notifying assignor about the new Assignment(partitions=[test-topic-0000457-37_m3sc-0])
10:35:39.113 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Adding newly assigned partitions: test-topic-0000457-37_m3sc-0
10:35:39.114 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-111] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.114 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-111] Instantiated an idempotent producer.
10:35:39.114 [pool-159-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Found no committed offset for partition test-topic-0000457-37_m3sc-0
10:35:39.115 [kafka-producer-network-thread | producer-110] INFO Metadata - [Producer clientId=producer-110] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.115 [kafka-producer-network-thread | producer-110] INFO TransactionManager - [Producer clientId=producer-110] ProducerId set to 150 with epoch 0
10:35:39.116 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.116 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.116 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.116 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139116
10:35:39.116 [pool-159-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Resetting offset for partition test-topic-0000457-37_m3sc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.116 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-112
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.117 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-460-rlIljZk-158-3ace56a8-bfcc-47e4-a2d6-d6e439dc95c6', protocol='range'}
10:35:39.117 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-112] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.117 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-112] Instantiated an idempotent producer.
10:35:39.117 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Finished assignment for group at generation 1: {consumer-sub-460-rlIljZk-158-3ace56a8-bfcc-47e4-a2d6-d6e439dc95c6=Assignment(partitions=[test-topic-0000460-NzJPttA-0])}
10:35:39.119 [kafka-producer-network-thread | producer-111] INFO Metadata - [Producer clientId=producer-111] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.119 [kafka-producer-network-thread | producer-111] INFO TransactionManager - [Producer clientId=producer-111] ProducerId set to 153 with epoch 0
10:35:39.120 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-460-rlIljZk-158-3ace56a8-bfcc-47e4-a2d6-d6e439dc95c6', protocol='range'}
10:35:39.120 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Notifying assignor about the new Assignment(partitions=[test-topic-0000460-NzJPttA-0])
10:35:39.120 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Adding newly assigned partitions: test-topic-0000460-NzJPttA-0
10:35:39.120 [pool-160-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Found no committed offset for partition test-topic-0000460-NzJPttA-0
10:35:39.121 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-463-mxbWA84-159-ce25485c-1f27-4a56-9903-5ce0da6c09df', protocol='range'}
10:35:39.121 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Finished assignment for group at generation 1: {consumer-sub-463-mxbWA84-159-ce25485c-1f27-4a56-9903-5ce0da6c09df=Assignment(partitions=[test-topic-0000463-AnsrbPc-0])}
10:35:39.122 [pool-160-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Resetting offset for partition test-topic-0000460-NzJPttA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.124 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-463-mxbWA84-159-ce25485c-1f27-4a56-9903-5ce0da6c09df', protocol='range'}
10:35:39.124 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Notifying assignor about the new Assignment(partitions=[test-topic-0000463-AnsrbPc-0])
10:35:39.124 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Adding newly assigned partitions: test-topic-0000463-AnsrbPc-0
10:35:39.125 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.125 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.125 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.125 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139125
10:35:39.125 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-113
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.125 [pool-161-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Found no committed offset for partition test-topic-0000463-AnsrbPc-0
10:35:39.125 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-113] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.125 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-113] Instantiated an idempotent producer.
10:35:39.127 [pool-161-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Resetting offset for partition test-topic-0000463-AnsrbPc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.127 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-466-qbRBPK4-160-173529e3-aee4-4a0e-89c1-da0cc1c4aa5b', protocol='range'}
10:35:39.128 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Finished assignment for group at generation 1: {consumer-sub-466-qbRBPK4-160-173529e3-aee4-4a0e-89c1-da0cc1c4aa5b=Assignment(partitions=[test-topic-0000466-rwZ2pKE-0])}
10:35:39.128 [kafka-producer-network-thread | producer-112] INFO Metadata - [Producer clientId=producer-112] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.129 [kafka-producer-network-thread | producer-112] INFO TransactionManager - [Producer clientId=producer-112] ProducerId set to 1128 with epoch 0
10:35:39.131 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-466-qbRBPK4-160-173529e3-aee4-4a0e-89c1-da0cc1c4aa5b', protocol='range'}
10:35:39.131 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Notifying assignor about the new Assignment(partitions=[test-topic-0000466-rwZ2pKE-0])
10:35:39.131 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Adding newly assigned partitions: test-topic-0000466-rwZ2pKE-0
10:35:39.132 [pool-162-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Found no committed offset for partition test-topic-0000466-rwZ2pKE-0
10:35:39.133 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.133 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.133 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.133 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139133
10:35:39.133 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-114
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.133 [pool-162-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Resetting offset for partition test-topic-0000466-rwZ2pKE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.134 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-114] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.134 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-114] Instantiated an idempotent producer.
10:35:39.134 [kafka-producer-network-thread | producer-113] INFO Metadata - [Producer clientId=producer-113] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.134 [kafka-producer-network-thread | producer-113] INFO TransactionManager - [Producer clientId=producer-113] ProducerId set to 159 with epoch 0
10:35:39.136 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.136 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.136 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.136 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139136
10:35:39.136 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-115
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.137 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-115] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.137 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-115] Instantiated an idempotent producer.
10:35:39.138 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.138 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.138 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.138 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139138
10:35:39.138 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-116
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.139 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-469-CHMVaMY-161-3af04603-bd18-4d91-b216-e85c38165e55', protocol='range'}
10:35:39.139 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-116] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.139 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Finished assignment for group at generation 1: {consumer-sub-469-CHMVaMY-161-3af04603-bd18-4d91-b216-e85c38165e55=Assignment(partitions=[test-topic-0000469-1ZGl9m0-0])}
10:35:39.139 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-116] Instantiated an idempotent producer.
10:35:39.140 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-472-nZDgjwA-162-b4481d95-8ca9-41bd-8716-9492555fa718', protocol='range'}
10:35:39.140 [kafka-producer-network-thread | producer-115] INFO Metadata - [Producer clientId=producer-115] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.140 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Finished assignment for group at generation 1: {consumer-sub-472-nZDgjwA-162-b4481d95-8ca9-41bd-8716-9492555fa718=Assignment(partitions=[test-topic-0000472-FWunwBk-0])}
10:35:39.140 [kafka-producer-network-thread | producer-115] INFO TransactionManager - [Producer clientId=producer-115] ProducerId set to 2137 with epoch 0
10:35:39.142 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.142 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.142 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.142 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139142
10:35:39.142 [kafka-producer-network-thread | producer-114] INFO Metadata - [Producer clientId=producer-114] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.142 [kafka-producer-network-thread | producer-114] INFO TransactionManager - [Producer clientId=producer-114] ProducerId set to 2140 with epoch 0
10:35:39.142 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-469-CHMVaMY-161-3af04603-bd18-4d91-b216-e85c38165e55', protocol='range'}
10:35:39.142 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-117
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.142 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Notifying assignor about the new Assignment(partitions=[test-topic-0000469-1ZGl9m0-0])
10:35:39.143 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Adding newly assigned partitions: test-topic-0000469-1ZGl9m0-0
10:35:39.143 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-117] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.143 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-117] Instantiated an idempotent producer.
10:35:39.143 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-475-4g3cL84-163-0b684e4f-06e1-4b36-8135-af6b74916c85', protocol='range'}
10:35:39.143 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Finished assignment for group at generation 1: {consumer-sub-475-4g3cL84-163-0b684e4f-06e1-4b36-8135-af6b74916c85=Assignment(partitions=[test-topic-0000475-2oxOTx4-0])}
10:35:39.143 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-472-nZDgjwA-162-b4481d95-8ca9-41bd-8716-9492555fa718', protocol='range'}
10:35:39.143 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Notifying assignor about the new Assignment(partitions=[test-topic-0000472-FWunwBk-0])
10:35:39.143 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Adding newly assigned partitions: test-topic-0000472-FWunwBk-0
10:35:39.143 [pool-163-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Found no committed offset for partition test-topic-0000469-1ZGl9m0-0
10:35:39.144 [kafka-producer-network-thread | producer-116] INFO Metadata - [Producer clientId=producer-116] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.144 [kafka-producer-network-thread | producer-116] INFO TransactionManager - [Producer clientId=producer-116] ProducerId set to 1132 with epoch 0
10:35:39.144 [pool-164-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Found no committed offset for partition test-topic-0000472-FWunwBk-0
10:35:39.145 [pool-163-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Resetting offset for partition test-topic-0000469-1ZGl9m0-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.145 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-475-4g3cL84-163-0b684e4f-06e1-4b36-8135-af6b74916c85', protocol='range'}
10:35:39.146 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Notifying assignor about the new Assignment(partitions=[test-topic-0000475-2oxOTx4-0])
10:35:39.146 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Adding newly assigned partitions: test-topic-0000475-2oxOTx4-0
10:35:39.146 [pool-164-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Resetting offset for partition test-topic-0000472-FWunwBk-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.146 [pool-165-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Found no committed offset for partition test-topic-0000475-2oxOTx4-0
10:35:39.147 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.147 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.147 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.147 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139147
10:35:39.148 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-118
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.148 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-118] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.148 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-118] Instantiated an idempotent producer.
10:35:39.148 [pool-165-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Resetting offset for partition test-topic-0000475-2oxOTx4-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.149 [kafka-producer-network-thread | producer-117] INFO Metadata - [Producer clientId=producer-117] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.149 [kafka-producer-network-thread | producer-117] INFO TransactionManager - [Producer clientId=producer-117] ProducerId set to 1134 with epoch 0
10:35:39.149 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-478--bnw0AY-164-8dbf987e-c319-4221-b745-31a685a2aa28', protocol='range'}
10:35:39.149 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Finished assignment for group at generation 1: {consumer-sub-478--bnw0AY-164-8dbf987e-c319-4221-b745-31a685a2aa28=Assignment(partitions=[test-topic-0000478-PJjxrHU-0])}
10:35:39.151 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.151 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.151 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.151 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139151
10:35:39.151 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-119
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.152 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-119] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.152 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-119] Instantiated an idempotent producer.
10:35:39.153 [kafka-producer-network-thread | producer-118] INFO Metadata - [Producer clientId=producer-118] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.153 [kafka-producer-network-thread | producer-118] INFO TransactionManager - [Producer clientId=producer-118] ProducerId set to 2142 with epoch 0
10:35:39.153 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-478--bnw0AY-164-8dbf987e-c319-4221-b745-31a685a2aa28', protocol='range'}
10:35:39.153 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Notifying assignor about the new Assignment(partitions=[test-topic-0000478-PJjxrHU-0])
10:35:39.153 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Adding newly assigned partitions: test-topic-0000478-PJjxrHU-0
10:35:39.154 [pool-166-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Found no committed offset for partition test-topic-0000478-PJjxrHU-0
10:35:39.155 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.155 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.155 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.155 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139155
10:35:39.155 [pool-166-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Resetting offset for partition test-topic-0000478-PJjxrHU-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.156 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-120
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.156 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-120] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.156 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-120] Instantiated an idempotent producer.
10:35:39.156 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-481-_wldBvc-165-a253e4d3-a3f1-4aa3-abec-cb2023dbe482', protocol='range'}
10:35:39.156 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Finished assignment for group at generation 1: {consumer-sub-481-_wldBvc-165-a253e4d3-a3f1-4aa3-abec-cb2023dbe482=Assignment(partitions=[test-topic-0000481-rS9biTw-0])}
10:35:39.157 [kafka-producer-network-thread | producer-119] INFO Metadata - [Producer clientId=producer-119] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.157 [kafka-producer-network-thread | producer-119] INFO TransactionManager - [Producer clientId=producer-119] ProducerId set to 1138 with epoch 0
10:35:39.160 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-481-_wldBvc-165-a253e4d3-a3f1-4aa3-abec-cb2023dbe482', protocol='range'}
10:35:39.160 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Notifying assignor about the new Assignment(partitions=[test-topic-0000481-rS9biTw-0])
10:35:39.160 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Adding newly assigned partitions: test-topic-0000481-rS9biTw-0
10:35:39.161 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-484-0dDycKg-166-8d72fcdc-85ee-456d-903a-cef871f75f0c', protocol='range'}
10:35:39.161 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Finished assignment for group at generation 1: {consumer-sub-484-0dDycKg-166-8d72fcdc-85ee-456d-903a-cef871f75f0c=Assignment(partitions=[test-topic-0000484-Rft_ITE-0])}
10:35:39.161 [pool-167-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Found no committed offset for partition test-topic-0000481-rS9biTw-0
10:35:39.163 [pool-167-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Resetting offset for partition test-topic-0000481-rS9biTw-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.164 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-484-0dDycKg-166-8d72fcdc-85ee-456d-903a-cef871f75f0c', protocol='range'}
10:35:39.164 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Notifying assignor about the new Assignment(partitions=[test-topic-0000484-Rft_ITE-0])
10:35:39.164 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Adding newly assigned partitions: test-topic-0000484-Rft_ITE-0
10:35:39.165 [pool-168-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Found no committed offset for partition test-topic-0000484-Rft_ITE-0
10:35:39.166 [pool-168-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Resetting offset for partition test-topic-0000484-Rft_ITE-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.168 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.168 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.168 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.168 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139168
10:35:39.168 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-121
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.169 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-121] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.169 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-121] Instantiated an idempotent producer.
10:35:39.170 [kafka-producer-network-thread | producer-120] INFO Metadata - [Producer clientId=producer-120] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.170 [kafka-producer-network-thread | producer-120] INFO TransactionManager - [Producer clientId=producer-120] ProducerId set to 2147 with epoch 0
10:35:39.171 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-487-tPuwjUY-167-487d5482-900a-4987-b7b0-a5eacebd5d81', protocol='range'}
10:35:39.171 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-490-qBSDzRw-168-4aa52690-67af-49f6-899a-35225c3c1c37', protocol='range'}
10:35:39.171 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.172 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Finished assignment for group at generation 1: {consumer-sub-487-tPuwjUY-167-487d5482-900a-4987-b7b0-a5eacebd5d81=Assignment(partitions=[test-topic-0000487-vhHh-EY-0])}
10:35:39.172 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Finished assignment for group at generation 1: {consumer-sub-490-qBSDzRw-168-4aa52690-67af-49f6-899a-35225c3c1c37=Assignment(partitions=[test-topic-0000490-f2jrk7M-0])}
10:35:39.172 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.172 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.172 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139172
10:35:39.172 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-122
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.173 [kafka-producer-network-thread | producer-121] INFO Metadata - [Producer clientId=producer-121] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.173 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-122] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.173 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-122] Instantiated an idempotent producer.
10:35:39.173 [kafka-producer-network-thread | producer-121] INFO TransactionManager - [Producer clientId=producer-121] ProducerId set to 1143 with epoch 0
10:35:39.174 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.175 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.175 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.175 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139174
10:35:39.175 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-487-tPuwjUY-167-487d5482-900a-4987-b7b0-a5eacebd5d81', protocol='range'}
10:35:39.175 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Notifying assignor about the new Assignment(partitions=[test-topic-0000487-vhHh-EY-0])
10:35:39.175 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Adding newly assigned partitions: test-topic-0000487-vhHh-EY-0
10:35:39.175 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-490-qBSDzRw-168-4aa52690-67af-49f6-899a-35225c3c1c37', protocol='range'}
10:35:39.175 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-123
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.175 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Notifying assignor about the new Assignment(partitions=[test-topic-0000490-f2jrk7M-0])
10:35:39.175 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Adding newly assigned partitions: test-topic-0000490-f2jrk7M-0
10:35:39.176 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-123] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.176 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-123] Instantiated an idempotent producer.
10:35:39.176 [pool-169-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Found no committed offset for partition test-topic-0000487-vhHh-EY-0
10:35:39.176 [pool-170-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Found no committed offset for partition test-topic-0000490-f2jrk7M-0
10:35:39.176 [kafka-producer-network-thread | producer-122] INFO Metadata - [Producer clientId=producer-122] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.176 [kafka-producer-network-thread | producer-122] INFO TransactionManager - [Producer clientId=producer-122] ProducerId set to 2149 with epoch 0
10:35:39.178 [pool-169-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Resetting offset for partition test-topic-0000487-vhHh-EY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.178 [pool-170-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Resetting offset for partition test-topic-0000490-f2jrk7M-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:39.182 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-493-RgWTaLU-169-ecd31458-473b-4724-af6e-01240f24773b', protocol='range'}
10:35:39.183 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Finished assignment for group at generation 1: {consumer-sub-493-RgWTaLU-169-ecd31458-473b-4724-af6e-01240f24773b=Assignment(partitions=[test-topic-0000493-T5rBBVM-0])}
10:35:39.184 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.184 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.184 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.184 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139184
10:35:39.184 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-124
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.185 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-124] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.185 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-124] Instantiated an idempotent producer.
10:35:39.186 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-493-RgWTaLU-169-ecd31458-473b-4724-af6e-01240f24773b', protocol='range'}
10:35:39.186 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Notifying assignor about the new Assignment(partitions=[test-topic-0000493-T5rBBVM-0])
10:35:39.186 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Adding newly assigned partitions: test-topic-0000493-T5rBBVM-0
10:35:39.187 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.187 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.187 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.187 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139187
10:35:39.187 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-125
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.187 [pool-171-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Found no committed offset for partition test-topic-0000493-T5rBBVM-0
10:35:39.188 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-125] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.188 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-125] Instantiated an idempotent producer.
10:35:39.189 [kafka-producer-network-thread | producer-123] INFO Metadata - [Producer clientId=producer-123] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.189 [kafka-producer-network-thread | producer-123] INFO TransactionManager - [Producer clientId=producer-123] ProducerId set to 169 with epoch 0
10:35:39.189 [pool-171-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Resetting offset for partition test-topic-0000493-T5rBBVM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:39.189 [kafka-producer-network-thread | producer-124] INFO Metadata - [Producer clientId=producer-124] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.190 [kafka-producer-network-thread | producer-124] INFO TransactionManager - [Producer clientId=producer-124] ProducerId set to 170 with epoch 0
10:35:39.190 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.190 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.190 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.190 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139190
10:35:39.190 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-126
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.191 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-496-f32gVfs-170-76a17a69-132d-4136-80ea-b4c32824cabc', protocol='range'}
10:35:39.191 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-126] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.191 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Finished assignment for group at generation 1: {consumer-sub-496-f32gVfs-170-76a17a69-132d-4136-80ea-b4c32824cabc=Assignment(partitions=[test-topic-0000496-f5cGpzY-0])}
10:35:39.191 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-126] Instantiated an idempotent producer.
10:35:39.193 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.193 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.193 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.193 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139193
10:35:39.193 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-127
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.194 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-127] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.194 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-127] Instantiated an idempotent producer.
10:35:39.195 [kafka-producer-network-thread | producer-126] INFO TransactionManager - [Producer clientId=producer-126] ProducerId set to 1149 with epoch 0
10:35:39.195 [kafka-producer-network-thread | producer-126] INFO Metadata - [Producer clientId=producer-126] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.195 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.196 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.196 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.196 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139195
10:35:39.196 [kafka-producer-network-thread | producer-125] INFO Metadata - [Producer clientId=producer-125] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.196 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-496-f32gVfs-170-76a17a69-132d-4136-80ea-b4c32824cabc', protocol='range'}
10:35:39.196 [kafka-producer-network-thread | producer-125] INFO TransactionManager - [Producer clientId=producer-125] ProducerId set to 2153 with epoch 0
10:35:39.196 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Notifying assignor about the new Assignment(partitions=[test-topic-0000496-f5cGpzY-0])
10:35:39.196 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Adding newly assigned partitions: test-topic-0000496-f5cGpzY-0
10:35:39.196 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-128
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.196 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-128] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.196 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-128] Instantiated an idempotent producer.
10:35:39.197 [pool-172-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Found no committed offset for partition test-topic-0000496-f5cGpzY-0
10:35:39.198 [pool-172-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Resetting offset for partition test-topic-0000496-f5cGpzY-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.200 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-499-lAdLlmc-171-10ab314e-d909-41cc-952d-4a200c3299bf', protocol='range'}
10:35:39.200 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Finished assignment for group at generation 1: {consumer-sub-499-lAdLlmc-171-10ab314e-d909-41cc-952d-4a200c3299bf=Assignment(partitions=[test-topic-0000499-rvuAtqA-0])}
10:35:39.201 [kafka-producer-network-thread | producer-127] INFO Metadata - [Producer clientId=producer-127] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.201 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.201 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.201 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.201 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139201
10:35:39.201 [kafka-producer-network-thread | producer-127] INFO TransactionManager - [Producer clientId=producer-127] ProducerId set to 173 with epoch 0
10:35:39.201 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-129
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.202 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-129] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.202 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-129] Instantiated an idempotent producer.
10:35:39.202 [kafka-producer-network-thread | producer-128] INFO Metadata - [Producer clientId=producer-128] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.202 [kafka-producer-network-thread | producer-128] INFO TransactionManager - [Producer clientId=producer-128] ProducerId set to 1151 with epoch 0
10:35:39.202 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-502-HkdCi6I-172-42275854-4a66-4a13-befa-20b1e4028262', protocol='range'}
10:35:39.203 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Finished assignment for group at generation 1: {consumer-sub-502-HkdCi6I-172-42275854-4a66-4a13-befa-20b1e4028262=Assignment(partitions=[test-topic-0000502-e6T4-_g-0])}
10:35:39.204 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-499-lAdLlmc-171-10ab314e-d909-41cc-952d-4a200c3299bf', protocol='range'}
10:35:39.204 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Notifying assignor about the new Assignment(partitions=[test-topic-0000499-rvuAtqA-0])
10:35:39.204 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Adding newly assigned partitions: test-topic-0000499-rvuAtqA-0
10:35:39.205 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.205 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.205 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.205 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139205
10:35:39.205 [pool-173-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Found no committed offset for partition test-topic-0000499-rvuAtqA-0
10:35:39.205 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-130
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.206 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-130] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.206 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-130] Instantiated an idempotent producer.
10:35:39.206 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-502-HkdCi6I-172-42275854-4a66-4a13-befa-20b1e4028262', protocol='range'}
10:35:39.206 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Notifying assignor about the new Assignment(partitions=[test-topic-0000502-e6T4-_g-0])
10:35:39.206 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Adding newly assigned partitions: test-topic-0000502-e6T4-_g-0
10:35:39.207 [pool-174-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Found no committed offset for partition test-topic-0000502-e6T4-_g-0
10:35:39.208 [pool-173-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Resetting offset for partition test-topic-0000499-rvuAtqA-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.208 [kafka-producer-network-thread | producer-129] INFO Metadata - [Producer clientId=producer-129] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.209 [kafka-producer-network-thread | producer-129] INFO TransactionManager - [Producer clientId=producer-129] ProducerId set to 176 with epoch 0
10:35:39.209 [pool-174-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Resetting offset for partition test-topic-0000502-e6T4-_g-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.131:9092 (id: 1 rack: null)], epoch=0}}.
10:35:39.216 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-505-ArOslyo-173-4c357d76-0f23-47ad-8a99-77d73c932e66', protocol='range'}
10:35:39.216 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Finished assignment for group at generation 1: {consumer-sub-505-ArOslyo-173-4c357d76-0f23-47ad-8a99-77d73c932e66=Assignment(partitions=[test-topic-0000505-tAmtBFc-0])}
10:35:39.217 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.217 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.217 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.217 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139217
10:35:39.217 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-131
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.218 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-131] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.218 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-131] Instantiated an idempotent producer.
10:35:39.218 [kafka-producer-network-thread | producer-130] INFO TransactionManager - [Producer clientId=producer-130] ProducerId set to 1156 with epoch 0
10:35:39.218 [kafka-producer-network-thread | producer-130] INFO Metadata - [Producer clientId=producer-130] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.219 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-505-ArOslyo-173-4c357d76-0f23-47ad-8a99-77d73c932e66', protocol='range'}
10:35:39.220 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Notifying assignor about the new Assignment(partitions=[test-topic-0000505-tAmtBFc-0])
10:35:39.220 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Adding newly assigned partitions: test-topic-0000505-tAmtBFc-0
10:35:39.220 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.220 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.220 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.220 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139220
10:35:39.221 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Found no committed offset for partition test-topic-0000505-tAmtBFc-0
10:35:39.221 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-132
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.221 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-132] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.221 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-132] Instantiated an idempotent producer.
10:35:39.222 [kafka-producer-network-thread | producer-131] INFO Metadata - [Producer clientId=producer-131] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.222 [kafka-producer-network-thread | producer-131] INFO TransactionManager - [Producer clientId=producer-131] ProducerId set to 180 with epoch 0
10:35:39.223 [pool-175-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Resetting offset for partition test-topic-0000505-tAmtBFc-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:39.229 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.229 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.229 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.229 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139229
10:35:39.229 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-133
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.230 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-133] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.230 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-133] Instantiated an idempotent producer.
10:35:39.230 [kafka-producer-network-thread | producer-132] INFO Metadata - [Producer clientId=producer-132] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.230 [kafka-producer-network-thread | producer-132] INFO TransactionManager - [Producer clientId=producer-132] ProducerId set to 2163 with epoch 0
10:35:39.231 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.232 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.232 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.232 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139231
10:35:39.232 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-134
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.232 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-134] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.233 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-134] Instantiated an idempotent producer.
10:35:39.233 [kafka-producer-network-thread | producer-133] INFO Metadata - [Producer clientId=producer-133] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.234 [kafka-producer-network-thread | producer-133] INFO TransactionManager - [Producer clientId=producer-133] ProducerId set to 1162 with epoch 0
10:35:39.235 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.235 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.235 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.235 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139235
10:35:39.235 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-135
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.236 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-135] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.236 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-135] Instantiated an idempotent producer.
10:35:39.236 [kafka-producer-network-thread | producer-134] INFO Metadata - [Producer clientId=producer-134] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.236 [kafka-producer-network-thread | producer-134] INFO TransactionManager - [Producer clientId=producer-134] ProducerId set to 1164 with epoch 0
10:35:39.238 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.238 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.238 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.238 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139238
10:35:39.239 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-136
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.239 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-136] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.239 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-136] Instantiated an idempotent producer.
10:35:39.242 [kafka-producer-network-thread | producer-135] INFO Metadata - [Producer clientId=producer-135] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.242 [kafka-producer-network-thread | producer-135] INFO TransactionManager - [Producer clientId=producer-135] ProducerId set to 182 with epoch 0
10:35:39.243 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.243 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.243 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.243 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139243
10:35:39.243 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-137
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.244 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-137] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.244 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-137] Instantiated an idempotent producer.
10:35:39.245 [kafka-producer-network-thread | producer-136] INFO Metadata - [Producer clientId=producer-136] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.245 [kafka-producer-network-thread | producer-136] INFO TransactionManager - [Producer clientId=producer-136] ProducerId set to 183 with epoch 0
10:35:39.246 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.246 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.246 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.246 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139246
10:35:39.246 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-138
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.247 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-138] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.247 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-138] Instantiated an idempotent producer.
10:35:39.247 [kafka-producer-network-thread | producer-137] INFO Metadata - [Producer clientId=producer-137] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.248 [kafka-producer-network-thread | producer-137] INFO TransactionManager - [Producer clientId=producer-137] ProducerId set to 2169 with epoch 0
10:35:39.250 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.250 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.250 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.250 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139250
10:35:39.250 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-139
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.251 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-139] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.251 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-139] Instantiated an idempotent producer.
10:35:39.253 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.253 [kafka-producer-network-thread | producer-138] INFO Metadata - [Producer clientId=producer-138] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.253 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.253 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.253 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139253
10:35:39.253 [kafka-producer-network-thread | producer-138] INFO TransactionManager - [Producer clientId=producer-138] ProducerId set to 186 with epoch 0
10:35:39.253 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-140
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.254 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-140] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.254 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-140] Instantiated an idempotent producer.
10:35:39.255 [kafka-producer-network-thread | producer-139] INFO Metadata - [Producer clientId=producer-139] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.255 [kafka-producer-network-thread | producer-139] INFO TransactionManager - [Producer clientId=producer-139] ProducerId set to 1168 with epoch 0
10:35:39.259 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.259 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.259 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.259 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139259
10:35:39.259 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-141
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.260 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-141] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.260 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-141] Instantiated an idempotent producer.
10:35:39.260 [kafka-producer-network-thread | producer-140] INFO Metadata - [Producer clientId=producer-140] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.261 [kafka-producer-network-thread | producer-140] INFO TransactionManager - [Producer clientId=producer-140] ProducerId set to 1171 with epoch 0
10:35:39.262 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.262 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.262 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.262 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139262
10:35:39.262 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-142
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.263 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-142] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.263 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-142] Instantiated an idempotent producer.
10:35:39.264 [kafka-producer-network-thread | producer-141] INFO Metadata - [Producer clientId=producer-141] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.264 [kafka-producer-network-thread | producer-141] INFO TransactionManager - [Producer clientId=producer-141] ProducerId set to 1172 with epoch 0
10:35:39.265 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.265 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.265 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.265 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139265
10:35:39.265 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-143
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.266 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-143] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.266 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-143] Instantiated an idempotent producer.
10:35:39.266 [kafka-producer-network-thread | producer-142] INFO Metadata - [Producer clientId=producer-142] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.267 [kafka-producer-network-thread | producer-142] INFO TransactionManager - [Producer clientId=producer-142] ProducerId set to 191 with epoch 0
10:35:39.268 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.268 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.268 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.268 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139268
10:35:39.268 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-144
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.269 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-144] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.269 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-144] Instantiated an idempotent producer.
10:35:39.269 [kafka-producer-network-thread | producer-143] INFO Metadata - [Producer clientId=producer-143] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.269 [kafka-producer-network-thread | producer-143] INFO TransactionManager - [Producer clientId=producer-143] ProducerId set to 2173 with epoch 0
10:35:39.270 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.270 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.271 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.271 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139270
10:35:39.271 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-145
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.271 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-145] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.271 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-145] Instantiated an idempotent producer.
10:35:39.272 [kafka-producer-network-thread | producer-144] INFO Metadata - [Producer clientId=producer-144] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.272 [kafka-producer-network-thread | producer-144] INFO TransactionManager - [Producer clientId=producer-144] ProducerId set to 193 with epoch 0
10:35:39.274 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.274 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.274 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.274 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139274
10:35:39.274 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-146
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.275 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-146] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.275 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-146] Instantiated an idempotent producer.
10:35:39.275 [kafka-producer-network-thread | producer-145] INFO Metadata - [Producer clientId=producer-145] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.275 [kafka-producer-network-thread | producer-145] INFO TransactionManager - [Producer clientId=producer-145] ProducerId set to 2177 with epoch 0
10:35:39.278 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.278 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.278 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.278 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139278
10:35:39.279 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-147
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.279 [kafka-producer-network-thread | producer-146] INFO Metadata - [Producer clientId=producer-146] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.280 [kafka-producer-network-thread | producer-146] INFO TransactionManager - [Producer clientId=producer-146] ProducerId set to 1176 with epoch 0
10:35:39.280 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-147] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.280 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-147] Instantiated an idempotent producer.
10:35:39.286 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.286 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.286 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.286 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139286
10:35:39.286 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-148
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.287 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-148] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.287 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-148] Instantiated an idempotent producer.
10:35:39.287 [kafka-producer-network-thread | producer-147] INFO Metadata - [Producer clientId=producer-147] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.287 [kafka-producer-network-thread | producer-147] INFO TransactionManager - [Producer clientId=producer-147] ProducerId set to 1181 with epoch 0
10:35:39.289 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.289 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.289 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.289 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139289
10:35:39.289 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-149
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.290 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-149] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.290 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-149] Instantiated an idempotent producer.
10:35:39.291 [kafka-producer-network-thread | producer-148] INFO Metadata - [Producer clientId=producer-148] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.291 [kafka-producer-network-thread | producer-148] INFO TransactionManager - [Producer clientId=producer-148] ProducerId set to 2181 with epoch 0
10:35:39.294 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.294 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.294 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.294 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139294
10:35:39.294 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-150
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.295 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-150] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.295 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-150] Instantiated an idempotent producer.
10:35:39.295 [kafka-producer-network-thread | producer-149] INFO Metadata - [Producer clientId=producer-149] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.296 [kafka-producer-network-thread | producer-149] INFO TransactionManager - [Producer clientId=producer-149] ProducerId set to 197 with epoch 0
10:35:39.297 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.297 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.297 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.297 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139297
10:35:39.297 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-151
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.297 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-151] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.298 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-151] Instantiated an idempotent producer.
10:35:39.299 [kafka-producer-network-thread | producer-150] INFO Metadata - [Producer clientId=producer-150] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.299 [kafka-producer-network-thread | producer-150] INFO TransactionManager - [Producer clientId=producer-150] ProducerId set to 198 with epoch 0
10:35:39.299 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.299 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.299 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.299 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139299
10:35:39.300 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-152
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.300 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-152] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.301 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-152] Instantiated an idempotent producer.
10:35:39.301 [kafka-producer-network-thread | producer-151] INFO Metadata - [Producer clientId=producer-151] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.301 [kafka-producer-network-thread | producer-151] INFO TransactionManager - [Producer clientId=producer-151] ProducerId set to 1185 with epoch 0
10:35:39.302 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.302 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.302 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.302 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139302
10:35:39.303 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-153
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.303 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-153] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.303 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-153] Instantiated an idempotent producer.
10:35:39.304 [kafka-producer-network-thread | producer-152] INFO Metadata - [Producer clientId=producer-152] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.304 [kafka-producer-network-thread | producer-152] INFO TransactionManager - [Producer clientId=producer-152] ProducerId set to 2186 with epoch 0
10:35:39.305 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.305 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.305 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.305 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139305
10:35:39.306 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-154
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.306 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-154] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.306 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-154] Instantiated an idempotent producer.
10:35:39.307 [kafka-producer-network-thread | producer-153] INFO Metadata - [Producer clientId=producer-153] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.307 [kafka-producer-network-thread | producer-153] INFO TransactionManager - [Producer clientId=producer-153] ProducerId set to 2187 with epoch 0
10:35:39.308 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.308 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.308 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.308 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139308
10:35:39.309 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-155
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.309 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-155] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.309 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-155] Instantiated an idempotent producer.
10:35:39.310 [kafka-producer-network-thread | producer-154] INFO Metadata - [Producer clientId=producer-154] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.310 [kafka-producer-network-thread | producer-154] INFO TransactionManager - [Producer clientId=producer-154] ProducerId set to 202 with epoch 0
10:35:39.311 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.311 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.311 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.311 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139311
10:35:39.311 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-156
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.312 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-156] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.312 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-156] Instantiated an idempotent producer.
10:35:39.313 [kafka-producer-network-thread | producer-155] INFO Metadata - [Producer clientId=producer-155] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.313 [kafka-producer-network-thread | producer-155] INFO TransactionManager - [Producer clientId=producer-155] ProducerId set to 203 with epoch 0
10:35:39.314 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.314 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.314 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.314 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139314
10:35:39.314 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-157
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.315 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-157] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.315 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-157] Instantiated an idempotent producer.
10:35:39.317 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.317 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.317 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.317 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139317
10:35:39.317 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-158
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.317 [kafka-producer-network-thread | producer-156] INFO Metadata - [Producer clientId=producer-156] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.317 [kafka-producer-network-thread | producer-156] INFO TransactionManager - [Producer clientId=producer-156] ProducerId set to 204 with epoch 0
10:35:39.318 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-158] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.318 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-158] Instantiated an idempotent producer.
10:35:39.319 [kafka-producer-network-thread | producer-157] INFO Metadata - [Producer clientId=producer-157] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.319 [kafka-producer-network-thread | producer-157] INFO TransactionManager - [Producer clientId=producer-157] ProducerId set to 206 with epoch 0
10:35:39.321 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.321 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.321 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.321 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139321
10:35:39.322 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-159
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.322 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-159] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.322 [kafka-producer-network-thread | producer-158] INFO Metadata - [Producer clientId=producer-158] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.322 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-159] Instantiated an idempotent producer.
10:35:39.322 [kafka-producer-network-thread | producer-158] INFO TransactionManager - [Producer clientId=producer-158] ProducerId set to 2189 with epoch 0
10:35:39.325 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.325 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.325 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.325 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139325
10:35:39.325 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-160
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.326 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-160] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.326 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-160] Instantiated an idempotent producer.
10:35:39.327 [kafka-producer-network-thread | producer-159] INFO Metadata - [Producer clientId=producer-159] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.327 [kafka-producer-network-thread | producer-159] INFO TransactionManager - [Producer clientId=producer-159] ProducerId set to 1188 with epoch 0
10:35:39.328 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.328 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.328 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.328 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139328
10:35:39.328 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-161
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.329 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-161] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.329 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-161] Instantiated an idempotent producer.
10:35:39.330 [kafka-producer-network-thread | producer-160] INFO Metadata - [Producer clientId=producer-160] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.330 [kafka-producer-network-thread | producer-160] INFO TransactionManager - [Producer clientId=producer-160] ProducerId set to 1189 with epoch 0
10:35:39.332 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.332 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.332 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.332 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139332
10:35:39.332 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-162
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.332 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-162] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.333 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-162] Instantiated an idempotent producer.
10:35:39.333 [kafka-producer-network-thread | producer-161] INFO Metadata - [Producer clientId=producer-161] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.334 [kafka-producer-network-thread | producer-161] INFO TransactionManager - [Producer clientId=producer-161] ProducerId set to 209 with epoch 0
10:35:39.334 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.334 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.334 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.334 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139334
10:35:39.335 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-163
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.335 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-163] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.335 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-163] Instantiated an idempotent producer.
10:35:39.336 [kafka-producer-network-thread | producer-162] INFO Metadata - [Producer clientId=producer-162] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.336 [kafka-producer-network-thread | producer-162] INFO TransactionManager - [Producer clientId=producer-162] ProducerId set to 2193 with epoch 0
10:35:39.340 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.340 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.340 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.340 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139340
10:35:39.340 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-164
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.341 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-164] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.341 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-164] Instantiated an idempotent producer.
10:35:39.341 [kafka-producer-network-thread | producer-163] INFO Metadata - [Producer clientId=producer-163] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.341 [kafka-producer-network-thread | producer-163] INFO TransactionManager - [Producer clientId=producer-163] ProducerId set to 1196 with epoch 0
10:35:39.343 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.343 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.343 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.343 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139343
10:35:39.343 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-165
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.344 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-165] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.344 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-165] Instantiated an idempotent producer.
10:35:39.344 [kafka-producer-network-thread | producer-164] INFO Metadata - [Producer clientId=producer-164] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.344 [kafka-producer-network-thread | producer-164] INFO TransactionManager - [Producer clientId=producer-164] ProducerId set to 2196 with epoch 0
10:35:39.345 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.346 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.346 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.346 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139346
10:35:39.346 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-166
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.346 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-166] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.347 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-166] Instantiated an idempotent producer.
10:35:39.348 [kafka-producer-network-thread | producer-165] INFO Metadata - [Producer clientId=producer-165] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.349 [kafka-producer-network-thread | producer-165] INFO TransactionManager - [Producer clientId=producer-165] ProducerId set to 1198 with epoch 0
10:35:39.350 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.350 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.350 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.350 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139350
10:35:39.350 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-167
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.351 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-167] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.351 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-167] Instantiated an idempotent producer.
10:35:39.352 [kafka-producer-network-thread | producer-166] INFO Metadata - [Producer clientId=producer-166] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.352 [kafka-producer-network-thread | producer-166] INFO TransactionManager - [Producer clientId=producer-166] ProducerId set to 2198 with epoch 0
10:35:39.352 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.353 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.353 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.353 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139353
10:35:39.353 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-168
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.353 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-168] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.354 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-168] Instantiated an idempotent producer.
10:35:39.360 [kafka-producer-network-thread | producer-167] INFO Metadata - [Producer clientId=producer-167] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.361 [kafka-producer-network-thread | producer-167] INFO TransactionManager - [Producer clientId=producer-167] ProducerId set to 1203 with epoch 0
10:35:39.364 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.364 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.364 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.364 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139364
10:35:39.364 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-169
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.365 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-169] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.365 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-169] Instantiated an idempotent producer.
10:35:39.365 [kafka-producer-network-thread | producer-168] INFO Metadata - [Producer clientId=producer-168] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.366 [kafka-producer-network-thread | producer-168] INFO TransactionManager - [Producer clientId=producer-168] ProducerId set to 2200 with epoch 0
10:35:39.368 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.368 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.369 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.369 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139368
10:35:39.369 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-170
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.369 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-170] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.370 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-170] Instantiated an idempotent producer.
10:35:39.370 [kafka-producer-network-thread | producer-169] INFO Metadata - [Producer clientId=producer-169] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.370 [kafka-producer-network-thread | producer-169] INFO TransactionManager - [Producer clientId=producer-169] ProducerId set to 215 with epoch 0
10:35:39.371 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.372 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.372 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.372 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139372
10:35:39.372 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-171
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.373 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-171] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.373 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-171] Instantiated an idempotent producer.
10:35:39.375 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.375 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.375 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.375 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139375
10:35:39.375 [kafka-producer-network-thread | producer-170] INFO TransactionManager - [Producer clientId=producer-170] ProducerId set to 2203 with epoch 0
10:35:39.375 [kafka-producer-network-thread | producer-170] INFO Metadata - [Producer clientId=producer-170] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.375 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-172
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.376 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-172] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.376 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-172] Instantiated an idempotent producer.
10:35:39.377 [kafka-producer-network-thread | producer-171] INFO Metadata - [Producer clientId=producer-171] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.377 [kafka-producer-network-thread | producer-171] INFO TransactionManager - [Producer clientId=producer-171] ProducerId set to 2204 with epoch 0
10:35:39.386 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.386 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.386 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.386 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139386
10:35:39.387 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-173
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.387 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-173] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.387 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-173] Instantiated an idempotent producer.
10:35:39.388 [kafka-producer-network-thread | producer-172] INFO Metadata - [Producer clientId=producer-172] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.388 [kafka-producer-network-thread | producer-172] INFO TransactionManager - [Producer clientId=producer-172] ProducerId set to 220 with epoch 0
10:35:39.389 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.389 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.390 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.390 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139389
10:35:39.390 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-174
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.390 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-174] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.390 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-174] Instantiated an idempotent producer.
10:35:39.392 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.392 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.392 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.392 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139392
10:35:39.393 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-175
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.393 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-175] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.393 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-175] Instantiated an idempotent producer.
10:35:39.394 [kafka-producer-network-thread | producer-174] INFO Metadata - [Producer clientId=producer-174] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.394 [kafka-producer-network-thread | producer-174] INFO TransactionManager - [Producer clientId=producer-174] ProducerId set to 2207 with epoch 0
10:35:39.395 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.395 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.395 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.395 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139395
10:35:39.396 [kafka-producer-network-thread | producer-173] INFO Metadata - [Producer clientId=producer-173] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.396 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-176
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.396 [kafka-producer-network-thread | producer-173] INFO TransactionManager - [Producer clientId=producer-173] ProducerId set to 1210 with epoch 0
10:35:39.396 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-176] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.396 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-176] Instantiated an idempotent producer.
10:35:39.397 [kafka-producer-network-thread | producer-175] INFO Metadata - [Producer clientId=producer-175] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.397 [kafka-producer-network-thread | producer-175] INFO TransactionManager - [Producer clientId=producer-175] ProducerId set to 1212 with epoch 0
10:35:39.398 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.398 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.398 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.398 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139398
10:35:39.399 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-177
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.400 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-177] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.400 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-177] Instantiated an idempotent producer.
10:35:39.400 [kafka-producer-network-thread | producer-176] INFO Metadata - [Producer clientId=producer-176] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.401 [kafka-producer-network-thread | producer-176] INFO TransactionManager - [Producer clientId=producer-176] ProducerId set to 1213 with epoch 0
10:35:39.402 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.402 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.402 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.402 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139402
10:35:39.402 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-178
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.403 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-178] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.403 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-178] Instantiated an idempotent producer.
10:35:39.403 [kafka-producer-network-thread | producer-177] INFO Metadata - [Producer clientId=producer-177] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.404 [kafka-producer-network-thread | producer-177] INFO TransactionManager - [Producer clientId=producer-177] ProducerId set to 224 with epoch 0
10:35:39.405 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.405 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.405 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.405 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139405
10:35:39.406 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-179
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.406 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-179] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.406 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-179] Instantiated an idempotent producer.
10:35:39.408 [kafka-producer-network-thread | producer-178] INFO Metadata - [Producer clientId=producer-178] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.408 [kafka-producer-network-thread | producer-178] INFO TransactionManager - [Producer clientId=producer-178] ProducerId set to 226 with epoch 0
10:35:39.408 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.408 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.408 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.408 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139408
10:35:39.409 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-180
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.409 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-180] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.409 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-180] Instantiated an idempotent producer.
10:35:39.410 [kafka-producer-network-thread | producer-179] INFO Metadata - [Producer clientId=producer-179] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.410 [kafka-producer-network-thread | producer-179] INFO TransactionManager - [Producer clientId=producer-179] ProducerId set to 2213 with epoch 0
10:35:39.411 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.411 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.411 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.411 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139411
10:35:39.412 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-181
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.412 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-181] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.412 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-181] Instantiated an idempotent producer.
10:35:39.413 [kafka-producer-network-thread | producer-180] INFO Metadata - [Producer clientId=producer-180] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.413 [kafka-producer-network-thread | producer-180] INFO TransactionManager - [Producer clientId=producer-180] ProducerId set to 227 with epoch 0
10:35:39.414 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.414 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.414 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.414 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139414
10:35:39.414 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-182
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.415 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-182] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.415 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-182] Instantiated an idempotent producer.
10:35:39.415 [kafka-producer-network-thread | producer-181] INFO Metadata - [Producer clientId=producer-181] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.415 [kafka-producer-network-thread | producer-181] INFO TransactionManager - [Producer clientId=producer-181] ProducerId set to 1217 with epoch 0
10:35:39.416 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.416 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.416 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.416 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139416
10:35:39.417 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-183
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.417 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-183] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.417 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-183] Instantiated an idempotent producer.
10:35:39.418 [kafka-producer-network-thread | producer-182] INFO Metadata - [Producer clientId=producer-182] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.418 [kafka-producer-network-thread | producer-182] INFO TransactionManager - [Producer clientId=producer-182] ProducerId set to 229 with epoch 0
10:35:39.419 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.419 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.419 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.419 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139419
10:35:39.420 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-184
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.420 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-184] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.420 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-184] Instantiated an idempotent producer.
10:35:39.421 [kafka-producer-network-thread | producer-183] INFO Metadata - [Producer clientId=producer-183] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.421 [kafka-producer-network-thread | producer-183] INFO TransactionManager - [Producer clientId=producer-183] ProducerId set to 2218 with epoch 0
10:35:39.424 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.424 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.424 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.424 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139424
10:35:39.424 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-185
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.425 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-185] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.425 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-185] Instantiated an idempotent producer.
10:35:39.425 [kafka-producer-network-thread | producer-184] INFO Metadata - [Producer clientId=producer-184] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.426 [kafka-producer-network-thread | producer-184] INFO TransactionManager - [Producer clientId=producer-184] ProducerId set to 1218 with epoch 0
10:35:39.426 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.427 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.427 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.427 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139427
10:35:39.427 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-186
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.427 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-186] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.427 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-186] Instantiated an idempotent producer.
10:35:39.428 [kafka-producer-network-thread | producer-185] INFO Metadata - [Producer clientId=producer-185] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.428 [kafka-producer-network-thread | producer-185] INFO TransactionManager - [Producer clientId=producer-185] ProducerId set to 2222 with epoch 0
10:35:39.429 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.429 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.429 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.429 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139429
10:35:39.430 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-187
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.430 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-187] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.430 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-187] Instantiated an idempotent producer.
10:35:39.431 [kafka-producer-network-thread | producer-186] INFO Metadata - [Producer clientId=producer-186] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.431 [kafka-producer-network-thread | producer-186] INFO TransactionManager - [Producer clientId=producer-186] ProducerId set to 232 with epoch 0
10:35:39.432 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.432 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.432 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.432 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139432
10:35:39.433 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-188
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.433 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-188] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.433 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-188] Instantiated an idempotent producer.
10:35:39.433 [kafka-producer-network-thread | producer-187] INFO Metadata - [Producer clientId=producer-187] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.433 [kafka-producer-network-thread | producer-187] INFO TransactionManager - [Producer clientId=producer-187] ProducerId set to 2224 with epoch 0
10:35:39.435 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.435 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.435 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.435 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139435
10:35:39.435 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-189
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.436 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-189] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.436 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-189] Instantiated an idempotent producer.
10:35:39.437 [kafka-producer-network-thread | producer-188] INFO Metadata - [Producer clientId=producer-188] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.437 [kafka-producer-network-thread | producer-188] INFO TransactionManager - [Producer clientId=producer-188] ProducerId set to 1221 with epoch 0
10:35:39.440 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.440 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.440 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.440 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139440
10:35:39.440 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-190
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.441 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-190] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.441 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-190] Instantiated an idempotent producer.
10:35:39.442 [kafka-producer-network-thread | producer-189] INFO Metadata - [Producer clientId=producer-189] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.442 [kafka-producer-network-thread | producer-189] INFO TransactionManager - [Producer clientId=producer-189] ProducerId set to 235 with epoch 0
10:35:39.443 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.443 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.443 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.443 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139443
10:35:39.443 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-191
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.444 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-191] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.444 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-191] Instantiated an idempotent producer.
10:35:39.444 [kafka-producer-network-thread | producer-190] INFO Metadata - [Producer clientId=producer-190] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.445 [kafka-producer-network-thread | producer-190] INFO TransactionManager - [Producer clientId=producer-190] ProducerId set to 1225 with epoch 0
10:35:39.448 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.448 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.448 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.448 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139448
10:35:39.448 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-192
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.449 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-192] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.449 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-192] Instantiated an idempotent producer.
10:35:39.450 [kafka-producer-network-thread | producer-191] INFO Metadata - [Producer clientId=producer-191] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.450 [kafka-producer-network-thread | producer-191] INFO TransactionManager - [Producer clientId=producer-191] ProducerId set to 236 with epoch 0
10:35:39.454 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.454 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.454 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.454 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139454
10:35:39.455 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-193
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.455 [kafka-producer-network-thread | producer-192] INFO Metadata - [Producer clientId=producer-192] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.455 [kafka-producer-network-thread | producer-192] INFO TransactionManager - [Producer clientId=producer-192] ProducerId set to 237 with epoch 0
10:35:39.455 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-193] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.456 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-193] Instantiated an idempotent producer.
10:35:39.462 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.462 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.462 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.462 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139462
10:35:39.463 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-194
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.463 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-194] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.463 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-194] Instantiated an idempotent producer.
10:35:39.464 [kafka-producer-network-thread | producer-193] INFO Metadata - [Producer clientId=producer-193] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.464 [kafka-producer-network-thread | producer-193] INFO TransactionManager - [Producer clientId=producer-193] ProducerId set to 2232 with epoch 0
10:35:39.465 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.465 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.465 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.465 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139465
10:35:39.465 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-195
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.466 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-195] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.466 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-195] Instantiated an idempotent producer.
10:35:39.466 [kafka-producer-network-thread | producer-194] INFO Metadata - [Producer clientId=producer-194] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.466 [kafka-producer-network-thread | producer-194] INFO TransactionManager - [Producer clientId=producer-194] ProducerId set to 1233 with epoch 0
10:35:39.468 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.468 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.468 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.468 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139468
10:35:39.468 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-196
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.469 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-196] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.469 [kafka-producer-network-thread | producer-195] INFO Metadata - [Producer clientId=producer-195] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.469 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-196] Instantiated an idempotent producer.
10:35:39.469 [kafka-producer-network-thread | producer-195] INFO TransactionManager - [Producer clientId=producer-195] ProducerId set to 2235 with epoch 0
10:35:39.471 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.471 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.471 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.471 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139471
10:35:39.472 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-197
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.472 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-197] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.472 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-197] Instantiated an idempotent producer.
10:35:39.473 [kafka-producer-network-thread | producer-196] INFO Metadata - [Producer clientId=producer-196] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.473 [kafka-producer-network-thread | producer-196] INFO TransactionManager - [Producer clientId=producer-196] ProducerId set to 2238 with epoch 0
10:35:39.474 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.474 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.474 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.474 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139474
10:35:39.475 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-198
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.475 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-198] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.475 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-198] Instantiated an idempotent producer.
10:35:39.476 [kafka-producer-network-thread | producer-197] INFO Metadata - [Producer clientId=producer-197] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.476 [kafka-producer-network-thread | producer-197] INFO TransactionManager - [Producer clientId=producer-197] ProducerId set to 2240 with epoch 0
10:35:39.479 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.479 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.479 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.479 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139479
10:35:39.479 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-199
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.480 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-199] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.480 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-199] Instantiated an idempotent producer.
10:35:39.481 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.481 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.482 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.482 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139481
10:35:39.482 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-200
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.483 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-200] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.483 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-200] Instantiated an idempotent producer.
10:35:39.485 [kafka-producer-network-thread | producer-198] INFO Metadata - [Producer clientId=producer-198] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.485 [kafka-producer-network-thread | producer-198] INFO TransactionManager - [Producer clientId=producer-198] ProducerId set to 2243 with epoch 0
10:35:39.486 [kafka-producer-network-thread | producer-199] INFO Metadata - [Producer clientId=producer-199] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.486 [kafka-producer-network-thread | producer-199] INFO TransactionManager - [Producer clientId=producer-199] ProducerId set to 2245 with epoch 0
10:35:39.487 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.487 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.487 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.487 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139487
10:35:39.487 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-201
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.488 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-201] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.488 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-201] Instantiated an idempotent producer.
10:35:39.488 [kafka-producer-network-thread | producer-200] INFO Metadata - [Producer clientId=producer-200] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.489 [kafka-producer-network-thread | producer-200] INFO TransactionManager - [Producer clientId=producer-200] ProducerId set to 1239 with epoch 0
10:35:39.489 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.489 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.489 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.489 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139489
10:35:39.490 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-202
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.490 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-202] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.490 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-202] Instantiated an idempotent producer.
10:35:39.491 [kafka-producer-network-thread | producer-201] INFO Metadata - [Producer clientId=producer-201] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.491 [kafka-producer-network-thread | producer-201] INFO TransactionManager - [Producer clientId=producer-201] ProducerId set to 242 with epoch 0
10:35:39.495 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.495 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.495 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.495 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139495
10:35:39.495 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-203
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.496 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-203] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.496 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-203] Instantiated an idempotent producer.
10:35:39.497 [kafka-producer-network-thread | producer-202] INFO Metadata - [Producer clientId=producer-202] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.497 [kafka-producer-network-thread | producer-202] INFO TransactionManager - [Producer clientId=producer-202] ProducerId set to 1242 with epoch 0
10:35:39.497 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.497 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.497 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.497 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139497
10:35:39.498 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-204
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.499 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-204] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.499 [kafka-producer-network-thread | producer-203] INFO Metadata - [Producer clientId=producer-203] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.499 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-204] Instantiated an idempotent producer.
10:35:39.499 [kafka-producer-network-thread | producer-203] INFO TransactionManager - [Producer clientId=producer-203] ProducerId set to 244 with epoch 0
10:35:39.500 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.500 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.500 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.500 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139500
10:35:39.501 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-205
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.501 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-205] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.501 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-205] Instantiated an idempotent producer.
10:35:39.503 [kafka-producer-network-thread | producer-204] INFO Metadata - [Producer clientId=producer-204] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.504 [kafka-producer-network-thread | producer-204] INFO TransactionManager - [Producer clientId=producer-204] ProducerId set to 1245 with epoch 0
10:35:39.510 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.510 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.510 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.510 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139510
10:35:39.510 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-206
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.510 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-206] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.511 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-206] Instantiated an idempotent producer.
10:35:39.511 [kafka-producer-network-thread | producer-205] INFO Metadata - [Producer clientId=producer-205] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.511 [kafka-producer-network-thread | producer-205] INFO TransactionManager - [Producer clientId=producer-205] ProducerId set to 1249 with epoch 0
10:35:39.512 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.512 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.512 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.512 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139512
10:35:39.513 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-207
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.513 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-207] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.513 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-207] Instantiated an idempotent producer.
10:35:39.515 [kafka-producer-network-thread | producer-206] INFO Metadata - [Producer clientId=producer-206] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.516 [kafka-producer-network-thread | producer-206] INFO TransactionManager - [Producer clientId=producer-206] ProducerId set to 2255 with epoch 0
10:35:39.518 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.518 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.518 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.518 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139518
10:35:39.518 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-208
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.518 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-208] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.518 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-208] Instantiated an idempotent producer.
10:35:39.519 [kafka-producer-network-thread | producer-207] INFO Metadata - [Producer clientId=producer-207] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.519 [kafka-producer-network-thread | producer-207] INFO TransactionManager - [Producer clientId=producer-207] ProducerId set to 247 with epoch 0
10:35:39.520 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.520 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.520 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.520 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139520
10:35:39.521 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-209
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.521 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-209] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.521 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-209] Instantiated an idempotent producer.
10:35:39.522 [kafka-producer-network-thread | producer-208] INFO Metadata - [Producer clientId=producer-208] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.522 [kafka-producer-network-thread | producer-208] INFO TransactionManager - [Producer clientId=producer-208] ProducerId set to 2260 with epoch 0
10:35:39.523 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.523 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.523 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.523 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139523
10:35:39.523 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-210
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.524 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-210] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.524 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-210] Instantiated an idempotent producer.
10:35:39.524 [kafka-producer-network-thread | producer-209] INFO Metadata - [Producer clientId=producer-209] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.525 [kafka-producer-network-thread | producer-209] INFO TransactionManager - [Producer clientId=producer-209] ProducerId set to 1252 with epoch 0
10:35:39.525 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.525 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.525 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.527 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139525
10:35:39.527 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-211
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.528 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-211] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.528 [kafka-producer-network-thread | producer-210] INFO Metadata - [Producer clientId=producer-210] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.528 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-211] Instantiated an idempotent producer.
10:35:39.528 [kafka-producer-network-thread | producer-210] INFO TransactionManager - [Producer clientId=producer-210] ProducerId set to 250 with epoch 0
10:35:39.530 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.530 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.530 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.530 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139530
10:35:39.530 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-212
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.530 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-212] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.530 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-212] Instantiated an idempotent producer.
10:35:39.534 [kafka-producer-network-thread | producer-211] INFO Metadata - [Producer clientId=producer-211] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.534 [kafka-producer-network-thread | producer-211] INFO TransactionManager - [Producer clientId=producer-211] ProducerId set to 1253 with epoch 0
10:35:39.536 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.536 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.536 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.536 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139536
10:35:39.536 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-213
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.537 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-213] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.537 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-213] Instantiated an idempotent producer.
10:35:39.539 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.539 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.539 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.539 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139539
10:35:39.540 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-214
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.540 [kafka-producer-network-thread | producer-212] INFO Metadata - [Producer clientId=producer-212] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.540 [kafka-producer-network-thread | producer-212] INFO TransactionManager - [Producer clientId=producer-212] ProducerId set to 2266 with epoch 0
10:35:39.540 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-214] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.540 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-214] Instantiated an idempotent producer.
10:35:39.541 [kafka-producer-network-thread | producer-213] INFO Metadata - [Producer clientId=producer-213] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.541 [kafka-producer-network-thread | producer-213] INFO TransactionManager - [Producer clientId=producer-213] ProducerId set to 255 with epoch 0
10:35:39.542 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.542 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.542 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.542 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139542
10:35:39.542 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-215
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.543 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-215] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.543 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-215] Instantiated an idempotent producer.
10:35:39.544 [kafka-producer-network-thread | producer-214] INFO Metadata - [Producer clientId=producer-214] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.544 [kafka-producer-network-thread | producer-214] INFO TransactionManager - [Producer clientId=producer-214] ProducerId set to 257 with epoch 0
10:35:39.545 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.545 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.545 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.545 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139545
10:35:39.545 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-216
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.546 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-216] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.546 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-216] Instantiated an idempotent producer.
10:35:39.546 [kafka-producer-network-thread | producer-215] INFO Metadata - [Producer clientId=producer-215] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.546 [kafka-producer-network-thread | producer-215] INFO TransactionManager - [Producer clientId=producer-215] ProducerId set to 258 with epoch 0
10:35:39.548 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.548 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.548 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.548 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139548
10:35:39.548 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-217
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.549 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-217] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.549 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-217] Instantiated an idempotent producer.
10:35:39.549 [kafka-producer-network-thread | producer-216] INFO Metadata - [Producer clientId=producer-216] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.550 [kafka-producer-network-thread | producer-216] INFO TransactionManager - [Producer clientId=producer-216] ProducerId set to 260 with epoch 0
10:35:39.551 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.551 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.551 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.551 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139551
10:35:39.551 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-218
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.552 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-218] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.552 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-218] Instantiated an idempotent producer.
10:35:39.552 [kafka-producer-network-thread | producer-217] INFO Metadata - [Producer clientId=producer-217] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.553 [kafka-producer-network-thread | producer-217] INFO TransactionManager - [Producer clientId=producer-217] ProducerId set to 1260 with epoch 0
10:35:39.553 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.554 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.554 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.554 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139553
10:35:39.554 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-219
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.554 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-219] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.554 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-219] Instantiated an idempotent producer.
10:35:39.555 [kafka-producer-network-thread | producer-218] INFO Metadata - [Producer clientId=producer-218] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.555 [kafka-producer-network-thread | producer-218] INFO TransactionManager - [Producer clientId=producer-218] ProducerId set to 261 with epoch 0
10:35:39.556 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.556 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.556 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.556 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139556
10:35:39.556 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-220
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.557 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-220] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.557 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-220] Instantiated an idempotent producer.
10:35:39.558 [kafka-producer-network-thread | producer-219] INFO Metadata - [Producer clientId=producer-219] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.558 [kafka-producer-network-thread | producer-219] INFO TransactionManager - [Producer clientId=producer-219] ProducerId set to 2272 with epoch 0
10:35:39.560 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.560 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.560 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.560 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139560
10:35:39.560 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-221
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.560 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-221] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.561 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-221] Instantiated an idempotent producer.
10:35:39.562 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.562 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.562 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.562 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139562
10:35:39.562 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-222
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.562 [kafka-producer-network-thread | producer-220] INFO Metadata - [Producer clientId=producer-220] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.562 [kafka-producer-network-thread | producer-220] INFO TransactionManager - [Producer clientId=producer-220] ProducerId set to 262 with epoch 0
10:35:39.563 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-222] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.563 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-222] Instantiated an idempotent producer.
10:35:39.564 [kafka-producer-network-thread | producer-221] INFO Metadata - [Producer clientId=producer-221] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.564 [kafka-producer-network-thread | producer-221] INFO TransactionManager - [Producer clientId=producer-221] ProducerId set to 2273 with epoch 0
10:35:39.564 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.565 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.565 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.565 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139565
10:35:39.565 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-223
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.565 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-223] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.565 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-223] Instantiated an idempotent producer.
10:35:39.566 [kafka-producer-network-thread | producer-222] INFO Metadata - [Producer clientId=producer-222] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.566 [kafka-producer-network-thread | producer-222] INFO TransactionManager - [Producer clientId=producer-222] ProducerId set to 1268 with epoch 0
10:35:39.567 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.567 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.567 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.567 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139567
10:35:39.567 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-224
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.567 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-224] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.568 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-224] Instantiated an idempotent producer.
10:35:39.568 [kafka-producer-network-thread | producer-223] INFO Metadata - [Producer clientId=producer-223] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.568 [kafka-producer-network-thread | producer-223] INFO TransactionManager - [Producer clientId=producer-223] ProducerId set to 2276 with epoch 0
10:35:39.569 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.569 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.569 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.569 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139569
10:35:39.569 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-225
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.570 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-225] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.570 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-225] Instantiated an idempotent producer.
10:35:39.571 [kafka-producer-network-thread | producer-224] INFO Metadata - [Producer clientId=producer-224] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.571 [kafka-producer-network-thread | producer-224] INFO TransactionManager - [Producer clientId=producer-224] ProducerId set to 2277 with epoch 0
10:35:39.571 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.571 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.571 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.571 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139571
10:35:39.571 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-226
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.572 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-226] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.572 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-226] Instantiated an idempotent producer.
10:35:39.573 [kafka-producer-network-thread | producer-225] INFO Metadata - [Producer clientId=producer-225] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.573 [kafka-producer-network-thread | producer-225] INFO TransactionManager - [Producer clientId=producer-225] ProducerId set to 1271 with epoch 0
10:35:39.573 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.573 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.573 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.573 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139573
10:35:39.573 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-227
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.574 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-227] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.574 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-227] Instantiated an idempotent producer.
10:35:39.575 [kafka-producer-network-thread | producer-226] INFO TransactionManager - [Producer clientId=producer-226] ProducerId set to 2279 with epoch 0
10:35:39.575 [kafka-producer-network-thread | producer-226] INFO Metadata - [Producer clientId=producer-226] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.575 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.575 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.575 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.575 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139575
10:35:39.576 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-228
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.576 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-228] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.576 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-228] Instantiated an idempotent producer.
10:35:39.577 [kafka-producer-network-thread | producer-227] INFO TransactionManager - [Producer clientId=producer-227] ProducerId set to 266 with epoch 0
10:35:39.577 [kafka-producer-network-thread | producer-227] INFO Metadata - [Producer clientId=producer-227] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.578 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.578 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.578 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.578 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139578
10:35:39.578 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-229
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.578 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-229] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.578 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-229] Instantiated an idempotent producer.
10:35:39.579 [kafka-producer-network-thread | producer-228] INFO Metadata - [Producer clientId=producer-228] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.579 [kafka-producer-network-thread | producer-228] INFO TransactionManager - [Producer clientId=producer-228] ProducerId set to 1274 with epoch 0
10:35:39.580 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.580 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.580 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.580 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139580
10:35:39.580 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-230
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.580 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-230] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.580 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-230] Instantiated an idempotent producer.
10:35:39.581 [kafka-producer-network-thread | producer-229] INFO Metadata - [Producer clientId=producer-229] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.581 [kafka-producer-network-thread | producer-229] INFO TransactionManager - [Producer clientId=producer-229] ProducerId set to 267 with epoch 0
10:35:39.582 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.582 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.582 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.582 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139582
10:35:39.582 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-231
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.582 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-231] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.583 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-231] Instantiated an idempotent producer.
10:35:39.583 [kafka-producer-network-thread | producer-230] INFO Metadata - [Producer clientId=producer-230] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.583 [kafka-producer-network-thread | producer-230] INFO TransactionManager - [Producer clientId=producer-230] ProducerId set to 268 with epoch 0
10:35:39.584 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.584 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.584 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.584 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139584
10:35:39.584 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-232
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.584 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-232] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.584 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-232] Instantiated an idempotent producer.
10:35:39.585 [kafka-producer-network-thread | producer-231] INFO Metadata - [Producer clientId=producer-231] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.585 [kafka-producer-network-thread | producer-231] INFO TransactionManager - [Producer clientId=producer-231] ProducerId set to 270 with epoch 0
10:35:39.586 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.586 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.586 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.586 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139586
10:35:39.586 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-233
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.587 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-233] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.587 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-233] Instantiated an idempotent producer.
10:35:39.587 [kafka-producer-network-thread | producer-232] INFO Metadata - [Producer clientId=producer-232] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.588 [kafka-producer-network-thread | producer-232] INFO TransactionManager - [Producer clientId=producer-232] ProducerId set to 1276 with epoch 0
10:35:39.588 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.588 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.588 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.588 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139588
10:35:39.588 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-234
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.589 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-234] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.589 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-234] Instantiated an idempotent producer.
10:35:39.589 [kafka-producer-network-thread | producer-233] INFO Metadata - [Producer clientId=producer-233] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.590 [kafka-producer-network-thread | producer-233] INFO TransactionManager - [Producer clientId=producer-233] ProducerId set to 272 with epoch 0
10:35:39.590 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.590 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.590 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.590 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139590
10:35:39.591 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-235
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.591 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-235] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.591 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-235] Instantiated an idempotent producer.
10:35:39.592 [kafka-producer-network-thread | producer-234] INFO Metadata - [Producer clientId=producer-234] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.592 [kafka-producer-network-thread | producer-234] INFO TransactionManager - [Producer clientId=producer-234] ProducerId set to 1278 with epoch 0
10:35:39.592 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.592 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.592 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.592 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139592
10:35:39.593 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-236
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.593 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-236] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.593 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-236] Instantiated an idempotent producer.
10:35:39.594 [kafka-producer-network-thread | producer-235] INFO Metadata - [Producer clientId=producer-235] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.594 [kafka-producer-network-thread | producer-235] INFO TransactionManager - [Producer clientId=producer-235] ProducerId set to 2286 with epoch 0
10:35:39.595 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.595 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.595 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.595 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139595
10:35:39.595 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-237
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.595 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-237] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.596 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-237] Instantiated an idempotent producer.
10:35:39.596 [kafka-producer-network-thread | producer-236] INFO Metadata - [Producer clientId=producer-236] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.596 [kafka-producer-network-thread | producer-236] INFO TransactionManager - [Producer clientId=producer-236] ProducerId set to 277 with epoch 0
10:35:39.597 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.597 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.597 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.597 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139597
10:35:39.598 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-238
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.598 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-238] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.598 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-238] Instantiated an idempotent producer.
10:35:39.599 [kafka-producer-network-thread | producer-237] INFO Metadata - [Producer clientId=producer-237] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.599 [kafka-producer-network-thread | producer-237] INFO TransactionManager - [Producer clientId=producer-237] ProducerId set to 279 with epoch 0
10:35:39.600 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.600 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.600 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.600 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139600
10:35:39.600 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-239
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.601 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-239] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.601 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-239] Instantiated an idempotent producer.
10:35:39.602 [kafka-producer-network-thread | producer-238] INFO Metadata - [Producer clientId=producer-238] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.602 [kafka-producer-network-thread | producer-238] INFO TransactionManager - [Producer clientId=producer-238] ProducerId set to 281 with epoch 0
10:35:39.602 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.602 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.602 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.602 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139602
10:35:39.603 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-240
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.603 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-240] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.603 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-240] Instantiated an idempotent producer.
10:35:39.605 [kafka-producer-network-thread | producer-239] INFO Metadata - [Producer clientId=producer-239] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.605 [kafka-producer-network-thread | producer-239] INFO TransactionManager - [Producer clientId=producer-239] ProducerId set to 282 with epoch 0
10:35:39.606 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.606 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.606 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.606 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139606
10:35:39.606 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-241
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.606 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-241] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.607 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-241] Instantiated an idempotent producer.
10:35:39.607 [kafka-producer-network-thread | producer-240] INFO Metadata - [Producer clientId=producer-240] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.608 [kafka-producer-network-thread | producer-240] INFO TransactionManager - [Producer clientId=producer-240] ProducerId set to 284 with epoch 0
10:35:39.608 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.608 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.608 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.608 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139608
10:35:39.609 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-242
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.609 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-242] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.609 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-242] Instantiated an idempotent producer.
10:35:39.611 [kafka-producer-network-thread | producer-241] INFO TransactionManager - [Producer clientId=producer-241] ProducerId set to 287 with epoch 0
10:35:39.611 [kafka-producer-network-thread | producer-241] INFO Metadata - [Producer clientId=producer-241] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.611 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.611 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.611 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.611 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139611
10:35:39.612 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-243
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.612 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-243] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.612 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-243] Instantiated an idempotent producer.
10:35:39.614 [kafka-producer-network-thread | producer-242] INFO Metadata - [Producer clientId=producer-242] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.614 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.615 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.615 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.615 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139615
10:35:39.615 [kafka-producer-network-thread | producer-242] INFO TransactionManager - [Producer clientId=producer-242] ProducerId set to 289 with epoch 0
10:35:39.615 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-244
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.615 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-244] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.616 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-244] Instantiated an idempotent producer.
10:35:39.616 [kafka-producer-network-thread | producer-243] INFO Metadata - [Producer clientId=producer-243] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.616 [kafka-producer-network-thread | producer-243] INFO TransactionManager - [Producer clientId=producer-243] ProducerId set to 290 with epoch 0
10:35:39.617 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.617 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.617 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.617 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139617
10:35:39.618 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-245
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.618 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-245] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.618 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-245] Instantiated an idempotent producer.
10:35:39.619 [kafka-producer-network-thread | producer-244] INFO Metadata - [Producer clientId=producer-244] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.619 [kafka-producer-network-thread | producer-244] INFO TransactionManager - [Producer clientId=producer-244] ProducerId set to 2292 with epoch 0
10:35:39.622 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.622 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.622 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.622 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139622
10:35:39.623 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-246
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.623 [kafka-producer-network-thread | producer-245] INFO Metadata - [Producer clientId=producer-245] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.623 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-246] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.623 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-246] Instantiated an idempotent producer.
10:35:39.623 [kafka-producer-network-thread | producer-245] INFO TransactionManager - [Producer clientId=producer-245] ProducerId set to 1289 with epoch 0
10:35:39.625 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.625 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.625 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.625 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139625
10:35:39.626 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-247
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.626 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-247] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.626 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-247] Instantiated an idempotent producer.
10:35:39.627 [kafka-producer-network-thread | producer-246] INFO Metadata - [Producer clientId=producer-246] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.627 [kafka-producer-network-thread | producer-246] INFO TransactionManager - [Producer clientId=producer-246] ProducerId set to 2296 with epoch 0
10:35:39.630 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.630 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.630 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.630 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139630
10:35:39.630 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-248
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.630 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-248] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.631 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-248] Instantiated an idempotent producer.
10:35:39.634 [kafka-producer-network-thread | producer-247] INFO Metadata - [Producer clientId=producer-247] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.634 [kafka-producer-network-thread | producer-247] INFO TransactionManager - [Producer clientId=producer-247] ProducerId set to 295 with epoch 0
10:35:39.635 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.635 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.635 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.635 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139635
10:35:39.635 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-249
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.636 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-249] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.636 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-249] Instantiated an idempotent producer.
10:35:39.636 [kafka-producer-network-thread | producer-248] INFO Metadata - [Producer clientId=producer-248] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.636 [kafka-producer-network-thread | producer-248] INFO TransactionManager - [Producer clientId=producer-248] ProducerId set to 2298 with epoch 0
10:35:39.638 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.638 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.638 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.638 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139638
10:35:39.638 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-250
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.639 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-250] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.639 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-250] Instantiated an idempotent producer.
10:35:39.639 [kafka-producer-network-thread | producer-249] INFO Metadata - [Producer clientId=producer-249] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.640 [kafka-producer-network-thread | producer-249] INFO TransactionManager - [Producer clientId=producer-249] ProducerId set to 298 with epoch 0
10:35:39.641 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.641 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.641 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.641 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139641
10:35:39.641 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-251
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.641 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-251] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.642 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-251] Instantiated an idempotent producer.
10:35:39.642 [kafka-producer-network-thread | producer-250] INFO Metadata - [Producer clientId=producer-250] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.642 [kafka-producer-network-thread | producer-250] INFO TransactionManager - [Producer clientId=producer-250] ProducerId set to 1293 with epoch 0
10:35:39.643 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.643 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.643 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.643 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139643
10:35:39.644 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-252
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.644 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-252] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.644 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-252] Instantiated an idempotent producer.
10:35:39.645 [kafka-producer-network-thread | producer-251] INFO Metadata - [Producer clientId=producer-251] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.645 [kafka-producer-network-thread | producer-251] INFO TransactionManager - [Producer clientId=producer-251] ProducerId set to 2301 with epoch 0
10:35:39.646 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.646 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.646 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.646 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139646
10:35:39.646 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-253
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.647 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-253] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.647 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-253] Instantiated an idempotent producer.
10:35:39.647 [kafka-producer-network-thread | producer-252] INFO Metadata - [Producer clientId=producer-252] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.647 [kafka-producer-network-thread | producer-252] INFO TransactionManager - [Producer clientId=producer-252] ProducerId set to 301 with epoch 0
10:35:39.649 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.649 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.649 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.649 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139649
10:35:39.649 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-254
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.649 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-254] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.649 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-254] Instantiated an idempotent producer.
10:35:39.650 [kafka-producer-network-thread | producer-253] INFO Metadata - [Producer clientId=producer-253] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.650 [kafka-producer-network-thread | producer-253] INFO TransactionManager - [Producer clientId=producer-253] ProducerId set to 1295 with epoch 0
10:35:39.651 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.651 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.651 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.651 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139651
10:35:39.652 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-255
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.652 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-255] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.652 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-255] Instantiated an idempotent producer.
10:35:39.652 [kafka-producer-network-thread | producer-254] INFO Metadata - [Producer clientId=producer-254] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.653 [kafka-producer-network-thread | producer-254] INFO TransactionManager - [Producer clientId=producer-254] ProducerId set to 1297 with epoch 0
10:35:39.654 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.654 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.654 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.654 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139654
10:35:39.654 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-256
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.655 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-256] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.655 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-256] Instantiated an idempotent producer.
10:35:39.655 [kafka-producer-network-thread | producer-255] INFO Metadata - [Producer clientId=producer-255] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.655 [kafka-producer-network-thread | producer-255] INFO TransactionManager - [Producer clientId=producer-255] ProducerId set to 1299 with epoch 0
10:35:39.657 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.657 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.657 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.657 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139657
10:35:39.657 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-257
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.657 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-257] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.658 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-257] Instantiated an idempotent producer.
10:35:39.658 [kafka-producer-network-thread | producer-256] INFO Metadata - [Producer clientId=producer-256] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.658 [kafka-producer-network-thread | producer-256] INFO TransactionManager - [Producer clientId=producer-256] ProducerId set to 1301 with epoch 0
10:35:39.659 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.659 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.659 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.659 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139659
10:35:39.659 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-258
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.659 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-258] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.660 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-258] Instantiated an idempotent producer.
10:35:39.660 [kafka-producer-network-thread | producer-257] INFO Metadata - [Producer clientId=producer-257] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.661 [kafka-producer-network-thread | producer-257] INFO TransactionManager - [Producer clientId=producer-257] ProducerId set to 304 with epoch 0
10:35:39.661 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.661 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.661 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.661 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139661
10:35:39.662 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-259
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.662 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-259] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.662 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-259] Instantiated an idempotent producer.
10:35:39.663 [kafka-producer-network-thread | producer-258] INFO Metadata - [Producer clientId=producer-258] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.663 [kafka-producer-network-thread | producer-258] INFO TransactionManager - [Producer clientId=producer-258] ProducerId set to 1304 with epoch 0
10:35:39.664 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.664 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.664 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.664 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139664
10:35:39.664 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-260
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.665 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-260] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.665 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-260] Instantiated an idempotent producer.
10:35:39.665 [kafka-producer-network-thread | producer-259] INFO Metadata - [Producer clientId=producer-259] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.666 [kafka-producer-network-thread | producer-259] INFO TransactionManager - [Producer clientId=producer-259] ProducerId set to 306 with epoch 0
10:35:39.666 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.667 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.667 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.667 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139667
10:35:39.667 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-261
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.667 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-261] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.668 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-261] Instantiated an idempotent producer.
10:35:39.668 [kafka-producer-network-thread | producer-260] INFO Metadata - [Producer clientId=producer-260] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.668 [kafka-producer-network-thread | producer-260] INFO TransactionManager - [Producer clientId=producer-260] ProducerId set to 1307 with epoch 0
10:35:39.669 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.669 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.669 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.669 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139669
10:35:39.670 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-262
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.670 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-262] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.670 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-262] Instantiated an idempotent producer.
10:35:39.671 [kafka-producer-network-thread | producer-261] INFO Metadata - [Producer clientId=producer-261] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.671 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.671 [kafka-producer-network-thread | producer-261] INFO TransactionManager - [Producer clientId=producer-261] ProducerId set to 2309 with epoch 0
10:35:39.671 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.671 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.671 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139671
10:35:39.671 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-263
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.672 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-263] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.672 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-263] Instantiated an idempotent producer.
10:35:39.672 [kafka-producer-network-thread | producer-262] INFO Metadata - [Producer clientId=producer-262] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.673 [kafka-producer-network-thread | producer-262] INFO TransactionManager - [Producer clientId=producer-262] ProducerId set to 307 with epoch 0
10:35:39.673 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.673 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.673 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.673 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139673
10:35:39.673 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-264
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.674 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-264] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.674 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-264] Instantiated an idempotent producer.
10:35:39.674 [kafka-producer-network-thread | producer-263] INFO Metadata - [Producer clientId=producer-263] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.675 [kafka-producer-network-thread | producer-263] INFO TransactionManager - [Producer clientId=producer-263] ProducerId set to 1312 with epoch 0
10:35:39.675 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.675 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.675 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.675 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139675
10:35:39.675 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-265
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.676 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-265] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.676 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-265] Instantiated an idempotent producer.
10:35:39.677 [kafka-producer-network-thread | producer-264] INFO Metadata - [Producer clientId=producer-264] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.677 [kafka-producer-network-thread | producer-264] INFO TransactionManager - [Producer clientId=producer-264] ProducerId set to 310 with epoch 0
10:35:39.677 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.677 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.677 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.677 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139677
10:35:39.677 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-266
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.678 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-266] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.678 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-266] Instantiated an idempotent producer.
10:35:39.678 [kafka-producer-network-thread | producer-265] INFO Metadata - [Producer clientId=producer-265] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.679 [kafka-producer-network-thread | producer-265] INFO TransactionManager - [Producer clientId=producer-265] ProducerId set to 1313 with epoch 0
10:35:39.679 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.679 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.679 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.679 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139679
10:35:39.680 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-267
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.680 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-267] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.680 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-267] Instantiated an idempotent producer.
10:35:39.681 [kafka-producer-network-thread | producer-266] INFO Metadata - [Producer clientId=producer-266] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.681 [kafka-producer-network-thread | producer-266] INFO TransactionManager - [Producer clientId=producer-266] ProducerId set to 312 with epoch 0
10:35:39.681 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.681 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.681 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.681 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139681
10:35:39.682 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-268
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.682 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-268] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.682 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-268] Instantiated an idempotent producer.
10:35:39.683 [kafka-producer-network-thread | producer-267] INFO Metadata - [Producer clientId=producer-267] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.683 [kafka-producer-network-thread | producer-267] INFO TransactionManager - [Producer clientId=producer-267] ProducerId set to 2311 with epoch 0
10:35:39.684 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.684 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.684 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.684 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139684
10:35:39.684 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-269
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.685 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-269] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.685 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-269] Instantiated an idempotent producer.
10:35:39.685 [kafka-producer-network-thread | producer-268] INFO Metadata - [Producer clientId=producer-268] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.685 [kafka-producer-network-thread | producer-268] INFO TransactionManager - [Producer clientId=producer-268] ProducerId set to 1315 with epoch 0
10:35:39.686 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.686 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.686 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.686 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139686
10:35:39.687 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-270
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.687 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-270] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.687 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-270] Instantiated an idempotent producer.
10:35:39.688 [kafka-producer-network-thread | producer-269] INFO Metadata - [Producer clientId=producer-269] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.688 [kafka-producer-network-thread | producer-269] INFO TransactionManager - [Producer clientId=producer-269] ProducerId set to 2312 with epoch 0
10:35:39.688 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.689 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.689 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.689 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139689
10:35:39.689 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-271
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.689 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-271] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.689 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-271] Instantiated an idempotent producer.
10:35:39.690 [kafka-producer-network-thread | producer-270] INFO Metadata - [Producer clientId=producer-270] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.690 [kafka-producer-network-thread | producer-270] INFO TransactionManager - [Producer clientId=producer-270] ProducerId set to 318 with epoch 0
10:35:39.691 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.692 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.692 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.692 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139692
10:35:39.692 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-272
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.692 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-272] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.692 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-272] Instantiated an idempotent producer.
10:35:39.693 [kafka-producer-network-thread | producer-271] INFO Metadata - [Producer clientId=producer-271] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.693 [kafka-producer-network-thread | producer-271] INFO TransactionManager - [Producer clientId=producer-271] ProducerId set to 1318 with epoch 0
10:35:39.694 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.694 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.694 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.694 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139694
10:35:39.694 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-273
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.694 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-273] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.694 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-273] Instantiated an idempotent producer.
10:35:39.696 [kafka-producer-network-thread | producer-272] INFO Metadata - [Producer clientId=producer-272] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.696 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.696 [kafka-producer-network-thread | producer-272] INFO TransactionManager - [Producer clientId=producer-272] ProducerId set to 320 with epoch 0
10:35:39.696 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.696 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.696 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139696
10:35:39.696 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-274
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.697 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-274] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.697 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-274] Instantiated an idempotent producer.
10:35:39.698 [kafka-producer-network-thread | producer-273] INFO Metadata - [Producer clientId=producer-273] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.698 [kafka-producer-network-thread | producer-273] INFO TransactionManager - [Producer clientId=producer-273] ProducerId set to 2316 with epoch 0
10:35:39.699 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.699 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.699 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.699 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139699
10:35:39.699 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-275
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.700 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-275] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.700 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-275] Instantiated an idempotent producer.
10:35:39.700 [kafka-producer-network-thread | producer-274] INFO Metadata - [Producer clientId=producer-274] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.700 [kafka-producer-network-thread | producer-274] INFO TransactionManager - [Producer clientId=producer-274] ProducerId set to 2317 with epoch 0
10:35:39.702 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.702 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.702 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.702 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139702
10:35:39.702 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-276
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.702 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-276] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.702 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-276] Instantiated an idempotent producer.
10:35:39.703 [kafka-producer-network-thread | producer-275] INFO Metadata - [Producer clientId=producer-275] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.703 [kafka-producer-network-thread | producer-275] INFO TransactionManager - [Producer clientId=producer-275] ProducerId set to 1322 with epoch 0
10:35:39.704 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.704 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.704 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.704 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139704
10:35:39.704 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-277
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.705 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-277] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.705 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-277] Instantiated an idempotent producer.
10:35:39.705 [kafka-producer-network-thread | producer-276] INFO Metadata - [Producer clientId=producer-276] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.705 [kafka-producer-network-thread | producer-276] INFO TransactionManager - [Producer clientId=producer-276] ProducerId set to 323 with epoch 0
10:35:39.707 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.707 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.707 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.707 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139707
10:35:39.707 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-278
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.707 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-278] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.707 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-278] Instantiated an idempotent producer.
10:35:39.708 [kafka-producer-network-thread | producer-277] INFO Metadata - [Producer clientId=producer-277] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.708 [kafka-producer-network-thread | producer-277] INFO TransactionManager - [Producer clientId=producer-277] ProducerId set to 325 with epoch 0
10:35:39.709 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.709 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.709 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.709 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139709
10:35:39.709 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-279
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.710 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-279] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.710 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-279] Instantiated an idempotent producer.
10:35:39.710 [kafka-producer-network-thread | producer-278] INFO Metadata - [Producer clientId=producer-278] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.711 [kafka-producer-network-thread | producer-278] INFO TransactionManager - [Producer clientId=producer-278] ProducerId set to 2319 with epoch 0
10:35:39.711 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.711 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.711 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.711 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139711
10:35:39.712 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-280
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.712 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-280] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.712 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-280] Instantiated an idempotent producer.
10:35:39.713 [kafka-producer-network-thread | producer-279] INFO Metadata - [Producer clientId=producer-279] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.713 [kafka-producer-network-thread | producer-279] INFO TransactionManager - [Producer clientId=producer-279] ProducerId set to 2321 with epoch 0
10:35:39.714 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.714 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.714 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.714 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139714
10:35:39.714 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-281
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.715 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-281] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.715 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-281] Instantiated an idempotent producer.
10:35:39.715 [kafka-producer-network-thread | producer-280] INFO Metadata - [Producer clientId=producer-280] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.715 [kafka-producer-network-thread | producer-280] INFO TransactionManager - [Producer clientId=producer-280] ProducerId set to 328 with epoch 0
10:35:39.716 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.716 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.716 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.716 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139716
10:35:39.717 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-282
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.717 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-282] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.717 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-282] Instantiated an idempotent producer.
10:35:39.718 [kafka-producer-network-thread | producer-281] INFO Metadata - [Producer clientId=producer-281] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.718 [kafka-producer-network-thread | producer-281] INFO TransactionManager - [Producer clientId=producer-281] ProducerId set to 1328 with epoch 0
10:35:39.719 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.719 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.719 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.719 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139719
10:35:39.719 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-283
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.720 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-283] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.720 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-283] Instantiated an idempotent producer.
10:35:39.721 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.721 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.721 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.721 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139721
10:35:39.722 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-284
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.722 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-284] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.722 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-284] Instantiated an idempotent producer.
10:35:39.723 [kafka-producer-network-thread | producer-283] INFO Metadata - [Producer clientId=producer-283] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.723 [kafka-producer-network-thread | producer-283] INFO TransactionManager - [Producer clientId=producer-283] ProducerId set to 329 with epoch 0
10:35:39.724 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.724 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.724 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.724 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139724
10:35:39.724 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-285
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.725 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-285] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.725 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-285] Instantiated an idempotent producer.
10:35:39.725 [kafka-producer-network-thread | producer-284] INFO Metadata - [Producer clientId=producer-284] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.725 [kafka-producer-network-thread | producer-284] INFO TransactionManager - [Producer clientId=producer-284] ProducerId set to 1332 with epoch 0
10:35:39.726 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.726 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.726 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.726 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139726
10:35:39.727 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-286
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.727 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-286] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.727 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-286] Instantiated an idempotent producer.
10:35:39.727 [kafka-producer-network-thread | producer-285] INFO Metadata - [Producer clientId=producer-285] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.728 [kafka-producer-network-thread | producer-285] INFO TransactionManager - [Producer clientId=producer-285] ProducerId set to 2328 with epoch 0
10:35:39.728 [kafka-producer-network-thread | producer-282] INFO Metadata - [Producer clientId=producer-282] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.728 [kafka-producer-network-thread | producer-282] INFO TransactionManager - [Producer clientId=producer-282] ProducerId set to 2329 with epoch 0
10:35:39.729 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.729 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.729 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.729 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139729
10:35:39.729 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-287
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.730 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-287] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.730 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-287] Instantiated an idempotent producer.
10:35:39.730 [kafka-producer-network-thread | producer-286] INFO Metadata - [Producer clientId=producer-286] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.730 [kafka-producer-network-thread | producer-286] INFO TransactionManager - [Producer clientId=producer-286] ProducerId set to 331 with epoch 0
10:35:39.734 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.734 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.734 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.734 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139734
10:35:39.735 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-288
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.735 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-288] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.735 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-288] Instantiated an idempotent producer.
10:35:39.736 [kafka-producer-network-thread | producer-287] INFO Metadata - [Producer clientId=producer-287] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.737 [kafka-producer-network-thread | producer-287] INFO TransactionManager - [Producer clientId=producer-287] ProducerId set to 1335 with epoch 0
10:35:39.737 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.737 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.737 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.737 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139737
10:35:39.737 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-289
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.738 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-289] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.738 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-289] Instantiated an idempotent producer.
10:35:39.739 [kafka-producer-network-thread | producer-288] INFO Metadata - [Producer clientId=producer-288] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.739 [kafka-producer-network-thread | producer-288] INFO TransactionManager - [Producer clientId=producer-288] ProducerId set to 1337 with epoch 0
10:35:39.740 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.740 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.740 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.740 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139740
10:35:39.740 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-290
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.740 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-290] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.741 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-290] Instantiated an idempotent producer.
10:35:39.741 [kafka-producer-network-thread | producer-289] INFO Metadata - [Producer clientId=producer-289] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.741 [kafka-producer-network-thread | producer-289] INFO TransactionManager - [Producer clientId=producer-289] ProducerId set to 2335 with epoch 0
10:35:39.742 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.742 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.742 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.742 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139742
10:35:39.743 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-291
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.743 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-291] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.743 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-291] Instantiated an idempotent producer.
10:35:39.743 [kafka-producer-network-thread | producer-290] INFO Metadata - [Producer clientId=producer-290] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.744 [kafka-producer-network-thread | producer-290] INFO TransactionManager - [Producer clientId=producer-290] ProducerId set to 334 with epoch 0
10:35:39.745 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.745 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.745 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.745 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139745
10:35:39.745 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-292
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.746 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-292] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.746 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-292] Instantiated an idempotent producer.
10:35:39.746 [kafka-producer-network-thread | producer-291] INFO Metadata - [Producer clientId=producer-291] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.746 [kafka-producer-network-thread | producer-291] INFO TransactionManager - [Producer clientId=producer-291] ProducerId set to 2337 with epoch 0
10:35:39.747 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.747 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.747 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.747 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139747
10:35:39.748 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-293
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.748 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-293] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.748 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-293] Instantiated an idempotent producer.
10:35:39.749 [kafka-producer-network-thread | producer-292] INFO Metadata - [Producer clientId=producer-292] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.749 [kafka-producer-network-thread | producer-292] INFO TransactionManager - [Producer clientId=producer-292] ProducerId set to 336 with epoch 0
10:35:39.750 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.750 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.750 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.750 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139750
10:35:39.750 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-294
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.751 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-294] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.751 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-294] Instantiated an idempotent producer.
10:35:39.751 [kafka-producer-network-thread | producer-293] INFO Metadata - [Producer clientId=producer-293] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.751 [kafka-producer-network-thread | producer-293] INFO TransactionManager - [Producer clientId=producer-293] ProducerId set to 1341 with epoch 0
10:35:39.752 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.752 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.752 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.752 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139752
10:35:39.753 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-295
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.753 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-295] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.753 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-295] Instantiated an idempotent producer.
10:35:39.754 [kafka-producer-network-thread | producer-294] INFO Metadata - [Producer clientId=producer-294] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.754 [kafka-producer-network-thread | producer-294] INFO TransactionManager - [Producer clientId=producer-294] ProducerId set to 337 with epoch 0
10:35:39.755 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.755 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.755 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.755 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139755
10:35:39.755 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-296
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.756 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-296] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.756 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-296] Instantiated an idempotent producer.
10:35:39.756 [kafka-producer-network-thread | producer-295] INFO Metadata - [Producer clientId=producer-295] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.756 [kafka-producer-network-thread | producer-295] INFO TransactionManager - [Producer clientId=producer-295] ProducerId set to 2342 with epoch 0
10:35:39.757 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.757 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.757 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.757 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139757
10:35:39.758 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-297
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.758 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-297] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.758 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-297] Instantiated an idempotent producer.
10:35:39.758 [kafka-producer-network-thread | producer-296] INFO Metadata - [Producer clientId=producer-296] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.759 [kafka-producer-network-thread | producer-296] INFO TransactionManager - [Producer clientId=producer-296] ProducerId set to 339 with epoch 0
10:35:39.760 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.760 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.760 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.760 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139760
10:35:39.760 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-298
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.760 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-298] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.760 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-298] Instantiated an idempotent producer.
10:35:39.761 [kafka-producer-network-thread | producer-297] INFO Metadata - [Producer clientId=producer-297] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.761 [kafka-producer-network-thread | producer-297] INFO TransactionManager - [Producer clientId=producer-297] ProducerId set to 1344 with epoch 0
10:35:39.762 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.762 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.762 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.762 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139762
10:35:39.762 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-299
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.763 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-299] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.763 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-299] Instantiated an idempotent producer.
10:35:39.764 [kafka-producer-network-thread | producer-298] INFO Metadata - [Producer clientId=producer-298] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.764 [kafka-producer-network-thread | producer-298] INFO TransactionManager - [Producer clientId=producer-298] ProducerId set to 1345 with epoch 0
10:35:39.765 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.765 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.765 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.765 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139765
10:35:39.765 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-300
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.765 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-300] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.766 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-300] Instantiated an idempotent producer.
10:35:39.766 [kafka-producer-network-thread | producer-299] INFO Metadata - [Producer clientId=producer-299] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.766 [kafka-producer-network-thread | producer-299] INFO TransactionManager - [Producer clientId=producer-299] ProducerId set to 1347 with epoch 0
10:35:39.767 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.767 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.767 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.767 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139767
10:35:39.768 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-301
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.768 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-301] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.768 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-301] Instantiated an idempotent producer.
10:35:39.769 [kafka-producer-network-thread | producer-300] INFO Metadata - [Producer clientId=producer-300] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.769 [kafka-producer-network-thread | producer-300] INFO TransactionManager - [Producer clientId=producer-300] ProducerId set to 2347 with epoch 0
10:35:39.769 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.769 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.769 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.769 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139769
10:35:39.769 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-302
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.770 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-302] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.770 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-302] Instantiated an idempotent producer.
10:35:39.770 [kafka-producer-network-thread | producer-301] INFO Metadata - [Producer clientId=producer-301] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.771 [kafka-producer-network-thread | producer-301] INFO TransactionManager - [Producer clientId=producer-301] ProducerId set to 1349 with epoch 0
10:35:39.771 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.771 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.771 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.771 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139771
10:35:39.771 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-303
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.772 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-303] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.772 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-303] Instantiated an idempotent producer.
10:35:39.772 [kafka-producer-network-thread | producer-302] INFO Metadata - [Producer clientId=producer-302] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.773 [kafka-producer-network-thread | producer-302] INFO TransactionManager - [Producer clientId=producer-302] ProducerId set to 343 with epoch 0
10:35:39.773 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.773 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.773 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.773 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139773
10:35:39.774 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-304
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.774 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-304] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.774 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-304] Instantiated an idempotent producer.
10:35:39.775 [kafka-producer-network-thread | producer-303] INFO Metadata - [Producer clientId=producer-303] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.775 [kafka-producer-network-thread | producer-303] INFO TransactionManager - [Producer clientId=producer-303] ProducerId set to 2352 with epoch 0
10:35:39.775 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.775 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.775 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.775 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139775
10:35:39.776 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-305
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.776 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-305] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.776 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-305] Instantiated an idempotent producer.
10:35:39.777 [kafka-producer-network-thread | producer-304] INFO Metadata - [Producer clientId=producer-304] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.777 [kafka-producer-network-thread | producer-304] INFO TransactionManager - [Producer clientId=producer-304] ProducerId set to 2354 with epoch 0
10:35:39.777 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.778 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.778 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.778 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139777
10:35:39.778 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-306
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.778 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-306] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.778 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-306] Instantiated an idempotent producer.
10:35:39.779 [kafka-producer-network-thread | producer-305] INFO Metadata - [Producer clientId=producer-305] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.779 [kafka-producer-network-thread | producer-305] INFO TransactionManager - [Producer clientId=producer-305] ProducerId set to 2356 with epoch 0
10:35:39.780 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.780 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.780 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.780 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139780
10:35:39.780 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-307
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.780 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-307] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.780 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-307] Instantiated an idempotent producer.
10:35:39.781 [kafka-producer-network-thread | producer-306] INFO Metadata - [Producer clientId=producer-306] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.781 [kafka-producer-network-thread | producer-306] INFO TransactionManager - [Producer clientId=producer-306] ProducerId set to 1354 with epoch 0
10:35:39.781 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.782 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.782 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.782 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139781
10:35:39.782 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-308
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.782 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-308] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.782 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-308] Instantiated an idempotent producer.
10:35:39.784 [kafka-producer-network-thread | producer-307] INFO Metadata - [Producer clientId=producer-307] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.784 [kafka-producer-network-thread | producer-307] INFO TransactionManager - [Producer clientId=producer-307] ProducerId set to 2357 with epoch 0
10:35:39.785 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.785 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.785 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.785 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139785
10:35:39.785 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-309
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.785 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-309] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.785 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-309] Instantiated an idempotent producer.
10:35:39.786 [kafka-producer-network-thread | producer-308] INFO Metadata - [Producer clientId=producer-308] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.787 [kafka-producer-network-thread | producer-308] INFO TransactionManager - [Producer clientId=producer-308] ProducerId set to 1357 with epoch 0
10:35:39.787 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.787 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.787 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.787 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139787
10:35:39.787 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-310
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.787 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-310] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.787 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-310] Instantiated an idempotent producer.
10:35:39.788 [kafka-producer-network-thread | producer-309] INFO Metadata - [Producer clientId=producer-309] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.788 [kafka-producer-network-thread | producer-309] INFO TransactionManager - [Producer clientId=producer-309] ProducerId set to 1358 with epoch 0
10:35:39.789 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.789 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.789 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.789 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139789
10:35:39.789 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-311
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.789 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-311] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.789 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-311] Instantiated an idempotent producer.
10:35:39.790 [kafka-producer-network-thread | producer-310] INFO Metadata - [Producer clientId=producer-310] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.790 [kafka-producer-network-thread | producer-310] INFO TransactionManager - [Producer clientId=producer-310] ProducerId set to 2361 with epoch 0
10:35:39.791 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.791 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.791 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.791 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139791
10:35:39.791 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-312
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.792 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-312] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.792 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-312] Instantiated an idempotent producer.
10:35:39.792 [kafka-producer-network-thread | producer-311] INFO Metadata - [Producer clientId=producer-311] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.792 [kafka-producer-network-thread | producer-311] INFO TransactionManager - [Producer clientId=producer-311] ProducerId set to 2362 with epoch 0
10:35:39.793 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.793 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.793 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.793 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139793
10:35:39.793 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-313
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.793 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-313] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.794 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-313] Instantiated an idempotent producer.
10:35:39.795 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.795 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.795 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.795 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139795
10:35:39.795 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-314
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.795 [kafka-producer-network-thread | producer-312] INFO Metadata - [Producer clientId=producer-312] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.795 [kafka-producer-network-thread | producer-312] INFO TransactionManager - [Producer clientId=producer-312] ProducerId set to 347 with epoch 0
10:35:39.796 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-314] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.796 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-314] Instantiated an idempotent producer.
10:35:39.796 [kafka-producer-network-thread | producer-313] INFO Metadata - [Producer clientId=producer-313] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.796 [kafka-producer-network-thread | producer-313] INFO TransactionManager - [Producer clientId=producer-313] ProducerId set to 348 with epoch 0
10:35:39.797 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.797 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.797 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.797 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139797
10:35:39.797 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-315
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.798 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-315] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.798 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-315] Instantiated an idempotent producer.
10:35:39.798 [kafka-producer-network-thread | producer-314] INFO Metadata - [Producer clientId=producer-314] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.799 [kafka-producer-network-thread | producer-314] INFO TransactionManager - [Producer clientId=producer-314] ProducerId set to 350 with epoch 0
10:35:39.799 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.799 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.799 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.799 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139799
10:35:39.800 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-316
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.800 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-316] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.800 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-316] Instantiated an idempotent producer.
10:35:39.801 [kafka-producer-network-thread | producer-315] INFO Metadata - [Producer clientId=producer-315] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.801 [kafka-producer-network-thread | producer-315] INFO TransactionManager - [Producer clientId=producer-315] ProducerId set to 352 with epoch 0
10:35:39.802 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.802 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.802 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.802 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139802
10:35:39.802 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-317
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.802 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-317] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.802 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-317] Instantiated an idempotent producer.
10:35:39.803 [kafka-producer-network-thread | producer-316] INFO Metadata - [Producer clientId=producer-316] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.803 [kafka-producer-network-thread | producer-316] INFO TransactionManager - [Producer clientId=producer-316] ProducerId set to 1364 with epoch 0
10:35:39.803 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.803 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.803 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.804 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139803
10:35:39.804 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-318
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.804 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-318] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.804 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-318] Instantiated an idempotent producer.
10:35:39.805 [kafka-producer-network-thread | producer-317] INFO Metadata - [Producer clientId=producer-317] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.805 [kafka-producer-network-thread | producer-317] INFO TransactionManager - [Producer clientId=producer-317] ProducerId set to 1367 with epoch 0
10:35:39.806 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.806 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.806 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.806 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139806
10:35:39.806 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-319
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.806 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-319] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.806 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-319] Instantiated an idempotent producer.
10:35:39.807 [kafka-producer-network-thread | producer-318] INFO Metadata - [Producer clientId=producer-318] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.807 [kafka-producer-network-thread | producer-318] INFO TransactionManager - [Producer clientId=producer-318] ProducerId set to 354 with epoch 0
10:35:39.808 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.808 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.808 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.808 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139808
10:35:39.808 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-320
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.808 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-320] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.809 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-320] Instantiated an idempotent producer.
10:35:39.809 [kafka-producer-network-thread | producer-319] INFO Metadata - [Producer clientId=producer-319] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.809 [kafka-producer-network-thread | producer-319] INFO TransactionManager - [Producer clientId=producer-319] ProducerId set to 355 with epoch 0
10:35:39.810 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.810 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.810 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.810 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139810
10:35:39.810 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-321
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.811 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-321] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.811 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-321] Instantiated an idempotent producer.
10:35:39.812 [kafka-producer-network-thread | producer-320] INFO Metadata - [Producer clientId=producer-320] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.812 [kafka-producer-network-thread | producer-320] INFO TransactionManager - [Producer clientId=producer-320] ProducerId set to 357 with epoch 0
10:35:39.812 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.812 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.812 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.812 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139812
10:35:39.812 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-322
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.813 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-322] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.813 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-322] Instantiated an idempotent producer.
10:35:39.813 [kafka-producer-network-thread | producer-321] INFO Metadata - [Producer clientId=producer-321] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.814 [kafka-producer-network-thread | producer-321] INFO TransactionManager - [Producer clientId=producer-321] ProducerId set to 1369 with epoch 0
10:35:39.814 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.814 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.814 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.814 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139814
10:35:39.814 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-323
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.815 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-323] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.815 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-323] Instantiated an idempotent producer.
10:35:39.815 [kafka-producer-network-thread | producer-322] INFO Metadata - [Producer clientId=producer-322] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.815 [kafka-producer-network-thread | producer-322] INFO TransactionManager - [Producer clientId=producer-322] ProducerId set to 1371 with epoch 0
10:35:39.816 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.816 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.816 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.816 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139816
10:35:39.816 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-324
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.816 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-324] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.817 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-324] Instantiated an idempotent producer.
10:35:39.817 [kafka-producer-network-thread | producer-323] INFO TransactionManager - [Producer clientId=producer-323] ProducerId set to 1372 with epoch 0
10:35:39.817 [kafka-producer-network-thread | producer-323] INFO Metadata - [Producer clientId=producer-323] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.818 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.818 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.818 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.818 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139818
10:35:39.818 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-325
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.818 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-325] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.818 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-325] Instantiated an idempotent producer.
10:35:39.819 [kafka-producer-network-thread | producer-324] INFO Metadata - [Producer clientId=producer-324] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.819 [kafka-producer-network-thread | producer-324] INFO TransactionManager - [Producer clientId=producer-324] ProducerId set to 360 with epoch 0
10:35:39.819 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.820 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.820 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.820 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139820
10:35:39.820 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-326
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.820 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-326] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.820 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-326] Instantiated an idempotent producer.
10:35:39.821 [kafka-producer-network-thread | producer-325] INFO Metadata - [Producer clientId=producer-325] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.821 [kafka-producer-network-thread | producer-325] INFO TransactionManager - [Producer clientId=producer-325] ProducerId set to 1377 with epoch 0
10:35:39.821 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.821 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.821 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.821 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139821
10:35:39.822 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-327
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.822 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-327] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.822 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-327] Instantiated an idempotent producer.
10:35:39.823 [kafka-producer-network-thread | producer-326] INFO Metadata - [Producer clientId=producer-326] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.823 [kafka-producer-network-thread | producer-326] INFO TransactionManager - [Producer clientId=producer-326] ProducerId set to 361 with epoch 0
10:35:39.823 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.823 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.823 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.823 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139823
10:35:39.824 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-328
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.824 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-328] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.824 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-328] Instantiated an idempotent producer.
10:35:39.825 [kafka-producer-network-thread | producer-327] INFO Metadata - [Producer clientId=producer-327] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.825 [kafka-producer-network-thread | producer-327] INFO TransactionManager - [Producer clientId=producer-327] ProducerId set to 1379 with epoch 0
10:35:39.825 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.825 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.825 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.825 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139825
10:35:39.826 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-329
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.826 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-329] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.826 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-329] Instantiated an idempotent producer.
10:35:39.827 [kafka-producer-network-thread | producer-328] INFO Metadata - [Producer clientId=producer-328] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.827 [kafka-producer-network-thread | producer-328] INFO TransactionManager - [Producer clientId=producer-328] ProducerId set to 1380 with epoch 0
10:35:39.828 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.828 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.828 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.828 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139828
10:35:39.828 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-330
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.828 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-330] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.829 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-330] Instantiated an idempotent producer.
10:35:39.829 [kafka-producer-network-thread | producer-329] INFO Metadata - [Producer clientId=producer-329] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.829 [kafka-producer-network-thread | producer-329] INFO TransactionManager - [Producer clientId=producer-329] ProducerId set to 364 with epoch 0
10:35:39.830 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.830 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.830 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.830 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139830
10:35:39.830 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-331
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.831 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-331] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.831 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-331] Instantiated an idempotent producer.
10:35:39.831 [kafka-producer-network-thread | producer-330] INFO Metadata - [Producer clientId=producer-330] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.832 [kafka-producer-network-thread | producer-330] INFO TransactionManager - [Producer clientId=producer-330] ProducerId set to 2371 with epoch 0
10:35:39.832 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.832 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.832 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.832 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139832
10:35:39.833 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-332
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.833 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-332] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.833 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-332] Instantiated an idempotent producer.
10:35:39.834 [kafka-producer-network-thread | producer-331] INFO Metadata - [Producer clientId=producer-331] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.834 [kafka-producer-network-thread | producer-331] INFO TransactionManager - [Producer clientId=producer-331] ProducerId set to 1386 with epoch 0
10:35:39.835 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.835 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.835 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.835 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139835
10:35:39.835 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-333
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.835 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-333] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.835 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-333] Instantiated an idempotent producer.
10:35:39.836 [kafka-producer-network-thread | producer-332] INFO TransactionManager - [Producer clientId=producer-332] ProducerId set to 2372 with epoch 0
10:35:39.836 [kafka-producer-network-thread | producer-332] INFO Metadata - [Producer clientId=producer-332] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.837 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.837 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.837 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.837 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139837
10:35:39.837 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-334
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.838 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-334] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.838 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-334] Instantiated an idempotent producer.
10:35:39.838 [kafka-producer-network-thread | producer-333] INFO Metadata - [Producer clientId=producer-333] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.838 [kafka-producer-network-thread | producer-333] INFO TransactionManager - [Producer clientId=producer-333] ProducerId set to 2374 with epoch 0
10:35:39.839 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.839 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.839 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.839 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139839
10:35:39.839 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-335
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.840 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-335] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.840 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-335] Instantiated an idempotent producer.
10:35:39.841 [kafka-producer-network-thread | producer-334] INFO Metadata - [Producer clientId=producer-334] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.841 [kafka-producer-network-thread | producer-334] INFO TransactionManager - [Producer clientId=producer-334] ProducerId set to 2375 with epoch 0
10:35:39.841 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.841 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.841 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.841 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139841
10:35:39.842 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-336
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.842 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-336] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.842 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-336] Instantiated an idempotent producer.
10:35:39.843 [kafka-producer-network-thread | producer-335] INFO Metadata - [Producer clientId=producer-335] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.843 [kafka-producer-network-thread | producer-335] INFO TransactionManager - [Producer clientId=producer-335] ProducerId set to 2376 with epoch 0
10:35:39.846 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.846 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.846 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.846 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139846
10:35:39.846 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-337
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.846 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-337] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.846 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-337] Instantiated an idempotent producer.
10:35:39.847 [kafka-producer-network-thread | producer-336] INFO Metadata - [Producer clientId=producer-336] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.847 [kafka-producer-network-thread | producer-336] INFO TransactionManager - [Producer clientId=producer-336] ProducerId set to 1391 with epoch 0
10:35:39.848 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.848 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.848 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.848 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139848
10:35:39.848 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-338
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.849 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-338] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.849 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-338] Instantiated an idempotent producer.
10:35:39.849 [kafka-producer-network-thread | producer-337] INFO Metadata - [Producer clientId=producer-337] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.850 [kafka-producer-network-thread | producer-337] INFO TransactionManager - [Producer clientId=producer-337] ProducerId set to 373 with epoch 0
10:35:39.852 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.852 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.852 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.852 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139852
10:35:39.852 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-339
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.853 [kafka-producer-network-thread | producer-338] INFO Metadata - [Producer clientId=producer-338] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.853 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-339] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.853 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-339] Instantiated an idempotent producer.
10:35:39.853 [kafka-producer-network-thread | producer-338] INFO TransactionManager - [Producer clientId=producer-338] ProducerId set to 2377 with epoch 0
10:35:39.855 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.855 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.855 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.855 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139855
10:35:39.855 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-340
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.856 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-340] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.856 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-340] Instantiated an idempotent producer.
10:35:39.857 [kafka-producer-network-thread | producer-339] INFO Metadata - [Producer clientId=producer-339] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.857 [kafka-producer-network-thread | producer-339] INFO TransactionManager - [Producer clientId=producer-339] ProducerId set to 2379 with epoch 0
10:35:39.857 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.858 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.858 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.858 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139857
10:35:39.858 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-341
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.858 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-341] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.859 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-341] Instantiated an idempotent producer.
10:35:39.859 [kafka-producer-network-thread | producer-340] INFO Metadata - [Producer clientId=producer-340] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.860 [kafka-producer-network-thread | producer-340] INFO TransactionManager - [Producer clientId=producer-340] ProducerId set to 1394 with epoch 0
10:35:39.860 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.860 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.860 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.860 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139860
10:35:39.861 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-342
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.861 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-342] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.861 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-342] Instantiated an idempotent producer.
10:35:39.862 [kafka-producer-network-thread | producer-341] INFO Metadata - [Producer clientId=producer-341] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.862 [kafka-producer-network-thread | producer-341] INFO TransactionManager - [Producer clientId=producer-341] ProducerId set to 379 with epoch 0
10:35:39.864 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.864 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.864 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.864 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139864
10:35:39.864 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-343
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.864 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-343] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.864 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-343] Instantiated an idempotent producer.
10:35:39.866 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.866 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.866 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.866 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139866
10:35:39.866 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-344
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.867 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-344] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.867 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-344] Instantiated an idempotent producer.
10:35:39.867 [kafka-producer-network-thread | producer-342] INFO Metadata - [Producer clientId=producer-342] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.867 [kafka-producer-network-thread | producer-342] INFO TransactionManager - [Producer clientId=producer-342] ProducerId set to 2383 with epoch 0
10:35:39.868 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.868 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.868 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.868 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139868
10:35:39.869 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-345
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.869 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-345] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.869 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-345] Instantiated an idempotent producer.
10:35:39.870 [kafka-producer-network-thread | producer-343] INFO Metadata - [Producer clientId=producer-343] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.870 [kafka-producer-network-thread | producer-343] INFO TransactionManager - [Producer clientId=producer-343] ProducerId set to 381 with epoch 0
10:35:39.871 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.871 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.871 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.871 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139871
10:35:39.871 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-346
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.872 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-346] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.872 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-346] Instantiated an idempotent producer.
10:35:39.872 [kafka-producer-network-thread | producer-344] INFO Metadata - [Producer clientId=producer-344] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.872 [kafka-producer-network-thread | producer-344] INFO TransactionManager - [Producer clientId=producer-344] ProducerId set to 2384 with epoch 0
10:35:39.873 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.873 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.873 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.873 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139873
10:35:39.874 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-347
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.874 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-347] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.874 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-347] Instantiated an idempotent producer.
10:35:39.875 [kafka-producer-network-thread | producer-345] INFO Metadata - [Producer clientId=producer-345] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.875 [kafka-producer-network-thread | producer-345] INFO TransactionManager - [Producer clientId=producer-345] ProducerId set to 384 with epoch 0
10:35:39.876 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.876 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.876 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.876 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139876
10:35:39.876 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-348
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.877 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-348] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.877 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-348] Instantiated an idempotent producer.
10:35:39.877 [kafka-producer-network-thread | producer-346] INFO Metadata - [Producer clientId=producer-346] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.877 [kafka-producer-network-thread | producer-346] INFO TransactionManager - [Producer clientId=producer-346] ProducerId set to 1401 with epoch 0
10:35:39.878 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.878 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.878 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.878 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139878
10:35:39.879 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-349
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.879 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-349] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.879 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-349] Instantiated an idempotent producer.
10:35:39.880 [kafka-producer-network-thread | producer-348] INFO Metadata - [Producer clientId=producer-348] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.881 [kafka-producer-network-thread | producer-348] INFO TransactionManager - [Producer clientId=producer-348] ProducerId set to 1402 with epoch 0
10:35:39.881 [kafka-producer-network-thread | producer-347] INFO Metadata - [Producer clientId=producer-347] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.881 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.881 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.881 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.881 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139881
10:35:39.881 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-350
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.882 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-350] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.882 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-350] Instantiated an idempotent producer.
10:35:39.883 [kafka-producer-network-thread | producer-347] INFO TransactionManager - [Producer clientId=producer-347] ProducerId set to 1403 with epoch 0
10:35:39.883 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.883 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.883 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.883 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139883
10:35:39.884 [kafka-producer-network-thread | producer-349] INFO Metadata - [Producer clientId=producer-349] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.884 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-351
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.884 [kafka-producer-network-thread | producer-349] INFO TransactionManager - [Producer clientId=producer-349] ProducerId set to 390 with epoch 0
10:35:39.884 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-351] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.884 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-351] Instantiated an idempotent producer.
10:35:39.885 [kafka-producer-network-thread | producer-350] INFO Metadata - [Producer clientId=producer-350] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.885 [kafka-producer-network-thread | producer-350] INFO TransactionManager - [Producer clientId=producer-350] ProducerId set to 391 with epoch 0
10:35:39.890 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.890 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.891 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.891 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139890
10:35:39.891 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-352
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.891 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-352] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.891 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-352] Instantiated an idempotent producer.
10:35:39.892 [kafka-producer-network-thread | producer-351] INFO Metadata - [Producer clientId=producer-351] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.892 [kafka-producer-network-thread | producer-351] INFO TransactionManager - [Producer clientId=producer-351] ProducerId set to 1406 with epoch 0
10:35:39.893 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.893 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.893 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.893 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139893
10:35:39.893 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-353
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.894 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-353] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.894 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-353] Instantiated an idempotent producer.
10:35:39.894 [kafka-producer-network-thread | producer-352] INFO Metadata - [Producer clientId=producer-352] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.895 [kafka-producer-network-thread | producer-352] INFO TransactionManager - [Producer clientId=producer-352] ProducerId set to 2389 with epoch 0
10:35:39.895 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.896 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.896 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.896 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139896
10:35:39.896 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-354
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.896 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-354] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.896 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-354] Instantiated an idempotent producer.
10:35:39.898 [kafka-producer-network-thread | producer-353] INFO Metadata - [Producer clientId=producer-353] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.898 [kafka-producer-network-thread | producer-353] INFO TransactionManager - [Producer clientId=producer-353] ProducerId set to 1409 with epoch 0
10:35:39.899 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.899 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.899 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.899 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139899
10:35:39.899 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-355
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.899 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-355] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.899 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-355] Instantiated an idempotent producer.
10:35:39.900 [kafka-producer-network-thread | producer-354] INFO Metadata - [Producer clientId=producer-354] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.900 [kafka-producer-network-thread | producer-354] INFO TransactionManager - [Producer clientId=producer-354] ProducerId set to 2390 with epoch 0
10:35:39.901 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.901 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.901 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.901 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139901
10:35:39.901 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-356
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.902 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-356] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.902 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-356] Instantiated an idempotent producer.
10:35:39.903 [kafka-producer-network-thread | producer-355] INFO Metadata - [Producer clientId=producer-355] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.903 [kafka-producer-network-thread | producer-355] INFO TransactionManager - [Producer clientId=producer-355] ProducerId set to 2392 with epoch 0
10:35:39.904 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.904 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.904 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.904 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139904
10:35:39.904 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-357
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.905 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-357] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.905 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-357] Instantiated an idempotent producer.
10:35:39.906 [kafka-producer-network-thread | producer-356] INFO Metadata - [Producer clientId=producer-356] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.906 [kafka-producer-network-thread | producer-356] INFO TransactionManager - [Producer clientId=producer-356] ProducerId set to 2394 with epoch 0
10:35:39.909 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.909 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.909 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.909 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139909
10:35:39.909 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-358
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.909 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-358] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.909 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-358] Instantiated an idempotent producer.
10:35:39.910 [kafka-producer-network-thread | producer-357] INFO Metadata - [Producer clientId=producer-357] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.910 [kafka-producer-network-thread | producer-357] INFO TransactionManager - [Producer clientId=producer-357] ProducerId set to 2398 with epoch 0
10:35:39.911 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.911 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.911 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.911 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139911
10:35:39.912 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-359
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.912 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-359] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.912 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-359] Instantiated an idempotent producer.
10:35:39.913 [kafka-producer-network-thread | producer-358] INFO Metadata - [Producer clientId=producer-358] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.913 [kafka-producer-network-thread | producer-358] INFO TransactionManager - [Producer clientId=producer-358] ProducerId set to 1414 with epoch 0
10:35:39.914 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.914 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.914 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.914 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139914
10:35:39.914 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-360
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.915 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-360] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.915 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-360] Instantiated an idempotent producer.
10:35:39.915 [kafka-producer-network-thread | producer-359] INFO Metadata - [Producer clientId=producer-359] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.916 [kafka-producer-network-thread | producer-359] INFO TransactionManager - [Producer clientId=producer-359] ProducerId set to 2400 with epoch 0
10:35:39.916 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.916 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.917 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.917 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139916
10:35:39.917 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-361
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.917 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-361] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.917 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-361] Instantiated an idempotent producer.
10:35:39.918 [kafka-producer-network-thread | producer-360] INFO Metadata - [Producer clientId=producer-360] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.918 [kafka-producer-network-thread | producer-360] INFO TransactionManager - [Producer clientId=producer-360] ProducerId set to 401 with epoch 0
10:35:39.919 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.919 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.919 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.919 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139919
10:35:39.919 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-362
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.920 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-362] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.920 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-362] Instantiated an idempotent producer.
10:35:39.920 [kafka-producer-network-thread | producer-361] INFO Metadata - [Producer clientId=producer-361] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.920 [kafka-producer-network-thread | producer-361] INFO TransactionManager - [Producer clientId=producer-361] ProducerId set to 1419 with epoch 0
10:35:39.922 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.922 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.922 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.922 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139922
10:35:39.922 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-363
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.922 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-363] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.923 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-363] Instantiated an idempotent producer.
10:35:39.923 [kafka-producer-network-thread | producer-362] INFO Metadata - [Producer clientId=producer-362] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.923 [kafka-producer-network-thread | producer-362] INFO TransactionManager - [Producer clientId=producer-362] ProducerId set to 2403 with epoch 0
10:35:39.924 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.924 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.924 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.924 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139924
10:35:39.925 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-364
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.925 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-364] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.925 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-364] Instantiated an idempotent producer.
10:35:39.926 [kafka-producer-network-thread | producer-363] INFO Metadata - [Producer clientId=producer-363] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.926 [kafka-producer-network-thread | producer-363] INFO TransactionManager - [Producer clientId=producer-363] ProducerId set to 1421 with epoch 0
10:35:39.926 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.927 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.927 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.927 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139927
10:35:39.927 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-365
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.927 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-365] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.927 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-365] Instantiated an idempotent producer.
10:35:39.928 [kafka-producer-network-thread | producer-364] INFO Metadata - [Producer clientId=producer-364] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.928 [kafka-producer-network-thread | producer-364] INFO TransactionManager - [Producer clientId=producer-364] ProducerId set to 1422 with epoch 0
10:35:39.929 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.929 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.929 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.929 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139929
10:35:39.929 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-366
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.930 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-366] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.930 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-366] Instantiated an idempotent producer.
10:35:39.931 [kafka-producer-network-thread | producer-365] INFO Metadata - [Producer clientId=producer-365] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.931 [kafka-producer-network-thread | producer-365] INFO TransactionManager - [Producer clientId=producer-365] ProducerId set to 1424 with epoch 0
10:35:39.934 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.934 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.934 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.934 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139934
10:35:39.934 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-367
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.935 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-367] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.935 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-367] Instantiated an idempotent producer.
10:35:39.935 [kafka-producer-network-thread | producer-366] INFO Metadata - [Producer clientId=producer-366] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.935 [kafka-producer-network-thread | producer-366] INFO TransactionManager - [Producer clientId=producer-366] ProducerId set to 2409 with epoch 0
10:35:39.937 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.937 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.937 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.937 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139937
10:35:39.937 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-368
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.938 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-368] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.938 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-368] Instantiated an idempotent producer.
10:35:39.938 [kafka-producer-network-thread | producer-367] INFO Metadata - [Producer clientId=producer-367] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.938 [kafka-producer-network-thread | producer-367] INFO TransactionManager - [Producer clientId=producer-367] ProducerId set to 2410 with epoch 0
10:35:39.939 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.939 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.939 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.939 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139939
10:35:39.940 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-369
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.940 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-369] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.940 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-369] Instantiated an idempotent producer.
10:35:39.941 [kafka-producer-network-thread | producer-368] INFO Metadata - [Producer clientId=producer-368] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.941 [kafka-producer-network-thread | producer-368] INFO TransactionManager - [Producer clientId=producer-368] ProducerId set to 2411 with epoch 0
10:35:39.942 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.942 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.942 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.942 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139942
10:35:39.942 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-370
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.942 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-370] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.943 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-370] Instantiated an idempotent producer.
10:35:39.943 [kafka-producer-network-thread | producer-369] INFO Metadata - [Producer clientId=producer-369] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.943 [kafka-producer-network-thread | producer-369] INFO TransactionManager - [Producer clientId=producer-369] ProducerId set to 2413 with epoch 0
10:35:39.945 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.945 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.945 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.945 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139945
10:35:39.945 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-371
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.945 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-371] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.946 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-371] Instantiated an idempotent producer.
10:35:39.947 [kafka-producer-network-thread | producer-370] INFO Metadata - [Producer clientId=producer-370] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.947 [kafka-producer-network-thread | producer-370] INFO TransactionManager - [Producer clientId=producer-370] ProducerId set to 411 with epoch 0
10:35:39.948 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.948 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.948 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.948 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139948
10:35:39.948 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-372
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.948 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-372] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.948 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-372] Instantiated an idempotent producer.
10:35:39.949 [kafka-producer-network-thread | producer-371] INFO Metadata - [Producer clientId=producer-371] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.949 [kafka-producer-network-thread | producer-371] INFO TransactionManager - [Producer clientId=producer-371] ProducerId set to 1428 with epoch 0
10:35:39.950 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.950 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.950 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.950 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139950
10:35:39.950 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-373
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.950 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-373] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.951 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-373] Instantiated an idempotent producer.
10:35:39.953 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.953 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.953 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.953 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139953
10:35:39.953 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-374
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.953 [kafka-producer-network-thread | producer-372] INFO Metadata - [Producer clientId=producer-372] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.953 [kafka-producer-network-thread | producer-372] INFO TransactionManager - [Producer clientId=producer-372] ProducerId set to 413 with epoch 0
10:35:39.953 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-374] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.954 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-374] Instantiated an idempotent producer.
10:35:39.954 [kafka-producer-network-thread | producer-373] INFO Metadata - [Producer clientId=producer-373] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.954 [kafka-producer-network-thread | producer-373] INFO TransactionManager - [Producer clientId=producer-373] ProducerId set to 415 with epoch 0
10:35:39.955 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.955 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.955 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.955 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139955
10:35:39.955 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-375
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.956 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-375] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.956 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-375] Instantiated an idempotent producer.
10:35:39.957 [kafka-producer-network-thread | producer-374] INFO Metadata - [Producer clientId=producer-374] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.957 [kafka-producer-network-thread | producer-374] INFO TransactionManager - [Producer clientId=producer-374] ProducerId set to 416 with epoch 0
10:35:39.958 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.958 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.958 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.958 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139958
10:35:39.958 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-376
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.958 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-376] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.958 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-376] Instantiated an idempotent producer.
10:35:39.959 [kafka-producer-network-thread | producer-375] INFO Metadata - [Producer clientId=producer-375] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.959 [kafka-producer-network-thread | producer-375] INFO TransactionManager - [Producer clientId=producer-375] ProducerId set to 2420 with epoch 0
10:35:39.960 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.960 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.960 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.960 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139960
10:35:39.961 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-377
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.961 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-377] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.961 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-377] Instantiated an idempotent producer.
10:35:39.963 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.963 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.963 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.963 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139963
10:35:39.964 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-378
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.964 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-378] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.964 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-378] Instantiated an idempotent producer.
10:35:39.965 [kafka-producer-network-thread | producer-377] INFO Metadata - [Producer clientId=producer-377] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.965 [kafka-producer-network-thread | producer-377] INFO TransactionManager - [Producer clientId=producer-377] ProducerId set to 420 with epoch 0
10:35:39.966 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.966 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.966 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.966 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139966
10:35:39.966 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-379
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.966 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-379] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.966 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-379] Instantiated an idempotent producer.
10:35:39.967 [kafka-producer-network-thread | producer-376] INFO Metadata - [Producer clientId=producer-376] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.967 [kafka-producer-network-thread | producer-376] INFO TransactionManager - [Producer clientId=producer-376] ProducerId set to 2422 with epoch 0
10:35:39.967 [kafka-producer-network-thread | producer-378] INFO Metadata - [Producer clientId=producer-378] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.968 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.968 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.968 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.969 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139968
10:35:39.969 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-380
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.969 [kafka-producer-network-thread | producer-378] INFO TransactionManager - [Producer clientId=producer-378] ProducerId set to 2425 with epoch 0
10:35:39.969 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-380] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.969 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-380] Instantiated an idempotent producer.
10:35:39.970 [kafka-producer-network-thread | producer-379] INFO Metadata - [Producer clientId=producer-379] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.970 [kafka-producer-network-thread | producer-379] INFO TransactionManager - [Producer clientId=producer-379] ProducerId set to 2428 with epoch 0
10:35:39.972 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.972 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.972 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.972 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139972
10:35:39.972 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-381
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.972 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-381] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.973 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-381] Instantiated an idempotent producer.
10:35:39.974 [kafka-producer-network-thread | producer-380] INFO TransactionManager - [Producer clientId=producer-380] ProducerId set to 423 with epoch 0
10:35:39.974 [kafka-producer-network-thread | producer-380] INFO Metadata - [Producer clientId=producer-380] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.975 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.975 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.975 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.975 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139975
10:35:39.975 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-382
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.976 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-382] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.976 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-382] Instantiated an idempotent producer.
10:35:39.977 [kafka-producer-network-thread | producer-381] INFO Metadata - [Producer clientId=producer-381] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.977 [kafka-producer-network-thread | producer-381] INFO TransactionManager - [Producer clientId=producer-381] ProducerId set to 1440 with epoch 0
10:35:39.984 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.984 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.984 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.984 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139984
10:35:39.984 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-383
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.985 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-383] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.985 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-383] Instantiated an idempotent producer.
10:35:39.985 [kafka-producer-network-thread | producer-382] INFO Metadata - [Producer clientId=producer-382] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.985 [kafka-producer-network-thread | producer-382] INFO TransactionManager - [Producer clientId=producer-382] ProducerId set to 1445 with epoch 0
10:35:39.988 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.988 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.988 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.988 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139988
10:35:39.989 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-384
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.989 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-384] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.989 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-384] Instantiated an idempotent producer.
10:35:39.990 [kafka-producer-network-thread | producer-383] INFO Metadata - [Producer clientId=producer-383] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.990 [kafka-producer-network-thread | producer-383] INFO TransactionManager - [Producer clientId=producer-383] ProducerId set to 426 with epoch 0
10:35:39.991 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.992 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.992 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.992 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139992
10:35:39.992 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-385
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.992 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-385] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.992 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-385] Instantiated an idempotent producer.
10:35:39.993 [kafka-producer-network-thread | producer-384] INFO Metadata - [Producer clientId=producer-384] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:39.993 [kafka-producer-network-thread | producer-384] INFO TransactionManager - [Producer clientId=producer-384] ProducerId set to 428 with epoch 0
10:35:39.996 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.996 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.996 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.996 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139996
10:35:39.996 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-386
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.996 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-386] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:39.996 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-386] Instantiated an idempotent producer.
10:35:39.999 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:39.999 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:39.999 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:39.999 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806139999
10:35:39.999 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-387
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:39.999 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-387] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.000 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-387] Instantiated an idempotent producer.
10:35:40.001 [kafka-producer-network-thread | producer-386] INFO Metadata - [Producer clientId=producer-386] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.001 [kafka-producer-network-thread | producer-386] INFO TransactionManager - [Producer clientId=producer-386] ProducerId set to 435 with epoch 0
10:35:40.002 [kafka-producer-network-thread | producer-385] INFO Metadata - [Producer clientId=producer-385] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.003 [kafka-producer-network-thread | producer-385] INFO TransactionManager - [Producer clientId=producer-385] ProducerId set to 2435 with epoch 0
10:35:40.012 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.012 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.012 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.012 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140012
10:35:40.012 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-388
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.014 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-388] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.014 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-388] Instantiated an idempotent producer.
10:35:40.014 [kafka-producer-network-thread | producer-387] INFO Metadata - [Producer clientId=producer-387] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.014 [kafka-producer-network-thread | producer-387] INFO TransactionManager - [Producer clientId=producer-387] ProducerId set to 2440 with epoch 0
10:35:40.017 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.017 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.017 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.017 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140017
10:35:40.017 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-389
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.018 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-389] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.018 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-389] Instantiated an idempotent producer.
10:35:40.020 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.020 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.020 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.020 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140020
10:35:40.021 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-390
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.021 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-390] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.021 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-390] Instantiated an idempotent producer.
10:35:40.023 [kafka-producer-network-thread | producer-388] INFO TransactionManager - [Producer clientId=producer-388] ProducerId set to 2443 with epoch 0
10:35:40.023 [kafka-producer-network-thread | producer-388] INFO Metadata - [Producer clientId=producer-388] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.025 [kafka-producer-network-thread | producer-389] INFO Metadata - [Producer clientId=producer-389] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.025 [kafka-producer-network-thread | producer-389] INFO TransactionManager - [Producer clientId=producer-389] ProducerId set to 2444 with epoch 0
10:35:40.026 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.026 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.026 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.026 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140026
10:35:40.026 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-391
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.027 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-391] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.027 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-391] Instantiated an idempotent producer.
10:35:40.027 [kafka-producer-network-thread | producer-390] INFO Metadata - [Producer clientId=producer-390] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.027 [kafka-producer-network-thread | producer-390] INFO TransactionManager - [Producer clientId=producer-390] ProducerId set to 445 with epoch 0
10:35:40.028 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.028 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.028 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.028 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140028
10:35:40.029 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-392
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.029 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-392] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.029 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-392] Instantiated an idempotent producer.
10:35:40.032 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.032 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.032 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.032 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140032
10:35:40.032 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-393
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.032 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-393] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.032 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-393] Instantiated an idempotent producer.
10:35:40.033 [kafka-producer-network-thread | producer-391] INFO Metadata - [Producer clientId=producer-391] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.033 [kafka-producer-network-thread | producer-391] INFO TransactionManager - [Producer clientId=producer-391] ProducerId set to 2448 with epoch 0
10:35:40.034 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.034 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.034 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.034 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140034
10:35:40.034 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-394
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.035 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-394] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.035 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-394] Instantiated an idempotent producer.
10:35:40.036 [kafka-producer-network-thread | producer-393] INFO Metadata - [Producer clientId=producer-393] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.036 [kafka-producer-network-thread | producer-393] INFO TransactionManager - [Producer clientId=producer-393] ProducerId set to 449 with epoch 0
10:35:40.037 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.037 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.037 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.037 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140037
10:35:40.037 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-395
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.038 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-395] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.038 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-395] Instantiated an idempotent producer.
10:35:40.038 [kafka-producer-network-thread | producer-392] INFO Metadata - [Producer clientId=producer-392] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.038 [kafka-producer-network-thread | producer-392] INFO TransactionManager - [Producer clientId=producer-392] ProducerId set to 1460 with epoch 0
10:35:40.039 [kafka-producer-network-thread | producer-394] INFO Metadata - [Producer clientId=producer-394] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.039 [kafka-producer-network-thread | producer-394] INFO TransactionManager - [Producer clientId=producer-394] ProducerId set to 1461 with epoch 0
10:35:40.040 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.040 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.040 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.040 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140040
10:35:40.040 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-396
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.041 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-396] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.041 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-396] Instantiated an idempotent producer.
10:35:40.041 [kafka-producer-network-thread | producer-395] INFO Metadata - [Producer clientId=producer-395] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.041 [kafka-producer-network-thread | producer-395] INFO TransactionManager - [Producer clientId=producer-395] ProducerId set to 2450 with epoch 0
10:35:40.042 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.042 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.042 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.042 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140042
10:35:40.043 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-397
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.043 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-397] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.043 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-397] Instantiated an idempotent producer.
10:35:40.044 [kafka-producer-network-thread | producer-396] INFO Metadata - [Producer clientId=producer-396] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.044 [kafka-producer-network-thread | producer-396] INFO TransactionManager - [Producer clientId=producer-396] ProducerId set to 1464 with epoch 0
10:35:40.045 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.045 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.045 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.045 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140045
10:35:40.045 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-398
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.046 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-398] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.046 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-398] Instantiated an idempotent producer.
10:35:40.047 [kafka-producer-network-thread | producer-397] INFO Metadata - [Producer clientId=producer-397] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.047 [kafka-producer-network-thread | producer-397] INFO TransactionManager - [Producer clientId=producer-397] ProducerId set to 451 with epoch 0
10:35:40.047 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.047 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.047 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.047 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140047
10:35:40.048 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-399
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.048 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-399] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.048 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-399] Instantiated an idempotent producer.
10:35:40.048 [kafka-producer-network-thread | producer-398] INFO Metadata - [Producer clientId=producer-398] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.049 [kafka-producer-network-thread | producer-398] INFO TransactionManager - [Producer clientId=producer-398] ProducerId set to 1465 with epoch 0
10:35:40.050 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.050 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.050 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.050 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140050
10:35:40.050 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-400
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.050 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-400] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.051 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-400] Instantiated an idempotent producer.
10:35:40.052 [kafka-producer-network-thread | producer-399] INFO Metadata - [Producer clientId=producer-399] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.052 [kafka-producer-network-thread | producer-399] INFO TransactionManager - [Producer clientId=producer-399] ProducerId set to 452 with epoch 0
10:35:40.052 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.052 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.052 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.052 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140052
10:35:40.052 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-401
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.053 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-401] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.053 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-401] Instantiated an idempotent producer.
10:35:40.054 [kafka-producer-network-thread | producer-400] INFO Metadata - [Producer clientId=producer-400] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.054 [kafka-producer-network-thread | producer-400] INFO TransactionManager - [Producer clientId=producer-400] ProducerId set to 1467 with epoch 0
10:35:40.054 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.055 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.055 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.055 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140055
10:35:40.055 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-402
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.055 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-402] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.055 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-402] Instantiated an idempotent producer.
10:35:40.056 [kafka-producer-network-thread | producer-401] INFO Metadata - [Producer clientId=producer-401] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.056 [kafka-producer-network-thread | producer-401] INFO TransactionManager - [Producer clientId=producer-401] ProducerId set to 453 with epoch 0
10:35:40.057 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.057 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.057 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.057 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140057
10:35:40.057 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-403
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.058 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-403] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.058 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-403] Instantiated an idempotent producer.
10:35:40.059 [kafka-producer-network-thread | producer-402] INFO Metadata - [Producer clientId=producer-402] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.061 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.061 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.061 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.061 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140061
10:35:40.061 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-404
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.061 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-404] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.061 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-404] Instantiated an idempotent producer.
10:35:40.063 [kafka-producer-network-thread | producer-402] INFO TransactionManager - [Producer clientId=producer-402] ProducerId set to 454 with epoch 0
10:35:40.063 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.063 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.063 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.063 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140063
10:35:40.064 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-405
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.064 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-405] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.064 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-405] Instantiated an idempotent producer.
10:35:40.065 [kafka-producer-network-thread | producer-404] INFO Metadata - [Producer clientId=producer-404] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.065 [kafka-producer-network-thread | producer-404] INFO TransactionManager - [Producer clientId=producer-404] ProducerId set to 2455 with epoch 0
10:35:40.065 [kafka-producer-network-thread | producer-403] INFO Metadata - [Producer clientId=producer-403] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.065 [kafka-producer-network-thread | producer-403] INFO TransactionManager - [Producer clientId=producer-403] ProducerId set to 2456 with epoch 0
10:35:40.066 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.066 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.066 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.066 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140066
10:35:40.066 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-406
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.067 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-406] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.067 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-406] Instantiated an idempotent producer.
10:35:40.067 [kafka-producer-network-thread | producer-405] INFO Metadata - [Producer clientId=producer-405] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.068 [kafka-producer-network-thread | producer-405] INFO TransactionManager - [Producer clientId=producer-405] ProducerId set to 1470 with epoch 0
10:35:40.068 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.068 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.068 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.068 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140068
10:35:40.069 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-407
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.069 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-407] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.069 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-407] Instantiated an idempotent producer.
10:35:40.070 [kafka-producer-network-thread | producer-406] INFO Metadata - [Producer clientId=producer-406] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.070 [kafka-producer-network-thread | producer-406] INFO TransactionManager - [Producer clientId=producer-406] ProducerId set to 456 with epoch 0
10:35:40.071 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.071 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.071 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.071 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140071
10:35:40.071 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-408
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.072 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-408] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.072 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-408] Instantiated an idempotent producer.
10:35:40.072 [kafka-producer-network-thread | producer-407] INFO Metadata - [Producer clientId=producer-407] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.072 [kafka-producer-network-thread | producer-407] INFO TransactionManager - [Producer clientId=producer-407] ProducerId set to 457 with epoch 0
10:35:40.073 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.073 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.073 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.073 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140073
10:35:40.073 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-409
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.074 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-409] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.074 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-409] Instantiated an idempotent producer.
10:35:40.075 [kafka-producer-network-thread | producer-408] INFO Metadata - [Producer clientId=producer-408] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.075 [kafka-producer-network-thread | producer-408] INFO TransactionManager - [Producer clientId=producer-408] ProducerId set to 2459 with epoch 0
10:35:40.076 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.076 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.076 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.076 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140076
10:35:40.076 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-410
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.077 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-410] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.077 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-410] Instantiated an idempotent producer.
10:35:40.078 [kafka-producer-network-thread | producer-409] INFO Metadata - [Producer clientId=producer-409] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.078 [kafka-producer-network-thread | producer-409] INFO TransactionManager - [Producer clientId=producer-409] ProducerId set to 2460 with epoch 0
10:35:40.078 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.078 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.078 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.078 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140078
10:35:40.079 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-411
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.079 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-411] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.079 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-411] Instantiated an idempotent producer.
10:35:40.080 [kafka-producer-network-thread | producer-410] INFO Metadata - [Producer clientId=producer-410] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.080 [kafka-producer-network-thread | producer-410] INFO TransactionManager - [Producer clientId=producer-410] ProducerId set to 1474 with epoch 0
10:35:40.081 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.081 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.081 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.081 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140081
10:35:40.081 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-412
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.081 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-412] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.081 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-412] Instantiated an idempotent producer.
10:35:40.083 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.083 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.083 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.083 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140083
10:35:40.083 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-413
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.084 [kafka-producer-network-thread | producer-411] INFO Metadata - [Producer clientId=producer-411] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.084 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-413] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.084 [kafka-producer-network-thread | producer-411] INFO TransactionManager - [Producer clientId=producer-411] ProducerId set to 2462 with epoch 0
10:35:40.084 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-413] Instantiated an idempotent producer.
10:35:40.084 [kafka-producer-network-thread | producer-412] INFO Metadata - [Producer clientId=producer-412] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.085 [kafka-producer-network-thread | producer-412] INFO TransactionManager - [Producer clientId=producer-412] ProducerId set to 1476 with epoch 0
10:35:40.085 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.085 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.085 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.085 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140085
10:35:40.086 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-414
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.086 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-414] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.086 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-414] Instantiated an idempotent producer.
10:35:40.087 [kafka-producer-network-thread | producer-413] INFO Metadata - [Producer clientId=producer-413] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.087 [kafka-producer-network-thread | producer-413] INFO TransactionManager - [Producer clientId=producer-413] ProducerId set to 2463 with epoch 0
10:35:40.088 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.088 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.088 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.088 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140088
10:35:40.088 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-415
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.088 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-415] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.089 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-415] Instantiated an idempotent producer.
10:35:40.089 [kafka-producer-network-thread | producer-414] INFO Metadata - [Producer clientId=producer-414] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.090 [kafka-producer-network-thread | producer-414] INFO TransactionManager - [Producer clientId=producer-414] ProducerId set to 459 with epoch 0
10:35:40.090 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.090 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.090 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.090 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140090
10:35:40.091 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-416
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.091 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-416] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.091 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-416] Instantiated an idempotent producer.
10:35:40.092 [kafka-producer-network-thread | producer-415] INFO Metadata - [Producer clientId=producer-415] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.092 [kafka-producer-network-thread | producer-415] INFO TransactionManager - [Producer clientId=producer-415] ProducerId set to 460 with epoch 0
10:35:40.093 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.093 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.093 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.093 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140093
10:35:40.093 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-417
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.093 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-417] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.094 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-417] Instantiated an idempotent producer.
10:35:40.094 [kafka-producer-network-thread | producer-416] INFO Metadata - [Producer clientId=producer-416] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.094 [kafka-producer-network-thread | producer-416] INFO TransactionManager - [Producer clientId=producer-416] ProducerId set to 462 with epoch 0
10:35:40.095 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.095 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.095 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.095 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140095
10:35:40.096 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-418
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.096 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-418] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.096 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-418] Instantiated an idempotent producer.
10:35:40.097 [kafka-producer-network-thread | producer-417] INFO Metadata - [Producer clientId=producer-417] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.097 [kafka-producer-network-thread | producer-417] INFO TransactionManager - [Producer clientId=producer-417] ProducerId set to 2464 with epoch 0
10:35:40.098 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.098 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.098 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.098 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140098
10:35:40.098 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-419
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.098 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-419] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.098 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-419] Instantiated an idempotent producer.
10:35:40.101 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.101 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.101 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.101 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140101
10:35:40.101 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-420
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.102 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-420] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.102 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-420] Instantiated an idempotent producer.
10:35:40.103 [kafka-producer-network-thread | producer-419] INFO Metadata - [Producer clientId=producer-419] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.103 [kafka-producer-network-thread | producer-419] INFO TransactionManager - [Producer clientId=producer-419] ProducerId set to 2467 with epoch 0
10:35:40.103 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.103 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.103 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.103 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140103
10:35:40.104 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-421
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.104 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-421] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.104 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-421] Instantiated an idempotent producer.
10:35:40.105 [kafka-producer-network-thread | producer-420] INFO Metadata - [Producer clientId=producer-420] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.105 [kafka-producer-network-thread | producer-420] INFO TransactionManager - [Producer clientId=producer-420] ProducerId set to 465 with epoch 0
10:35:40.105 [kafka-producer-network-thread | producer-418] INFO Metadata - [Producer clientId=producer-418] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.105 [kafka-producer-network-thread | producer-418] INFO TransactionManager - [Producer clientId=producer-418] ProducerId set to 1479 with epoch 0
10:35:40.106 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.106 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.106 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.106 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140106
10:35:40.106 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-422
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.107 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-422] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.107 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-422] Instantiated an idempotent producer.
10:35:40.107 [kafka-producer-network-thread | producer-421] INFO Metadata - [Producer clientId=producer-421] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.107 [kafka-producer-network-thread | producer-421] INFO TransactionManager - [Producer clientId=producer-421] ProducerId set to 467 with epoch 0
10:35:40.108 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.108 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.108 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.108 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140108
10:35:40.109 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-423
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.109 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-423] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.109 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-423] Instantiated an idempotent producer.
10:35:40.110 [kafka-producer-network-thread | producer-422] INFO Metadata - [Producer clientId=producer-422] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.110 [kafka-producer-network-thread | producer-422] INFO TransactionManager - [Producer clientId=producer-422] ProducerId set to 469 with epoch 0
10:35:40.120 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.120 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.120 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.120 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140120
10:35:40.120 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-424
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.121 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-424] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.121 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-424] Instantiated an idempotent producer.
10:35:40.122 [kafka-producer-network-thread | producer-423] INFO Metadata - [Producer clientId=producer-423] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.122 [kafka-producer-network-thread | producer-423] INFO TransactionManager - [Producer clientId=producer-423] ProducerId set to 2470 with epoch 0
10:35:40.124 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.124 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.124 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.124 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140124
10:35:40.124 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-425
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.124 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-425] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.125 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-425] Instantiated an idempotent producer.
10:35:40.127 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.127 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.127 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.127 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140127
10:35:40.127 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-426
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.128 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-426] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.128 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-426] Instantiated an idempotent producer.
10:35:40.129 [kafka-producer-network-thread | producer-425] INFO Metadata - [Producer clientId=producer-425] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.129 [kafka-producer-network-thread | producer-425] INFO TransactionManager - [Producer clientId=producer-425] ProducerId set to 472 with epoch 0
10:35:40.131 [kafka-producer-network-thread | producer-424] INFO Metadata - [Producer clientId=producer-424] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.131 [kafka-producer-network-thread | producer-424] INFO TransactionManager - [Producer clientId=producer-424] ProducerId set to 1483 with epoch 0
10:35:40.132 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.132 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.132 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.132 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140132
10:35:40.132 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-427
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.133 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-427] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.133 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-427] Instantiated an idempotent producer.
10:35:40.133 [kafka-producer-network-thread | producer-426] INFO Metadata - [Producer clientId=producer-426] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.133 [kafka-producer-network-thread | producer-426] INFO TransactionManager - [Producer clientId=producer-426] ProducerId set to 1484 with epoch 0
10:35:40.135 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.135 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.135 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.135 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140135
10:35:40.135 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-428
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.135 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-428] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.135 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-428] Instantiated an idempotent producer.
10:35:40.136 [kafka-producer-network-thread | producer-427] INFO Metadata - [Producer clientId=producer-427] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.136 [kafka-producer-network-thread | producer-427] INFO TransactionManager - [Producer clientId=producer-427] ProducerId set to 474 with epoch 0
10:35:40.137 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.137 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.137 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.137 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140137
10:35:40.137 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-429
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.138 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-429] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.138 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-429] Instantiated an idempotent producer.
10:35:40.138 [kafka-producer-network-thread | producer-428] INFO Metadata - [Producer clientId=producer-428] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.139 [kafka-producer-network-thread | producer-428] INFO TransactionManager - [Producer clientId=producer-428] ProducerId set to 2473 with epoch 0
10:35:40.139 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.139 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.139 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.139 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140139
10:35:40.140 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-430
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.140 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-430] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.140 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-430] Instantiated an idempotent producer.
10:35:40.141 [kafka-producer-network-thread | producer-429] INFO Metadata - [Producer clientId=producer-429] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.141 [kafka-producer-network-thread | producer-429] INFO TransactionManager - [Producer clientId=producer-429] ProducerId set to 2474 with epoch 0
10:35:40.142 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.142 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.142 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.142 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140142
10:35:40.142 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-431
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.143 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-431] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.143 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-431] Instantiated an idempotent producer.
10:35:40.144 [kafka-producer-network-thread | producer-430] INFO Metadata - [Producer clientId=producer-430] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.144 [kafka-producer-network-thread | producer-430] INFO TransactionManager - [Producer clientId=producer-430] ProducerId set to 2475 with epoch 0
10:35:40.144 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.144 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.144 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.144 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140144
10:35:40.145 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-432
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.145 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-432] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.145 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-432] Instantiated an idempotent producer.
10:35:40.146 [kafka-producer-network-thread | producer-431] INFO Metadata - [Producer clientId=producer-431] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.146 [kafka-producer-network-thread | producer-431] INFO TransactionManager - [Producer clientId=producer-431] ProducerId set to 1486 with epoch 0
10:35:40.147 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.147 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.147 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.147 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140147
10:35:40.147 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-433
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.147 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-433] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.147 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-433] Instantiated an idempotent producer.
10:35:40.148 [kafka-producer-network-thread | producer-432] INFO Metadata - [Producer clientId=producer-432] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.148 [kafka-producer-network-thread | producer-432] INFO TransactionManager - [Producer clientId=producer-432] ProducerId set to 1487 with epoch 0
10:35:40.149 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.149 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.149 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.149 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140149
10:35:40.149 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-434
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.150 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-434] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.150 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-434] Instantiated an idempotent producer.
10:35:40.151 [kafka-producer-network-thread | producer-433] INFO Metadata - [Producer clientId=producer-433] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.151 [kafka-producer-network-thread | producer-433] INFO TransactionManager - [Producer clientId=producer-433] ProducerId set to 2476 with epoch 0
10:35:40.151 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.151 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.151 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.151 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140151
10:35:40.152 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-435
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.152 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-435] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.152 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-435] Instantiated an idempotent producer.
10:35:40.153 [kafka-producer-network-thread | producer-434] INFO Metadata - [Producer clientId=producer-434] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.154 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.154 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.154 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.154 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140154
10:35:40.154 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-436
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.154 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-436] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.155 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-436] Instantiated an idempotent producer.
10:35:40.155 [kafka-producer-network-thread | producer-435] INFO Metadata - [Producer clientId=producer-435] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.155 [kafka-producer-network-thread | producer-435] INFO TransactionManager - [Producer clientId=producer-435] ProducerId set to 481 with epoch 0
10:35:40.156 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.156 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.156 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.156 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140156
10:35:40.156 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-437
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.157 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-437] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.157 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-437] Instantiated an idempotent producer.
10:35:40.157 [kafka-producer-network-thread | producer-436] INFO Metadata - [Producer clientId=producer-436] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.158 [kafka-producer-network-thread | producer-436] INFO TransactionManager - [Producer clientId=producer-436] ProducerId set to 2478 with epoch 0
10:35:40.158 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.158 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.158 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.158 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140158
10:35:40.159 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-438
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.159 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-438] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.159 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-438] Instantiated an idempotent producer.
10:35:40.160 [kafka-producer-network-thread | producer-437] INFO Metadata - [Producer clientId=producer-437] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.160 [kafka-producer-network-thread | producer-437] INFO TransactionManager - [Producer clientId=producer-437] ProducerId set to 1489 with epoch 0
10:35:40.161 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.161 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.161 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.161 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140161
10:35:40.161 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-439
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.162 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-439] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.162 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-439] Instantiated an idempotent producer.
10:35:40.163 [kafka-producer-network-thread | producer-438] INFO Metadata - [Producer clientId=producer-438] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.163 [kafka-producer-network-thread | producer-438] INFO TransactionManager - [Producer clientId=producer-438] ProducerId set to 482 with epoch 0
10:35:40.163 [kafka-producer-network-thread | producer-434] INFO TransactionManager - [Producer clientId=producer-434] ProducerId set to 1488 with epoch 0
10:35:40.163 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.164 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.164 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.164 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140164
10:35:40.164 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-440
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.164 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-440] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.164 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-440] Instantiated an idempotent producer.
10:35:40.166 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.166 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.166 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.166 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140166
10:35:40.166 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-441
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.166 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-441] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.167 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-441] Instantiated an idempotent producer.
10:35:40.167 [kafka-producer-network-thread | producer-440] INFO Metadata - [Producer clientId=producer-440] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.167 [kafka-producer-network-thread | producer-440] INFO TransactionManager - [Producer clientId=producer-440] ProducerId set to 2480 with epoch 0
10:35:40.169 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.169 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.169 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.169 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140169
10:35:40.169 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-442
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.169 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-442] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.169 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-442] Instantiated an idempotent producer.
10:35:40.170 [kafka-producer-network-thread | producer-441] INFO Metadata - [Producer clientId=producer-441] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.170 [kafka-producer-network-thread | producer-441] INFO TransactionManager - [Producer clientId=producer-441] ProducerId set to 1492 with epoch 0
10:35:40.171 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.171 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.171 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.171 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140171
10:35:40.171 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-443
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.172 [kafka-producer-network-thread | producer-439] INFO Metadata - [Producer clientId=producer-439] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.172 [kafka-producer-network-thread | producer-439] INFO TransactionManager - [Producer clientId=producer-439] ProducerId set to 484 with epoch 0
10:35:40.172 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-443] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.172 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-443] Instantiated an idempotent producer.
10:35:40.172 [kafka-producer-network-thread | producer-442] INFO Metadata - [Producer clientId=producer-442] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.173 [kafka-producer-network-thread | producer-442] INFO TransactionManager - [Producer clientId=producer-442] ProducerId set to 486 with epoch 0
10:35:40.173 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.173 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.174 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.174 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140173
10:35:40.174 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-444
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.174 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-444] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.174 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-444] Instantiated an idempotent producer.
10:35:40.175 [kafka-producer-network-thread | producer-443] INFO Metadata - [Producer clientId=producer-443] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.176 [kafka-producer-network-thread | producer-443] INFO TransactionManager - [Producer clientId=producer-443] ProducerId set to 2481 with epoch 0
10:35:40.176 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.176 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.176 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.176 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140176
10:35:40.176 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-445
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.177 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-445] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.177 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-445] Instantiated an idempotent producer.
10:35:40.177 [kafka-producer-network-thread | producer-444] INFO Metadata - [Producer clientId=producer-444] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.177 [kafka-producer-network-thread | producer-444] INFO TransactionManager - [Producer clientId=producer-444] ProducerId set to 487 with epoch 0
10:35:40.179 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.179 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.179 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.179 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140179
10:35:40.179 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-446
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.179 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-446] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.179 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-446] Instantiated an idempotent producer.
10:35:40.180 [kafka-producer-network-thread | producer-445] INFO Metadata - [Producer clientId=producer-445] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.180 [kafka-producer-network-thread | producer-445] INFO TransactionManager - [Producer clientId=producer-445] ProducerId set to 488 with epoch 0
10:35:40.181 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.181 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.181 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.181 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140181
10:35:40.181 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-447
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.182 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-447] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.182 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-447] Instantiated an idempotent producer.
10:35:40.182 [kafka-producer-network-thread | producer-446] INFO Metadata - [Producer clientId=producer-446] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.182 [kafka-producer-network-thread | producer-446] INFO TransactionManager - [Producer clientId=producer-446] ProducerId set to 489 with epoch 0
10:35:40.183 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.183 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.183 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.183 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140183
10:35:40.184 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-448
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.184 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-448] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.184 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-448] Instantiated an idempotent producer.
10:35:40.185 [kafka-producer-network-thread | producer-447] INFO Metadata - [Producer clientId=producer-447] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.185 [kafka-producer-network-thread | producer-447] INFO TransactionManager - [Producer clientId=producer-447] ProducerId set to 2484 with epoch 0
10:35:40.186 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.186 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.186 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.186 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140186
10:35:40.186 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-449
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.187 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-449] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.187 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-449] Instantiated an idempotent producer.
10:35:40.187 [kafka-producer-network-thread | producer-448] INFO Metadata - [Producer clientId=producer-448] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.188 [kafka-producer-network-thread | producer-448] INFO TransactionManager - [Producer clientId=producer-448] ProducerId set to 1495 with epoch 0
10:35:40.188 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.188 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.188 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.189 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140188
10:35:40.189 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-450
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.189 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-450] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.189 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-450] Instantiated an idempotent producer.
10:35:40.190 [kafka-producer-network-thread | producer-449] INFO Metadata - [Producer clientId=producer-449] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.190 [kafka-producer-network-thread | producer-449] INFO TransactionManager - [Producer clientId=producer-449] ProducerId set to 1496 with epoch 0
10:35:40.191 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.191 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.191 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.191 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140191
10:35:40.191 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-451
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.191 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-451] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.191 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-451] Instantiated an idempotent producer.
10:35:40.192 [kafka-producer-network-thread | producer-450] INFO Metadata - [Producer clientId=producer-450] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.192 [kafka-producer-network-thread | producer-450] INFO TransactionManager - [Producer clientId=producer-450] ProducerId set to 1497 with epoch 0
10:35:40.193 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.193 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.193 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.193 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140193
10:35:40.194 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-452
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.194 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-452] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.194 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-452] Instantiated an idempotent producer.
10:35:40.194 [kafka-producer-network-thread | producer-451] INFO Metadata - [Producer clientId=producer-451] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.194 [kafka-producer-network-thread | producer-451] INFO TransactionManager - [Producer clientId=producer-451] ProducerId set to 1498 with epoch 0
10:35:40.196 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.196 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.196 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.196 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140196
10:35:40.196 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-453
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.196 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-453] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.196 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-453] Instantiated an idempotent producer.
10:35:40.197 [kafka-producer-network-thread | producer-452] INFO Metadata - [Producer clientId=producer-452] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.197 [kafka-producer-network-thread | producer-452] INFO TransactionManager - [Producer clientId=producer-452] ProducerId set to 1499 with epoch 0
10:35:40.198 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.198 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.198 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.198 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140198
10:35:40.198 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-454
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.199 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-454] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.199 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-454] Instantiated an idempotent producer.
10:35:40.199 [kafka-producer-network-thread | producer-453] INFO Metadata - [Producer clientId=producer-453] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.200 [kafka-producer-network-thread | producer-453] INFO TransactionManager - [Producer clientId=producer-453] ProducerId set to 1500 with epoch 0
10:35:40.201 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.201 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.201 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.201 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140201
10:35:40.201 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-455
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.201 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-455] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.201 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-455] Instantiated an idempotent producer.
10:35:40.202 [kafka-producer-network-thread | producer-454] INFO TransactionManager - [Producer clientId=producer-454] ProducerId set to 2489 with epoch 0
10:35:40.202 [kafka-producer-network-thread | producer-454] INFO Metadata - [Producer clientId=producer-454] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.203 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.203 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.203 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.203 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140203
10:35:40.203 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-456
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.204 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-456] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.204 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-456] Instantiated an idempotent producer.
10:35:40.205 [kafka-producer-network-thread | producer-455] INFO Metadata - [Producer clientId=producer-455] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.205 [kafka-producer-network-thread | producer-455] INFO TransactionManager - [Producer clientId=producer-455] ProducerId set to 2490 with epoch 0
10:35:40.206 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.206 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.206 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.206 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140206
10:35:40.207 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-457
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.207 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-457] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.207 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-457] Instantiated an idempotent producer.
10:35:40.208 [kafka-producer-network-thread | producer-456] INFO Metadata - [Producer clientId=producer-456] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.208 [kafka-producer-network-thread | producer-456] INFO TransactionManager - [Producer clientId=producer-456] ProducerId set to 491 with epoch 0
10:35:40.209 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.209 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.209 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.209 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140209
10:35:40.209 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-458
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.209 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-458] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.209 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-458] Instantiated an idempotent producer.
10:35:40.210 [kafka-producer-network-thread | producer-457] INFO Metadata - [Producer clientId=producer-457] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.210 [kafka-producer-network-thread | producer-457] INFO TransactionManager - [Producer clientId=producer-457] ProducerId set to 1502 with epoch 0
10:35:40.211 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.211 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.211 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.211 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140211
10:35:40.211 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-459
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.212 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-459] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.212 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-459] Instantiated an idempotent producer.
10:35:40.212 [kafka-producer-network-thread | producer-458] INFO Metadata - [Producer clientId=producer-458] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.213 [kafka-producer-network-thread | producer-458] INFO TransactionManager - [Producer clientId=producer-458] ProducerId set to 1504 with epoch 0
10:35:40.213 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.213 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.213 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.213 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140213
10:35:40.214 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-460
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.214 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-460] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.214 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-460] Instantiated an idempotent producer.
10:35:40.215 [kafka-producer-network-thread | producer-459] INFO Metadata - [Producer clientId=producer-459] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.215 [kafka-producer-network-thread | producer-459] INFO TransactionManager - [Producer clientId=producer-459] ProducerId set to 493 with epoch 0
10:35:40.216 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.216 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.216 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.216 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140216
10:35:40.216 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-461
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.216 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-461] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.217 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-461] Instantiated an idempotent producer.
10:35:40.217 [kafka-producer-network-thread | producer-460] INFO Metadata - [Producer clientId=producer-460] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.217 [kafka-producer-network-thread | producer-460] INFO TransactionManager - [Producer clientId=producer-460] ProducerId set to 1505 with epoch 0
10:35:40.218 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.218 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.218 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.218 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140218
10:35:40.218 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-462
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.219 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-462] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.219 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-462] Instantiated an idempotent producer.
10:35:40.219 [kafka-producer-network-thread | producer-461] INFO Metadata - [Producer clientId=producer-461] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.220 [kafka-producer-network-thread | producer-461] INFO TransactionManager - [Producer clientId=producer-461] ProducerId set to 1506 with epoch 0
10:35:40.220 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.220 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.220 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.220 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140220
10:35:40.221 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-463
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.221 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-463] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.221 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-463] Instantiated an idempotent producer.
10:35:40.222 [kafka-producer-network-thread | producer-462] INFO Metadata - [Producer clientId=producer-462] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.222 [kafka-producer-network-thread | producer-462] INFO TransactionManager - [Producer clientId=producer-462] ProducerId set to 1508 with epoch 0
10:35:40.223 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.223 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.223 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.223 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140223
10:35:40.223 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-464
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.223 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-464] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.223 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-464] Instantiated an idempotent producer.
10:35:40.224 [kafka-producer-network-thread | producer-463] INFO Metadata - [Producer clientId=producer-463] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.224 [kafka-producer-network-thread | producer-463] INFO TransactionManager - [Producer clientId=producer-463] ProducerId set to 1509 with epoch 0
10:35:40.225 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.225 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.225 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.225 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140225
10:35:40.225 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-465
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.226 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-465] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.226 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-465] Instantiated an idempotent producer.
10:35:40.226 [kafka-producer-network-thread | producer-464] INFO Metadata - [Producer clientId=producer-464] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.226 [kafka-producer-network-thread | producer-464] INFO TransactionManager - [Producer clientId=producer-464] ProducerId set to 1510 with epoch 0
10:35:40.227 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.227 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.227 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.227 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140227
10:35:40.228 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-466
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.228 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-466] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.228 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-466] Instantiated an idempotent producer.
10:35:40.229 [kafka-producer-network-thread | producer-465] INFO Metadata - [Producer clientId=producer-465] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.229 [kafka-producer-network-thread | producer-465] INFO TransactionManager - [Producer clientId=producer-465] ProducerId set to 1511 with epoch 0
10:35:40.230 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.230 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.230 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.230 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140230
10:35:40.230 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-467
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.231 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-467] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.231 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-467] Instantiated an idempotent producer.
10:35:40.231 [kafka-producer-network-thread | producer-466] INFO Metadata - [Producer clientId=producer-466] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.231 [kafka-producer-network-thread | producer-466] INFO TransactionManager - [Producer clientId=producer-466] ProducerId set to 495 with epoch 0
10:35:40.232 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.232 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.232 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.232 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140232
10:35:40.233 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-468
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.233 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-468] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.233 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-468] Instantiated an idempotent producer.
10:35:40.234 [kafka-producer-network-thread | producer-467] INFO Metadata - [Producer clientId=producer-467] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.234 [kafka-producer-network-thread | producer-467] INFO TransactionManager - [Producer clientId=producer-467] ProducerId set to 496 with epoch 0
10:35:40.234 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.235 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.235 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.235 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140235
10:35:40.235 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-469
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.235 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-469] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.235 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-469] Instantiated an idempotent producer.
10:35:40.236 [kafka-producer-network-thread | producer-468] INFO Metadata - [Producer clientId=producer-468] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.236 [kafka-producer-network-thread | producer-468] INFO TransactionManager - [Producer clientId=producer-468] ProducerId set to 497 with epoch 0
10:35:40.237 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.237 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.237 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.237 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140237
10:35:40.237 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-470
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.238 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-470] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.238 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-470] Instantiated an idempotent producer.
10:35:40.238 [kafka-producer-network-thread | producer-469] INFO Metadata - [Producer clientId=producer-469] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.238 [kafka-producer-network-thread | producer-469] INFO TransactionManager - [Producer clientId=producer-469] ProducerId set to 1512 with epoch 0
10:35:40.239 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.240 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.240 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.240 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140239
10:35:40.240 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-471
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.240 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-471] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.240 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-471] Instantiated an idempotent producer.
10:35:40.241 [kafka-producer-network-thread | producer-470] INFO Metadata - [Producer clientId=producer-470] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.241 [kafka-producer-network-thread | producer-470] INFO TransactionManager - [Producer clientId=producer-470] ProducerId set to 498 with epoch 0
10:35:40.242 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.242 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.242 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.242 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140242
10:35:40.242 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-472
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.242 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-472] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.243 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-472] Instantiated an idempotent producer.
10:35:40.243 [kafka-producer-network-thread | producer-471] INFO Metadata - [Producer clientId=producer-471] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.243 [kafka-producer-network-thread | producer-471] INFO TransactionManager - [Producer clientId=producer-471] ProducerId set to 2492 with epoch 0
10:35:40.244 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.244 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.244 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.244 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140244
10:35:40.244 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-473
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.245 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-473] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.245 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-473] Instantiated an idempotent producer.
10:35:40.245 [kafka-producer-network-thread | producer-472] INFO Metadata - [Producer clientId=producer-472] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.246 [kafka-producer-network-thread | producer-472] INFO TransactionManager - [Producer clientId=producer-472] ProducerId set to 2493 with epoch 0
10:35:40.246 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.246 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.247 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.247 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140246
10:35:40.247 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-474
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.247 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-474] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.247 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-474] Instantiated an idempotent producer.
10:35:40.248 [kafka-producer-network-thread | producer-473] INFO Metadata - [Producer clientId=producer-473] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.248 [kafka-producer-network-thread | producer-473] INFO TransactionManager - [Producer clientId=producer-473] ProducerId set to 499 with epoch 0
10:35:40.249 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.249 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.249 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.249 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140249
10:35:40.249 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-475
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.249 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-475] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.250 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-475] Instantiated an idempotent producer.
10:35:40.250 [kafka-producer-network-thread | producer-474] INFO Metadata - [Producer clientId=producer-474] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.250 [kafka-producer-network-thread | producer-474] INFO TransactionManager - [Producer clientId=producer-474] ProducerId set to 500 with epoch 0
10:35:40.251 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.251 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.251 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.251 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140251
10:35:40.252 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-476
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.252 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-476] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.252 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-476] Instantiated an idempotent producer.
10:35:40.253 [kafka-producer-network-thread | producer-475] INFO Metadata - [Producer clientId=producer-475] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.253 [kafka-producer-network-thread | producer-475] INFO TransactionManager - [Producer clientId=producer-475] ProducerId set to 501 with epoch 0
10:35:40.254 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.254 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.254 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.254 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140254
10:35:40.254 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-477
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.255 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-477] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.255 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-477] Instantiated an idempotent producer.
10:35:40.255 [kafka-producer-network-thread | producer-476] INFO Metadata - [Producer clientId=producer-476] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.255 [kafka-producer-network-thread | producer-476] INFO TransactionManager - [Producer clientId=producer-476] ProducerId set to 502 with epoch 0
10:35:40.256 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.256 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.256 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.256 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140256
10:35:40.256 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-478
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.257 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-478] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.257 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-478] Instantiated an idempotent producer.
10:35:40.257 [kafka-producer-network-thread | producer-477] INFO Metadata - [Producer clientId=producer-477] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.257 [kafka-producer-network-thread | producer-477] INFO TransactionManager - [Producer clientId=producer-477] ProducerId set to 2494 with epoch 0
10:35:40.258 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.258 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.258 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.258 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140258
10:35:40.259 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-479
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.259 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-479] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.259 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-479] Instantiated an idempotent producer.
10:35:40.260 [kafka-producer-network-thread | producer-478] INFO Metadata - [Producer clientId=producer-478] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.260 [kafka-producer-network-thread | producer-478] INFO TransactionManager - [Producer clientId=producer-478] ProducerId set to 1513 with epoch 0
10:35:40.261 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.261 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.261 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.261 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140261
10:35:40.261 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-480
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.261 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-480] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.261 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-480] Instantiated an idempotent producer.
10:35:40.262 [kafka-producer-network-thread | producer-479] INFO Metadata - [Producer clientId=producer-479] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.262 [kafka-producer-network-thread | producer-479] INFO TransactionManager - [Producer clientId=producer-479] ProducerId set to 1514 with epoch 0
10:35:40.263 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.263 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.263 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.263 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140263
10:35:40.263 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-481
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.264 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-481] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.264 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-481] Instantiated an idempotent producer.
10:35:40.264 [kafka-producer-network-thread | producer-480] INFO Metadata - [Producer clientId=producer-480] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.264 [kafka-producer-network-thread | producer-480] INFO TransactionManager - [Producer clientId=producer-480] ProducerId set to 2495 with epoch 0
10:35:40.265 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.265 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.265 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.265 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140265
10:35:40.266 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-482
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.266 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-482] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.266 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-482] Instantiated an idempotent producer.
10:35:40.267 [kafka-producer-network-thread | producer-481] INFO Metadata - [Producer clientId=producer-481] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.267 [kafka-producer-network-thread | producer-481] INFO TransactionManager - [Producer clientId=producer-481] ProducerId set to 2496 with epoch 0
10:35:40.268 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.268 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.268 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.268 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140268
10:35:40.268 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-483
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.268 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-483] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.268 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-483] Instantiated an idempotent producer.
10:35:40.269 [kafka-producer-network-thread | producer-482] INFO Metadata - [Producer clientId=producer-482] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.269 [kafka-producer-network-thread | producer-482] INFO TransactionManager - [Producer clientId=producer-482] ProducerId set to 503 with epoch 0
10:35:40.270 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.270 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.270 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.270 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140270
10:35:40.270 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-484
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.271 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-484] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.271 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-484] Instantiated an idempotent producer.
10:35:40.271 [kafka-producer-network-thread | producer-483] INFO Metadata - [Producer clientId=producer-483] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.272 [kafka-producer-network-thread | producer-483] INFO TransactionManager - [Producer clientId=producer-483] ProducerId set to 1515 with epoch 0
10:35:40.272 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.272 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.272 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.272 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140272
10:35:40.273 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-485
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.273 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-485] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.273 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-485] Instantiated an idempotent producer.
10:35:40.273 [kafka-producer-network-thread | producer-484] INFO Metadata - [Producer clientId=producer-484] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.274 [kafka-producer-network-thread | producer-484] INFO TransactionManager - [Producer clientId=producer-484] ProducerId set to 2497 with epoch 0
10:35:40.275 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.275 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.275 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.275 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140275
10:35:40.275 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-486
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.275 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-486] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.275 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-486] Instantiated an idempotent producer.
10:35:40.276 [kafka-producer-network-thread | producer-485] INFO Metadata - [Producer clientId=producer-485] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.276 [kafka-producer-network-thread | producer-485] INFO TransactionManager - [Producer clientId=producer-485] ProducerId set to 2498 with epoch 0
10:35:40.277 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.277 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.277 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.277 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140277
10:35:40.277 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-487
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.278 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-487] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.278 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-487] Instantiated an idempotent producer.
10:35:40.278 [kafka-producer-network-thread | producer-486] INFO Metadata - [Producer clientId=producer-486] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.278 [kafka-producer-network-thread | producer-486] INFO TransactionManager - [Producer clientId=producer-486] ProducerId set to 1516 with epoch 0
10:35:40.279 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.279 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.279 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.279 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140279
10:35:40.280 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-488
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.280 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-488] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.280 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-488] Instantiated an idempotent producer.
10:35:40.281 [kafka-producer-network-thread | producer-487] INFO Metadata - [Producer clientId=producer-487] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.281 [kafka-producer-network-thread | producer-487] INFO TransactionManager - [Producer clientId=producer-487] ProducerId set to 2499 with epoch 0
10:35:40.282 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.282 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.282 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.282 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140282
10:35:40.282 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-489
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.283 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-489] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.283 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-489] Instantiated an idempotent producer.
10:35:40.283 [kafka-producer-network-thread | producer-488] INFO Metadata - [Producer clientId=producer-488] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.283 [kafka-producer-network-thread | producer-488] INFO TransactionManager - [Producer clientId=producer-488] ProducerId set to 2500 with epoch 0
10:35:40.284 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.284 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.284 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.284 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140284
10:35:40.285 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-490
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.285 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-490] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.285 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-490] Instantiated an idempotent producer.
10:35:40.286 [kafka-producer-network-thread | producer-489] INFO Metadata - [Producer clientId=producer-489] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.286 [kafka-producer-network-thread | producer-489] INFO TransactionManager - [Producer clientId=producer-489] ProducerId set to 504 with epoch 0
10:35:40.287 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.287 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.287 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.287 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140287
10:35:40.287 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-491
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.287 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-491] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.288 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-491] Instantiated an idempotent producer.
10:35:40.288 [kafka-producer-network-thread | producer-490] INFO Metadata - [Producer clientId=producer-490] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.288 [kafka-producer-network-thread | producer-490] INFO TransactionManager - [Producer clientId=producer-490] ProducerId set to 2501 with epoch 0
10:35:40.289 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.289 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.289 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.289 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140289
10:35:40.290 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-492
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.290 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-492] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.290 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-492] Instantiated an idempotent producer.
10:35:40.291 [kafka-producer-network-thread | producer-491] INFO Metadata - [Producer clientId=producer-491] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.291 [kafka-producer-network-thread | producer-491] INFO TransactionManager - [Producer clientId=producer-491] ProducerId set to 2502 with epoch 0
10:35:40.291 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.292 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.292 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.292 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140292
10:35:40.292 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-493
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.292 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-493] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.292 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-493] Instantiated an idempotent producer.
10:35:40.293 [kafka-producer-network-thread | producer-492] INFO Metadata - [Producer clientId=producer-492] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.293 [kafka-producer-network-thread | producer-492] INFO TransactionManager - [Producer clientId=producer-492] ProducerId set to 2503 with epoch 0
10:35:40.294 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.294 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.294 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.294 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140294
10:35:40.294 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-494
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.295 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-494] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.295 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-494] Instantiated an idempotent producer.
10:35:40.295 [kafka-producer-network-thread | producer-493] INFO Metadata - [Producer clientId=producer-493] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.295 [kafka-producer-network-thread | producer-493] INFO TransactionManager - [Producer clientId=producer-493] ProducerId set to 2504 with epoch 0
10:35:40.296 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.296 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.296 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.296 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140296
10:35:40.297 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-495
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.297 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-495] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.297 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-495] Instantiated an idempotent producer.
10:35:40.298 [kafka-producer-network-thread | producer-494] INFO Metadata - [Producer clientId=producer-494] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.298 [kafka-producer-network-thread | producer-494] INFO TransactionManager - [Producer clientId=producer-494] ProducerId set to 1517 with epoch 0
10:35:40.299 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.299 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.299 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.299 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140299
10:35:40.299 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-496
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.299 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-496] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.299 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-496] Instantiated an idempotent producer.
10:35:40.300 [kafka-producer-network-thread | producer-495] INFO Metadata - [Producer clientId=producer-495] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.300 [kafka-producer-network-thread | producer-495] INFO TransactionManager - [Producer clientId=producer-495] ProducerId set to 2505 with epoch 0
10:35:40.301 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.301 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.301 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.301 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140301
10:35:40.301 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-497
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.302 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-497] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.302 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-497] Instantiated an idempotent producer.
10:35:40.302 [kafka-producer-network-thread | producer-496] INFO Metadata - [Producer clientId=producer-496] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.303 [kafka-producer-network-thread | producer-496] INFO TransactionManager - [Producer clientId=producer-496] ProducerId set to 1518 with epoch 0
10:35:40.303 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.303 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.303 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.303 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140303
10:35:40.304 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-498
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.304 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-498] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.304 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-498] Instantiated an idempotent producer.
10:35:40.305 [kafka-producer-network-thread | producer-497] INFO TransactionManager - [Producer clientId=producer-497] ProducerId set to 1519 with epoch 0
10:35:40.305 [kafka-producer-network-thread | producer-497] INFO Metadata - [Producer clientId=producer-497] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.306 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.306 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.306 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.306 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140306
10:35:40.306 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-499
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.306 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-499] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.306 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-499] Instantiated an idempotent producer.
10:35:40.307 [kafka-producer-network-thread | producer-498] INFO Metadata - [Producer clientId=producer-498] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.307 [kafka-producer-network-thread | producer-498] INFO TransactionManager - [Producer clientId=producer-498] ProducerId set to 1520 with epoch 0
10:35:40.308 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.308 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.308 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.308 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140308
10:35:40.308 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-500
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.309 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-500] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.309 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-500] Instantiated an idempotent producer.
10:35:40.309 [kafka-producer-network-thread | producer-499] INFO Metadata - [Producer clientId=producer-499] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.310 [kafka-producer-network-thread | producer-499] INFO TransactionManager - [Producer clientId=producer-499] ProducerId set to 505 with epoch 0
10:35:40.310 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.311 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.311 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.311 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140311
10:35:40.311 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-501
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.311 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-501] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.311 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-501] Instantiated an idempotent producer.
10:35:40.312 [kafka-producer-network-thread | producer-500] INFO Metadata - [Producer clientId=producer-500] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.312 [kafka-producer-network-thread | producer-500] INFO TransactionManager - [Producer clientId=producer-500] ProducerId set to 506 with epoch 0
10:35:40.313 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.313 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.313 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.313 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140313
10:35:40.313 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-502
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.314 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-502] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.314 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-502] Instantiated an idempotent producer.
10:35:40.315 [kafka-producer-network-thread | producer-501] INFO Metadata - [Producer clientId=producer-501] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.315 [kafka-producer-network-thread | producer-501] INFO TransactionManager - [Producer clientId=producer-501] ProducerId set to 1521 with epoch 0
10:35:40.315 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.315 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.315 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.315 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140315
10:35:40.316 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-503
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.316 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-503] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.316 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-503] Instantiated an idempotent producer.
10:35:40.317 [kafka-producer-network-thread | producer-502] INFO Metadata - [Producer clientId=producer-502] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.317 [kafka-producer-network-thread | producer-502] INFO TransactionManager - [Producer clientId=producer-502] ProducerId set to 2506 with epoch 0
10:35:40.318 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.318 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.318 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.318 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140318
10:35:40.318 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-504
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.318 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-504] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.318 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-504] Instantiated an idempotent producer.
10:35:40.319 [kafka-producer-network-thread | producer-503] INFO Metadata - [Producer clientId=producer-503] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.319 [kafka-producer-network-thread | producer-503] INFO TransactionManager - [Producer clientId=producer-503] ProducerId set to 1522 with epoch 0
10:35:40.320 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.320 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.320 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.320 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140320
10:35:40.321 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-505
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.321 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-505] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.321 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-505] Instantiated an idempotent producer.
10:35:40.321 [kafka-producer-network-thread | producer-504] INFO Metadata - [Producer clientId=producer-504] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.322 [kafka-producer-network-thread | producer-504] INFO TransactionManager - [Producer clientId=producer-504] ProducerId set to 507 with epoch 0
10:35:40.323 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.323 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.323 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.323 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140323
10:35:40.323 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-506
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.323 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-506] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.323 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-506] Instantiated an idempotent producer.
10:35:40.324 [kafka-producer-network-thread | producer-505] INFO Metadata - [Producer clientId=producer-505] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.324 [kafka-producer-network-thread | producer-505] INFO TransactionManager - [Producer clientId=producer-505] ProducerId set to 508 with epoch 0
10:35:40.325 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.325 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.325 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.325 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140325
10:35:40.325 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-507
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.326 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-507] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.326 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-507] Instantiated an idempotent producer.
10:35:40.326 [kafka-producer-network-thread | producer-506] INFO Metadata - [Producer clientId=producer-506] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.326 [kafka-producer-network-thread | producer-506] INFO TransactionManager - [Producer clientId=producer-506] ProducerId set to 1523 with epoch 0
10:35:40.327 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.327 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.327 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.327 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140327
10:35:40.328 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-508
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.328 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-508] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.328 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-508] Instantiated an idempotent producer.
10:35:40.328 [kafka-producer-network-thread | producer-507] INFO Metadata - [Producer clientId=producer-507] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.329 [kafka-producer-network-thread | producer-507] INFO TransactionManager - [Producer clientId=producer-507] ProducerId set to 509 with epoch 0
10:35:40.330 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.330 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.330 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.330 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140330
10:35:40.330 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-509
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.330 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-509] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.330 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-509] Instantiated an idempotent producer.
10:35:40.331 [kafka-producer-network-thread | producer-508] INFO Metadata - [Producer clientId=producer-508] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.331 [kafka-producer-network-thread | producer-508] INFO TransactionManager - [Producer clientId=producer-508] ProducerId set to 2507 with epoch 0
10:35:40.332 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.332 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.332 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.332 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140332
10:35:40.332 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-510
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.333 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-510] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.333 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-510] Instantiated an idempotent producer.
10:35:40.334 [kafka-producer-network-thread | producer-509] INFO Metadata - [Producer clientId=producer-509] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.334 [kafka-producer-network-thread | producer-509] INFO TransactionManager - [Producer clientId=producer-509] ProducerId set to 2508 with epoch 0
10:35:40.334 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.334 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.334 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.334 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140334
10:35:40.335 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-511
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.335 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-511] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.335 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-511] Instantiated an idempotent producer.
10:35:40.336 [kafka-producer-network-thread | producer-510] INFO Metadata - [Producer clientId=producer-510] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.336 [kafka-producer-network-thread | producer-510] INFO TransactionManager - [Producer clientId=producer-510] ProducerId set to 510 with epoch 0
10:35:40.337 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.337 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.337 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.337 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140337
10:35:40.337 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-512
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.338 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-512] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.338 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-512] Instantiated an idempotent producer.
10:35:40.339 [kafka-producer-network-thread | producer-511] INFO Metadata - [Producer clientId=producer-511] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.339 [kafka-producer-network-thread | producer-511] INFO TransactionManager - [Producer clientId=producer-511] ProducerId set to 1524 with epoch 0
10:35:40.340 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.340 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.340 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.340 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140340
10:35:40.340 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-513
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.341 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-513] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.341 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-513] Instantiated an idempotent producer.
10:35:40.341 [kafka-producer-network-thread | producer-512] INFO Metadata - [Producer clientId=producer-512] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.342 [kafka-producer-network-thread | producer-512] INFO TransactionManager - [Producer clientId=producer-512] ProducerId set to 1525 with epoch 0
10:35:40.342 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.343 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.343 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.343 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140343
10:35:40.343 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-514
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.343 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-514] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.344 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-514] Instantiated an idempotent producer.
10:35:40.344 [kafka-producer-network-thread | producer-513] INFO Metadata - [Producer clientId=producer-513] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.344 [kafka-producer-network-thread | producer-513] INFO TransactionManager - [Producer clientId=producer-513] ProducerId set to 511 with epoch 0
10:35:40.345 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.345 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.345 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.345 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140345
10:35:40.346 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-515
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.346 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-515] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.346 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-515] Instantiated an idempotent producer.
10:35:40.346 [kafka-producer-network-thread | producer-514] INFO Metadata - [Producer clientId=producer-514] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.347 [kafka-producer-network-thread | producer-514] INFO TransactionManager - [Producer clientId=producer-514] ProducerId set to 2509 with epoch 0
10:35:40.348 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.348 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.348 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.348 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140348
10:35:40.348 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-516
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.348 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-516] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.349 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-516] Instantiated an idempotent producer.
10:35:40.349 [kafka-producer-network-thread | producer-515] INFO Metadata - [Producer clientId=producer-515] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.349 [kafka-producer-network-thread | producer-515] INFO TransactionManager - [Producer clientId=producer-515] ProducerId set to 512 with epoch 0
10:35:40.350 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.350 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.350 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.350 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140350
10:35:40.351 [qtp235162442-29] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.162:9092, 10.0.0.131:9092, 10.0.0.91:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-517
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

10:35:40.351 [qtp235162442-29] WARN KafkaProducer - [Producer clientId=producer-517] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
10:35:40.351 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-517] Instantiated an idempotent producer.
10:35:40.351 [kafka-producer-network-thread | producer-516] INFO Metadata - [Producer clientId=producer-516] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.351 [kafka-producer-network-thread | producer-516] INFO TransactionManager - [Producer clientId=producer-516] ProducerId set to 1526 with epoch 0
10:35:40.353 [qtp235162442-29] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
10:35:40.353 [qtp235162442-29] INFO AppInfoParser - Kafka version: 3.6.1
10:35:40.353 [qtp235162442-29] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
10:35:40.353 [qtp235162442-29] INFO AppInfoParser - Kafka startTimeMs: 1716806140353
10:35:40.354 [kafka-producer-network-thread | producer-517] INFO Metadata - [Producer clientId=producer-517] Cluster ID: XhHaNLtfTGiln-MRq5UUGg
10:35:40.354 [kafka-producer-network-thread | producer-517] INFO TransactionManager - [Producer clientId=producer-517] ProducerId set to 1527 with epoch 0
10:35:40.357 [qtp235162442-29] INFO LocalWorker - Created 523 producers in 1763.480418 ms from {
  "topics" : [ "test-topic-0000000-V_-J4Ns", "test-topic-0000001-_L2etTM", "test-topic-0000002-mWviUz4", "test-topic-0000003-uwAasiE", "test-topic-0000004-_jh6Paw", "test-topic-0000005-zLcoUuQ", "test-topic-0000006-TuXPgEs", "test-topic-0000007-hcTxvVI", "test-topic-0000008-1b4q-6A", "test-topic-0000009-kq5W4ws", "test-topic-0000010-U6HXPng", "test-topic-0000011-Cay-DAA", "test-topic-0000012-Ng5Acgs", "test-topic-0000013-upYB7Dk", "test-topic-0000014-ChReB10", "test-topic-0000015-zGJ8u9I", "test-topic-0000016-MLlCoec", "test-topic-0000017-herdNUY", "test-topic-0000018-zd2LNnc", "test-topic-0000019-aCPUnu8", "test-topic-0000020-BckBXFM", "test-topic-0000021-hBCvCM0", "test-topic-0000022-adVjIaQ", "test-topic-0000023-CgaQHoY", "test-topic-0000024-rfDuPhI", "test-topic-0000025-IRIRha0", "test-topic-0000026-nuKfo6s", "test-topic-0000027-9p659UY", "test-topic-0000028-Uo_eHQg", "test-topic-0000029-FqJSgYk", "test-topic-0000030-oKheqbI", "test-topic-0000031-_-x9Y-Y", "test-topic-0000032-0oLVaME", "test-topic-0000033-83IZ3Ek", "test-topic-0000034-mQDs78Y", "test-topic-0000035-D5gwAp8", "test-topic-0000036-QcrO7Oo", "test-topic-0000037-nN3KNZc", "test-topic-0000038-JUQumFc", "test-topic-0000039-pX8IC6w", "test-topic-0000040-ZPiiadY", "test-topic-0000041-ydfyZmM", "test-topic-0000042-1GeCLLg", "test-topic-0000043-UplvRtE", "test-topic-0000044-NnZ7sfo", "test-topic-0000045-hToj12A", "test-topic-0000046-q-UQa6M", "test-topic-0000047-Ox8AStE", "test-topic-0000048-ZpV7aXE", "test-topic-0000049-sFgFDYQ", "test-topic-0000050-o3flfLQ", "test-topic-0000051-mg6J7vc", "test-topic-0000052-2HKJDng", "test-topic-0000053-feWXbYw", "test-topic-0000054-KaJTQek", "test-topic-0000055-PfazGY4", "test-topic-0000056-IKlglPM", "test-topic-0000057-9CrTJXU", "test-topic-0000058-nA5y_Cg", "test-topic-0000059-BRUmEGk", "test-topic-0000060-CtNY0Oc", "test-topic-0000061-cZAtpwQ", "test-topic-0000062-07W2Brk", "test-topic-0000063-acg2hlw", "test-topic-0000064-Fd6J5P4", "test-topic-0000065-I3G69EA", "test-topic-0000066-lNr9Esg", "test-topic-0000067-8UqVjsA", "test-topic-0000068-8iw4CwY", "test-topic-0000069-jkLdO_I", "test-topic-0000070-HtSFP-Q", "test-topic-0000071-u8J3V_M", "test-topic-0000072-CoqydXI", "test-topic-0000073-CgvL2Cw", "test-topic-0000074-oKipbYM", "test-topic-0000075--J8tYNY", "test-topic-0000076-9ukLbdc", "test-topic-0000077-QShU9L8", "test-topic-0000078-v3dkS3w", "test-topic-0000079-cEsvck0", "test-topic-0000080-BP5ahnA", "test-topic-0000081-tWWwXcM", "test-topic-0000082-FLXnEIs", "test-topic-0000083--iQFMsM", "test-topic-0000084-uZZph5s", "test-topic-0000085-N2NHIBM", "test-topic-0000086-rDLOM9A", "test-topic-0000087-BdKfjaM", "test-topic-0000088-Stb9i1o", "test-topic-0000089-cUuvms4", "test-topic-0000090-hvu1OFA", "test-topic-0000091-E9z7puA", "test-topic-0000092-ITMnF9M", "test-topic-0000093-Xtpbidg", "test-topic-0000094-Gf5KW3M", "test-topic-0000095-OJ8qG24", "test-topic-0000096-Xko5_9E", "test-topic-0000097-zLO3jFY", "test-topic-0000098-y4YM_IQ", "test-topic-0000099-n4gar8Y", "test-topic-0000100-U4JejkA", "test-topic-0000101-4QmiLzY", "test-topic-0000102-e4pXojU", "test-topic-0000103-BaW4fGY", "test-topic-0000104-B33sxLQ", "test-topic-0000105-k5OKWKU", "test-topic-0000106--MB_6Bg", "test-topic-0000107-PH9FtE8", "test-topic-0000108-tVrkZeM", "test-topic-0000109-LtOlXJY", "test-topic-0000110-h48B1yY", "test-topic-0000111-qk735oU", "test-topic-0000112-SsxIWSY", "test-topic-0000113-06zzoUI", "test-topic-0000114-YcMWCzw", "test-topic-0000115-x3VDmZM", "test-topic-0000116-6vUz-_0", "test-topic-0000117-80wS2qM", "test-topic-0000118-Mhw4hJk", "test-topic-0000119-olBpjAQ", "test-topic-0000120-ayHXIYg", "test-topic-0000121-114XZfc", "test-topic-0000122-nKZVG2I", "test-topic-0000123-XVMYyOs", "test-topic-0000124-2EDO_w4", "test-topic-0000125-HJPpWEM", "test-topic-0000126-subPdR8", "test-topic-0000127-rXhL7lw", "test-topic-0000128-70Bxi3o", "test-topic-0000129-L3bU_s4", "test-topic-0000130-fdJ7vTs", "test-topic-0000131-WwC0zPA", "test-topic-0000132-pCsNv9k", "test-topic-0000133-1ZZQVqE", "test-topic-0000134-epw7hoc", "test-topic-0000135-xX1NcEU", "test-topic-0000136-nBov2d0", "test-topic-0000137-pvw5UQ4", "test-topic-0000138-Gk72ELc", "test-topic-0000139-XTb1OHw", "test-topic-0000140-s_lqv10", "test-topic-0000141-je7uCiY", "test-topic-0000142-QTL4iuM", "test-topic-0000143-KdAejLo", "test-topic-0000144-dhlIydM", "test-topic-0000145-SgkRMUE", "test-topic-0000146-yA8GAAg", "test-topic-0000147-QlAAz6c", "test-topic-0000148-qpE9hNw", "test-topic-0000149-8KXiMXo", "test-topic-0000150-_DOtdIU", "test-topic-0000151-VWnPQfI", "test-topic-0000152-w3PodLw", "test-topic-0000153-Z5B6iTE", "test-topic-0000154-HE2aBZ8", "test-topic-0000155-JRrqLso", "test-topic-0000156-bc3ldNc", "test-topic-0000157-6w1ItIc", "test-topic-0000158-3hQB-P0", "test-topic-0000159-BpwEomY", "test-topic-0000160-B3v6Dzk", "test-topic-0000161-izOh4uU", "test-topic-0000162-6speXiw", "test-topic-0000163-ZKG2hH8", "test-topic-0000164-I8pyLg8", "test-topic-0000165-q4xVhnU", "test-topic-0000166-Xn8hVBw", "test-topic-0000167-OuQBj9E", "test-topic-0000168-COzjbSw", "test-topic-0000169-ghF_OKc", "test-topic-0000170-SC3-2aE", "test-topic-0000171-nASs854", "test-topic-0000172-MDi5xIU", "test-topic-0000173-nW0LQ64", "test-topic-0000174-L6X_C_M", "test-topic-0000175-LbeFESo", "test-topic-0000176-yj43cLU", "test-topic-0000177-Wpa3TgE", "test-topic-0000178-i0eYwS4", "test-topic-0000179-qUP5u0A", "test-topic-0000180-Oavet3o", "test-topic-0000181-brF3U9o", "test-topic-0000182-SI9Ap9M", "test-topic-0000183-XVN63qs", "test-topic-0000184-k_ZYxDY", "test-topic-0000185-YEuF7ro", "test-topic-0000186-SGxsiEU", "test-topic-0000187-qg-xV74", "test-topic-0000188-IupYo24", "test-topic-0000189-C96NruM", "test-topic-0000190-3m3hz00", "test-topic-0000191-hZB66s0", "test-topic-0000192-5_EYlU8", "test-topic-0000193-IKe7u9w", "test-topic-0000194-U723O5c", "test-topic-0000195--poYDLI", "test-topic-0000196-Ej9h6yQ", "test-topic-0000197-oc6SfvE", "test-topic-0000198-ZOiPYTM", "test-topic-0000199-pa8qKEk", "test-topic-0000200-i7o_FeE", "test-topic-0000201-Z93cjbE", "test-topic-0000202-wnvH5hQ", "test-topic-0000203-N2lKrPM", "test-topic-0000204-bcfb7Zw", "test-topic-0000205-noMcOW4", "test-topic-0000206-kW22P5Q", "test-topic-0000207-9yplzhc", "test-topic-0000208-hdUPCA4", "test-topic-0000209-RK9DesA", "test-topic-0000210-6Vc_YO4", "test-topic-0000211-Ph8tip0", "test-topic-0000212-18OyexY", "test-topic-0000213-rfKl9gM", "test-topic-0000214-WIM8B8M", "test-topic-0000215--oU7w3E", "test-topic-0000216-GRO7rDY", "test-topic-0000217-Ajth_NQ", "test-topic-0000218-XsGTNZY", "test-topic-0000219-LFO-0gY", "test-topic-0000220-N-ilnxQ", "test-topic-0000221-vda2Fpc", "test-topic-0000222-8Bb78FA", "test-topic-0000223-ah3LCNA", "test-topic-0000224-zd7Lsfo", "test-topic-0000225-LswO6fQ", "test-topic-0000226-9ja4qbw", "test-topic-0000227-XVyx0sk", "test-topic-0000228-sKuN91c", "test-topic-0000229--X-ffVY", "test-topic-0000230-zszkeQw", "test-topic-0000231-RPflSO0", "test-topic-0000232-Zo-CFTw", "test-topic-0000233-lqvzGWs", "test-topic-0000234-xpYB_FI", "test-topic-0000235-cCNi4L4", "test-topic-0000236-qJgSJeA", "test-topic-0000237-0KPI-Kc", "test-topic-0000238-pVDipQg", "test-topic-0000239-xpKP3MA", "test-topic-0000240-57YmGB0", "test-topic-0000241-R-_-_cA", "test-topic-0000242-I248bIk", "test-topic-0000243-QPIb6P4", "test-topic-0000244-xZzYGvA", "test-topic-0000245-7iyXljM", "test-topic-0000246-bKVi8pU", "test-topic-0000247-bLhN7IM", "test-topic-0000248-mHJMpfw", "test-topic-0000249-jUr1e74", "test-topic-0000250-oUn3sNE", "test-topic-0000251-60O01-I", "test-topic-0000252-6lgeSwg", "test-topic-0000253-QAvk_uQ", "test-topic-0000254-VnWfTUU", "test-topic-0000255-80lNhq8", "test-topic-0000256--7oN2X0", "test-topic-0000257-9t0S1Gw", "test-topic-0000258-FQUB1dw", "test-topic-0000259-zpR5ZgQ", "test-topic-0000260-PXHQ_Ok", "test-topic-0000261-8gMIGeI", "test-topic-0000262-2mGVp-c", "test-topic-0000263-WRJbx_0", "test-topic-0000264-17M3hn4", "test-topic-0000265-TgfBbRU", "test-topic-0000266-lhsbsZo", "test-topic-0000267-hjJ29jw", "test-topic-0000268-JN0QTJM", "test-topic-0000269-c4F7jJc", "test-topic-0000270-rVOw8Y4", "test-topic-0000271-2pWwc2U", "test-topic-0000272-Mfxr4iI", "test-topic-0000273-ozFgvkE", "test-topic-0000274-d_ffdj4", "test-topic-0000275-7wsHjKM", "test-topic-0000276-Qjcym0k", "test-topic-0000277-cGMK6aw", "test-topic-0000278-wsorooo", "test-topic-0000279-9OGUnCI", "test-topic-0000280-Tf41vck", "test-topic-0000281-QaUltrg", "test-topic-0000282-TkLdATY", "test-topic-0000283-KIHGGJM", "test-topic-0000284-fQ0neYo", "test-topic-0000285-1M6bgwk", "test-topic-0000286-UC4nEGw", "test-topic-0000287-Yl3RL6s", "test-topic-0000288-sD8U5xU", "test-topic-0000289-tlcNYIU", "test-topic-0000290-8DTi4zY", "test-topic-0000291-jDPLlqM", "test-topic-0000292--jBlQhg", "test-topic-0000293-zf2NVNc", "test-topic-0000294-yxxuPQU", "test-topic-0000295-I5j6jbk", "test-topic-0000296-ILF1reY", "test-topic-0000297-z7vfoe8", "test-topic-0000298-ceeBYS0", "test-topic-0000299-udU6sa4", "test-topic-0000300-HgY9AfQ", "test-topic-0000301-yA-mZIA", "test-topic-0000302-6Lv04mY", "test-topic-0000303-dBuNhEc", "test-topic-0000304-ov6qkF0", "test-topic-0000305-mJFLSYE", "test-topic-0000306-J6HJ000", "test-topic-0000307-jPsw980", "test-topic-0000308-jtSkUl8", "test-topic-0000309-c9mTla0", "test-topic-0000310-nAgI1eA", "test-topic-0000311-0DneSIw", "test-topic-0000312-ed_LmNw", "test-topic-0000313-X7YT0wM", "test-topic-0000314-pygrJAY", "test-topic-0000315-Iur51Vc", "test-topic-0000316-Lxd4VNo", "test-topic-0000317-ubQJ00Y", "test-topic-0000318-HCcyFAU", "test-topic-0000319-9t7gUAI", "test-topic-0000320-LWaQ7gQ", "test-topic-0000321-sPRQmX0", "test-topic-0000322-xRObVwo", "test-topic-0000323-12eh1-c", "test-topic-0000324-Jswq4iY", "test-topic-0000325-yVBo-XQ", "test-topic-0000326-3rLSH6U", "test-topic-0000327-41--JmI", "test-topic-0000328-gFAenbQ", "test-topic-0000329-WdTHVTo", "test-topic-0000330-lxfjXUo", "test-topic-0000331-SozV4lU", "test-topic-0000332-2MTwpEQ", "test-topic-0000333-DoL-_qE", "test-topic-0000334-lg5rX9A", "test-topic-0000335-0kpDlKU", "test-topic-0000336-elfKoQ8", "test-topic-0000337-Z2pSJcI", "test-topic-0000338-clgomvY", "test-topic-0000339-VpAdebs", "test-topic-0000340-6fVYvHQ", "test-topic-0000341-NxLdLHY", "test-topic-0000342-ObSet9k", "test-topic-0000343-QjcgwwM", "test-topic-0000344-XX_NrnY", "test-topic-0000345-Jileed0", "test-topic-0000346-67ml2YA", "test-topic-0000347-GZ5kMHA", "test-topic-0000348-QMdcBDk", "test-topic-0000349-MJA-dNs", "test-topic-0000350-_ITnn1E", "test-topic-0000351-8JX-LvY", "test-topic-0000352-sGfuRYg", "test-topic-0000353-JLB9pJY", "test-topic-0000354-1i6arZg", "test-topic-0000355-8KDY5A8", "test-topic-0000356-AWTjPVI", "test-topic-0000357-JiCDLfo", "test-topic-0000358-VRn-TQc", "test-topic-0000359-14Bphjc", "test-topic-0000360-OJseECk", "test-topic-0000361-LZwO7zU", "test-topic-0000362-SQlrXTA", "test-topic-0000363-eBUdYHA", "test-topic-0000364-kAq5nsI", "test-topic-0000365-hUvAzTs", "test-topic-0000366-9xD2yw0", "test-topic-0000367-NouK178", "test-topic-0000368--d8Ll3c", "test-topic-0000369-T1fzYEM", "test-topic-0000370-mEr65Xk", "test-topic-0000371-jdnRcq0", "test-topic-0000372-lFz6jcg", "test-topic-0000373-_NDkX0c", "test-topic-0000374-2WIODrU", "test-topic-0000375-ipG6pcY", "test-topic-0000376-OIelxdU", "test-topic-0000377-1uhgrYg", "test-topic-0000378-WvMwu-Q", "test-topic-0000379-TfxtvR0", "test-topic-0000380-8a7zkeY", "test-topic-0000381-eHRwzgk", "test-topic-0000382-L601XY4", "test-topic-0000383-jonmxMc", "test-topic-0000384-e72V1OQ", "test-topic-0000385-UMXA7Q8", "test-topic-0000386-YlO9QCE", "test-topic-0000387-Fo5upVs", "test-topic-0000388-y1l0tN0", "test-topic-0000389-JM-_Sqc", "test-topic-0000390-boVCq2s", "test-topic-0000391-QVLIF3k", "test-topic-0000392-h9quh4M", "test-topic-0000393-ip6mGCA", "test-topic-0000394-xlkFLyI", "test-topic-0000395-g3DZMz8", "test-topic-0000396-iQiW4q0", "test-topic-0000397-bh_sXo0", "test-topic-0000398-TMjfpVw", "test-topic-0000399-34PzjdU", "test-topic-0000400-X7FM4dU", "test-topic-0000401-kDPaYUQ", "test-topic-0000402-2uRMWRc", "test-topic-0000403-cSYU2uM", "test-topic-0000404-zgn4DJk", "test-topic-0000405-Axk_d2E", "test-topic-0000406-veksnbI", "test-topic-0000407-5j-2_hY", "test-topic-0000408-S-CpsDs", "test-topic-0000409-sCB18EQ", "test-topic-0000410-NBIQinI", "test-topic-0000411-_6MOWp8", "test-topic-0000412-gJ9uDSE", "test-topic-0000413-0bQ68A4", "test-topic-0000414-9UQSk_8", "test-topic-0000415-EgHOvbM", "test-topic-0000416-zSApoFU", "test-topic-0000417-dq8UmCk", "test-topic-0000418-qY6RauQ", "test-topic-0000419-iR7CTgw", "test-topic-0000420-xU4mlwU", "test-topic-0000421-AwE19r0", "test-topic-0000422-bGxJCBI", "test-topic-0000423-YGvwBmY", "test-topic-0000424-rZeSqAQ", "test-topic-0000425-sKYfgjs", "test-topic-0000426-Tuacql0", "test-topic-0000427-q9wDEgM", "test-topic-0000428-ADA7tkg", "test-topic-0000429-CPGHw9Y", "test-topic-0000430-1HkZXP0", "test-topic-0000431-DhwonSg", "test-topic-0000432-7SRFDmo", "test-topic-0000433-ahog9AU", "test-topic-0000434-d9R83Q8", "test-topic-0000435-Qwas_J4", "test-topic-0000436-1z7Eoyk", "test-topic-0000437-iy1VCgM", "test-topic-0000438-I17H0xI", "test-topic-0000439-mHkFOzE", "test-topic-0000440-1LNbTec", "test-topic-0000441-8jsxoE8", "test-topic-0000442-upMlwWs", "test-topic-0000443-bnQQPjQ", "test-topic-0000444-L6pS8yo", "test-topic-0000445-e-Tdli0", "test-topic-0000446-jzG6nuE", "test-topic-0000447-u4OjsPw", "test-topic-0000448-54rGmRw", "test-topic-0000449-1SmBLCI", "test-topic-0000450-7C2T5CE", "test-topic-0000451-iYHTx2A", "test-topic-0000452-LSTlXgw", "test-topic-0000453-BJlud3s", "test-topic-0000454-jINTbDs", "test-topic-0000455-daOAzEA", "test-topic-0000456-6ptY2Os", "test-topic-0000457-37_m3sc", "test-topic-0000458-Icxb4iM", "test-topic-0000459-MNkGC_s", "test-topic-0000460-NzJPttA", "test-topic-0000461-k_PeNlk", "test-topic-0000462-z6p7aDE", "test-topic-0000463-AnsrbPc", "test-topic-0000464-4tPINXU", "test-topic-0000465-HmeLmcc", "test-topic-0000466-rwZ2pKE", "test-topic-0000467-Qkiigxw", "test-topic-0000468-8HwUt7c", "test-topic-0000469-1ZGl9m0", "test-topic-0000470-TRXisxQ", "test-topic-0000471-37XDUVk", "test-topic-0000472-FWunwBk", "test-topic-0000473-3uWoles", "test-topic-0000474-KzUzZg0", "test-topic-0000475-2oxOTx4", "test-topic-0000476-PiC40UI", "test-topic-0000477-t9Z_daM", "test-topic-0000478-PJjxrHU", "test-topic-0000479-ydhOm-E", "test-topic-0000480-BzVHq3o", "test-topic-0000481-rS9biTw", "test-topic-0000482-ab5taRg", "test-topic-0000483-ViaETJk", "test-topic-0000484-Rft_ITE", "test-topic-0000485-ZrqtTyI", "test-topic-0000486-EMB4niY", "test-topic-0000487-vhHh-EY", "test-topic-0000488-fvCaGnk", "test-topic-0000489-WDWGJQM", "test-topic-0000490-f2jrk7M", "test-topic-0000491-UyX-fmc", "test-topic-0000492-bACsG4c", "test-topic-0000493-T5rBBVM", "test-topic-0000494-fSAGqTc", "test-topic-0000495--wea_oI", "test-topic-0000496-f5cGpzY", "test-topic-0000497-67TPGMk", "test-topic-0000498-wqjzaQ4", "test-topic-0000499-rvuAtqA", "test-topic-0000500-V4Uhu4M", "test-topic-0000501-HwkEl-A", "test-topic-0000502-e6T4-_g", "test-topic-0000503--6t1L80", "test-topic-0000504-Ta8k9BI", "test-topic-0000505-tAmtBFc", "test-topic-0000506-x_MZG5s" ],
  "producerIndex" : 0,
  "isTpcH" : true
}
10:35:40.359 [main] INFO WorkloadGenerator - Created 507 producers in 1778.051935 ms
10:35:40.360 [main] INFO WorkloadGenerator - Waiting for consumers to be ready...
10:35:41.326 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-003-nQrvCqU-4-7d3ed392-4827-466f-b22a-a7e27fc26b82', protocol='range'}
10:35:41.326 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Finished assignment for group at generation 1: {consumer-sub-003-nQrvCqU-4-1c0e3489-8620-46d5-a091-3acdaa699e69=Assignment(partitions=[test-topic-0000003-uwAasiE-0]), consumer-sub-003-nQrvCqU-4-ec6d0c36-7e2c-4190-9daf-2fc62141c8d9=Assignment(partitions=[]), consumer-sub-003-nQrvCqU-4-7d3ed392-4827-466f-b22a-a7e27fc26b82=Assignment(partitions=[])}
10:35:41.327 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-005-O3eWxIY-6-ec23536a-0ba0-4b4a-868e-cb46ba0ae817', protocol='range'}
10:35:41.327 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-001-Sc_ClX8-2-1690bdac-c0fe-4257-aa15-68c897f71ce8', protocol='range'}
10:35:41.327 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Finished assignment for group at generation 1: {consumer-sub-005-O3eWxIY-6-d142a9f4-9b31-487d-9df7-7bec51e88b36=Assignment(partitions=[]), consumer-sub-005-O3eWxIY-6-5a614e3a-8d61-483f-a189-bdc762790a72=Assignment(partitions=[test-topic-0000005-zLcoUuQ-0]), consumer-sub-005-O3eWxIY-6-ec23536a-0ba0-4b4a-868e-cb46ba0ae817=Assignment(partitions=[])}
10:35:41.328 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Finished assignment for group at generation 1: {consumer-sub-001-Sc_ClX8-2-2f202406-02ba-403d-bf0f-94303fe9959d=Assignment(partitions=[]), consumer-sub-001-Sc_ClX8-2-1690bdac-c0fe-4257-aa15-68c897f71ce8=Assignment(partitions=[test-topic-0000001-_L2etTM-0]), consumer-sub-001-Sc_ClX8-2-f3fd309e-4e66-43ce-9667-1071a4be0abc=Assignment(partitions=[])}
10:35:41.328 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-002--gDe5LI-3-42165364-8a79-4795-9dd3-bb0dcc960d7f', protocol='range'}
10:35:41.328 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Finished assignment for group at generation 1: {consumer-sub-002--gDe5LI-3-e9e278aa-83fd-46ca-b4ad-5d2de6d82a33=Assignment(partitions=[]), consumer-sub-002--gDe5LI-3-42165364-8a79-4795-9dd3-bb0dcc960d7f=Assignment(partitions=[]), consumer-sub-002--gDe5LI-3-2100443c-b6b7-4e82-8cfb-bdfad83ae60e=Assignment(partitions=[test-topic-0000002-mWviUz4-0])}
10:35:41.331 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-003-nQrvCqU-4-7d3ed392-4827-466f-b22a-a7e27fc26b82', protocol='range'}
10:35:41.331 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Notifying assignor about the new Assignment(partitions=[])
10:35:41.331 [pool-6-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Adding newly assigned partitions: 
10:35:41.332 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-001-Sc_ClX8-2-1690bdac-c0fe-4257-aa15-68c897f71ce8', protocol='range'}
10:35:41.332 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Notifying assignor about the new Assignment(partitions=[test-topic-0000001-_L2etTM-0])
10:35:41.332 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Adding newly assigned partitions: test-topic-0000001-_L2etTM-0
10:35:41.333 [pool-4-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Found no committed offset for partition test-topic-0000001-_L2etTM-0
10:35:41.334 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-005-O3eWxIY-6-ec23536a-0ba0-4b4a-868e-cb46ba0ae817', protocol='range'}
10:35:41.335 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Notifying assignor about the new Assignment(partitions=[])
10:35:41.335 [pool-8-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Adding newly assigned partitions: 
10:35:41.335 [pool-4-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Resetting offset for partition test-topic-0000001-_L2etTM-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.91:9092 (id: 2 rack: null)], epoch=0}}.
10:35:41.335 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-002--gDe5LI-3-42165364-8a79-4795-9dd3-bb0dcc960d7f', protocol='range'}
10:35:41.335 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Notifying assignor about the new Assignment(partitions=[])
10:35:41.335 [pool-5-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Adding newly assigned partitions: 
10:35:41.336 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-004-9YDQMtE-5-70fc8c8e-d3f6-4a37-9178-35555d22a998', protocol='range'}
10:35:41.337 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Finished assignment for group at generation 1: {consumer-sub-004-9YDQMtE-5-0535c9d0-dad0-45e3-88b7-8300b8ae635e=Assignment(partitions=[test-topic-0000004-_jh6Paw-0]), consumer-sub-004-9YDQMtE-5-c1de32f7-b998-4cca-ae59-e0f38254f397=Assignment(partitions=[]), consumer-sub-004-9YDQMtE-5-70fc8c8e-d3f6-4a37-9178-35555d22a998=Assignment(partitions=[])}
10:35:41.341 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-004-9YDQMtE-5-70fc8c8e-d3f6-4a37-9178-35555d22a998', protocol='range'}
10:35:41.341 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Notifying assignor about the new Assignment(partitions=[])
10:35:41.341 [pool-7-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Adding newly assigned partitions: 
10:35:41.385 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-000-veGIiUw-1-a42b0377-140f-458e-a983-e4386a3c47bb', protocol='range'}
10:35:41.385 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Finished assignment for group at generation 1: {consumer-sub-000-veGIiUw-1-a42b0377-140f-458e-a983-e4386a3c47bb=Assignment(partitions=[]), consumer-sub-000-veGIiUw-1-3d66d482-1834-4020-8541-d8607f32ac54=Assignment(partitions=[test-topic-0000000-V_-J4Ns-0]), consumer-sub-000-veGIiUw-1-89dd2fd9-4c46-4e62-83f8-2eda267fdbf7=Assignment(partitions=[])}
10:35:41.387 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-000-veGIiUw-1-a42b0377-140f-458e-a983-e4386a3c47bb', protocol='range'}
10:35:41.388 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Notifying assignor about the new Assignment(partitions=[])
10:35:41.388 [pool-3-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Adding newly assigned partitions: 
10:35:41.625 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Successfully joined group with generation Generation{generationId=1, memberId='consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3', protocol='range'}
10:35:41.635 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Finished assignment for group at generation 1: {consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3=Assignment(partitions=[test-topic-0000006-TuXPgEs-0])}
10:35:41.642 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Successfully synced group in generation Generation{generationId=1, memberId='consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3', protocol='range'}
10:35:41.643 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Notifying assignor about the new Assignment(partitions=[test-topic-0000006-TuXPgEs-0])
10:35:41.646 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Adding newly assigned partitions: test-topic-0000006-TuXPgEs-0
10:35:41.662 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Found no committed offset for partition test-topic-0000006-TuXPgEs-0
10:35:41.675 [pool-2-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Resetting offset for partition test-topic-0000006-TuXPgEs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:35:42.442 [main] INFO WorkloadGenerator - Waiting for topics to be ready -- Sent: 1550, Received: 1545, Expected: 0
10:35:42.442 [main] INFO WorkloadGenerator - All consumers are ready!
10:35:42.443 [main] INFO WorkloadGenerator - [BenchmarkStart] Starting benchmark Kafka-tpc-h-tpc-h-q6-10000-500-2024-05-27-10-35-31 at 1716806142443
10:35:42.468 [qtp235162442-28] INFO WorkerHandler - Start load publish-rate: 3333.3333333333335 msg/s -- payload-size: 0 -- producer index: 0
10:35:43.479 [local-worker-2-3] INFO LocalWorker - [TpcHBenchmark] Launched 417 completable futures. Awaiting...
10:35:43.480 [local-worker-2-4] INFO LocalWorker - [TpcHBenchmark] Launched 417 completable futures. Awaiting...
10:35:43.483 [local-worker-2-7] INFO LocalWorker - [TpcHBenchmark] Launched 417 completable futures. Awaiting...
10:35:43.489 [local-worker-2-2] INFO LocalWorker - [TpcHBenchmark] Launched 417 completable futures. Awaiting...
10:35:43.491 [local-worker-2-6] INFO LocalWorker - [TpcHBenchmark] Launched 417 completable futures. Awaiting...
10:35:43.498 [local-worker-2-5] INFO LocalWorker - [TpcHBenchmark] Launched 417 completable futures. Awaiting...
10:35:43.500 [local-worker-2-1] INFO LocalWorker - [TpcHBenchmark] Launched 417 completable futures. Awaiting...
10:35:43.501 [local-worker-2-8] INFO LocalWorker - [TpcHBenchmark] Launched 415 completable futures. Awaiting...
10:35:43.816 [local-worker-2-5] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-4 after sending 417 messages. Sleeping...
10:35:43.845 [local-worker-2-8] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-7 after sending 415 messages. Sleeping...
10:35:43.847 [local-worker-2-7] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-6 after sending 417 messages. Sleeping...
10:35:43.860 [local-worker-2-2] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-1 after sending 417 messages. Sleeping...
10:35:43.890 [local-worker-2-6] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-5 after sending 417 messages. Sleeping...
10:35:43.906 [local-worker-2-1] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-0 after sending 417 messages. Sleeping...
10:35:43.921 [local-worker-2-3] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-2 after sending 417 messages. Sleeping...
10:35:43.954 [local-worker-2-4] INFO LocalWorker - [TpcHBenchmark] Finished TPC-H producer 0-3 after sending 417 messages. Sleeping...
10:38:14.286 [pool-2-thread-1] INFO LocalWorker - [RESULT] TPC-H query result: {"rows":[{"columns":{"revenue":1106886908.0572}}]}
10:38:22.482 [main] INFO WorkloadGenerator - [BenchmarkEnd] Ending benchmark Kafka-tpc-h-tpc-h-q6-10000-500-2024-05-27-10-35-31 at 1716806302481
10:38:22.603 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.606 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.606 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.606 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.606 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-1 unregistered
10:38:22.607 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.608 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.608 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.608 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.608 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-2 unregistered
10:38:22.608 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.609 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.609 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.609 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.610 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-3 unregistered
10:38:22.610 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.611 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.611 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.611 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.611 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-4 unregistered
10:38:22.611 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.612 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.612 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.612 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.612 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-5 unregistered
10:38:22.612 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.613 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.613 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.613 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.614 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-6 unregistered
10:38:22.614 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.615 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.615 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.615 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.615 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-7 unregistered
10:38:22.615 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.616 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.617 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.617 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.617 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-8 unregistered
10:38:22.617 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.618 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.618 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.618 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.618 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-9 unregistered
10:38:22.618 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.619 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.619 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.619 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.619 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-10 unregistered
10:38:22.619 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.620 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.620 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.620 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.620 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-11 unregistered
10:38:22.620 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.621 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.621 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.621 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.621 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-12 unregistered
10:38:22.621 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.622 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.622 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.622 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.623 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-13 unregistered
10:38:22.623 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.624 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.624 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.624 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.624 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-14 unregistered
10:38:22.624 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.625 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.625 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.625 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.625 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-15 unregistered
10:38:22.625 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.626 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.626 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.626 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.626 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-16 unregistered
10:38:22.626 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.628 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.628 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.628 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.628 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-17 unregistered
10:38:22.628 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.629 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.629 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.629 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.629 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-18 unregistered
10:38:22.629 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.630 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.630 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.630 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.630 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-19 unregistered
10:38:22.630 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.631 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.631 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.631 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.631 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-20 unregistered
10:38:22.631 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.632 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.632 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.632 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.632 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-21 unregistered
10:38:22.632 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.633 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.633 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.633 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.633 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-22 unregistered
10:38:22.633 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.635 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.635 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.635 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.635 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-23 unregistered
10:38:22.635 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.636 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.636 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.636 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.636 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-24 unregistered
10:38:22.636 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.637 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.637 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.637 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.637 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-25 unregistered
10:38:22.637 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-26] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.638 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.638 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.638 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.638 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-26 unregistered
10:38:22.639 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.640 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.640 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.640 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.640 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-27 unregistered
10:38:22.640 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-28] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.641 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.641 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.642 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.642 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-28 unregistered
10:38:22.642 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.643 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.643 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.643 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.643 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-29 unregistered
10:38:22.643 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-30] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.644 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.644 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.644 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.644 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-30 unregistered
10:38:22.644 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-31] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.645 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.645 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.645 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.645 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-31 unregistered
10:38:22.645 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-32] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.646 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.646 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.646 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.646 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-32 unregistered
10:38:22.646 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-33] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.648 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.648 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.648 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.648 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-33 unregistered
10:38:22.648 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-34] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.649 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.649 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.649 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.649 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-34 unregistered
10:38:22.649 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-35] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.650 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.650 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.650 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.650 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-35 unregistered
10:38:22.650 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-36] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.651 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.651 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.651 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.652 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-36 unregistered
10:38:22.652 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-37] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.653 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.653 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.653 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.653 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-37 unregistered
10:38:22.653 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-38] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.654 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.654 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.654 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.654 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-38 unregistered
10:38:22.654 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-39] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.655 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.655 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.655 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.655 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-39 unregistered
10:38:22.655 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-40] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.656 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.657 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.657 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.657 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-40 unregistered
10:38:22.657 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-41] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.658 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.658 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.658 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.658 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-41 unregistered
10:38:22.658 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-42] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.659 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.659 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.659 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.659 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-42 unregistered
10:38:22.659 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-43] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.660 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.660 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.660 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.660 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-43 unregistered
10:38:22.660 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-44] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.661 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.661 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.661 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.661 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-44 unregistered
10:38:22.661 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-45] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.662 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.662 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.662 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.663 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-45 unregistered
10:38:22.663 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-46] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.664 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.664 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.664 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.664 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-46 unregistered
10:38:22.664 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-47] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.665 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.665 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.665 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.665 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-47 unregistered
10:38:22.665 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-48] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.666 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.666 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.666 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.666 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-48 unregistered
10:38:22.666 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-49] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.667 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.667 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.667 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.667 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-49 unregistered
10:38:22.667 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-50] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.668 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.668 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.668 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.668 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-50 unregistered
10:38:22.669 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-51] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.670 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.670 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.670 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.670 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-51 unregistered
10:38:22.670 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-52] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.671 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.671 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.671 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.671 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-52 unregistered
10:38:22.671 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-53] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.672 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.672 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.672 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.672 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-53 unregistered
10:38:22.672 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-54] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.673 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.673 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.674 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.674 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-54 unregistered
10:38:22.674 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-55] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.675 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.675 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.675 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.675 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-55 unregistered
10:38:22.675 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-56] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.676 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.676 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.676 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.676 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-56 unregistered
10:38:22.676 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-57] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.677 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.677 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.677 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.677 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-57 unregistered
10:38:22.677 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-58] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.678 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.678 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.678 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.678 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-58 unregistered
10:38:22.678 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-59] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.679 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.679 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.679 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.679 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-59 unregistered
10:38:22.679 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-60] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.680 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.680 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.680 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.680 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-60 unregistered
10:38:22.680 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-61] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.681 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.681 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.681 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.681 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-61 unregistered
10:38:22.681 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-62] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.683 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.683 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.683 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.683 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-62 unregistered
10:38:22.683 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-63] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.684 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.684 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.684 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.684 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-63 unregistered
10:38:22.684 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-64] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.685 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.685 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.685 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.685 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-64 unregistered
10:38:22.685 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-65] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.686 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.686 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.686 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.686 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-65 unregistered
10:38:22.686 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-66] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.688 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.688 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.688 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.688 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-66 unregistered
10:38:22.688 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-67] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.689 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.689 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.689 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.689 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-67 unregistered
10:38:22.689 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-68] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.690 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.690 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.690 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.690 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-68 unregistered
10:38:22.690 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-69] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.691 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.691 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.691 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.691 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-69 unregistered
10:38:22.691 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-70] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.692 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.693 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.693 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.693 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-70 unregistered
10:38:22.693 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-71] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.694 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.694 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.694 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.694 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-71 unregistered
10:38:22.694 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-72] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.695 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.695 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.695 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.695 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-72 unregistered
10:38:22.695 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-73] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.696 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.696 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.696 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.696 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-73 unregistered
10:38:22.696 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-74] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.697 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.697 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.697 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.697 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-74 unregistered
10:38:22.697 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-75] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.698 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.699 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.699 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.699 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-75 unregistered
10:38:22.699 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-76] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.700 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.700 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.700 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.700 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-76 unregistered
10:38:22.700 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-77] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.701 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.701 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.701 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.701 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-77 unregistered
10:38:22.701 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-78] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.702 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.702 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.702 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.703 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-78 unregistered
10:38:22.703 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-79] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.704 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.704 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.704 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.704 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-79 unregistered
10:38:22.704 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-80] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.705 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.705 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.705 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.705 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-80 unregistered
10:38:22.705 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-81] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.706 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.706 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.706 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.706 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-81 unregistered
10:38:22.706 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-82] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.707 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.707 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.707 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.708 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-82 unregistered
10:38:22.708 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-83] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.708 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.708 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.708 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.708 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-83 unregistered
10:38:22.709 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-84] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.709 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.709 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.709 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.709 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-84 unregistered
10:38:22.709 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-85] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.710 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.710 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.710 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.710 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-85 unregistered
10:38:22.710 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-86] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.711 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.711 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.711 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.712 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-86 unregistered
10:38:22.712 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-87] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.712 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.712 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.712 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.713 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-87 unregistered
10:38:22.713 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-88] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.713 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.713 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.713 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.713 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-88 unregistered
10:38:22.713 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-89] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.714 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.714 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.714 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.714 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-89 unregistered
10:38:22.714 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-90] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.716 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.716 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.716 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.716 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-90 unregistered
10:38:22.716 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-91] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.717 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.717 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.717 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.717 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-91 unregistered
10:38:22.717 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-92] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.718 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.718 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.718 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.718 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-92 unregistered
10:38:22.718 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-93] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.719 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.719 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.719 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.719 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-93 unregistered
10:38:22.719 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-94] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.720 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.720 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.720 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.720 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-94 unregistered
10:38:22.720 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-95] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.721 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.721 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.721 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.721 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-95 unregistered
10:38:22.721 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-96] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.722 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.722 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.722 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.722 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-96 unregistered
10:38:22.722 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-97] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.723 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.723 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.723 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.723 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-97 unregistered
10:38:22.723 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-98] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.724 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.724 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.724 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.724 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-98 unregistered
10:38:22.724 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-99] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.725 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.725 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.725 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.725 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-99 unregistered
10:38:22.725 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-100] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.726 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.726 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.726 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.726 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-100 unregistered
10:38:22.726 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-101] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.727 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.727 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.727 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.727 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-101 unregistered
10:38:22.727 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-102] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.728 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.728 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.728 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.728 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-102 unregistered
10:38:22.728 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-103] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.729 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.729 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.729 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.729 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-103 unregistered
10:38:22.729 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-104] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.730 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.730 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.730 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.730 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-104 unregistered
10:38:22.730 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-105] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.731 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.731 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.731 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.731 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-105 unregistered
10:38:22.731 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-106] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.732 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.732 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.732 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.732 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-106 unregistered
10:38:22.732 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-107] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.733 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.733 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.733 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.733 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-107 unregistered
10:38:22.733 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-108] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.734 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.734 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.734 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.734 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-108 unregistered
10:38:22.734 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-109] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.735 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.735 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.735 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.735 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-109 unregistered
10:38:22.735 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-110] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.736 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.736 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.736 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.736 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-110 unregistered
10:38:22.736 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-111] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.737 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.737 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.737 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.737 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-111 unregistered
10:38:22.737 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-112] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.738 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.738 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.738 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.738 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-112 unregistered
10:38:22.738 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-113] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.739 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.739 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.739 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.739 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-113 unregistered
10:38:22.739 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-114] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.740 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.740 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.740 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.740 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-114 unregistered
10:38:22.740 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-115] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.741 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.741 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.741 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.741 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-115 unregistered
10:38:22.741 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-116] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.742 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.742 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.742 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.742 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-116 unregistered
10:38:22.742 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-117] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.743 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.743 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.743 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.743 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-117 unregistered
10:38:22.743 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-118] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.745 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.745 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.745 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.745 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-118 unregistered
10:38:22.745 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-119] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.746 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.746 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.746 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.746 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-119 unregistered
10:38:22.746 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-120] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.747 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.747 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.747 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.747 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-120 unregistered
10:38:22.747 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-121] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.748 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.748 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.748 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.748 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-121 unregistered
10:38:22.748 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-122] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.749 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.749 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.749 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.749 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-122 unregistered
10:38:22.749 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-123] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.750 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.750 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.750 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.750 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-123 unregistered
10:38:22.750 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-124] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.751 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.751 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.751 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.751 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-124 unregistered
10:38:22.751 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-125] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.752 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.752 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.752 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.752 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-125 unregistered
10:38:22.752 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-126] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.753 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.753 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.753 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.753 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-126 unregistered
10:38:22.754 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-127] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.754 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.755 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.755 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.755 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-127 unregistered
10:38:22.755 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-128] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.756 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.756 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.756 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.756 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-128 unregistered
10:38:22.756 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-129] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.757 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.757 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.757 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.757 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-129 unregistered
10:38:22.757 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-130] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.758 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.758 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.758 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.758 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-130 unregistered
10:38:22.758 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-131] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.759 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.759 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.759 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.759 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-131 unregistered
10:38:22.759 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-132] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.760 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.760 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.760 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.760 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-132 unregistered
10:38:22.760 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-133] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.761 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.761 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.761 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.761 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-133 unregistered
10:38:22.761 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-134] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.762 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.762 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.762 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.762 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-134 unregistered
10:38:22.762 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-135] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.763 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.763 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.763 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.763 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-135 unregistered
10:38:22.763 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-136] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.764 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.764 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.764 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.764 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-136 unregistered
10:38:22.764 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-137] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.765 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.765 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.765 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.765 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-137 unregistered
10:38:22.765 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-138] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.766 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.766 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.766 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.766 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-138 unregistered
10:38:22.766 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-139] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.767 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.767 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.767 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.767 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-139 unregistered
10:38:22.767 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-140] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.768 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.768 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.768 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.768 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-140 unregistered
10:38:22.768 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-141] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.769 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.769 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.769 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.769 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-141 unregistered
10:38:22.769 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-142] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.769 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.769 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.769 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.770 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-142 unregistered
10:38:22.770 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-143] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.770 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.770 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.770 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.770 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-143 unregistered
10:38:22.770 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-144] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.771 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.771 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.771 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.771 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-144 unregistered
10:38:22.771 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-145] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.772 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.772 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.772 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.772 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-145 unregistered
10:38:22.772 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-146] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.773 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.773 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.773 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.773 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-146 unregistered
10:38:22.773 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-147] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.774 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.774 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.774 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.774 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-147 unregistered
10:38:22.774 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-148] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.775 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.775 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.775 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.775 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-148 unregistered
10:38:22.775 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-149] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.776 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.776 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.776 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.776 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-149 unregistered
10:38:22.776 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-150] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.777 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.777 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.777 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.777 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-150 unregistered
10:38:22.777 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-151] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.778 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.778 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.778 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.778 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-151 unregistered
10:38:22.778 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-152] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.779 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.779 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.779 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.779 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-152 unregistered
10:38:22.779 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-153] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.780 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.780 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.780 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.780 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-153 unregistered
10:38:22.780 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-154] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.781 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.781 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.781 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.781 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-154 unregistered
10:38:22.781 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-155] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.782 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.782 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.782 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.782 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-155 unregistered
10:38:22.782 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-156] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.783 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.783 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.783 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.783 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-156 unregistered
10:38:22.783 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-157] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.784 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.784 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.784 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.784 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-157 unregistered
10:38:22.784 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-158] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.785 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.785 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.785 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.785 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-158 unregistered
10:38:22.785 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-159] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.786 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.786 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.786 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.786 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-159 unregistered
10:38:22.786 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-160] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.787 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.787 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.787 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.787 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-160 unregistered
10:38:22.787 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-161] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.788 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.788 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.788 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.788 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-161 unregistered
10:38:22.788 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-162] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.789 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.789 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.789 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.789 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-162 unregistered
10:38:22.789 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-163] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.790 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.790 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.790 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.790 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-163 unregistered
10:38:22.790 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-164] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.791 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.791 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.791 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.791 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-164 unregistered
10:38:22.791 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-165] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.792 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.792 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.792 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.792 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-165 unregistered
10:38:22.792 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-166] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.793 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.793 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.793 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.793 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-166 unregistered
10:38:22.793 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-167] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.794 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.794 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.794 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.794 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-167 unregistered
10:38:22.794 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-168] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.795 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.795 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.795 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.795 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-168 unregistered
10:38:22.795 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-169] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.796 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.796 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.796 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.796 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-169 unregistered
10:38:22.796 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-170] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.797 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.797 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.797 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.797 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-170 unregistered
10:38:22.797 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-171] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.798 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.798 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.798 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.798 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-171 unregistered
10:38:22.798 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-172] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.799 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.799 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.799 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.799 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-172 unregistered
10:38:22.799 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-173] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.800 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.800 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.800 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.800 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-173 unregistered
10:38:22.800 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-174] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.801 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.801 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.801 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.801 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-174 unregistered
10:38:22.801 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-175] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.803 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.803 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.803 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.803 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-175 unregistered
10:38:22.803 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-176] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.804 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.804 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.804 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.804 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-176 unregistered
10:38:22.804 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-177] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.805 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.805 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.805 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.805 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-177 unregistered
10:38:22.805 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-178] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.805 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.805 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.805 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.805 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-178 unregistered
10:38:22.805 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-179] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.806 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.806 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.806 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.806 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-179 unregistered
10:38:22.806 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-180] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.807 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.807 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.807 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.807 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-180 unregistered
10:38:22.808 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-181] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.809 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.809 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.809 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.809 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-181 unregistered
10:38:22.809 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-182] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.810 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.810 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.810 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.810 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-182 unregistered
10:38:22.810 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-183] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.810 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.811 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.811 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.811 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-183 unregistered
10:38:22.811 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-184] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.812 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.812 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.812 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.812 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-184 unregistered
10:38:22.812 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-185] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.813 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.813 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.813 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.813 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-185 unregistered
10:38:22.813 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-186] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.814 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.814 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.814 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.814 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-186 unregistered
10:38:22.814 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-187] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.815 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.815 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.815 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.815 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-187 unregistered
10:38:22.815 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-188] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.816 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.816 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.816 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.816 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-188 unregistered
10:38:22.816 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-189] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.817 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.817 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.817 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.817 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-189 unregistered
10:38:22.817 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-190] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.818 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.818 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.818 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.818 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-190 unregistered
10:38:22.818 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-191] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.819 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.819 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.819 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.819 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-191 unregistered
10:38:22.819 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-192] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.820 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.820 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.820 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.820 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-192 unregistered
10:38:22.821 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-193] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.821 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.821 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.822 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.822 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-193 unregistered
10:38:22.822 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-194] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.823 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.823 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.823 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.823 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-194 unregistered
10:38:22.823 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-195] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.824 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.824 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.824 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.824 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-195 unregistered
10:38:22.824 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-196] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.825 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.825 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.825 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.825 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-196 unregistered
10:38:22.825 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-197] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.826 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.826 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.826 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.826 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-197 unregistered
10:38:22.826 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-198] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.827 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.827 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.827 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.827 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-198 unregistered
10:38:22.827 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-199] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.828 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.828 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.828 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.828 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-199 unregistered
10:38:22.828 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-200] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.829 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.829 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.829 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.829 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-200 unregistered
10:38:22.829 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-201] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.830 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.830 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.830 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.830 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-201 unregistered
10:38:22.830 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-202] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.831 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.831 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.831 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.831 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-202 unregistered
10:38:22.831 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-203] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.832 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.832 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.832 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.832 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-203 unregistered
10:38:22.832 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-204] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.833 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.833 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.833 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.833 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-204 unregistered
10:38:22.833 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-205] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.834 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.834 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.834 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.834 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-205 unregistered
10:38:22.834 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-206] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.835 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.835 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.835 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.835 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-206 unregistered
10:38:22.835 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-207] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.836 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.836 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.836 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.836 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-207 unregistered
10:38:22.836 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-208] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.837 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.837 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.837 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.837 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-208 unregistered
10:38:22.837 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-209] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.838 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.838 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.838 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.838 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-209 unregistered
10:38:22.838 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-210] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.839 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.839 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.839 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.840 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-210 unregistered
10:38:22.840 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-211] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.840 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.840 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.841 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.841 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-211 unregistered
10:38:22.841 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-212] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.841 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.841 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.842 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.842 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-212 unregistered
10:38:22.842 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-213] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.842 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.842 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.843 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.843 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-213 unregistered
10:38:22.843 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-214] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.844 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.844 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.844 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.844 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-214 unregistered
10:38:22.844 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-215] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.844 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.844 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.844 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.845 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-215 unregistered
10:38:22.845 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-216] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.845 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.845 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.845 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.845 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-216 unregistered
10:38:22.845 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-217] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.846 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.846 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.846 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.846 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-217 unregistered
10:38:22.846 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-218] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.847 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.847 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.847 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.847 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-218 unregistered
10:38:22.847 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-219] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.848 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.848 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.848 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.848 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-219 unregistered
10:38:22.848 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-220] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.849 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.849 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.849 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.849 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-220 unregistered
10:38:22.849 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-221] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.850 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.850 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.850 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.850 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-221 unregistered
10:38:22.850 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-222] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.851 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.851 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.851 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.851 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-222 unregistered
10:38:22.851 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-223] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.852 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.852 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.852 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.852 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-223 unregistered
10:38:22.852 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-224] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.853 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.853 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.853 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.853 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-224 unregistered
10:38:22.853 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-225] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.854 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.854 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.854 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.854 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-225 unregistered
10:38:22.854 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-226] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.855 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.855 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.855 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.855 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-226 unregistered
10:38:22.855 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-227] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.857 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.857 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.857 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.857 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-227 unregistered
10:38:22.857 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-228] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.858 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.858 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.858 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.858 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-228 unregistered
10:38:22.858 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-229] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.859 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.859 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.859 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.859 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-229 unregistered
10:38:22.859 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-230] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.860 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.860 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.860 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.860 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-230 unregistered
10:38:22.860 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-231] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.861 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.861 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.861 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.861 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-231 unregistered
10:38:22.861 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-232] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.862 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.862 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.862 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.862 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-232 unregistered
10:38:22.862 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-233] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.863 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.863 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.863 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.863 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-233 unregistered
10:38:22.864 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-234] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.864 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.864 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.864 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.865 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-234 unregistered
10:38:22.865 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-235] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.865 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.865 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.865 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.865 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-235 unregistered
10:38:22.865 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-236] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.866 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.866 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.866 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.866 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-236 unregistered
10:38:22.866 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-237] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.867 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.867 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.867 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.867 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-237 unregistered
10:38:22.867 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-238] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.869 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.869 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.869 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.869 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-238 unregistered
10:38:22.869 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-239] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.870 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.870 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.870 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.870 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-239 unregistered
10:38:22.870 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-240] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-240 unregistered
10:38:22.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-241] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-241 unregistered
10:38:22.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-242] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-242 unregistered
10:38:22.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-243] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-243 unregistered
10:38:22.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-244] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-244 unregistered
10:38:22.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-245] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-245 unregistered
10:38:22.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-246] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-246 unregistered
10:38:22.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-247] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-247 unregistered
10:38:22.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-248] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-248 unregistered
10:38:22.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-249] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-249 unregistered
10:38:22.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-250] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-250 unregistered
10:38:22.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-251] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-251 unregistered
10:38:22.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-252] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-252 unregistered
10:38:22.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-253] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-253 unregistered
10:38:22.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-254] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-254 unregistered
10:38:22.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-255] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-255 unregistered
10:38:22.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-256] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-256 unregistered
10:38:22.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-257] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-257 unregistered
10:38:22.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-258] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-258 unregistered
10:38:22.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-259] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-259 unregistered
10:38:22.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-260] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-260 unregistered
10:38:22.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-261] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-261 unregistered
10:38:22.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-262] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-262 unregistered
10:38:22.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-263] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-263 unregistered
10:38:22.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-264] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-264 unregistered
10:38:22.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-265] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.901 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.901 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.901 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.901 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-265 unregistered
10:38:22.901 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-266] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.902 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.902 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.902 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.902 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-266 unregistered
10:38:22.902 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-267] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.903 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.904 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.904 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.904 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-267 unregistered
10:38:22.904 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-268] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.904 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.904 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.904 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.905 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-268 unregistered
10:38:22.905 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-269] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.906 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.906 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.906 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.906 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-269 unregistered
10:38:22.906 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-270] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.907 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.907 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.907 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.907 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-270 unregistered
10:38:22.907 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-271] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.908 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.908 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.908 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.908 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-271 unregistered
10:38:22.908 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-272] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.909 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.909 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.909 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.909 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-272 unregistered
10:38:22.909 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-273] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.910 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.910 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.910 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.910 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-273 unregistered
10:38:22.910 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-274] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.911 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.911 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.911 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.911 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-274 unregistered
10:38:22.911 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-275] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.912 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.912 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.912 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.912 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-275 unregistered
10:38:22.912 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-276] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.914 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.914 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.914 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.914 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-276 unregistered
10:38:22.914 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-277] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.915 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.915 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.915 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.915 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-277 unregistered
10:38:22.915 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-278] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.916 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.916 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.916 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.916 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-278 unregistered
10:38:22.916 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-279] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.917 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.917 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.917 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.917 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-279 unregistered
10:38:22.918 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-280] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.919 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.919 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.919 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.919 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-280 unregistered
10:38:22.919 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-281] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.920 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.920 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.920 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.920 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-281 unregistered
10:38:22.920 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-282] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.921 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.921 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.921 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.921 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-282 unregistered
10:38:22.921 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-283] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.922 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.922 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.922 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.922 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-283 unregistered
10:38:22.922 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-284] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.923 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.923 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.923 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.923 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-284 unregistered
10:38:22.924 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-285] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.925 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.925 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.925 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.925 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-285 unregistered
10:38:22.925 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-286] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.926 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.926 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.926 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.926 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-286 unregistered
10:38:22.926 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-287] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.927 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.927 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.927 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.927 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-287 unregistered
10:38:22.927 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-288] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.928 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.928 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.928 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.928 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-288 unregistered
10:38:22.928 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-289] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.929 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.929 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.929 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.929 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-289 unregistered
10:38:22.929 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-290] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.930 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.930 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.930 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.930 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-290 unregistered
10:38:22.930 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-291] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.931 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.931 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.931 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.931 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-291 unregistered
10:38:22.931 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-292] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.932 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.932 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.932 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.932 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-292 unregistered
10:38:22.932 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-293] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.933 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.934 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.934 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.934 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-293 unregistered
10:38:22.934 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-294] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.934 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.934 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.934 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.935 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-294 unregistered
10:38:22.935 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-295] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.935 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.935 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.935 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.935 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-295 unregistered
10:38:22.935 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-296] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.936 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.936 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.936 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.936 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-296 unregistered
10:38:22.936 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-297] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.938 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.938 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.938 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.938 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-297 unregistered
10:38:22.938 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-298] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.939 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.939 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.939 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.939 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-298 unregistered
10:38:22.939 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-299] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.940 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.940 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.940 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.940 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-299 unregistered
10:38:22.940 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-300] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.941 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.941 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.941 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.941 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-300 unregistered
10:38:22.941 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-301] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.942 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.942 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.942 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.943 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-301 unregistered
10:38:22.943 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-302] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.944 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.944 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.944 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.944 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-302 unregistered
10:38:22.944 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-303] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.945 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.945 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.945 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.945 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-303 unregistered
10:38:22.945 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-304] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.946 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.946 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.946 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.946 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-304 unregistered
10:38:22.946 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-305] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.947 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.947 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.948 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.948 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-305 unregistered
10:38:22.948 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-306] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.949 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.949 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.949 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.949 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-306 unregistered
10:38:22.949 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-307] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.949 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.949 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.949 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.950 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-307 unregistered
10:38:22.950 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-308] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.951 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.951 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.951 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.951 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-308 unregistered
10:38:22.951 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-309] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.951 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.952 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.952 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.952 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-309 unregistered
10:38:22.952 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-310] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.952 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.952 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.952 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.952 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-310 unregistered
10:38:22.953 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-311] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.953 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.953 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.953 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.953 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-311 unregistered
10:38:22.953 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-312] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.954 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.954 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.954 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.954 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-312 unregistered
10:38:22.954 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-313] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.956 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.956 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.956 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.956 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-313 unregistered
10:38:22.956 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-314] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.957 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.957 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.957 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.957 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-314 unregistered
10:38:22.957 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-315] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.957 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.957 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.957 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.958 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-315 unregistered
10:38:22.958 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-316] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.958 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.958 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.958 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.958 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-316 unregistered
10:38:22.958 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-317] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.959 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.959 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.959 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.959 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-317 unregistered
10:38:22.959 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-318] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.960 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.960 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.960 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.960 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-318 unregistered
10:38:22.960 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-319] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.961 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.961 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.961 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.961 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-319 unregistered
10:38:22.961 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-320] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.962 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.962 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.962 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.963 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-320 unregistered
10:38:22.963 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-321] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.964 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.964 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.964 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.964 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-321 unregistered
10:38:22.964 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-322] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.965 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.965 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.965 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.965 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-322 unregistered
10:38:22.965 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-323] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.966 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.966 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.966 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.966 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-323 unregistered
10:38:22.966 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-324] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.967 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.967 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.967 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.967 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-324 unregistered
10:38:22.967 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-325] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.968 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.968 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.968 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.968 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-325 unregistered
10:38:22.968 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-326] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.969 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.970 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.970 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.970 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-326 unregistered
10:38:22.970 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-327] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.970 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.970 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.970 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.971 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-327 unregistered
10:38:22.971 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-328] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.971 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.971 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.971 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.971 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-328 unregistered
10:38:22.971 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-329] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.972 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.972 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.972 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.972 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-329 unregistered
10:38:22.972 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-330] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.973 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.973 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.973 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.973 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-330 unregistered
10:38:22.973 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-331] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.974 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.974 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.974 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.974 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-331 unregistered
10:38:22.974 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-332] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.975 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.975 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.975 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.975 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-332 unregistered
10:38:22.975 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-333] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.976 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.976 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.976 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.976 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-333 unregistered
10:38:22.976 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-334] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.977 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.977 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.977 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.977 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-334 unregistered
10:38:22.977 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-335] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.978 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.978 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.978 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.978 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-335 unregistered
10:38:22.978 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-336] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.979 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.979 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.979 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.979 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-336 unregistered
10:38:22.979 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-337] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.980 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.981 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.981 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.981 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-337 unregistered
10:38:22.981 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-338] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.982 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.982 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.982 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.982 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-338 unregistered
10:38:22.982 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-339] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.983 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.983 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.983 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.983 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-339 unregistered
10:38:22.983 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-340] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.984 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.984 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.984 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.984 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-340 unregistered
10:38:22.984 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-341] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.985 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.985 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.985 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.985 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-341 unregistered
10:38:22.985 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-342] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.985 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.985 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.986 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.986 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-342 unregistered
10:38:22.986 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-343] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.986 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.986 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.986 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.986 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-343 unregistered
10:38:22.987 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-344] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.988 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.988 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.988 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.988 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-344 unregistered
10:38:22.988 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-345] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.989 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.989 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.989 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.989 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-345 unregistered
10:38:22.989 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-346] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.989 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.989 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.989 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.990 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-346 unregistered
10:38:22.990 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-347] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.990 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.990 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.990 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.990 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-347 unregistered
10:38:22.991 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-348] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.991 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.992 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.992 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.992 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-348 unregistered
10:38:22.992 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-349] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.992 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.992 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.992 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.992 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-349 unregistered
10:38:22.992 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-350] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.994 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.994 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.994 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.994 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-350 unregistered
10:38:22.994 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-351] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.994 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.994 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.994 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.995 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-351 unregistered
10:38:22.995 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-352] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.995 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.995 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.995 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.995 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-352 unregistered
10:38:22.995 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-353] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.996 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.996 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.996 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.996 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-353 unregistered
10:38:22.996 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-354] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.997 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.997 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.997 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.997 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-354 unregistered
10:38:22.997 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-355] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.998 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.998 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.998 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.998 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-355 unregistered
10:38:22.998 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-356] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:22.999 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:22.999 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:22.999 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:22.999 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-356 unregistered
10:38:23.000 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-357] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.000 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.001 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.001 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.001 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-357 unregistered
10:38:23.001 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-358] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.002 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.002 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.002 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.002 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-358 unregistered
10:38:23.002 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-359] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.003 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.003 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.003 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.003 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-359 unregistered
10:38:23.003 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-360] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.004 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.004 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.004 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.004 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-360 unregistered
10:38:23.004 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-361] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.005 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.005 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.005 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.005 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-361 unregistered
10:38:23.005 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-362] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.006 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.006 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.006 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.006 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-362 unregistered
10:38:23.007 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-363] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.007 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.008 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.008 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.008 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-363 unregistered
10:38:23.008 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-364] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.008 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.008 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.008 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.009 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-364 unregistered
10:38:23.009 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-365] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.009 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.009 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.009 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.009 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-365 unregistered
10:38:23.009 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-366] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.011 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.011 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.011 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.011 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-366 unregistered
10:38:23.011 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-367] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.011 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.012 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.012 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.012 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-367 unregistered
10:38:23.012 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-368] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.013 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.013 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.013 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.013 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-368 unregistered
10:38:23.013 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-369] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.014 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.014 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.014 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.014 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-369 unregistered
10:38:23.014 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-370] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.015 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.015 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.015 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.015 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-370 unregistered
10:38:23.015 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-371] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.016 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.016 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.016 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.016 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-371 unregistered
10:38:23.016 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-372] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.017 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.017 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.017 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.017 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-372 unregistered
10:38:23.017 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-373] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.018 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.018 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.018 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.018 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-373 unregistered
10:38:23.018 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-374] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.019 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.019 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.019 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.019 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-374 unregistered
10:38:23.019 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-375] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.020 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.020 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.020 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.020 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-375 unregistered
10:38:23.020 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-376] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.021 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.021 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.021 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.021 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-376 unregistered
10:38:23.021 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-377] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.022 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.022 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.022 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.022 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-377 unregistered
10:38:23.022 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-378] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.023 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.023 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.023 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.023 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-378 unregistered
10:38:23.023 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-379] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.024 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.024 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.024 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.024 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-379 unregistered
10:38:23.024 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-380] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.025 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.025 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.025 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.025 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-380 unregistered
10:38:23.025 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-381] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.026 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.026 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.026 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.026 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-381 unregistered
10:38:23.026 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-382] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.026 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.027 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.027 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.027 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-382 unregistered
10:38:23.027 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-383] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.027 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.027 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.027 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.027 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-383 unregistered
10:38:23.027 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-384] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.029 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.029 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.029 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.029 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-384 unregistered
10:38:23.029 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-385] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.030 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.030 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.030 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.030 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-385 unregistered
10:38:23.030 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-386] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.031 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.031 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.031 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.031 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-386 unregistered
10:38:23.031 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-387] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.032 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.032 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.032 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.032 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-387 unregistered
10:38:23.032 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-388] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.034 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.034 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.034 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.034 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-388 unregistered
10:38:23.034 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-389] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.035 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.035 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.035 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.035 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-389 unregistered
10:38:23.035 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-390] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.036 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.036 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.036 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.036 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-390 unregistered
10:38:23.036 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-391] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.037 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.037 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.037 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.037 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-391 unregistered
10:38:23.037 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-392] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.038 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.038 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.038 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.038 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-392 unregistered
10:38:23.038 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-393] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.039 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.039 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.039 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.039 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-393 unregistered
10:38:23.039 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-394] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.040 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.040 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.040 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.040 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-394 unregistered
10:38:23.040 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-395] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.041 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.041 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.041 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.041 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-395 unregistered
10:38:23.041 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-396] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.042 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.042 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.042 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.042 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-396 unregistered
10:38:23.042 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-397] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.043 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.043 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.043 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.043 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-397 unregistered
10:38:23.043 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-398] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.043 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.044 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.044 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.044 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-398 unregistered
10:38:23.044 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-399] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.045 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.045 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.045 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.045 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-399 unregistered
10:38:23.045 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-400] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.046 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.046 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.046 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.046 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-400 unregistered
10:38:23.046 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-401] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.046 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.047 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.047 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.047 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-401 unregistered
10:38:23.047 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-402] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.047 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.047 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.047 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.048 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-402 unregistered
10:38:23.048 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-403] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.049 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.049 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.049 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.049 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-403 unregistered
10:38:23.049 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-404] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.050 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.050 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.050 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.050 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-404 unregistered
10:38:23.050 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-405] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.051 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.051 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.051 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.051 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-405 unregistered
10:38:23.051 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-406] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.052 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.052 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.052 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.052 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-406 unregistered
10:38:23.052 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-407] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.053 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.053 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.053 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.053 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-407 unregistered
10:38:23.053 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-408] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.054 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.054 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.054 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.054 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-408 unregistered
10:38:23.054 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-409] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.055 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.055 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.055 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.055 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-409 unregistered
10:38:23.055 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-410] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.056 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.056 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.056 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.056 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-410 unregistered
10:38:23.056 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-411] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.057 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.057 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.057 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.057 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-411 unregistered
10:38:23.057 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-412] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.058 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.058 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.058 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.058 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-412 unregistered
10:38:23.058 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-413] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.059 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.059 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.059 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.059 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-413 unregistered
10:38:23.059 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-414] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.060 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.060 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.060 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.060 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-414 unregistered
10:38:23.060 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-415] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.061 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.061 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.061 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.061 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-415 unregistered
10:38:23.061 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-416] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.061 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.062 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.062 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.062 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-416 unregistered
10:38:23.062 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-417] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.063 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.063 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.063 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.063 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-417 unregistered
10:38:23.063 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-418] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.064 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.064 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.064 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.064 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-418 unregistered
10:38:23.064 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-419] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.065 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.065 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.065 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.065 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-419 unregistered
10:38:23.065 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-420] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.066 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.066 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.066 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.066 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-420 unregistered
10:38:23.066 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-421] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.067 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.067 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.067 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.067 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-421 unregistered
10:38:23.067 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-422] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.068 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.068 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.068 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.068 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-422 unregistered
10:38:23.068 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-423] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.069 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.069 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.069 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.069 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-423 unregistered
10:38:23.069 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-424] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.070 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.070 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.070 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.070 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-424 unregistered
10:38:23.070 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-425] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.071 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.071 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.071 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.071 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-425 unregistered
10:38:23.071 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-426] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.072 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.072 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.072 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.072 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-426 unregistered
10:38:23.072 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-427] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.073 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.073 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.073 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.073 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-427 unregistered
10:38:23.073 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-428] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.074 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.074 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.074 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.074 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-428 unregistered
10:38:23.074 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-429] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.076 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.076 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.076 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.076 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-429 unregistered
10:38:23.076 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-430] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.077 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.077 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.077 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.077 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-430 unregistered
10:38:23.077 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-431] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.078 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.078 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.078 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.078 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-431 unregistered
10:38:23.078 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-432] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.079 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.079 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.079 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.079 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-432 unregistered
10:38:23.079 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-433] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.080 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.080 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.080 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.080 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-433 unregistered
10:38:23.080 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-434] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.081 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.081 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.081 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.081 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-434 unregistered
10:38:23.081 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-435] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.082 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.082 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.082 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.082 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-435 unregistered
10:38:23.082 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-436] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.083 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.083 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.083 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.083 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-436 unregistered
10:38:23.083 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-437] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.084 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.084 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.084 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.084 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-437 unregistered
10:38:23.084 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-438] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.085 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.085 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.085 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.085 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-438 unregistered
10:38:23.085 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-439] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.086 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.086 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.086 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.086 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-439 unregistered
10:38:23.086 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-440] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.087 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.087 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.087 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.087 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-440 unregistered
10:38:23.087 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-441] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.088 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.088 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.088 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.088 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-441 unregistered
10:38:23.088 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-442] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.089 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.089 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.089 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.089 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-442 unregistered
10:38:23.089 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-443] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.090 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.090 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.090 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.091 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-443 unregistered
10:38:23.091 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-444] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.091 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.091 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.091 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.092 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-444 unregistered
10:38:23.092 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-445] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.092 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.092 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.092 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.093 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-445 unregistered
10:38:23.093 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-446] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.094 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.094 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.094 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.094 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-446 unregistered
10:38:23.094 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-447] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.095 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.095 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.095 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.095 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-447 unregistered
10:38:23.095 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-448] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.096 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.096 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.096 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.096 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-448 unregistered
10:38:23.096 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-449] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.097 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.097 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.097 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.097 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-449 unregistered
10:38:23.097 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-450] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.098 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.098 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.098 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.098 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-450 unregistered
10:38:23.098 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-451] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.099 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.099 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.099 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.099 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-451 unregistered
10:38:23.099 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-452] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.100 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.100 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.100 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.100 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-452 unregistered
10:38:23.100 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-453] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.101 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.101 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.101 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.101 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-453 unregistered
10:38:23.101 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-454] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.102 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.103 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.103 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.103 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-454 unregistered
10:38:23.103 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-455] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.103 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.103 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.103 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.104 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-455 unregistered
10:38:23.104 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-456] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.105 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.105 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.105 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.105 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-456 unregistered
10:38:23.105 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-457] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.106 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.106 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.106 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.106 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-457 unregistered
10:38:23.106 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-458] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.107 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.107 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.107 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.107 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-458 unregistered
10:38:23.107 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-459] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.108 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.108 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.108 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.108 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-459 unregistered
10:38:23.108 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-460] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.109 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.109 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.109 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.109 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-460 unregistered
10:38:23.109 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-461] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.110 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.110 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.110 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.110 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-461 unregistered
10:38:23.110 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-462] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.111 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.111 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.111 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.112 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-462 unregistered
10:38:23.112 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-463] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.113 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.113 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.113 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.113 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-463 unregistered
10:38:23.113 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-464] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.114 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.114 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.114 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.114 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-464 unregistered
10:38:23.114 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-465] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.115 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.115 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.115 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.115 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-465 unregistered
10:38:23.115 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-466] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.116 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.116 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.116 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.116 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-466 unregistered
10:38:23.116 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-467] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.117 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.117 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.117 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.117 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-467 unregistered
10:38:23.117 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-468] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.117 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.117 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.117 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.117 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-468 unregistered
10:38:23.118 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-469] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.118 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.118 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.118 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.118 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-469 unregistered
10:38:23.118 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-470] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.119 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.119 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.119 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.119 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-470 unregistered
10:38:23.119 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-471] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.120 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.120 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.120 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.120 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-471 unregistered
10:38:23.120 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-472] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.121 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.121 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.121 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.121 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-472 unregistered
10:38:23.121 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-473] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.122 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.122 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.122 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.122 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-473 unregistered
10:38:23.122 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-474] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.123 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.123 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.123 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.123 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-474 unregistered
10:38:23.123 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-475] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.124 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.124 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.124 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.124 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-475 unregistered
10:38:23.124 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-476] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.125 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.125 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.125 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.125 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-476 unregistered
10:38:23.125 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-477] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.126 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.126 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.126 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.126 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-477 unregistered
10:38:23.126 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-478] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.127 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.127 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.127 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.127 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-478 unregistered
10:38:23.128 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-479] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.128 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.129 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.129 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.129 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-479 unregistered
10:38:23.129 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-480] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.130 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.130 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.130 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.130 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-480 unregistered
10:38:23.130 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-481] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.131 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.131 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.131 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.131 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-481 unregistered
10:38:23.131 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-482] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.132 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.132 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.132 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.132 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-482 unregistered
10:38:23.132 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-483] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.133 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.133 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.133 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.133 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-483 unregistered
10:38:23.133 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-484] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.134 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.134 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.134 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.134 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-484 unregistered
10:38:23.134 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-485] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.135 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.135 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.135 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.135 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-485 unregistered
10:38:23.135 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-486] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.136 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.136 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.136 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.136 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-486 unregistered
10:38:23.136 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-487] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.137 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.137 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.137 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.137 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-487 unregistered
10:38:23.137 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-488] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.138 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.138 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.138 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.138 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-488 unregistered
10:38:23.138 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-489] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.139 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.139 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.139 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.139 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-489 unregistered
10:38:23.139 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-490] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.140 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.140 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.140 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.140 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-490 unregistered
10:38:23.141 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-491] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.141 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.141 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.142 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.142 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-491 unregistered
10:38:23.142 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-492] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.143 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.143 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.143 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.143 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-492 unregistered
10:38:23.143 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-493] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.144 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.144 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.144 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.144 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-493 unregistered
10:38:23.144 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-494] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.145 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.145 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.145 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.145 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-494 unregistered
10:38:23.145 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-495] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.146 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.146 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.146 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.146 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-495 unregistered
10:38:23.146 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-496] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.147 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.147 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.147 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.147 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-496 unregistered
10:38:23.147 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-497] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.148 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.149 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.149 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.149 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-497 unregistered
10:38:23.149 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-498] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.150 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.150 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.150 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.150 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-498 unregistered
10:38:23.150 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-499] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.151 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.151 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.151 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.151 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-499 unregistered
10:38:23.151 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-500] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.152 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.152 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.152 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.152 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-500 unregistered
10:38:23.152 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-501] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.153 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.153 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.153 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.153 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-501 unregistered
10:38:23.153 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-502] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.154 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.154 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.154 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.154 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-502 unregistered
10:38:23.154 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-503] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.155 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.155 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.155 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.155 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-503 unregistered
10:38:23.155 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-504] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.156 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.156 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.156 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.156 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-504 unregistered
10:38:23.156 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-505] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.157 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.157 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.157 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.157 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-505 unregistered
10:38:23.157 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-506] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.158 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.158 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.158 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.158 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-506 unregistered
10:38:23.158 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-507] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.159 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.159 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.159 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.159 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-507 unregistered
10:38:23.159 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-508] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.159 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.160 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.160 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.160 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-508 unregistered
10:38:23.160 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-509] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.160 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.160 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.160 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.160 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-509 unregistered
10:38:23.160 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-510] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.161 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.161 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.161 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.161 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-510 unregistered
10:38:23.161 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-511] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.162 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.162 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.162 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.162 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-511 unregistered
10:38:23.162 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-512] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.163 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.163 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.163 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.163 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-512 unregistered
10:38:23.163 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-513] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.164 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.164 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.164 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.164 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-513 unregistered
10:38:23.164 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-514] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.165 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.165 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.165 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.166 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-514 unregistered
10:38:23.166 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-515] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.166 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.167 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.167 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.167 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-515 unregistered
10:38:23.167 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-516] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.167 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.168 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.168 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.168 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-516 unregistered
10:38:23.168 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-517] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:38:23.168 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.169 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.169 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.169 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-517 unregistered
10:38:23.224 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Member consumer-sub-000-veGIiUw-1-a42b0377-140f-458e-a983-e4386a3c47bb sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:23.225 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:23.225 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-000-veGIiUw-1, groupId=sub-000-veGIiUw] Request joining group due to: consumer pro-actively leaving the group
10:38:23.228 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.228 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.228 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.229 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-000-veGIiUw-1 unregistered
10:38:23.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Revoke previously assigned partitions test-topic-0000001-_L2etTM-0
10:38:23.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Member consumer-sub-001-Sc_ClX8-2-1690bdac-c0fe-4257-aa15-68c897f71ce8 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:23.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:23.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-001-Sc_ClX8-2, groupId=sub-001-Sc_ClX8] Request joining group due to: consumer pro-actively leaving the group
10:38:23.673 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.673 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.673 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.675 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-001-Sc_ClX8-2 unregistered
10:38:23.722 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Member consumer-sub-002--gDe5LI-3-42165364-8a79-4795-9dd3-bb0dcc960d7f sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:23.722 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:23.722 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-002--gDe5LI-3, groupId=sub-002--gDe5LI] Request joining group due to: consumer pro-actively leaving the group
10:38:23.724 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.724 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.724 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.725 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-002--gDe5LI-3 unregistered
10:38:23.752 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Member consumer-sub-003-nQrvCqU-4-7d3ed392-4827-466f-b22a-a7e27fc26b82 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:23.752 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:23.752 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-003-nQrvCqU-4, groupId=sub-003-nQrvCqU] Request joining group due to: consumer pro-actively leaving the group
10:38:23.752 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.752 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.753 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.753 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-003-nQrvCqU-4 unregistered
10:38:23.842 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Member consumer-sub-004-9YDQMtE-5-70fc8c8e-d3f6-4a37-9178-35555d22a998 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:23.842 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:23.842 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-004-9YDQMtE-5, groupId=sub-004-9YDQMtE] Request joining group due to: consumer pro-actively leaving the group
10:38:23.843 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.843 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.843 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.844 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-004-9YDQMtE-5 unregistered
10:38:23.857 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Member consumer-sub-005-O3eWxIY-6-ec23536a-0ba0-4b4a-868e-cb46ba0ae817 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:23.857 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:23.857 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-005-O3eWxIY-6, groupId=sub-005-O3eWxIY] Request joining group due to: consumer pro-actively leaving the group
10:38:23.857 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:23.857 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:23.858 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:23.858 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-005-O3eWxIY-6 unregistered
10:38:23.877 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Revoke previously assigned partitions test-topic-0000007-hcTxvVI-0
10:38:23.878 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Member consumer-sub-007-kSb0jfw-7-e169bd5f-d90e-4fbc-ae9d-c2aefe365c2c sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:23.878 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:23.878 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-007-kSb0jfw-7, groupId=sub-007-kSb0jfw] Request joining group due to: consumer pro-actively leaving the group
10:38:24.266 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:24.266 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:24.267 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:24.267 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-007-kSb0jfw-7 unregistered
10:38:24.346 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Revoke previously assigned partitions test-topic-0000010-U6HXPng-0
10:38:24.346 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Member consumer-sub-010-qhXZymU-8-b504aef7-4334-4c00-b48d-458960123435 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:24.347 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:24.347 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-010-qhXZymU-8, groupId=sub-010-qhXZymU] Request joining group due to: consumer pro-actively leaving the group
10:38:24.576 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:24.576 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:24.576 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:24.577 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-010-qhXZymU-8 unregistered
10:38:24.600 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Revoke previously assigned partitions test-topic-0000013-upYB7Dk-0
10:38:24.600 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Member consumer-sub-013-8FJsfOU-9-2a447fb9-1de0-432c-a0b1-fb86dc5fd606 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:24.600 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:24.600 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-013-8FJsfOU-9, groupId=sub-013-8FJsfOU] Request joining group due to: consumer pro-actively leaving the group
10:38:24.943 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:24.943 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:24.943 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:24.944 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-013-8FJsfOU-9 unregistered
10:38:24.981 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Revoke previously assigned partitions test-topic-0000016-MLlCoec-0
10:38:24.982 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Member consumer-sub-016-xxzskEg-10-771919ca-f496-4aab-8936-7764ec805179 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:24.982 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:24.982 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-016-xxzskEg-10, groupId=sub-016-xxzskEg] Request joining group due to: consumer pro-actively leaving the group
10:38:25.139 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:25.139 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:25.140 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:25.140 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-016-xxzskEg-10 unregistered
10:38:25.234 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Revoke previously assigned partitions test-topic-0000019-aCPUnu8-0
10:38:25.234 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Member consumer-sub-019-MASUH9w-11-e29cce5b-9813-4572-b85f-09dd9512b480 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:25.234 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:25.234 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-019-MASUH9w-11, groupId=sub-019-MASUH9w] Request joining group due to: consumer pro-actively leaving the group
10:38:25.539 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:25.539 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:25.539 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:25.540 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-019-MASUH9w-11 unregistered
10:38:25.551 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Revoke previously assigned partitions test-topic-0000022-adVjIaQ-0
10:38:25.551 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Member consumer-sub-022-oQkyCnM-12-d0e2d9fc-bf3a-4a86-bf18-400386646d89 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:25.551 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:25.551 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-022-oQkyCnM-12, groupId=sub-022-oQkyCnM] Request joining group due to: consumer pro-actively leaving the group
10:38:25.918 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:25.918 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:25.918 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:25.919 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-022-oQkyCnM-12 unregistered
10:38:25.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Revoke previously assigned partitions test-topic-0000025-IRIRha0-0
10:38:25.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Member consumer-sub-025-5EVGGWg-13-29821947-204b-400c-981d-9b6e7e9e1054 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:25.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:25.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-025-5EVGGWg-13, groupId=sub-025-5EVGGWg] Request joining group due to: consumer pro-actively leaving the group
10:38:26.459 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:26.459 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:26.459 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:26.459 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-025-5EVGGWg-13 unregistered
10:38:26.490 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Revoke previously assigned partitions test-topic-0000028-Uo_eHQg-0
10:38:26.490 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Member consumer-sub-028-ICc1E4A-14-9814b9d3-66ec-4df1-9d6b-8a0f266ed722 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:26.490 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:26.490 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-028-ICc1E4A-14, groupId=sub-028-ICc1E4A] Request joining group due to: consumer pro-actively leaving the group
10:38:26.688 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:26.688 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:26.688 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:26.688 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-028-ICc1E4A-14 unregistered
10:38:26.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Revoke previously assigned partitions test-topic-0000031-_-x9Y-Y-0
10:38:26.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Member consumer-sub-031-jsgw8Lw-15-5d732958-b733-4a42-a1bc-2c6e0c621837 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:26.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:26.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-031-jsgw8Lw-15, groupId=sub-031-jsgw8Lw] Request joining group due to: consumer pro-actively leaving the group
10:38:27.007 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:27.007 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:27.007 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:27.008 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-031-jsgw8Lw-15 unregistered
10:38:27.073 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Revoke previously assigned partitions test-topic-0000034-mQDs78Y-0
10:38:27.073 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Member consumer-sub-034-jXfQV4M-16-f9361b3e-95cb-432c-80f4-ae8927c8984b sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:27.073 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:27.073 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-034-jXfQV4M-16, groupId=sub-034-jXfQV4M] Request joining group due to: consumer pro-actively leaving the group
10:38:27.542 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:27.542 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:27.542 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:27.543 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-034-jXfQV4M-16 unregistered
10:38:27.619 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Revoke previously assigned partitions test-topic-0000037-nN3KNZc-0
10:38:27.619 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Member consumer-sub-037-EKNVMKY-17-1cf48839-5ba4-4a98-814f-3a0fa82abaa9 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:27.619 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:27.619 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-037-EKNVMKY-17, groupId=sub-037-EKNVMKY] Request joining group due to: consumer pro-actively leaving the group
10:38:27.972 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:27.972 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:27.972 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:27.973 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-037-EKNVMKY-17 unregistered
10:38:27.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Revoke previously assigned partitions test-topic-0000040-ZPiiadY-0
10:38:27.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Member consumer-sub-040-nUpe8ic-18-fdc8093f-54b8-4d61-9ea0-83a5a51684a4 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:27.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:27.986 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-040-nUpe8ic-18, groupId=sub-040-nUpe8ic] Request joining group due to: consumer pro-actively leaving the group
10:38:28.033 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:28.033 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:28.033 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:28.034 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-040-nUpe8ic-18 unregistered
10:38:28.038 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Revoke previously assigned partitions test-topic-0000043-UplvRtE-0
10:38:28.038 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Member consumer-sub-043-VRipANU-19-ff028afa-f38c-4a1a-86c7-082ab365bf54 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:28.038 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:28.038 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-043-VRipANU-19, groupId=sub-043-VRipANU] Request joining group due to: consumer pro-actively leaving the group
10:38:28.194 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:28.194 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:28.194 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:28.195 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-043-VRipANU-19 unregistered
10:38:28.274 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Revoke previously assigned partitions test-topic-0000046-q-UQa6M-0
10:38:28.274 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Member consumer-sub-046-vrUsMA0-20-a4df3078-fd6c-46fa-8666-2037a4c8c207 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:28.274 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:28.274 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-046-vrUsMA0-20, groupId=sub-046-vrUsMA0] Request joining group due to: consumer pro-actively leaving the group
10:38:28.756 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:28.756 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:28.756 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:28.757 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-046-vrUsMA0-20 unregistered
10:38:28.768 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Revoke previously assigned partitions test-topic-0000049-sFgFDYQ-0
10:38:28.769 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Member consumer-sub-049-QC2A1E8-21-c4c234fb-12c4-496e-a180-eb5841f277de sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:28.769 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:28.769 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-049-QC2A1E8-21, groupId=sub-049-QC2A1E8] Request joining group due to: consumer pro-actively leaving the group
10:38:29.094 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:29.094 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:29.094 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:29.094 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-049-QC2A1E8-21 unregistered
10:38:29.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Revoke previously assigned partitions test-topic-0000052-2HKJDng-0
10:38:29.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Member consumer-sub-052-oVomvmI-22-2d67d8a2-7ed2-48a1-9a6d-1e834e33bf94 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:29.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:29.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-052-oVomvmI-22, groupId=sub-052-oVomvmI] Request joining group due to: consumer pro-actively leaving the group
10:38:29.270 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:29.270 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:29.270 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:29.271 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-052-oVomvmI-22 unregistered
10:38:29.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Revoke previously assigned partitions test-topic-0000055-PfazGY4-0
10:38:29.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Member consumer-sub-055-1horpzI-23-c87a0144-a022-4fa2-81cd-73a1486ed25c sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:29.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:29.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-055-1horpzI-23, groupId=sub-055-1horpzI] Request joining group due to: consumer pro-actively leaving the group
10:38:29.629 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:29.629 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:29.629 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:29.630 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-055-1horpzI-23 unregistered
10:38:29.701 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Revoke previously assigned partitions test-topic-0000058-nA5y_Cg-0
10:38:29.701 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Member consumer-sub-058-CCgSZb8-24-aaab71c1-a76d-4e83-bf3f-03d8b0da3e1a sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:29.701 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:29.701 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-058-CCgSZb8-24, groupId=sub-058-CCgSZb8] Request joining group due to: consumer pro-actively leaving the group
10:38:30.065 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:30.065 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:30.065 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:30.065 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-058-CCgSZb8-24 unregistered
10:38:30.147 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Revoke previously assigned partitions test-topic-0000061-cZAtpwQ-0
10:38:30.148 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Member consumer-sub-061-p-joeqs-25-377bf9ad-cad9-4127-b7f1-c0cdc495f72b sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:30.148 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:30.148 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-061-p-joeqs-25, groupId=sub-061-p-joeqs] Request joining group due to: consumer pro-actively leaving the group
10:38:30.209 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:30.209 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:30.209 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:30.210 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-061-p-joeqs-25 unregistered
10:38:30.214 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Revoke previously assigned partitions test-topic-0000064-Fd6J5P4-0
10:38:30.214 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Member consumer-sub-064-0QANq0Y-26-1974649a-f45b-4841-a274-2bbbd3eb0b8e sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:30.214 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:30.214 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-064-0QANq0Y-26, groupId=sub-064-0QANq0Y] Request joining group due to: consumer pro-actively leaving the group
10:38:30.594 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:30.594 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:30.594 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:30.595 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-064-0QANq0Y-26 unregistered
10:38:30.624 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Revoke previously assigned partitions test-topic-0000067-8UqVjsA-0
10:38:30.624 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Member consumer-sub-067-gruf-jQ-27-408b849a-70a6-4c09-9ca0-50bbe99ee7af sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:30.624 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:30.624 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-067-gruf-jQ-27, groupId=sub-067-gruf-jQ] Request joining group due to: consumer pro-actively leaving the group
10:38:30.906 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:30.906 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:30.906 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:30.906 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-067-gruf-jQ-27 unregistered
10:38:30.996 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Revoke previously assigned partitions test-topic-0000070-HtSFP-Q-0
10:38:30.996 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Member consumer-sub-070-RHUsvvo-28-803d1002-d6da-408a-b0f1-eb69ca10a790 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:30.996 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:30.996 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-070-RHUsvvo-28, groupId=sub-070-RHUsvvo] Request joining group due to: consumer pro-actively leaving the group
10:38:31.095 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:31.095 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:31.095 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:31.096 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-070-RHUsvvo-28 unregistered
10:38:31.194 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Revoke previously assigned partitions test-topic-0000073-CgvL2Cw-0
10:38:31.195 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Member consumer-sub-073-WaSvAxI-29-67c8a4c4-1790-4179-ba5a-3b45492ff1e6 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:31.195 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:31.195 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-073-WaSvAxI-29, groupId=sub-073-WaSvAxI] Request joining group due to: consumer pro-actively leaving the group
10:38:31.312 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:31.312 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:31.312 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:31.313 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-073-WaSvAxI-29 unregistered
10:38:31.357 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Revoke previously assigned partitions test-topic-0000076-9ukLbdc-0
10:38:31.357 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Member consumer-sub-076-mvrRvF8-30-2f44c3d6-b3a4-455a-9619-2c00eb87bd77 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:31.357 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:31.357 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-076-mvrRvF8-30, groupId=sub-076-mvrRvF8] Request joining group due to: consumer pro-actively leaving the group
10:38:31.389 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:31.389 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:31.389 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:31.390 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-076-mvrRvF8-30 unregistered
10:38:31.432 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Revoke previously assigned partitions test-topic-0000079-cEsvck0-0
10:38:31.432 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Member consumer-sub-079-cvsLMw4-31-97e621d8-f74d-405e-bc1e-c46496a03899 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:31.432 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:31.432 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-079-cvsLMw4-31, groupId=sub-079-cvsLMw4] Request joining group due to: consumer pro-actively leaving the group
10:38:31.447 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:31.447 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:31.447 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:31.448 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-079-cvsLMw4-31 unregistered
10:38:31.499 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Revoke previously assigned partitions test-topic-0000082-FLXnEIs-0
10:38:31.499 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Member consumer-sub-082-zkxa8VI-32-49836d06-72e4-416f-8745-05a4829e645b sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:31.499 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:31.499 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-082-zkxa8VI-32, groupId=sub-082-zkxa8VI] Request joining group due to: consumer pro-actively leaving the group
10:38:31.561 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:31.561 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:31.561 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:31.561 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-082-zkxa8VI-32 unregistered
10:38:31.632 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Revoke previously assigned partitions test-topic-0000085-N2NHIBM-0
10:38:31.632 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Member consumer-sub-085-0JPJEnM-33-123c5a31-f57a-4b89-95cb-a2043ebeb525 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:31.632 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:31.632 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-085-0JPJEnM-33, groupId=sub-085-0JPJEnM] Request joining group due to: consumer pro-actively leaving the group
10:38:31.691 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:31.691 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:31.691 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:31.691 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-085-0JPJEnM-33 unregistered
10:38:31.714 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Revoke previously assigned partitions test-topic-0000088-Stb9i1o-0
10:38:31.714 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Member consumer-sub-088-qObEwis-34-19161730-c580-45bc-89e0-84cd02c6e32e sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:31.714 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:31.714 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-088-qObEwis-34, groupId=sub-088-qObEwis] Request joining group due to: consumer pro-actively leaving the group
10:38:31.993 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:31.993 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:31.993 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:31.994 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-088-qObEwis-34 unregistered
10:38:32.077 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Revoke previously assigned partitions test-topic-0000091-E9z7puA-0
10:38:32.077 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Member consumer-sub-091-4lK-O0k-35-dfe34f62-ae89-4513-97b7-16c5c0bc7526 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:32.077 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:32.077 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-091-4lK-O0k-35, groupId=sub-091-4lK-O0k] Request joining group due to: consumer pro-actively leaving the group
10:38:32.096 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:32.096 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:32.096 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:32.097 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-091-4lK-O0k-35 unregistered
10:38:32.134 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Revoke previously assigned partitions test-topic-0000094-Gf5KW3M-0
10:38:32.134 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Member consumer-sub-094-BrzruBE-36-b1603e9f-7b58-473e-910d-c6150a40603c sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:32.135 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:32.135 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-094-BrzruBE-36, groupId=sub-094-BrzruBE] Request joining group due to: consumer pro-actively leaving the group
10:38:32.260 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:32.260 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:32.260 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:32.261 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-094-BrzruBE-36 unregistered
10:38:32.353 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Revoke previously assigned partitions test-topic-0000097-zLO3jFY-0
10:38:32.353 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Member consumer-sub-097-avjoPdA-37-9c6f2478-0ddc-4729-95b6-412367cb7696 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:32.353 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:32.353 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-097-avjoPdA-37, groupId=sub-097-avjoPdA] Request joining group due to: consumer pro-actively leaving the group
10:38:32.579 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:32.579 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:32.579 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:32.579 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-097-avjoPdA-37 unregistered
10:38:32.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Revoke previously assigned partitions test-topic-0000100-U4JejkA-0
10:38:32.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Member consumer-sub-100-bqIr850-38-d2ac2605-6465-47ca-a740-95c2cff5ae03 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:32.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:32.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-100-bqIr850-38, groupId=sub-100-bqIr850] Request joining group due to: consumer pro-actively leaving the group
10:38:32.771 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:32.771 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:32.771 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:32.772 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-100-bqIr850-38 unregistered
10:38:32.852 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Revoke previously assigned partitions test-topic-0000103-BaW4fGY-0
10:38:32.852 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Member consumer-sub-103-ryJeykA-39-1abeb6d5-4e08-47fb-a575-83a4d6fd81f2 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:32.852 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:32.852 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-103-ryJeykA-39, groupId=sub-103-ryJeykA] Request joining group due to: consumer pro-actively leaving the group
10:38:32.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:32.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:32.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:32.901 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-103-ryJeykA-39 unregistered
10:38:32.922 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Revoke previously assigned partitions test-topic-0000106--MB_6Bg-0
10:38:32.922 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Member consumer-sub-106-0hMyMrI-40-d79b6ea2-04ab-452d-a68f-de5f05168619 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:32.922 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:32.922 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-106-0hMyMrI-40, groupId=sub-106-0hMyMrI] Request joining group due to: consumer pro-actively leaving the group
10:38:32.969 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:32.970 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:32.970 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:32.970 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-106-0hMyMrI-40 unregistered
10:38:33.025 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Revoke previously assigned partitions test-topic-0000109-LtOlXJY-0
10:38:33.025 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Member consumer-sub-109-59qp1r8-41-a131679f-f513-46c0-adc7-0d364539ede7 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:33.025 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:33.025 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-109-59qp1r8-41, groupId=sub-109-59qp1r8] Request joining group due to: consumer pro-actively leaving the group
10:38:33.306 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:33.306 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:33.306 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:33.307 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-109-59qp1r8-41 unregistered
10:38:33.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Revoke previously assigned partitions test-topic-0000112-SsxIWSY-0
10:38:33.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Member consumer-sub-112-ozdFI5w-42-9324967c-3da7-438c-ab9f-213aa34bde93 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:33.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:33.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-112-ozdFI5w-42, groupId=sub-112-ozdFI5w] Request joining group due to: consumer pro-actively leaving the group
10:38:33.531 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:33.531 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:33.531 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:33.532 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-112-ozdFI5w-42 unregistered
10:38:33.617 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Revoke previously assigned partitions test-topic-0000115-x3VDmZM-0
10:38:33.617 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Member consumer-sub-115-3zUz_KI-43-d9d2ab4c-33b5-4725-a77a-926ee2b1127f sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:33.617 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:33.617 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-115-3zUz_KI-43, groupId=sub-115-3zUz_KI] Request joining group due to: consumer pro-actively leaving the group
10:38:33.647 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:33.647 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:33.647 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:33.648 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-115-3zUz_KI-43 unregistered
10:38:33.729 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Revoke previously assigned partitions test-topic-0000118-Mhw4hJk-0
10:38:33.729 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Member consumer-sub-118-GV4H62g-44-8a4fcc86-ee12-4d15-b4a3-518495d57fe7 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:33.729 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:33.729 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-118-GV4H62g-44, groupId=sub-118-GV4H62g] Request joining group due to: consumer pro-actively leaving the group
10:38:34.161 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:34.161 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:34.161 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:34.161 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-118-GV4H62g-44 unregistered
10:38:34.212 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Revoke previously assigned partitions test-topic-0000121-114XZfc-0
10:38:34.213 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Member consumer-sub-121-7dR5cuk-45-a724d78a-3de0-4f47-9f2d-d3d011bbeef8 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:34.213 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:34.213 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-121-7dR5cuk-45, groupId=sub-121-7dR5cuk] Request joining group due to: consumer pro-actively leaving the group
10:38:34.641 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:34.641 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:34.641 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:34.642 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-121-7dR5cuk-45 unregistered
10:38:34.697 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Revoke previously assigned partitions test-topic-0000124-2EDO_w4-0
10:38:34.697 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Member consumer-sub-124-wVmvIYQ-46-3c5b5c23-01e1-4576-b3ad-c497d5cc5d52 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:34.697 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:34.697 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-124-wVmvIYQ-46, groupId=sub-124-wVmvIYQ] Request joining group due to: consumer pro-actively leaving the group
10:38:34.840 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:34.840 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:34.840 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:34.841 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-124-wVmvIYQ-46 unregistered
10:38:34.902 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Revoke previously assigned partitions test-topic-0000127-rXhL7lw-0
10:38:34.902 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Member consumer-sub-127-GFM7wfU-47-05427824-0a24-4d14-b7b9-a9f38be81146 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:34.902 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:34.902 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-127-GFM7wfU-47, groupId=sub-127-GFM7wfU] Request joining group due to: consumer pro-actively leaving the group
10:38:35.277 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:35.277 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:35.277 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:35.278 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-127-GFM7wfU-47 unregistered
10:38:35.297 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Revoke previously assigned partitions test-topic-0000130-fdJ7vTs-0
10:38:35.297 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Member consumer-sub-130-R2MzGZc-48-8688cfce-1470-4429-96fe-1df55f9e79f4 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:35.297 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:35.297 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-130-R2MzGZc-48, groupId=sub-130-R2MzGZc] Request joining group due to: consumer pro-actively leaving the group
10:38:35.472 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:35.472 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:35.472 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:35.473 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-130-R2MzGZc-48 unregistered
10:38:35.547 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Revoke previously assigned partitions test-topic-0000133-1ZZQVqE-0
10:38:35.547 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Member consumer-sub-133-herww4w-49-fa71df6c-21e2-48c5-b8d8-1e448dee0290 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:35.547 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:35.547 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-133-herww4w-49, groupId=sub-133-herww4w] Request joining group due to: consumer pro-actively leaving the group
10:38:36.043 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:36.043 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:36.043 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:36.044 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-133-herww4w-49 unregistered
10:38:36.134 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Revoke previously assigned partitions test-topic-0000136-nBov2d0-0
10:38:36.134 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Member consumer-sub-136-hnM0maI-50-8a67a670-0f38-4a67-87d9-3c148cb3c057 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:36.134 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:36.134 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-136-hnM0maI-50, groupId=sub-136-hnM0maI] Request joining group due to: consumer pro-actively leaving the group
10:38:36.177 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:36.177 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:36.177 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:36.177 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-136-hnM0maI-50 unregistered
10:38:36.223 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Revoke previously assigned partitions test-topic-0000139-XTb1OHw-0
10:38:36.223 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Member consumer-sub-139-Jd7jOg8-51-4f50d45d-3f54-420c-967b-35c7e9b87972 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:36.223 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:36.223 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-139-Jd7jOg8-51, groupId=sub-139-Jd7jOg8] Request joining group due to: consumer pro-actively leaving the group
10:38:36.722 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:36.723 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:36.723 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:36.723 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-139-Jd7jOg8-51 unregistered
10:38:36.774 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Revoke previously assigned partitions test-topic-0000142-QTL4iuM-0
10:38:36.774 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Member consumer-sub-142-zj_UYlg-52-cf1bd90e-0ffb-4a3f-9634-f06e2de032db sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:36.775 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:36.775 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-142-zj_UYlg-52, groupId=sub-142-zj_UYlg] Request joining group due to: consumer pro-actively leaving the group
10:38:36.814 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:36.814 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:36.814 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:36.814 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-142-zj_UYlg-52 unregistered
10:38:36.829 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Revoke previously assigned partitions test-topic-0000145-SgkRMUE-0
10:38:36.829 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Member consumer-sub-145-nXOR4_o-53-f1d9e39f-db20-4d96-9716-a869c277d388 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:36.829 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:36.829 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-145-nXOR4_o-53, groupId=sub-145-nXOR4_o] Request joining group due to: consumer pro-actively leaving the group
10:38:36.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:36.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:36.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:36.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-145-nXOR4_o-53 unregistered
10:38:36.956 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Revoke previously assigned partitions test-topic-0000148-qpE9hNw-0
10:38:36.956 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Member consumer-sub-148-dURIGro-54-2da45e9c-a8de-402c-a997-c9c62788ff0c sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:36.956 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:36.956 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-148-dURIGro-54, groupId=sub-148-dURIGro] Request joining group due to: consumer pro-actively leaving the group
10:38:37.220 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:37.220 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:37.221 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:37.221 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-148-dURIGro-54 unregistered
10:38:37.305 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Revoke previously assigned partitions test-topic-0000151-VWnPQfI-0
10:38:37.305 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Member consumer-sub-151-dol9qp0-55-823de585-bc89-4c6a-9e45-9f2485a7cd19 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:37.305 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:37.305 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-151-dol9qp0-55, groupId=sub-151-dol9qp0] Request joining group due to: consumer pro-actively leaving the group
10:38:37.795 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:37.795 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:37.795 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:37.795 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-151-dol9qp0-55 unregistered
10:38:37.873 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Revoke previously assigned partitions test-topic-0000154-HE2aBZ8-0
10:38:37.873 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Member consumer-sub-154-oYkwY_c-56-a5f71378-203c-41b8-afc3-928265aefb57 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:37.873 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:37.873 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-154-oYkwY_c-56, groupId=sub-154-oYkwY_c] Request joining group due to: consumer pro-actively leaving the group
10:38:38.053 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:38.053 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:38.053 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:38.053 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-154-oYkwY_c-56 unregistered
10:38:38.104 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Revoke previously assigned partitions test-topic-0000157-6w1ItIc-0
10:38:38.104 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Member consumer-sub-157-hxUlyBo-57-16cbca88-9fe9-41a0-bc1f-73cfda0ac225 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:38.104 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:38.104 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-157-hxUlyBo-57, groupId=sub-157-hxUlyBo] Request joining group due to: consumer pro-actively leaving the group
10:38:38.217 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:38.217 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:38.217 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:38.218 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-157-hxUlyBo-57 unregistered
10:38:38.240 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Revoke previously assigned partitions test-topic-0000160-B3v6Dzk-0
10:38:38.240 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Member consumer-sub-160-VA65eYM-58-2e206900-33a9-42ce-a449-5176ea44827a sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:38.240 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:38.240 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-160-VA65eYM-58, groupId=sub-160-VA65eYM] Request joining group due to: consumer pro-actively leaving the group
10:38:38.275 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:38.275 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:38.275 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:38.276 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-160-VA65eYM-58 unregistered
10:38:38.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Revoke previously assigned partitions test-topic-0000163-ZKG2hH8-0
10:38:38.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Member consumer-sub-163-nxfAmZ8-59-aceece95-3d0c-44db-a0eb-817a68e8dad5 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:38.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:38.289 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-163-nxfAmZ8-59, groupId=sub-163-nxfAmZ8] Request joining group due to: consumer pro-actively leaving the group
10:38:38.750 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:38.750 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:38.750 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:38.751 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-163-nxfAmZ8-59 unregistered
10:38:38.821 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Revoke previously assigned partitions test-topic-0000166-Xn8hVBw-0
10:38:38.821 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Member consumer-sub-166-uAWZs3Y-60-83ffa56a-7cbd-4f4c-8aa8-b879a1097287 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:38.821 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:38.821 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-166-uAWZs3Y-60, groupId=sub-166-uAWZs3Y] Request joining group due to: consumer pro-actively leaving the group
10:38:39.147 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:39.147 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:39.147 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:39.148 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-166-uAWZs3Y-60 unregistered
10:38:39.205 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Revoke previously assigned partitions test-topic-0000169-ghF_OKc-0
10:38:39.205 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Member consumer-sub-169-dswsaeQ-61-1b2d1a2c-986b-4fbf-9794-af81eeb13a9d sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:39.205 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:39.205 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-169-dswsaeQ-61, groupId=sub-169-dswsaeQ] Request joining group due to: consumer pro-actively leaving the group
10:38:39.680 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:39.680 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:39.680 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:39.680 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-169-dswsaeQ-61 unregistered
10:38:39.718 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Revoke previously assigned partitions test-topic-0000172-MDi5xIU-0
10:38:39.718 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Member consumer-sub-172-rVJbmyc-62-fb6a65f9-9ba0-45d4-b53d-bc96c51fde2a sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:39.718 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:39.718 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-172-rVJbmyc-62, groupId=sub-172-rVJbmyc] Request joining group due to: consumer pro-actively leaving the group
10:38:40.188 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:40.188 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:40.188 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:40.188 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-172-rVJbmyc-62 unregistered
10:38:40.197 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Revoke previously assigned partitions test-topic-0000175-LbeFESo-0
10:38:40.197 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Member consumer-sub-175-1iz0jec-63-54160100-12b3-4a89-b60b-4cb48e0730bc sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:40.197 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:40.197 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-175-1iz0jec-63, groupId=sub-175-1iz0jec] Request joining group due to: consumer pro-actively leaving the group
10:38:40.696 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:40.696 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:40.696 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:40.697 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-175-1iz0jec-63 unregistered
10:38:40.748 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Revoke previously assigned partitions test-topic-0000178-i0eYwS4-0
10:38:40.748 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Member consumer-sub-178-ke0_tAk-64-6e505a05-f5d4-4882-97cf-a79cde20bdf7 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:40.748 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:40.748 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-178-ke0_tAk-64, groupId=sub-178-ke0_tAk] Request joining group due to: consumer pro-actively leaving the group
10:38:41.048 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:41.048 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:41.048 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:41.048 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-178-ke0_tAk-64 unregistered
10:38:41.095 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Revoke previously assigned partitions test-topic-0000181-brF3U9o-0
10:38:41.095 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Member consumer-sub-181-BgUa2Oc-65-95ab5b8e-487d-413e-be6c-32cd7a2f010d sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:41.095 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:41.095 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-181-BgUa2Oc-65, groupId=sub-181-BgUa2Oc] Request joining group due to: consumer pro-actively leaving the group
10:38:41.322 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:41.322 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:41.322 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:41.323 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-181-BgUa2Oc-65 unregistered
10:38:41.355 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Revoke previously assigned partitions test-topic-0000184-k_ZYxDY-0
10:38:41.355 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Member consumer-sub-184-UCC2_8Y-66-dcb1583c-b79f-4796-880f-f0dba4328f28 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:41.355 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:41.355 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-184-UCC2_8Y-66, groupId=sub-184-UCC2_8Y] Request joining group due to: consumer pro-actively leaving the group
10:38:41.403 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:41.403 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:41.403 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:41.404 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-184-UCC2_8Y-66 unregistered
10:38:41.438 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Revoke previously assigned partitions test-topic-0000187-qg-xV74-0
10:38:41.438 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Member consumer-sub-187-dzCZ1J8-67-2807b9f8-f8d0-45bb-ab84-cfe8c8fb5006 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:41.438 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:41.438 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-187-dzCZ1J8-67, groupId=sub-187-dzCZ1J8] Request joining group due to: consumer pro-actively leaving the group
10:38:41.807 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:41.807 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:41.807 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:41.807 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-187-dzCZ1J8-67 unregistered
10:38:41.824 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Revoke previously assigned partitions test-topic-0000190-3m3hz00-0
10:38:41.824 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Member consumer-sub-190-rMQrnZo-68-dde23cb7-001d-414b-9c5d-3a5e13e56327 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:41.824 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:41.824 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-190-rMQrnZo-68, groupId=sub-190-rMQrnZo] Request joining group due to: consumer pro-actively leaving the group
10:38:41.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:41.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:41.901 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:41.901 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-190-rMQrnZo-68 unregistered
10:38:41.989 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Revoke previously assigned partitions test-topic-0000193-IKe7u9w-0
10:38:41.989 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Member consumer-sub-193-s8VGh8U-69-317de2be-8012-4e8e-a661-fa4bef4761ca sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:41.989 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:41.989 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-193-s8VGh8U-69, groupId=sub-193-s8VGh8U] Request joining group due to: consumer pro-actively leaving the group
10:38:42.272 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:42.272 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:42.272 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:42.273 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-193-s8VGh8U-69 unregistered
10:38:42.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Revoke previously assigned partitions test-topic-0000196-Ej9h6yQ-0
10:38:42.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Member consumer-sub-196-zfD1A_I-70-a5dbae94-61d6-4b64-b550-43de2f0b8b2c sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:42.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:42.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-196-zfD1A_I-70, groupId=sub-196-zfD1A_I] Request joining group due to: consumer pro-actively leaving the group
10:38:42.599 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:42.600 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:42.600 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:42.600 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-196-zfD1A_I-70 unregistered
10:38:42.603 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Revoke previously assigned partitions test-topic-0000199-pa8qKEk-0
10:38:42.604 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Member consumer-sub-199-gj6dzsM-71-f0d3225b-4c94-4154-96c9-a7ae80d3358a sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:42.604 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:42.604 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-199-gj6dzsM-71, groupId=sub-199-gj6dzsM] Request joining group due to: consumer pro-actively leaving the group
10:38:43.055 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:43.055 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:43.055 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:43.055 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-199-gj6dzsM-71 unregistered
10:38:43.108 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Revoke previously assigned partitions test-topic-0000202-wnvH5hQ-0
10:38:43.108 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Member consumer-sub-202-DL6rg0U-72-8b568640-82a2-4205-b244-ab0a1a6ef10f sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:43.108 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:43.108 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-202-DL6rg0U-72, groupId=sub-202-DL6rg0U] Request joining group due to: consumer pro-actively leaving the group
10:38:43.361 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:43.361 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:43.361 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:43.362 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-202-DL6rg0U-72 unregistered
10:38:43.367 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Revoke previously assigned partitions test-topic-0000205-noMcOW4-0
10:38:43.367 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Member consumer-sub-205-Xuji97M-73-6a278020-6305-4c7a-ac4f-c5d31cdc069a sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:43.367 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:43.367 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-205-Xuji97M-73, groupId=sub-205-Xuji97M] Request joining group due to: consumer pro-actively leaving the group
10:38:43.422 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:43.422 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:43.422 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:43.422 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-205-Xuji97M-73 unregistered
10:38:43.490 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Revoke previously assigned partitions test-topic-0000208-hdUPCA4-0
10:38:43.490 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Member consumer-sub-208-_BWsszI-74-75758e82-4145-4055-b0d0-e4ba0ada9700 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:43.491 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:43.491 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-208-_BWsszI-74, groupId=sub-208-_BWsszI] Request joining group due to: consumer pro-actively leaving the group
10:38:43.975 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:43.975 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:43.975 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:43.975 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-208-_BWsszI-74 unregistered
10:38:44.010 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Revoke previously assigned partitions test-topic-0000211-Ph8tip0-0
10:38:44.010 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Member consumer-sub-211-Gil9jaE-75-ace90156-d0ee-4340-9b7d-e4b792e0fc6b sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:44.010 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:44.010 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-211-Gil9jaE-75, groupId=sub-211-Gil9jaE] Request joining group due to: consumer pro-actively leaving the group
10:38:44.264 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:44.264 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:44.264 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:44.265 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-211-Gil9jaE-75 unregistered
10:38:44.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Revoke previously assigned partitions test-topic-0000214-WIM8B8M-0
10:38:44.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Member consumer-sub-214-u7Hz_Ns-76-858b4e25-8c50-446e-9dd3-ecfed657d7f9 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:44.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:44.285 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-214-u7Hz_Ns-76, groupId=sub-214-u7Hz_Ns] Request joining group due to: consumer pro-actively leaving the group
10:38:44.743 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:44.743 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:44.743 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:44.744 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-214-u7Hz_Ns-76 unregistered
10:38:44.766 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Revoke previously assigned partitions test-topic-0000217-Ajth_NQ-0
10:38:44.766 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Member consumer-sub-217-zmNMIvw-77-97baa124-ada5-4ac4-9ead-dbea2d97ecd9 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:44.767 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:44.767 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-217-zmNMIvw-77, groupId=sub-217-zmNMIvw] Request joining group due to: consumer pro-actively leaving the group
10:38:44.842 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:44.842 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:44.842 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:44.842 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-217-zmNMIvw-77 unregistered
10:38:44.871 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Revoke previously assigned partitions test-topic-0000220-N-ilnxQ-0
10:38:44.871 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Member consumer-sub-220-eLcgVIE-78-b972007e-a148-4d31-bf8f-b759f019658f sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:44.871 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:44.871 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-220-eLcgVIE-78, groupId=sub-220-eLcgVIE] Request joining group due to: consumer pro-actively leaving the group
10:38:44.974 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:44.974 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:44.974 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:44.975 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-220-eLcgVIE-78 unregistered
10:38:44.987 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Revoke previously assigned partitions test-topic-0000223-ah3LCNA-0
10:38:44.987 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Member consumer-sub-223-Borim14-79-50dbd4ea-b713-432f-8b37-b551a173928f sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:44.987 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:44.987 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-223-Borim14-79, groupId=sub-223-Borim14] Request joining group due to: consumer pro-actively leaving the group
10:38:45.111 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:45.112 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:45.112 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:45.112 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-223-Borim14-79 unregistered
10:38:45.142 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Revoke previously assigned partitions test-topic-0000226-9ja4qbw-0
10:38:45.142 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Member consumer-sub-226-RKLF2mE-80-fa4f0f54-fa1f-43c2-9370-75e0c0e806a0 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:45.142 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:45.142 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-226-RKLF2mE-80, groupId=sub-226-RKLF2mE] Request joining group due to: consumer pro-actively leaving the group
10:38:45.215 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:45.215 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:45.215 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:45.216 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-226-RKLF2mE-80 unregistered
10:38:45.257 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Revoke previously assigned partitions test-topic-0000229--X-ffVY-0
10:38:45.257 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Member consumer-sub-229-K6WIHn0-81-72101873-8e72-4076-b8f8-55064d9ef265 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:45.257 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:45.257 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-229-K6WIHn0-81, groupId=sub-229-K6WIHn0] Request joining group due to: consumer pro-actively leaving the group
10:38:45.611 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:45.611 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:45.611 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:45.611 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-229-K6WIHn0-81 unregistered
10:38:45.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Revoke previously assigned partitions test-topic-0000232-Zo-CFTw-0
10:38:45.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Member consumer-sub-232-HWA9cc4-82-d8e2cb3a-b101-41e8-9119-3b458fd9e777 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:45.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:45.633 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-232-HWA9cc4-82, groupId=sub-232-HWA9cc4] Request joining group due to: consumer pro-actively leaving the group
10:38:45.905 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:45.906 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:45.906 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:45.906 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-232-HWA9cc4-82 unregistered
10:38:45.968 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Revoke previously assigned partitions test-topic-0000235-cCNi4L4-0
10:38:45.968 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Member consumer-sub-235-MeSVaXE-83-d3d2c7bb-daec-474f-98d4-049616041ca5 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:45.968 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:45.968 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-235-MeSVaXE-83, groupId=sub-235-MeSVaXE] Request joining group due to: consumer pro-actively leaving the group
10:38:46.036 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:46.036 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:46.036 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:46.037 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-235-MeSVaXE-83 unregistered
10:38:46.116 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Revoke previously assigned partitions test-topic-0000238-pVDipQg-0
10:38:46.116 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Member consumer-sub-238-ONJOK5A-84-8ffc0de2-5043-4497-96f1-8c0d893ed98f sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:46.116 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:46.116 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-238-ONJOK5A-84, groupId=sub-238-ONJOK5A] Request joining group due to: consumer pro-actively leaving the group
10:38:46.217 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:46.217 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:46.217 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:46.218 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-238-ONJOK5A-84 unregistered
10:38:46.260 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Revoke previously assigned partitions test-topic-0000241-R-_-_cA-0
10:38:46.260 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Member consumer-sub-241-gvnU3Ck-85-ffeddb23-aa10-480f-8000-fed292d501c1 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:46.260 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:46.260 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-241-gvnU3Ck-85, groupId=sub-241-gvnU3Ck] Request joining group due to: consumer pro-actively leaving the group
10:38:46.365 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:46.366 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:46.366 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:46.366 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-241-gvnU3Ck-85 unregistered
10:38:46.402 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Revoke previously assigned partitions test-topic-0000244-xZzYGvA-0
10:38:46.402 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Member consumer-sub-244-jxtWLHw-86-be807ba6-7713-4537-8725-653c390f8539 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:46.402 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:46.402 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-244-jxtWLHw-86, groupId=sub-244-jxtWLHw] Request joining group due to: consumer pro-actively leaving the group
10:38:46.458 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:46.458 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:46.458 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:46.458 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-244-jxtWLHw-86 unregistered
10:38:46.535 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Revoke previously assigned partitions test-topic-0000247-bLhN7IM-0
10:38:46.535 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Member consumer-sub-247-K9XaCCg-87-4baccfb4-1b21-4de9-92b0-d41dbb639a31 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:46.536 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:46.536 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-247-K9XaCCg-87, groupId=sub-247-K9XaCCg] Request joining group due to: consumer pro-actively leaving the group
10:38:46.698 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:46.698 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:46.698 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:46.699 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-247-K9XaCCg-87 unregistered
10:38:46.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Revoke previously assigned partitions test-topic-0000250-oUn3sNE-0
10:38:46.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Member consumer-sub-250-rGmeKVQ-88-1abc8c25-e855-4205-b44f-f33265cfbb8c sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:46.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:46.785 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-250-rGmeKVQ-88, groupId=sub-250-rGmeKVQ] Request joining group due to: consumer pro-actively leaving the group
10:38:46.816 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:46.816 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:46.816 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:46.816 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-250-rGmeKVQ-88 unregistered
10:38:46.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Revoke previously assigned partitions test-topic-0000253-QAvk_uQ-0
10:38:46.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Member consumer-sub-253-RgeEIIQ-89-898266f5-2e8c-4b0e-b26d-d3b383299c6f sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:46.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:46.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-253-RgeEIIQ-89, groupId=sub-253-RgeEIIQ] Request joining group due to: consumer pro-actively leaving the group
10:38:47.142 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:47.142 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:47.142 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:47.143 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-253-RgeEIIQ-89 unregistered
10:38:47.209 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Revoke previously assigned partitions test-topic-0000256--7oN2X0-0
10:38:47.210 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Member consumer-sub-256-tSNX3eE-90-3dd1cbee-d0b6-4f30-8b43-bc0191ca1b79 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:47.210 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:47.210 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-256-tSNX3eE-90, groupId=sub-256-tSNX3eE] Request joining group due to: consumer pro-actively leaving the group
10:38:47.280 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:47.280 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:47.280 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:47.281 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-256-tSNX3eE-90 unregistered
10:38:47.352 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Revoke previously assigned partitions test-topic-0000259-zpR5ZgQ-0
10:38:47.353 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Member consumer-sub-259-qFaMuSA-91-81038daa-0bf3-4ce2-949d-3b635a694bf8 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:47.353 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:47.353 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-259-qFaMuSA-91, groupId=sub-259-qFaMuSA] Request joining group due to: consumer pro-actively leaving the group
10:38:47.650 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:47.650 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:47.650 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:47.650 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-259-qFaMuSA-91 unregistered
10:38:47.683 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Revoke previously assigned partitions test-topic-0000262-2mGVp-c-0
10:38:47.683 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Member consumer-sub-262-t6tbKE8-92-b66ddf5d-0783-489e-b3c0-bc0a40c009d4 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:47.683 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:47.683 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-262-t6tbKE8-92, groupId=sub-262-t6tbKE8] Request joining group due to: consumer pro-actively leaving the group
10:38:48.060 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:48.060 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:48.060 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:48.060 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-262-t6tbKE8-92 unregistered
10:38:48.144 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Revoke previously assigned partitions test-topic-0000265-TgfBbRU-0
10:38:48.144 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Member consumer-sub-265-y1eeaSk-93-950a37e4-c623-4368-82f6-1c64e6f7db28 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:48.144 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:48.144 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-265-y1eeaSk-93, groupId=sub-265-y1eeaSk] Request joining group due to: consumer pro-actively leaving the group
10:38:48.367 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:48.367 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:48.367 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:48.367 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-265-y1eeaSk-93 unregistered
10:38:48.421 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Revoke previously assigned partitions test-topic-0000268-JN0QTJM-0
10:38:48.421 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Member consumer-sub-268-Nx4dv8k-94-6432603c-6fb3-42b7-b287-cdef399856db sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:48.421 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:48.421 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-268-Nx4dv8k-94, groupId=sub-268-Nx4dv8k] Request joining group due to: consumer pro-actively leaving the group
10:38:48.459 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:48.459 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:48.459 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:48.460 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-268-Nx4dv8k-94 unregistered
10:38:48.543 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Revoke previously assigned partitions test-topic-0000271-2pWwc2U-0
10:38:48.543 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Member consumer-sub-271-_g-PJNA-95-66f1e284-2bc1-4f22-a89a-0f94949eec7d sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:48.544 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:48.544 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-271-_g-PJNA-95, groupId=sub-271-_g-PJNA] Request joining group due to: consumer pro-actively leaving the group
10:38:48.696 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:48.696 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:48.696 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:48.696 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-271-_g-PJNA-95 unregistered
10:38:48.763 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Revoke previously assigned partitions test-topic-0000274-d_ffdj4-0
10:38:48.763 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Member consumer-sub-274-97uhtFY-96-ccae2a18-32c8-4e34-94a5-d3d99f51026c sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:48.763 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:48.763 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-274-97uhtFY-96, groupId=sub-274-97uhtFY] Request joining group due to: consumer pro-actively leaving the group
10:38:48.844 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:48.844 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:48.844 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:48.845 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-274-97uhtFY-96 unregistered
10:38:48.919 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Revoke previously assigned partitions test-topic-0000277-cGMK6aw-0
10:38:48.920 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Member consumer-sub-277-zPD7C0Y-97-d35f9e28-5562-43e2-8f02-275e606dc320 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:48.920 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:48.920 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-277-zPD7C0Y-97, groupId=sub-277-zPD7C0Y] Request joining group due to: consumer pro-actively leaving the group
10:38:48.995 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:48.995 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:48.995 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:48.996 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-277-zPD7C0Y-97 unregistered
10:38:49.039 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Revoke previously assigned partitions test-topic-0000280-Tf41vck-0
10:38:49.039 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Member consumer-sub-280-Bur9X_M-98-da531213-0b50-427b-b528-4926bcaa5b81 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:49.039 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:49.039 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-280-Bur9X_M-98, groupId=sub-280-Bur9X_M] Request joining group due to: consumer pro-actively leaving the group
10:38:49.331 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:49.331 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:49.331 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:49.332 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-280-Bur9X_M-98 unregistered
10:38:49.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Revoke previously assigned partitions test-topic-0000283-KIHGGJM-0
10:38:49.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Member consumer-sub-283-qrdvKP0-99-79401b3a-32bc-4ef8-9ec1-e925cef5e3b0 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:49.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:49.344 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-283-qrdvKP0-99, groupId=sub-283-qrdvKP0] Request joining group due to: consumer pro-actively leaving the group
10:38:49.544 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:49.544 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:49.544 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:49.545 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-283-qrdvKP0-99 unregistered
10:38:49.645 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Revoke previously assigned partitions test-topic-0000286-UC4nEGw-0
10:38:49.645 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Member consumer-sub-286-C_QmO_E-100-18e41f9b-de38-4a50-8a96-67c3bf5290ad sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:49.645 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:49.645 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-286-C_QmO_E-100, groupId=sub-286-C_QmO_E] Request joining group due to: consumer pro-actively leaving the group
10:38:49.783 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:49.783 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:49.783 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:49.784 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-286-C_QmO_E-100 unregistered
10:38:49.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Revoke previously assigned partitions test-topic-0000289-tlcNYIU-0
10:38:49.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Member consumer-sub-289-5P3MXB0-101-5433975c-2eb5-41ce-bb37-0bab613a8885 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:49.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:49.875 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-289-5P3MXB0-101, groupId=sub-289-5P3MXB0] Request joining group due to: consumer pro-actively leaving the group
10:38:49.931 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:49.931 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:49.931 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:49.931 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-289-5P3MXB0-101 unregistered
10:38:49.996 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Revoke previously assigned partitions test-topic-0000292--jBlQhg-0
10:38:49.997 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Member consumer-sub-292-0_zH55A-102-77247aae-3898-445e-8d47-1cc25e2e9a44 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:49.997 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:49.997 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-292-0_zH55A-102, groupId=sub-292-0_zH55A] Request joining group due to: consumer pro-actively leaving the group
10:38:50.150 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:50.150 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:50.150 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:50.151 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-292-0_zH55A-102 unregistered
10:38:50.185 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Revoke previously assigned partitions test-topic-0000295-I5j6jbk-0
10:38:50.185 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Member consumer-sub-295-yYRDrkU-103-1be972a8-eb9f-4320-93be-bdfab0e0239e sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:50.186 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:50.186 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-295-yYRDrkU-103, groupId=sub-295-yYRDrkU] Request joining group due to: consumer pro-actively leaving the group
10:38:50.546 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:50.546 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:50.546 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:50.546 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-295-yYRDrkU-103 unregistered
10:38:50.592 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Revoke previously assigned partitions test-topic-0000298-ceeBYS0-0
10:38:50.593 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Member consumer-sub-298-GMkVXt0-104-609a9f17-e6d8-4445-8c1d-a90748f721b8 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:50.593 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:50.593 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-298-GMkVXt0-104, groupId=sub-298-GMkVXt0] Request joining group due to: consumer pro-actively leaving the group
10:38:51.054 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:51.054 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:51.054 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:51.054 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-298-GMkVXt0-104 unregistered
10:38:51.076 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Revoke previously assigned partitions test-topic-0000301-yA-mZIA-0
10:38:51.076 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Member consumer-sub-301-ForHoYM-105-c6edf2b8-ad3a-419b-932e-c7b72d1e9410 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:51.076 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:51.076 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-301-ForHoYM-105, groupId=sub-301-ForHoYM] Request joining group due to: consumer pro-actively leaving the group
10:38:51.359 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:51.359 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:51.359 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:51.360 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-301-ForHoYM-105 unregistered
10:38:51.453 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Revoke previously assigned partitions test-topic-0000304-ov6qkF0-0
10:38:51.453 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Member consumer-sub-304-lFC-9Mk-106-a274a443-45b4-49f6-9f22-fbe91f4db1cb sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:51.454 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:51.454 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-304-lFC-9Mk-106, groupId=sub-304-lFC-9Mk] Request joining group due to: consumer pro-actively leaving the group
10:38:51.773 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:51.773 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:51.773 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:51.773 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-304-lFC-9Mk-106 unregistered
10:38:51.870 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Revoke previously assigned partitions test-topic-0000307-jPsw980-0
10:38:51.871 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Member consumer-sub-307-obAgLJY-107-a4fb027d-b94c-46f0-9edb-417d5912784a sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:51.871 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:51.871 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-307-obAgLJY-107, groupId=sub-307-obAgLJY] Request joining group due to: consumer pro-actively leaving the group
10:38:52.063 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:52.064 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:52.064 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:52.064 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-307-obAgLJY-107 unregistered
10:38:52.128 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Revoke previously assigned partitions test-topic-0000310-nAgI1eA-0
10:38:52.128 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Member consumer-sub-310-R0E95os-108-89a83861-c1a0-4c00-9ab3-c7891d7aaa3e sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:52.128 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:52.128 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-310-R0E95os-108, groupId=sub-310-R0E95os] Request joining group due to: consumer pro-actively leaving the group
10:38:52.181 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:52.181 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:52.181 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:52.182 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-310-R0E95os-108 unregistered
10:38:52.235 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Revoke previously assigned partitions test-topic-0000313-X7YT0wM-0
10:38:52.235 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Member consumer-sub-313-R0lwR2M-109-f5e1e96f-dde4-4d8d-b2e9-9fc1ee9f0731 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:52.235 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:52.235 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-313-R0lwR2M-109, groupId=sub-313-R0lwR2M] Request joining group due to: consumer pro-actively leaving the group
10:38:52.597 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:52.597 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:52.597 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:52.598 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-313-R0lwR2M-109 unregistered
10:38:52.647 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Revoke previously assigned partitions test-topic-0000316-Lxd4VNo-0
10:38:52.647 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Member consumer-sub-316-BeFW2Tg-110-cc7f741d-c66a-4be6-8c76-29ad6f189395 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:52.647 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:52.647 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-316-BeFW2Tg-110, groupId=sub-316-BeFW2Tg] Request joining group due to: consumer pro-actively leaving the group
10:38:53.111 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:53.111 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:53.111 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:53.111 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-316-BeFW2Tg-110 unregistered
10:38:53.154 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Revoke previously assigned partitions test-topic-0000319-9t7gUAI-0
10:38:53.154 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Member consumer-sub-319-GAjFQLU-111-1425e678-b56d-449e-ae82-cbc4b7ae4cf3 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:53.154 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:53.154 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-319-GAjFQLU-111, groupId=sub-319-GAjFQLU] Request joining group due to: consumer pro-actively leaving the group
10:38:53.623 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:53.623 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:53.624 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:53.624 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-319-GAjFQLU-111 unregistered
10:38:53.660 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Revoke previously assigned partitions test-topic-0000322-xRObVwo-0
10:38:53.660 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Member consumer-sub-322-Q_l-zqA-112-a575abb0-64d6-4ca0-897a-fd5b2aa2fe99 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:53.660 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:53.660 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-322-Q_l-zqA-112, groupId=sub-322-Q_l-zqA] Request joining group due to: consumer pro-actively leaving the group
10:38:54.153 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:54.153 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:54.153 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:54.154 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-322-Q_l-zqA-112 unregistered
10:38:54.159 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Revoke previously assigned partitions test-topic-0000325-yVBo-XQ-0
10:38:54.159 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Member consumer-sub-325-wXE01jo-113-ef21c79d-29e6-41ef-b4bd-6c6a56fe2ec2 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:54.159 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:54.159 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-325-wXE01jo-113, groupId=sub-325-wXE01jo] Request joining group due to: consumer pro-actively leaving the group
10:38:54.565 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:54.565 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:54.565 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:54.566 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-325-wXE01jo-113 unregistered
10:38:54.617 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Revoke previously assigned partitions test-topic-0000328-gFAenbQ-0
10:38:54.617 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Member consumer-sub-328-IrnBZGs-114-71307c36-04e7-4213-a03d-d3c31cf0d39e sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:54.618 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:54.618 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-328-IrnBZGs-114, groupId=sub-328-IrnBZGs] Request joining group due to: consumer pro-actively leaving the group
10:38:54.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:54.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:54.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:54.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-328-IrnBZGs-114 unregistered
10:38:54.916 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Revoke previously assigned partitions test-topic-0000331-SozV4lU-0
10:38:54.916 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Member consumer-sub-331-OY1AMrs-115-7cc71e94-13d6-44b3-987d-09938f1de11c sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:54.916 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:54.916 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-331-OY1AMrs-115, groupId=sub-331-OY1AMrs] Request joining group due to: consumer pro-actively leaving the group
10:38:55.248 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:55.248 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:55.248 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:55.248 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-331-OY1AMrs-115 unregistered
10:38:55.304 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Revoke previously assigned partitions test-topic-0000334-lg5rX9A-0
10:38:55.305 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Member consumer-sub-334-vbmgVHU-116-e98b5212-d2e6-4f1d-bf2f-605757253042 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:55.305 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:55.305 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-334-vbmgVHU-116, groupId=sub-334-vbmgVHU] Request joining group due to: consumer pro-actively leaving the group
10:38:55.656 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:55.656 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:55.656 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:55.656 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-334-vbmgVHU-116 unregistered
10:38:55.721 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Revoke previously assigned partitions test-topic-0000337-Z2pSJcI-0
10:38:55.721 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Member consumer-sub-337-sKVKKJo-117-946f75c5-777f-413b-9c1e-9b74ed1b13b2 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:55.721 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:55.721 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-337-sKVKKJo-117, groupId=sub-337-sKVKKJo] Request joining group due to: consumer pro-actively leaving the group
10:38:55.764 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:55.764 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:55.764 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:55.764 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-337-sKVKKJo-117 unregistered
10:38:55.826 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Revoke previously assigned partitions test-topic-0000340-6fVYvHQ-0
10:38:55.826 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Member consumer-sub-340-sJB-GGc-118-d2346536-70e9-4de6-8d09-c852d3827518 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:55.826 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:55.826 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-340-sJB-GGc-118, groupId=sub-340-sJB-GGc] Request joining group due to: consumer pro-actively leaving the group
10:38:56.198 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:56.198 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:56.198 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:56.199 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-340-sJB-GGc-118 unregistered
10:38:56.262 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Revoke previously assigned partitions test-topic-0000343-QjcgwwM-0
10:38:56.262 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Member consumer-sub-343-tCi6D5E-119-c83ba2ca-452f-47dd-b274-ff861b66007a sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:56.262 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:56.262 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-343-tCi6D5E-119, groupId=sub-343-tCi6D5E] Request joining group due to: consumer pro-actively leaving the group
10:38:56.437 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:56.437 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:56.437 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:56.438 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-343-tCi6D5E-119 unregistered
10:38:56.536 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Revoke previously assigned partitions test-topic-0000346-67ml2YA-0
10:38:56.536 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Member consumer-sub-346-6ZznPpc-120-bfbda878-3d45-4e0f-9b71-a5f3deeea35f sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:56.536 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:56.536 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-346-6ZznPpc-120, groupId=sub-346-6ZznPpc] Request joining group due to: consumer pro-actively leaving the group
10:38:56.988 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:56.988 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:56.988 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:56.988 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-346-6ZznPpc-120 unregistered
10:38:57.065 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Revoke previously assigned partitions test-topic-0000349-MJA-dNs-0
10:38:57.065 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Member consumer-sub-349-puyQhKk-121-537bd1f5-797d-47dc-b325-2cb968d84043 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:57.066 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:57.066 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-349-puyQhKk-121, groupId=sub-349-puyQhKk] Request joining group due to: consumer pro-actively leaving the group
10:38:57.307 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:57.307 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:57.307 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:57.308 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-349-puyQhKk-121 unregistered
10:38:57.339 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Revoke previously assigned partitions test-topic-0000352-sGfuRYg-0
10:38:57.339 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Member consumer-sub-352-tPmGvSE-122-6f6b8759-01ba-4f80-a60b-a55e43012241 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:57.339 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:57.339 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-352-tPmGvSE-122, groupId=sub-352-tPmGvSE] Request joining group due to: consumer pro-actively leaving the group
10:38:57.347 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:57.347 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:57.347 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:57.347 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-352-tPmGvSE-122 unregistered
10:38:57.400 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Revoke previously assigned partitions test-topic-0000355-8KDY5A8-0
10:38:57.400 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Member consumer-sub-355-XWukxHo-123-9dbe8adb-d45e-444b-94da-2478cc2a206b sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:57.400 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:57.400 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-355-XWukxHo-123, groupId=sub-355-XWukxHo] Request joining group due to: consumer pro-actively leaving the group
10:38:57.861 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:57.861 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:57.861 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:57.861 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-355-XWukxHo-123 unregistered
10:38:57.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Revoke previously assigned partitions test-topic-0000358-VRn-TQc-0
10:38:57.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Member consumer-sub-358-AcQiokY-124-52b6ec66-a41c-4c69-a0b0-035c7f098e27 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:57.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:57.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-358-AcQiokY-124, groupId=sub-358-AcQiokY] Request joining group due to: consumer pro-actively leaving the group
10:38:57.971 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:57.971 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:57.971 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:57.971 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-358-AcQiokY-124 unregistered
10:38:57.978 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Revoke previously assigned partitions test-topic-0000361-LZwO7zU-0
10:38:57.978 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Member consumer-sub-361-Gb3dfKI-125-1bad7ba4-ed26-4acb-979f-cba307a9415b sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:57.978 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:57.978 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-361-Gb3dfKI-125, groupId=sub-361-Gb3dfKI] Request joining group due to: consumer pro-actively leaving the group
10:38:58.065 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:58.065 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:58.065 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:58.066 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-361-Gb3dfKI-125 unregistered
10:38:58.124 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Revoke previously assigned partitions test-topic-0000364-kAq5nsI-0
10:38:58.124 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Member consumer-sub-364--B3TswQ-126-97ac7737-92d9-48de-a41b-b7b9ee9bfc6a sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:58.124 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:58.124 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-364--B3TswQ-126, groupId=sub-364--B3TswQ] Request joining group due to: consumer pro-actively leaving the group
10:38:58.436 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:58.437 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:58.437 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:58.437 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-364--B3TswQ-126 unregistered
10:38:58.443 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Revoke previously assigned partitions test-topic-0000367-NouK178-0
10:38:58.444 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Member consumer-sub-367-ql_4kYc-127-bada1af4-9b48-4af0-895d-174651bfa242 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:58.444 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:58.444 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-367-ql_4kYc-127, groupId=sub-367-ql_4kYc] Request joining group due to: consumer pro-actively leaving the group
10:38:58.838 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:58.839 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:58.839 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:58.839 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-367-ql_4kYc-127 unregistered
10:38:58.848 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Revoke previously assigned partitions test-topic-0000370-mEr65Xk-0
10:38:58.848 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Member consumer-sub-370-v5wLaPc-128-548de164-e564-4272-b293-b36ed7828710 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:58.848 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:58.848 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-370-v5wLaPc-128, groupId=sub-370-v5wLaPc] Request joining group due to: consumer pro-actively leaving the group
10:38:58.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:58.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:58.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:58.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-370-v5wLaPc-128 unregistered
10:38:58.901 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Revoke previously assigned partitions test-topic-0000373-_NDkX0c-0
10:38:58.901 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Member consumer-sub-373-4hV6wFE-129-08a1e9eb-6997-49d4-b916-e7a6be4a3326 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:58.901 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:58.901 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-373-4hV6wFE-129, groupId=sub-373-4hV6wFE] Request joining group due to: consumer pro-actively leaving the group
10:38:59.070 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:59.070 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:59.070 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:59.071 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-373-4hV6wFE-129 unregistered
10:38:59.074 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Revoke previously assigned partitions test-topic-0000376-OIelxdU-0
10:38:59.074 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Member consumer-sub-376-igw_F3A-130-ff958076-5daf-4ef9-a3f0-20871e9d8dc1 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:38:59.074 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:59.074 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-376-igw_F3A-130, groupId=sub-376-igw_F3A] Request joining group due to: consumer pro-actively leaving the group
10:38:59.116 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:59.116 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:59.116 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:59.116 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-376-igw_F3A-130 unregistered
10:38:59.199 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Revoke previously assigned partitions test-topic-0000379-TfxtvR0-0
10:38:59.199 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Member consumer-sub-379-OGtMICI-131-f1e10ad5-6366-4772-9b68-e28ea3db908f sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:59.199 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:59.199 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-379-OGtMICI-131, groupId=sub-379-OGtMICI] Request joining group due to: consumer pro-actively leaving the group
10:38:59.360 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:59.360 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:59.361 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:59.361 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-379-OGtMICI-131 unregistered
10:38:59.398 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Revoke previously assigned partitions test-topic-0000382-L601XY4-0
10:38:59.398 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Member consumer-sub-382-5bYhotQ-132-fa08d952-979a-4212-9456-f2611f673495 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:38:59.398 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:59.398 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-382-5bYhotQ-132, groupId=sub-382-5bYhotQ] Request joining group due to: consumer pro-actively leaving the group
10:38:59.677 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:59.677 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:59.677 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:59.677 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-382-5bYhotQ-132 unregistered
10:38:59.753 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Revoke previously assigned partitions test-topic-0000385-UMXA7Q8-0
10:38:59.753 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Member consumer-sub-385-vae6fZg-133-38203741-818d-492f-9d32-edf057ad12e9 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:38:59.753 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:38:59.753 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-385-vae6fZg-133, groupId=sub-385-vae6fZg] Request joining group due to: consumer pro-actively leaving the group
10:38:59.967 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:38:59.967 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:38:59.967 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:38:59.967 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-385-vae6fZg-133 unregistered
10:39:00.066 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Revoke previously assigned partitions test-topic-0000388-y1l0tN0-0
10:39:00.066 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Member consumer-sub-388-P5cW7Tg-134-1b32509e-9473-4521-98ad-aa35ee6eaa4b sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:00.066 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:00.066 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-388-P5cW7Tg-134, groupId=sub-388-P5cW7Tg] Request joining group due to: consumer pro-actively leaving the group
10:39:00.483 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:00.483 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:00.483 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:00.483 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-388-P5cW7Tg-134 unregistered
10:39:00.498 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Revoke previously assigned partitions test-topic-0000391-QVLIF3k-0
10:39:00.498 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Member consumer-sub-391-RUDds4Y-135-d3019b5e-8534-49bc-b853-d3c0d9a867cf sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:00.498 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:00.498 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-391-RUDds4Y-135, groupId=sub-391-RUDds4Y] Request joining group due to: consumer pro-actively leaving the group
10:39:00.839 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:00.839 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:00.839 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:00.839 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-391-RUDds4Y-135 unregistered
10:39:00.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Revoke previously assigned partitions test-topic-0000394-xlkFLyI-0
10:39:00.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Member consumer-sub-394-tyloWTo-136-e9fc70cf-e16d-4053-a49c-daac33d7904f sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:00.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:00.912 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-394-tyloWTo-136, groupId=sub-394-tyloWTo] Request joining group due to: consumer pro-actively leaving the group
10:39:01.366 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:01.366 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:01.366 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:01.366 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-394-tyloWTo-136 unregistered
10:39:01.425 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Revoke previously assigned partitions test-topic-0000397-bh_sXo0-0
10:39:01.425 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Member consumer-sub-397-zg7ub-4-137-4174d177-e964-4955-9901-066928aee244 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:01.425 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:01.425 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-397-zg7ub-4-137, groupId=sub-397-zg7ub-4] Request joining group due to: consumer pro-actively leaving the group
10:39:01.570 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:01.570 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:01.570 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:01.571 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-397-zg7ub-4-137 unregistered
10:39:01.641 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Revoke previously assigned partitions test-topic-0000400-X7FM4dU-0
10:39:01.641 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Member consumer-sub-400-KsDN_SE-138-a50dbd55-6d38-426c-921a-b28b437dc3f8 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:01.642 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:01.642 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-400-KsDN_SE-138, groupId=sub-400-KsDN_SE] Request joining group due to: consumer pro-actively leaving the group
10:39:01.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:01.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:01.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:01.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-400-KsDN_SE-138 unregistered
10:39:01.958 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Revoke previously assigned partitions test-topic-0000403-cSYU2uM-0
10:39:01.958 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Member consumer-sub-403-NN_e-UM-139-42367471-f51f-43fb-a9f1-fd2a61198725 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:01.958 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:01.959 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-403-NN_e-UM-139, groupId=sub-403-NN_e-UM] Request joining group due to: consumer pro-actively leaving the group
10:39:02.127 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:02.127 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:02.127 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:02.127 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-403-NN_e-UM-139 unregistered
10:39:02.193 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Revoke previously assigned partitions test-topic-0000406-veksnbI-0
10:39:02.193 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Member consumer-sub-406-fYmqBzg-140-ffd6987b-6002-475e-9888-c0f04f7077c2 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:02.193 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:02.193 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-406-fYmqBzg-140, groupId=sub-406-fYmqBzg] Request joining group due to: consumer pro-actively leaving the group
10:39:02.590 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:02.590 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:02.590 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:02.591 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-406-fYmqBzg-140 unregistered
10:39:02.649 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Revoke previously assigned partitions test-topic-0000409-sCB18EQ-0
10:39:02.649 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Member consumer-sub-409-GRwWUd0-141-c8d5cf57-8542-4fe1-a772-b8d2446a5b30 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:02.649 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:02.649 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-409-GRwWUd0-141, groupId=sub-409-GRwWUd0] Request joining group due to: consumer pro-actively leaving the group
10:39:03.058 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:03.058 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:03.058 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:03.058 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-409-GRwWUd0-141 unregistered
10:39:03.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Revoke previously assigned partitions test-topic-0000412-gJ9uDSE-0
10:39:03.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Member consumer-sub-412-KLerxmg-142-6e086eaa-8161-49b1-9569-ce0606965e02 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:03.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:03.109 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-412-KLerxmg-142, groupId=sub-412-KLerxmg] Request joining group due to: consumer pro-actively leaving the group
10:39:03.603 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:03.603 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:03.603 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:03.604 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-412-KLerxmg-142 unregistered
10:39:03.604 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Revoke previously assigned partitions test-topic-0000415-EgHOvbM-0
10:39:03.604 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Member consumer-sub-415-DqirbL0-143-f8fe638f-c59a-4202-93aa-239a11191bb9 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:03.604 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:03.604 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-415-DqirbL0-143, groupId=sub-415-DqirbL0] Request joining group due to: consumer pro-actively leaving the group
10:39:04.076 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:04.076 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:04.076 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:04.077 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-415-DqirbL0-143 unregistered
10:39:04.168 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Revoke previously assigned partitions test-topic-0000418-qY6RauQ-0
10:39:04.168 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Member consumer-sub-418-BG0vOxQ-144-d83790f0-2e55-4bc5-bcf3-765044c564a9 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:04.168 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:04.168 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-418-BG0vOxQ-144, groupId=sub-418-BG0vOxQ] Request joining group due to: consumer pro-actively leaving the group
10:39:04.622 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:04.622 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:04.622 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:04.623 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-418-BG0vOxQ-144 unregistered
10:39:04.672 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Revoke previously assigned partitions test-topic-0000421-AwE19r0-0
10:39:04.672 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Member consumer-sub-421-By8iGYI-145-6d7190be-74ba-48d6-aa90-38c8f3cc0a57 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:04.673 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:04.673 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-421-By8iGYI-145, groupId=sub-421-By8iGYI] Request joining group due to: consumer pro-actively leaving the group
10:39:05.026 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:05.027 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:05.027 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:05.027 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-421-By8iGYI-145 unregistered
10:39:05.107 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Revoke previously assigned partitions test-topic-0000424-rZeSqAQ-0
10:39:05.107 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Member consumer-sub-424-VmduDzo-146-daf58349-dabd-4ff8-b983-136d6353ef1a sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:05.107 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:05.107 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-424-VmduDzo-146, groupId=sub-424-VmduDzo] Request joining group due to: consumer pro-actively leaving the group
10:39:05.497 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:05.497 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:05.497 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:05.497 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-424-VmduDzo-146 unregistered
10:39:05.537 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Revoke previously assigned partitions test-topic-0000427-q9wDEgM-0
10:39:05.537 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Member consumer-sub-427-_nunaqs-147-d79526e0-4c10-409a-8e41-83cf768bb428 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:05.537 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:05.537 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-427-_nunaqs-147, groupId=sub-427-_nunaqs] Request joining group due to: consumer pro-actively leaving the group
10:39:05.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:05.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:05.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:05.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-427-_nunaqs-147 unregistered
10:39:05.938 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Revoke previously assigned partitions test-topic-0000430-1HkZXP0-0
10:39:05.938 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Member consumer-sub-430-HIP-Ecc-148-aeaf283d-6744-421f-8447-932a6732df5b sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:05.938 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:05.938 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-430-HIP-Ecc-148, groupId=sub-430-HIP-Ecc] Request joining group due to: consumer pro-actively leaving the group
10:39:06.236 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:06.236 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:06.236 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:06.236 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-430-HIP-Ecc-148 unregistered
10:39:06.271 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Revoke previously assigned partitions test-topic-0000433-ahog9AU-0
10:39:06.271 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Member consumer-sub-433-5Z6gPg8-149-9a960151-dec6-46ab-b396-a6a0d37429ff sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:06.271 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:06.271 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-433-5Z6gPg8-149, groupId=sub-433-5Z6gPg8] Request joining group due to: consumer pro-actively leaving the group
10:39:06.491 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:06.491 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:06.491 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:06.492 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-433-5Z6gPg8-149 unregistered
10:39:06.553 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Revoke previously assigned partitions test-topic-0000436-1z7Eoyk-0
10:39:06.553 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Member consumer-sub-436-l5QsKDs-150-d71d1b89-8a4c-4d9a-9fa9-704d39eb93a8 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:06.554 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:06.554 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-436-l5QsKDs-150, groupId=sub-436-l5QsKDs] Request joining group due to: consumer pro-actively leaving the group
10:39:06.981 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:06.981 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:06.981 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:06.982 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-436-l5QsKDs-150 unregistered
10:39:06.999 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Revoke previously assigned partitions test-topic-0000439-mHkFOzE-0
10:39:06.999 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Member consumer-sub-439-0u7s0Zo-151-6f6de5ab-714d-4b03-9b85-c60a3913515d sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:06.999 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:06.999 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-439-0u7s0Zo-151, groupId=sub-439-0u7s0Zo] Request joining group due to: consumer pro-actively leaving the group
10:39:07.025 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:07.025 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:07.025 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:07.025 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-439-0u7s0Zo-151 unregistered
10:39:07.037 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Revoke previously assigned partitions test-topic-0000442-upMlwWs-0
10:39:07.037 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Member consumer-sub-442-GTggPn4-152-e878d4d0-5443-4046-958f-50bab84bcca8 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:07.038 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:07.038 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-442-GTggPn4-152, groupId=sub-442-GTggPn4] Request joining group due to: consumer pro-actively leaving the group
10:39:07.300 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:07.300 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:07.300 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:07.300 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-442-GTggPn4-152 unregistered
10:39:07.307 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Revoke previously assigned partitions test-topic-0000445-e-Tdli0-0
10:39:07.307 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Member consumer-sub-445-ZjQdD0o-153-af4ba00b-a55e-43bf-98db-41931d38d375 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:07.307 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:07.307 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-445-ZjQdD0o-153, groupId=sub-445-ZjQdD0o] Request joining group due to: consumer pro-actively leaving the group
10:39:07.366 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:07.366 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:07.366 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:07.367 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-445-ZjQdD0o-153 unregistered
10:39:07.405 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Revoke previously assigned partitions test-topic-0000448-54rGmRw-0
10:39:07.405 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Member consumer-sub-448-EYn8owI-154-0ae8c1f4-24f5-4a5d-8caa-fd1801ddef7f sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:07.405 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:07.405 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-448-EYn8owI-154, groupId=sub-448-EYn8owI] Request joining group due to: consumer pro-actively leaving the group
10:39:07.579 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:07.579 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:07.579 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:07.580 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-448-EYn8owI-154 unregistered
10:39:07.657 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Revoke previously assigned partitions test-topic-0000451-iYHTx2A-0
10:39:07.658 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Member consumer-sub-451-f4gaQWo-155-d7cb18f9-426f-4b03-8aef-749da5027c57 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:07.658 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:07.658 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-451-f4gaQWo-155, groupId=sub-451-f4gaQWo] Request joining group due to: consumer pro-actively leaving the group
10:39:07.999 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:07.999 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:07.999 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:07.999 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-451-f4gaQWo-155 unregistered
10:39:08.019 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Revoke previously assigned partitions test-topic-0000454-jINTbDs-0
10:39:08.019 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Member consumer-sub-454-VOt8IBo-156-cce8af2a-086c-4d80-b5b0-11d10d9e2bcd sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:08.019 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:08.019 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-454-VOt8IBo-156, groupId=sub-454-VOt8IBo] Request joining group due to: consumer pro-actively leaving the group
10:39:08.401 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:08.401 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:08.401 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:08.401 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-454-VOt8IBo-156 unregistered
10:39:08.476 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Revoke previously assigned partitions test-topic-0000457-37_m3sc-0
10:39:08.476 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Member consumer-sub-457-HrOiLw0-157-79837063-8780-454c-81cd-b21c75c2f00d sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:08.476 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:08.476 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-457-HrOiLw0-157, groupId=sub-457-HrOiLw0] Request joining group due to: consumer pro-actively leaving the group
10:39:08.603 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:08.603 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:08.603 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:08.603 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-457-HrOiLw0-157 unregistered
10:39:08.622 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Revoke previously assigned partitions test-topic-0000460-NzJPttA-0
10:39:08.622 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Member consumer-sub-460-rlIljZk-158-3ace56a8-bfcc-47e4-a2d6-d6e439dc95c6 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:08.622 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:08.622 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-460-rlIljZk-158, groupId=sub-460-rlIljZk] Request joining group due to: consumer pro-actively leaving the group
10:39:08.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:08.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:08.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:08.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-460-rlIljZk-158 unregistered
10:39:08.954 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Revoke previously assigned partitions test-topic-0000463-AnsrbPc-0
10:39:08.954 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Member consumer-sub-463-mxbWA84-159-ce25485c-1f27-4a56-9903-5ce0da6c09df sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:08.954 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:08.954 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-463-mxbWA84-159, groupId=sub-463-mxbWA84] Request joining group due to: consumer pro-actively leaving the group
10:39:09.297 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:09.297 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:09.297 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:09.298 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-463-mxbWA84-159 unregistered
10:39:09.389 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Revoke previously assigned partitions test-topic-0000466-rwZ2pKE-0
10:39:09.390 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Member consumer-sub-466-qbRBPK4-160-173529e3-aee4-4a0e-89c1-da0cc1c4aa5b sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:09.390 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:09.390 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-466-qbRBPK4-160, groupId=sub-466-qbRBPK4] Request joining group due to: consumer pro-actively leaving the group
10:39:09.789 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:09.789 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:09.789 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:09.790 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-466-qbRBPK4-160 unregistered
10:39:09.816 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Revoke previously assigned partitions test-topic-0000469-1ZGl9m0-0
10:39:09.816 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Member consumer-sub-469-CHMVaMY-161-3af04603-bd18-4d91-b216-e85c38165e55 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:09.816 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:09.816 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-469-CHMVaMY-161, groupId=sub-469-CHMVaMY] Request joining group due to: consumer pro-actively leaving the group
10:39:09.819 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:09.820 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:09.820 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:09.820 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-469-CHMVaMY-161 unregistered
10:39:09.889 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Revoke previously assigned partitions test-topic-0000472-FWunwBk-0
10:39:09.890 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Member consumer-sub-472-nZDgjwA-162-b4481d95-8ca9-41bd-8716-9492555fa718 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:09.890 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:09.890 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-472-nZDgjwA-162, groupId=sub-472-nZDgjwA] Request joining group due to: consumer pro-actively leaving the group
10:39:10.296 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:10.296 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:10.297 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:10.297 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-472-nZDgjwA-162 unregistered
10:39:10.315 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Revoke previously assigned partitions test-topic-0000475-2oxOTx4-0
10:39:10.315 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Member consumer-sub-475-4g3cL84-163-0b684e4f-06e1-4b36-8135-af6b74916c85 sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:10.315 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:10.315 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-475-4g3cL84-163, groupId=sub-475-4g3cL84] Request joining group due to: consumer pro-actively leaving the group
10:39:10.509 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:10.509 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:10.509 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:10.509 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-475-4g3cL84-163 unregistered
10:39:10.528 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Revoke previously assigned partitions test-topic-0000478-PJjxrHU-0
10:39:10.528 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Member consumer-sub-478--bnw0AY-164-8dbf987e-c319-4221-b745-31a685a2aa28 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:10.528 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:10.528 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-478--bnw0AY-164, groupId=sub-478--bnw0AY] Request joining group due to: consumer pro-actively leaving the group
10:39:10.647 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:10.647 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:10.648 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:10.648 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-478--bnw0AY-164 unregistered
10:39:10.679 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Revoke previously assigned partitions test-topic-0000481-rS9biTw-0
10:39:10.679 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Member consumer-sub-481-_wldBvc-165-a253e4d3-a3f1-4aa3-abec-cb2023dbe482 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:10.679 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:10.679 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-481-_wldBvc-165, groupId=sub-481-_wldBvc] Request joining group due to: consumer pro-actively leaving the group
10:39:11.141 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:11.141 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:11.141 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:11.141 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-481-_wldBvc-165 unregistered
10:39:11.242 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Revoke previously assigned partitions test-topic-0000484-Rft_ITE-0
10:39:11.242 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Member consumer-sub-484-0dDycKg-166-8d72fcdc-85ee-456d-903a-cef871f75f0c sending LeaveGroup request to coordinator 10.0.0.91:9092 (id: 2147483645 rack: null) due to the consumer is being closed
10:39:11.242 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:11.242 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-484-0dDycKg-166, groupId=sub-484-0dDycKg] Request joining group due to: consumer pro-actively leaving the group
10:39:11.582 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:11.582 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:11.582 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:11.583 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-484-0dDycKg-166 unregistered
10:39:11.613 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Revoke previously assigned partitions test-topic-0000487-vhHh-EY-0
10:39:11.613 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Member consumer-sub-487-tPuwjUY-167-487d5482-900a-4987-b7b0-a5eacebd5d81 sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:11.613 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:11.613 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-487-tPuwjUY-167, groupId=sub-487-tPuwjUY] Request joining group due to: consumer pro-actively leaving the group
10:39:12.077 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.077 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.077 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.078 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-487-tPuwjUY-167 unregistered
10:39:12.080 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Revoke previously assigned partitions test-topic-0000490-f2jrk7M-0
10:39:12.080 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Member consumer-sub-490-qBSDzRw-168-4aa52690-67af-49f6-899a-35225c3c1c37 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:12.080 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:12.080 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-490-qBSDzRw-168, groupId=sub-490-qBSDzRw] Request joining group due to: consumer pro-actively leaving the group
10:39:12.383 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.383 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.383 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.384 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-490-qBSDzRw-168 unregistered
10:39:12.414 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Revoke previously assigned partitions test-topic-0000493-T5rBBVM-0
10:39:12.414 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Member consumer-sub-493-RgWTaLU-169-ecd31458-473b-4724-af6e-01240f24773b sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:12.414 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:12.414 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-493-RgWTaLU-169, groupId=sub-493-RgWTaLU] Request joining group due to: consumer pro-actively leaving the group
10:39:12.440 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.440 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.440 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.441 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-493-RgWTaLU-169 unregistered
10:39:12.473 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Revoke previously assigned partitions test-topic-0000496-f5cGpzY-0
10:39:12.473 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Member consumer-sub-496-f32gVfs-170-76a17a69-132d-4136-80ea-b4c32824cabc sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:12.473 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:12.473 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-496-f32gVfs-170, groupId=sub-496-f32gVfs] Request joining group due to: consumer pro-actively leaving the group
10:39:12.506 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.506 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.506 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.506 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-496-f32gVfs-170 unregistered
10:39:12.546 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Revoke previously assigned partitions test-topic-0000499-rvuAtqA-0
10:39:12.546 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Member consumer-sub-499-lAdLlmc-171-10ab314e-d909-41cc-952d-4a200c3299bf sending LeaveGroup request to coordinator 10.0.0.162:9092 (id: 2147483647 rack: null) due to the consumer is being closed
10:39:12.546 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:12.546 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-499-lAdLlmc-171, groupId=sub-499-lAdLlmc] Request joining group due to: consumer pro-actively leaving the group
10:39:12.758 [pool-175-thread-1] WARN AbstractFetch - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Received unknown topic or partition error in fetch for partition test-topic-0000505-tAmtBFc-0
10:39:12.765 [pool-175-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Error while fetching metadata with correlation id 551 : {test-topic-0000505-tAmtBFc=LEADER_NOT_AVAILABLE}
10:39:12.766 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Request joining group due to: cached metadata has changed from (version2: {test-topic-0000505-tAmtBFc=[NO_RACKS]}) at the beginning of the rebalance to (version3: {test-topic-0000505-tAmtBFc=[]})
10:39:12.766 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Revoke previously assigned partitions test-topic-0000505-tAmtBFc-0
10:39:12.766 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] (Re-)joining group
10:39:12.767 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Successfully joined group with generation Generation{generationId=2, memberId='consumer-sub-505-ArOslyo-173-4c357d76-0f23-47ad-8a99-77d73c932e66', protocol='range'}
10:39:12.775 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.775 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.775 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.776 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-499-lAdLlmc-171 unregistered
10:39:12.791 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Revoke previously assigned partitions test-topic-0000502-e6T4-_g-0
10:39:12.792 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Member consumer-sub-502-HkdCi6I-172-42275854-4a66-4a13-befa-20b1e4028262 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:12.792 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:12.792 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-502-HkdCi6I-172, groupId=sub-502-HkdCi6I] Request joining group due to: consumer pro-actively leaving the group
10:39:12.793 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.793 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.793 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.794 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-502-HkdCi6I-172 unregistered
10:39:12.798 [pool-2-thread-1] WARN AbstractFetch - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Received unknown topic or partition error in fetch for partition test-topic-0000006-TuXPgEs-0
10:39:12.800 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1321 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:12.801 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Request joining group due to: cached metadata has changed from (version2: {test-topic-0000006-TuXPgEs=[NO_RACKS]}) at the beginning of the rebalance to (version3: {test-topic-0000006-TuXPgEs=[]})
10:39:12.801 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Revoke previously assigned partitions test-topic-0000006-TuXPgEs-0
10:39:12.802 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] (Re-)joining group
10:39:12.803 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Successfully joined group with generation Generation{generationId=2, memberId='consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3', protocol='range'}
10:39:12.867 [pool-175-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Error while fetching metadata with correlation id 553 : {test-topic-0000505-tAmtBFc=LEADER_NOT_AVAILABLE}
10:39:12.867 [pool-175-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Finished assignment for group at generation 2: {consumer-sub-505-ArOslyo-173-4c357d76-0f23-47ad-8a99-77d73c932e66=Assignment(partitions=[])}
10:39:12.867 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Member consumer-sub-505-ArOslyo-173-4c357d76-0f23-47ad-8a99-77d73c932e66 sending LeaveGroup request to coordinator 10.0.0.131:9092 (id: 2147483646 rack: null) due to the consumer is being closed
10:39:12.867 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Resetting generation and member id due to: consumer pro-actively leaving the group
10:39:12.867 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Request joining group due to: consumer pro-actively leaving the group
10:39:12.869 [qtp235162442-24] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-505-ArOslyo-173, groupId=sub-505-ArOslyo] Generation data was cleared by heartbeat thread to Generation{generationId=-1, memberId='', protocol='null'} and state is now UNJOINED before receiving SyncGroup response, marking this rebalance as failed and retry
10:39:12.870 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.870 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.870 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.870 [qtp235162442-24] INFO AppInfoParser - App info kafka.consumer for consumer-sub-505-ArOslyo-173 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-1 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-2 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-3 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-4 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-5 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-6 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-7 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-8 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-9 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.871 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.871 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-10 unregistered
10:39:12.871 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.871 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-11 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-12 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-13 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-14 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-15 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-16 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-17 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-18 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-19 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-20 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-21 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-22 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-23 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-24 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-25 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-26] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.872 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-26 unregistered
10:39:12.872 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.872 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.872 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-27 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-28] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-28 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-29 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-30] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-30 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-31] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-31 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-32] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-32 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-33] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-33 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-34] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-34 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-35] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-35 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-36] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-36 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-37] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-37 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-38] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-38 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-39] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-39 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-40] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-40 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-41] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-41 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-42] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-42 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-43] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.873 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-43 unregistered
10:39:12.873 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-44] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.873 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.873 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-44 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-45] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-45 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-46] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-46 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-47] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-47 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-48] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-48 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-49] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-49 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-50] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-50 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-51] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-51 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-52] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-52 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-53] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-53 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-54] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-54 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-55] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-55 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-56] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-56 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-57] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-57 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-58] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-58 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-59] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-59 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-60] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-60 unregistered
10:39:12.874 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-61] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.874 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.874 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.874 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-61 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-62] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-62 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-63] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-63 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-64] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-64 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-65] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-65 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-66] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-66 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-67] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-67 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-68] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-68 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-69] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-69 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-70] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-70 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-71] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-71 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-72] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-72 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-73] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-73 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-74] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-74 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-75] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-75 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-76] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-76 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-77] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-77 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-78] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.875 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.875 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.875 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-78 unregistered
10:39:12.875 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-79] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-79 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-80] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-80 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-81] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-81 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-82] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-82 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-83] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-83 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-84] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-84 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-85] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-85 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-86] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-86 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-87] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-87 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-88] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-88 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-89] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-89 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-90] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-90 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-91] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-91 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-92] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-92 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-93] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-93 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-94] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.876 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-94 unregistered
10:39:12.876 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-95] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.876 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.876 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-95 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-96] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-96 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-97] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-97 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-98] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-98 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-99] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-99 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-100] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-100 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-101] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-101 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-102] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-102 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-103] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-103 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-104] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-104 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-105] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-105 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-106] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-106 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-107] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-107 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-108] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-108 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-109] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-109 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-110] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-110 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-111] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.877 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-111 unregistered
10:39:12.877 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-112] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.877 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.877 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-112 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-113] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-113 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-114] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-114 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-115] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-115 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-116] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-116 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-117] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-117 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-118] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-118 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-119] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-119 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-120] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-120 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-121] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-121 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-122] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-122 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-123] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-123 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-124] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-124 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-125] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-125 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-126] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-126 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-127] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.878 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-127 unregistered
10:39:12.878 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-128] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.878 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.878 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-128 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-129] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-129 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-130] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-130 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-131] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-131 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-132] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-132 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-133] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-133 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-134] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-134 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-135] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-135 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-136] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-136 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-137] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-137 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-138] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-138 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-139] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-139 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-140] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-140 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-141] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-141 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-142] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-142 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-143] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-143 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-144] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.879 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-144 unregistered
10:39:12.879 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-145] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.879 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.879 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-145 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-146] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-146 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-147] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-147 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-148] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-148 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-149] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-149 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-150] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-150 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-151] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-151 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-152] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-152 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-153] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-153 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-154] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-154 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-155] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-155 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-156] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-156 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-157] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-157 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-158] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-158 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-159] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-159 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-160] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-160 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-161] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.880 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.880 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-161 unregistered
10:39:12.880 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-162] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.880 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-162 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-163] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-163 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-164] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-164 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-165] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-165 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-166] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-166 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-167] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-167 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-168] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-168 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-169] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-169 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-170] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-170 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-171] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-171 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-172] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-172 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-173] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-173 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-174] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-174 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-175] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-175 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-176] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-176 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-177] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-177 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-178] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-178 unregistered
10:39:12.881 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-179] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.881 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.881 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.881 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-179 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-180] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-180 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-181] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-181 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-182] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-182 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-183] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-183 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-184] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-184 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-185] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-185 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-186] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-186 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-187] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-187 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-188] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-188 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-189] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-189 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-190] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-190 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-191] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-191 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-192] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-192 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-193] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-193 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-194] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-194 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-195] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-195 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-196] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.882 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-196 unregistered
10:39:12.882 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-197] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.882 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.882 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-197 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-198] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-198 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-199] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-199 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-200] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-200 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-201] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-201 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-202] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-202 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-203] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-203 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-204] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-204 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-205] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-205 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-206] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-206 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-207] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-207 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-208] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-208 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-209] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-209 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-210] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-210 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-211] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-211 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-212] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-212 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-213] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-213 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-214] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-214 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-215] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.883 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.883 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.883 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-215 unregistered
10:39:12.883 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-216] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-216 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-217] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-217 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-218] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-218 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-219] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-219 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-220] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-220 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-221] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-221 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-222] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-222 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-223] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-223 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-224] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-224 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-225] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-225 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-226] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-226 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-227] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-227 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-228] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-228 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-229] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-229 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-230] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-230 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-231] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-231 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-232] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-232 unregistered
10:39:12.884 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-233] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.884 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.884 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.884 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-233 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-234] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-234 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-235] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-235 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-236] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-236 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-237] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-237 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-238] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-238 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-239] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-239 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-240] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-240 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-241] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-241 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-242] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-242 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-243] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-243 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-244] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-244 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-245] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-245 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-246] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-246 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-247] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-247 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-248] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-248 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-249] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-249 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-250] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.885 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-250 unregistered
10:39:12.885 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-251] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.885 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.885 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-251 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-252] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-252 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-253] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-253 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-254] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-254 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-255] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-255 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-256] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-256 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-257] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-257 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-258] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-258 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-259] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-259 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-260] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-260 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-261] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-261 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-262] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-262 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-263] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-263 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-264] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-264 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-265] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-265 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-266] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-266 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-267] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-267 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-268] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.886 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-268 unregistered
10:39:12.886 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-269] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.886 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.886 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-269 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-270] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-270 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-271] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-271 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-272] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-272 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-273] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-273 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-274] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-274 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-275] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-275 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-276] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-276 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-277] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-277 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-278] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-278 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-279] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-279 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-280] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-280 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-281] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-281 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-282] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-282 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-283] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-283 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-284] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-284 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-285] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-285 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-286] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.887 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-286 unregistered
10:39:12.887 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-287] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.887 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.887 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-287 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-288] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-288 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-289] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-289 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-290] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-290 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-291] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-291 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-292] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-292 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-293] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-293 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-294] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-294 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-295] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-295 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-296] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-296 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-297] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-297 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-298] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-298 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-299] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-299 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-300] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-300 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-301] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-301 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-302] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-302 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-303] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-303 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-304] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.888 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.888 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.888 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-304 unregistered
10:39:12.888 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-305] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-305 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-306] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-306 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-307] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-307 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-308] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-308 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-309] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-309 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-310] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-310 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-311] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-311 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-312] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-312 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-313] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-313 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-314] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-314 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-315] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-315 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-316] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-316 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-317] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-317 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-318] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-318 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-319] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-319 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-320] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-320 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-321] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.889 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-321 unregistered
10:39:12.889 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-322] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.889 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.889 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-322 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-323] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-323 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-324] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-324 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-325] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-325 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-326] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-326 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-327] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-327 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-328] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-328 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-329] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-329 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-330] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-330 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-331] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-331 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-332] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-332 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-333] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-333 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-334] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-334 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-335] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-335 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-336] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-336 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-337] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-337 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-338] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.890 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-338 unregistered
10:39:12.890 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-339] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.890 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.890 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-339 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-340] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-340 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-341] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-341 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-342] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-342 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-343] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-343 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-344] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-344 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-345] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-345 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-346] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-346 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-347] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-347 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-348] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-348 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-349] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-349 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-350] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-350 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-351] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-351 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-352] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-352 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-353] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-353 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-354] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-354 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-355] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-355 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-356] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.891 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.891 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-356 unregistered
10:39:12.891 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-357] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.891 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-357 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-358] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-358 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-359] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-359 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-360] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-360 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-361] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-361 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-362] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-362 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-363] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-363 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-364] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-364 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-365] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-365 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-366] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-366 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-367] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-367 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-368] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-368 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-369] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-369 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-370] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-370 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-371] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-371 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-372] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-372 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-373] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.892 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-373 unregistered
10:39:12.892 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-374] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.892 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.892 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-374 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-375] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-375 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-376] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-376 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-377] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-377 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-378] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-378 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-379] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-379 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-380] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-380 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-381] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-381 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-382] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-382 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-383] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-383 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-384] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-384 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-385] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-385 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-386] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-386 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-387] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-387 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-388] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-388 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-389] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-389 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-390] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-390 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-391] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.893 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.893 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.893 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-391 unregistered
10:39:12.893 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-392] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-392 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-393] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-393 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-394] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-394 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-395] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-395 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-396] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-396 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-397] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-397 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-398] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-398 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-399] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-399 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-400] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-400 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-401] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-401 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-402] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-402 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-403] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-403 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-404] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-404 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-405] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-405 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-406] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-406 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-407] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-407 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-408] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-408 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-409] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.894 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-409 unregistered
10:39:12.894 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-410] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.894 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.894 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-410 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-411] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-411 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-412] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-412 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-413] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-413 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-414] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-414 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-415] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-415 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-416] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-416 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-417] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-417 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-418] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-418 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-419] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-419 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-420] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-420 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-421] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-421 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-422] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-422 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-423] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-423 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-424] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-424 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-425] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-425 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-426] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-426 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-427] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-427 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-428] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.895 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.895 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.895 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-428 unregistered
10:39:12.895 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-429] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-429 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-430] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-430 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-431] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-431 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-432] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-432 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-433] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-433 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-434] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-434 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-435] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-435 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-436] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-436 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-437] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-437 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-438] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-438 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-439] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-439 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-440] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-440 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-441] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-441 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-442] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-442 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-443] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-443 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-444] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-444 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-445] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-445 unregistered
10:39:12.896 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-446] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.896 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.896 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.896 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-446 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-447] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-447 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-448] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-448 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-449] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-449 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-450] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-450 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-451] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-451 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-452] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-452 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-453] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-453 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-454] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-454 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-455] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-455 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-456] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-456 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-457] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-457 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-458] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-458 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-459] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-459 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-460] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-460 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-461] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-461 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-462] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-462 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-463] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.897 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.897 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-463 unregistered
10:39:12.897 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-464] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.897 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-464 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-465] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-465 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-466] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-466 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-467] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-467 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-468] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-468 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-469] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-469 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-470] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-470 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-471] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-471 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-472] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-472 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-473] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-473 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-474] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-474 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-475] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-475 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-476] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-476 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-477] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-477 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-478] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-478 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-479] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.898 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-479 unregistered
10:39:12.898 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-480] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.898 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.898 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-480 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-481] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-481 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-482] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-482 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-483] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-483 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-484] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-484 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-485] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-485 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-486] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-486 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-487] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-487 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-488] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-488 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-489] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-489 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-490] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-490 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-491] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-491 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-492] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-492 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-493] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-493 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-494] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-494 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-495] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-495 unregistered
10:39:12.899 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-496] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.899 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.899 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.899 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-496 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-497] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-497 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-498] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-498 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-499] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-499 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-500] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-500 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-501] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-501 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-502] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-502 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-503] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-503 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-504] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-504 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-505] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-505 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-506] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-506 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-507] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-507 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-508] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-508 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-509] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-509 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-510] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-510 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-511] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-511 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-512] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-512 unregistered
10:39:12.900 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-513] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.900 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.900 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.900 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-513 unregistered
10:39:12.901 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-514] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.901 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.901 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-514 unregistered
10:39:12.901 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-515] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.901 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.901 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-515 unregistered
10:39:12.901 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-516] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.901 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.901 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-516 unregistered
10:39:12.901 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-517] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
10:39:12.901 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:12.901 [qtp235162442-24] INFO Metrics - Metrics reporters closed
10:39:12.901 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-517 unregistered
10:39:12.902 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1323 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:12.902 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Finished assignment for group at generation 2: {consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3=Assignment(partitions=[])}
10:39:12.904 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Successfully synced group in generation Generation{generationId=2, memberId='consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3', protocol='range'}
10:39:12.904 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Notifying assignor about the new Assignment(partitions=[])
10:39:12.905 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Adding newly assigned partitions: 
10:39:12.906 [qtp235162442-24] INFO KafkaBenchmarkDriver - Preparing to delete topics...
10:39:13.004 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1325 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.106 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1326 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.207 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1327 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.309 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1328 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.410 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1329 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.512 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1330 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.613 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1331 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.715 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1332 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.832 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1333 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:13.933 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1334 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:14.035 [pool-2-thread-1] WARN NetworkClient - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Error while fetching metadata with correlation id 1335 : {test-topic-0000006-TuXPgEs=LEADER_NOT_AVAILABLE}
10:39:14.086 [qtp235162442-24] INFO KafkaBenchmarkDriver - Topics left over: 1
10:39:14.086 [kafka-admin-client-thread | adminclient-1] INFO AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
10:39:14.087 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Metrics scheduler closed
10:39:14.087 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
10:39:14.087 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Metrics reporters closed
10:39:14.136 [pool-2-thread-1] INFO Metadata - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Resetting the last seen epoch of partition test-topic-0000006-TuXPgEs-0 to 0 since the associated topicId changed from null to kp52ZNigSzqteeLSZjXrOQ
10:39:14.136 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Request joining group due to: cached metadata has changed from (version4: {test-topic-0000006-TuXPgEs=[]}) at the beginning of the rebalance to (version16: {test-topic-0000006-TuXPgEs=[NO_RACKS]})
10:39:14.136 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Revoke previously assigned partitions 
10:39:14.136 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] (Re-)joining group
10:39:14.138 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Successfully joined group with generation Generation{generationId=3, memberId='consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3', protocol='range'}
10:39:14.138 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Finished assignment for group at generation 3: {consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3=Assignment(partitions=[test-topic-0000006-TuXPgEs-0])}
10:39:14.140 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Successfully synced group in generation Generation{generationId=3, memberId='consumer-sub-006-tfQv-qI-1-1d532f62-d5ae-4186-9ad5-8308779c5ae3', protocol='range'}
10:39:14.140 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Notifying assignor about the new Assignment(partitions=[test-topic-0000006-TuXPgEs-0])
10:39:14.140 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Adding newly assigned partitions: test-topic-0000006-TuXPgEs-0
10:39:14.141 [pool-2-thread-1] INFO ConsumerCoordinator - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Found no committed offset for partition test-topic-0000006-TuXPgEs-0
10:39:14.142 [pool-2-thread-1] INFO SubscriptionState - [Consumer clientId=consumer-sub-006-tfQv-qI-1, groupId=sub-006-tfQv-qI] Resetting offset for partition test-topic-0000006-TuXPgEs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.0.0.162:9092 (id: 0 rack: null)], epoch=0}}.
10:40:31.698 [kafka-admin-client-thread | adminclient-1] INFO NetworkClient - [AdminClient clientId=adminclient-1] Node -2 disconnected.
10:40:49.851 [main] INFO Benchmark - Using default worker file workers.yaml!
10:40:49.858 [main] INFO Benchmark - Reading workers list from workers.yaml
10:40:49.907 [main] INFO Benchmark - Starting benchmark with config: {
  "drivers" : [ "driver-kafka/kafka-experiment.yaml" ],
  "workers" : [ "http://10.0.0.42:8080", "http://10.0.0.246:8080", "http://10.0.0.175:8080" ],
  "workersFile" : "/opt/benchmark/workers.yaml",
  "tpcHFiles" : [ "workloads/tpc-h-q1-10000-800.yaml", "workloads/tpc-h-q6-10000-800.yaml" ],
  "workloads" : [ "workloads/tpc-h-base-long.yaml" ],
  "output" : null
}
10:40:49.923 [main] INFO Benchmark - Workloads: {
  "tpc-h-base-long" : {
    "name" : "tpc-h",
    "topics" : 0,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 0,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 10000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 10,
    "warmupDurationMinutes" : 1
  }
}
10:40:49.934 [main] INFO Benchmark - TPC-H arguments: [ {
  "queryId" : "tpc-h-q1-10000-800",
  "query" : "PricingSummaryReport",
  "sourceDataS3FolderUri" : "s3://tpc-h-chunks/chunks-by-file-size/7kb",
  "numberOfChunks" : 10000,
  "numberOfWorkers" : 800
}, {
  "queryId" : "tpc-h-q6-10000-800",
  "query" : "ForecastingRevenueChange",
  "sourceDataS3FolderUri" : "s3://tpc-h-chunks/chunks-by-file-size/7kb",
  "numberOfChunks" : 10000,
  "numberOfWorkers" : 800
} ]
10:40:50.290 [main] INFO CentralWorkerStats - Central worker stats initialized
10:40:50.534 [main] INFO DistributedWorkersEnsemble - Workers list - producers: [http://10.0.0.42:8080,http://10.0.0.246:8080,http://10.0.0.175:8080]
10:40:50.534 [main] INFO DistributedWorkersEnsemble - Workers list - consumers: http://10.0.0.42:8080,http://10.0.0.246:8080,http://10.0.0.175:8080
10:40:50.537 [main] INFO Benchmark - --------------- WORKLOAD : tpc-h --- DRIVER : Kafka---------------
