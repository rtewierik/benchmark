sudo bin/benchmark \
> --drivers driver-pravega/pravega-experiment.yaml \
> workloads/throughput-1kb-10-max.yaml
16:11:08.029 [main] INFO Benchmark - Using default worker file workers.yaml!
16:11:08.037 [main] INFO Benchmark - Reading workers list from workers.yaml
16:11:08.088 [main] INFO Benchmark - Starting benchmark with config: {
  "drivers" : [ "driver-pravega/pravega-experiment.yaml" ],
  "workers" : [ "http://10.0.0.254:8080", "http://10.0.0.158:8080", "http://10.0.0.137:8080" ],
  "workersFile" : "/opt/benchmark/workers.yaml",
  "tpcHFiles" : null,
  "workloads" : [ "workloads/throughput-1kb-10-max.yaml" ],
  "output" : null
}
16:11:08.105 [main] INFO Benchmark - Workloads: {
  "throughput-1kb-10-max" : {
    "name" : "throughput-1kb-10",
    "topics" : 10,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 1024,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "payload/payload-1Kb.data",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 1000000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 2,
    "warmupDurationMinutes" : 1
  }
}
16:11:08.106 [main] INFO Benchmark - TPC-H arguments: [ null ]
16:11:08.150 [main] INFO InstanceWorkerStats - Instance worker stats initialized.
16:11:08.748 [main] INFO DistributedWorkersEnsemble - Workers list - producers: [http://10.0.0.254:8080]
16:11:08.748 [main] INFO DistributedWorkersEnsemble - Workers list - consumers: http://10.0.0.137:8080,http://10.0.0.158:8080
16:11:08.751 [main] INFO Benchmark - --------------- WORKLOAD : throughput-1kb-10 --- DRIVER : Pravega---------------
16:11:09.516 [main] INFO LocalWorker - Driver: {
  "name" : "Pravega",
  "driverClass" : "io.openmessaging.benchmark.driver.pravega.PravegaBenchmarkDriver"
}
16:11:09.522 [main] INFO PravegaBenchmarkDriver - Pravega driver configuration: {
  "client" : {
    "controllerURI" : "tcp://10.0.0.242:9090",
    "scopeName" : "examples"
  },
  "writer" : {
    "enableConnectionPooling" : true
  },
  "includeTimestampInEvent" : true,
  "enableTransaction" : false,
  "eventsPerTransaction" : 1,
  "enableStreamAutoScaling" : false,
  "eventsPerSecond" : -1,
  "kbytesPerSecond" : 1000000,
  "createScope" : true,
  "deleteStreams" : false
}
16:11:09.734 [main] INFO ControllerImpl - Controller client connecting to server at 10.0.0.242:9090
16:11:09.756 [main] INFO ControllerImpl - Controller client connecting to server at 10.0.0.242:9090
16:11:09.762 [main] INFO ControllerImpl - Controller client connecting to server at 10.0.0.242:9090
16:11:12.731 [main] INFO WorkloadGenerator - Created 10 topics in 2964.000326 ms
16:11:18.009 [main] INFO WorkloadGenerator - Created 10 consumers in 5275.975039 ms
16:11:18.164 [main] INFO WorkloadGenerator - Created 10 producers in 154.991519 ms
16:11:18.164 [main] INFO WorkloadGenerator - Waiting for consumers to be ready...
16:11:18.186 [main] INFO WorkloadGenerator - Waiting for topics to be ready -- Sent: 3, Received: 0, Expected: 10
16:11:20.189 [main] INFO WorkloadGenerator - Waiting for topics to be ready -- Sent: 10, Received: 10, Expected: 10
16:11:20.189 [main] INFO WorkloadGenerator - All consumers are ready!
16:11:20.242 [main] INFO WorkloadGenerator - ----- Starting warm-up traffic (1m) ------
16:11:30.728 [main] INFO WorkloadGenerator - Pub rate 320951.8 msg/s / 313.4 MB/s | Pub err     0.0 err/s | Cons rate 284267.9 msg/s / 277.6 MB/s | Backlog: 366.9 K | Pub Latency (ms) avg: 1290.8 - 50%: 1294.0 - 99%: 3267.4 - 99.9%: 3467.8 - Max: 3507.6 | Pub Delay Latency (us) avg: 2068708.6 - 50%: 1302519.0 - 99%: 5258911.0 - 99.9%: 5501151.0 - Max: 5624799.0
16:11:40.969 [main] INFO WorkloadGenerator - Pub rate 307333.0 msg/s / 300.1 MB/s | Pub err     0.0 err/s | Cons rate 301432.1 msg/s / 294.4 MB/s | Backlog: 428.9 K | Pub Latency (ms) avg: 1759.5 - 50%: 1644.1 - 99%: 4318.7 - 99.9%: 4792.1 - Max: 4795.6 | Pub Delay Latency (us) avg: 8536905.0 - 50%: 8319039.0 - 99%: 12291455.0 - 99.9%: 12295487.0 - Max: 12311295.0
16:11:51.162 [main] INFO WorkloadGenerator - Pub rate 310979.0 msg/s / 303.7 MB/s | Pub err     0.0 err/s | Cons rate 268967.4 msg/s / 262.7 MB/s | Backlog: 859.1 K | Pub Latency (ms) avg: 1750.0 - 50%: 1571.3 - 99%: 4230.9 - 99.9%: 4626.2 - Max: 4648.7 | Pub Delay Latency (us) avg: 15844045.1 - 50%: 15530495.0 - 99%: 19553279.0 - 99.9%: 20061823.0 - Max: 20064639.0
16:12:01.380 [main] INFO WorkloadGenerator - Pub rate 315414.4 msg/s / 308.0 MB/s | Pub err     0.0 err/s | Cons rate 356106.1 msg/s / 347.8 MB/s | Backlog: 444.2 K | Pub Latency (ms) avg: 1831.0 - 50%: 1662.1 - 99%: 4846.4 - 99.9%: 5644.2 - Max: 5647.8 | Pub Delay Latency (us) avg: 22897660.5 - 50%: 22957823.0 - 99%: 26878591.0 - 99.9%: 26884735.0 - Max: 26885375.0
16:12:11.611 [main] INFO WorkloadGenerator - Pub rate 307458.9 msg/s / 300.3 MB/s | Pub err     0.0 err/s | Cons rate 348422.0 msg/s / 340.3 MB/s | Backlog: 25.6 K | Pub Latency (ms) avg: 1831.1 - 50%: 1577.6 - 99%: 6485.4 - 99.9%: 7287.8 - Max: 7309.4 | Pub Delay Latency (us) avg: 29974505.9 - 50%: 30029183.0 - 99%: 33781503.0 - 99.9%: 33924095.0 - Max: 33949439.0
16:12:21.845 [main] INFO WorkloadGenerator - Pub rate 302719.0 msg/s / 295.6 MB/s | Pub err     0.0 err/s | Cons rate 236757.9 msg/s / 231.2 MB/s | Backlog: 700.6 K | Pub Latency (ms) avg: 1739.9 - 50%: 1613.9 - 99%: 4077.3 - 99.9%: 5786.3 - Max: 5794.9 | Pub Delay Latency (us) avg: 36989941.7 - 50%: 36790271.0 - 99%: 40408831.0 - 99.9%: 40760575.0 - Max: 40913919.0
16:12:22.434 [main] INFO WorkloadGenerator - ----- Aggregated Pub Latency (ms) avg: 1708.5 - 50%: 1596.2 - 95%: 3276.0 - 99%: 4808.2 - 99.9%: 6843.0 - 99.99%: 7293.4 - Max: 7309.4 | Pub Delay (us)  avg: 19353175.1 - 50%: 19489791.0 - 95%: 38689535.0 - 99%: 40171775.0 - 99.9%: 40768255.0 - 99.99%: 41014783.0 - Max: 41022975.0
16:12:22.627 [main] INFO WorkloadGenerator - ----- Starting benchmark traffic (2m)------
16:12:32.780 [main] INFO WorkloadGenerator - Pub rate 318839.3 msg/s / 311.4 MB/s | Pub err     0.0 err/s | Cons rate 302743.9 msg/s / 295.6 MB/s | Backlog: 861.6 K | Pub Latency (ms) avg: 1865.2 - 50%: 1764.2 - 99%: 4245.8 - 99.9%: 4848.4 - Max: 5158.1 | Pub Delay Latency (us) avg: 44339344.6 - 50%: 44178687.0 - 99%: 48395007.0 - 99.9%: 48487679.0 - Max: 48570623.0
16:12:43.125 [main] INFO WorkloadGenerator - Pub rate 313738.4 msg/s / 306.4 MB/s | Pub err     0.0 err/s | Cons rate 369924.2 msg/s / 361.3 MB/s | Backlog: 288.8 K | Pub Latency (ms) avg: 1744.0 - 50%: 1591.5 - 99%: 3453.5 - 99.9%: 3662.4 - Max: 3778.8 | Pub Delay Latency (us) avg: 51386089.1 - 50%: 51126783.0 - 99%: 54689279.0 - 99.9%: 55088127.0 - Max: 55108607.0
16:12:53.357 [main] INFO WorkloadGenerator - Pub rate 322320.6 msg/s / 314.8 MB/s | Pub err     0.0 err/s | Cons rate 275450.5 msg/s / 269.0 MB/s | Backlog: 773.9 K | Pub Latency (ms) avg: 1794.3 - 50%: 1609.6 - 99%: 4970.3 - 99.9%: 5099.9 - Max: 5111.6 | Pub Delay Latency (us) avg: 58199622.3 - 50%: 58676735.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:13:03.557 [main] INFO WorkloadGenerator - Pub rate 312278.2 msg/s / 305.0 MB/s | Pub err     0.0 err/s | Cons rate 356420.0 msg/s / 348.1 MB/s | Backlog: 322.5 K | Pub Latency (ms) avg: 1761.6 - 50%: 1483.8 - 99%: 5972.4 - 99.9%: 6714.4 - Max: 6975.4 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:13:13.761 [main] INFO WorkloadGenerator - Pub rate 308551.3 msg/s / 301.3 MB/s | Pub err     0.0 err/s | Cons rate 285780.9 msg/s / 279.1 MB/s | Backlog: 554.7 K | Pub Latency (ms) avg: 1739.1 - 50%: 1610.0 - 99%: 5285.7 - 99.9%: 6465.0 - Max: 6519.2 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:13:23.953 [main] INFO WorkloadGenerator - Pub rate 316138.3 msg/s / 308.7 MB/s | Pub err     0.0 err/s | Cons rate 285272.7 msg/s / 278.6 MB/s | Backlog: 869.5 K | Pub Latency (ms) avg: 1867.5 - 50%: 1513.1 - 99%: 6346.1 - 99.9%: 7577.7 - Max: 7890.2 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:13:34.152 [main] INFO WorkloadGenerator - Pub rate 307232.3 msg/s / 300.0 MB/s | Pub err     0.0 err/s | Cons rate 367319.7 msg/s / 358.7 MB/s | Backlog: 257.1 K | Pub Latency (ms) avg: 1752.8 - 50%: 1658.5 - 99%: 3139.9 - 99.9%: 3771.3 - Max: 4114.0 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:13:44.358 [main] INFO WorkloadGenerator - Pub rate 312191.4 msg/s / 304.9 MB/s | Pub err     0.0 err/s | Cons rate 315916.6 msg/s / 308.5 MB/s | Backlog: 219.1 K | Pub Latency (ms) avg: 1840.3 - 50%: 1530.8 - 99%: 5412.1 - 99.9%: 5571.7 - Max: 5724.2 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:13:54.578 [main] INFO WorkloadGenerator - Pub rate 297250.8 msg/s / 290.3 MB/s | Pub err     0.0 err/s | Cons rate 245470.8 msg/s / 239.7 MB/s | Backlog: 747.5 K | Pub Latency (ms) avg: 1686.9 - 50%: 1425.1 - 99%: 6001.2 - 99.9%: 6223.8 - Max: 6226.1 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:14:04.830 [main] INFO WorkloadGenerator - Pub rate 313272.1 msg/s / 305.9 MB/s | Pub err     0.0 err/s | Cons rate 317276.2 msg/s / 309.8 MB/s | Backlog: 706.5 K | Pub Latency (ms) avg: 1467.9 - 50%: 1392.9 - 99%: 2592.4 - 99.9%: 3032.2 - Max: 3255.2 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:14:15.038 [main] INFO WorkloadGenerator - Pub rate 315713.9 msg/s / 308.3 MB/s | Pub err     0.0 err/s | Cons rate 360135.0 msg/s / 351.7 MB/s | Backlog: 252.5 K | Pub Latency (ms) avg: 1565.1 - 50%: 1538.0 - 99%: 3946.1 - 99.9%: 3975.3 - Max: 3987.6 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:14:25.274 [main] INFO WorkloadGenerator - Pub rate 294425.4 msg/s / 287.5 MB/s | Pub err     0.0 err/s | Cons rate 280219.3 msg/s / 273.7 MB/s | Backlog: 397.8 K | Pub Latency (ms) avg: 1448.4 - 50%: 1291.9 - 99%: 4197.9 - 99.9%: 4530.4 - Max: 4666.7 | Pub Delay Latency (us) avg: 60000128.0 - 50%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - Max: 60000255.0
16:14:25.606 [main] INFO WorkloadGenerator - ----- Aggregated Pub Latency (ms) avg: 1714.8 - 50%: 1531.9 - 95%: 3229.2 - 99%: 5272.6 - 99.9%: 6498.3 - 99.99%: 7458.6 - Max: 7890.2 | Pub Delay (us)  avg: 57912564.0 - 50%: 60000255.0 - 95%: 60000255.0 - 99%: 60000255.0 - 99.9%: 60000255.0 - 99.99%: 60000255.0 - Max: 60000255.0
16:14:25.679 [main] INFO WorkloadGenerator - ----- Completed run. Stopping worker and yielding results ------
16:14:41.955 [main] INFO PravegaBenchmarkDriver - close: clientConfig=ClientConfig(controllerURI=tcp://10.0.0.242:9090, credentials=null, trustStore=null, validateHostName=true, maxConnectionsPerSegmentStore=10, isDefaultMaxConnections=true, deriveTlsEnabledFromControllerURI=true, enableTlsToController=false, enableTlsToSegmentStore=false, metricListener=null)
16:14:41.958 [main] INFO ConnectionPoolImpl - Shutting down connection pool
16:14:41.958 [main] INFO SocketConnectionFactoryImpl - Shutting down connection factory
16:14:41.965 [main] INFO ConnectionPoolImpl - Shutting down connection pool
16:14:41.965 [main] INFO SocketConnectionFactoryImpl - Shutting down connection factory
16:14:41.968 [main] INFO ConnectionPoolImpl - Shutting down connection pool
16:14:41.968 [main] INFO SocketConnectionFactoryImpl - Shutting down connection factory