21:26:04.463 [main] INFO log - Logging initialized @4214ms to org.eclipse.jetty.util.log.Slf4jLog
21:26:04.537 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
21:26:04.565 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@ea27e34{/,null,AVAILABLE}
21:26:04.579 [main] INFO AbstractConnector - Started ServerConnector@1095f122{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
21:26:04.580 [main] INFO Server - Started @4334ms
21:26:04.582 [main] INFO PrometheusMetricsProvider - Started Prometheus stats endpoint at 0.0.0.0:8081
21:26:04.616 [main] INFO BenchmarkWorker - Starting benchmark with config: {
  "httpPort" : 8080,
  "statsPort" : 8081
}
21:26:04.657 [main] INFO Javalin - 
 _________________________________________
|        _                  _ _           |
|       | | __ ___   ____ _| (_)_ __      |
|    _  | |/ _` \ \ / / _` | | | '_ \     |
|   | |_| | (_| |\ V / (_| | | | | | |    |
|    \___/ \__,_| \_/ \__,_|_|_|_| |_|    |
|_________________________________________|
|                                         |
|    https://javalin.io/documentation     |
|_________________________________________|
21:26:04.659 [main] INFO Javalin - Starting Javalin ...
21:26:04.665 [main] INFO Server - jetty-9.4.42.v20210604; built: 2021-06-04T17:33:38.939Z; git: 5cd5e6d2375eeab146813b0de9f19eda6ab6e6cb; jvm 11.0.23+9-LTS
21:26:04.677 [main] INFO session - DefaultSessionIdManager workerName=node0
21:26:04.677 [main] INFO session - No SessionScavenger set, using defaults
21:26:04.678 [main] INFO session - node0 Scavenging every 660000ms
21:26:04.679 [main] INFO ContextHandler - Started i.j.e.j.@3122b117{/,null,AVAILABLE}
21:26:04.680 [main] INFO ContextHandler - Started o.e.j.s.ServletContextHandler@29a23c3d{/,null,AVAILABLE}
21:26:04.681 [main] INFO AbstractConnector - Started ServerConnector@faa3fed{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
21:26:04.681 [main] INFO Server - Started @4436ms
21:26:04.681 [main] INFO EmbeddedServer - Jetty is listening on: [http://localhost:8080]
21:26:04.681 [main] INFO Javalin - Javalin has started \o/
21:26:04.748 [main] INFO InstanceWorkerStats - Instance worker stats initialized.
21:26:10.952 [main] INFO Benchmark - Using default worker file workers.yaml!
21:26:10.959 [main] INFO Benchmark - Reading workers list from workers.yaml
21:26:11.007 [main] INFO Benchmark - Starting benchmark with config: {
  "drivers" : [ "driver-kafka/kafka-experiment.yaml" ],
  "workers" : [ "http://10.0.0.141:8080", "http://10.0.0.174:8080", "http://10.0.0.206:8080" ],
  "workersFile" : "/opt/benchmark/workers.yaml",
  "tpcHFiles" : null,
  "workloads" : [ "workloads/throughput-100b-10-max.yaml", "workloads/throughput-100b-100-max.yaml", "workloads/throughput-100b-500-max.yaml", "workloads/throughput-100b-10-max.yaml", "workloads/throughput-100b-100-max.yaml", "workloads/throughput-100b-500-max.yaml", "workloads/throughput-100b-10-max.yaml", "workloads/throughput-100b-100-max.yaml", "workloads/throughput-100b-500-max.yaml", "workloads/throughput-1kb-10-max.yaml", "workloads/throughput-1kb-100-max.yaml", "workloads/throughput-1kb-500-max.yaml", "workloads/throughput-1kb-10-max.yaml", "workloads/throughput-1kb-100-max.yaml", "workloads/throughput-1kb-500-max.yaml", "workloads/throughput-1kb-10-max.yaml", "workloads/throughput-1kb-100-max.yaml", "workloads/throughput-1kb-500-max.yaml", "workloads/throughput-100b-10-max.yaml", "workloads/throughput-100b-100-max.yaml", "workloads/throughput-100b-500-max.yaml", "workloads/throughput-100b-10-max.yaml", "workloads/throughput-100b-100-max.yaml", "workloads/throughput-100b-500-max.yaml", "workloads/throughput-100b-10-max.yaml", "workloads/throughput-100b-100-max.yaml", "workloads/throughput-100b-500-max.yaml" ],
  "output" : null
}
21:26:11.047 [main] INFO Benchmark - Workloads: {
  "throughput-100b-10-max" : {
    "name" : "throughput-100b-10",
    "topics" : 10,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 100,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "payload/payload-100b.data",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 1000000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 2,
    "warmupDurationMinutes" : 1
  },
  "throughput-100b-100-max" : {
    "name" : "throughput-100b-100",
    "topics" : 100,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 100,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "payload/payload-100b.data",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 1000000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 2,
    "warmupDurationMinutes" : 1
  },
  "throughput-100b-500-max" : {
    "name" : "throughput-100b-500",
    "topics" : 500,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 100,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "payload/payload-100b.data",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 1000000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 2,
    "warmupDurationMinutes" : 1
  },
  "throughput-1kb-10-max" : {
    "name" : "throughput-1kb-10",
    "topics" : 10,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 1024,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "payload/payload-1Kb.data",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 1000000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 2,
    "warmupDurationMinutes" : 1
  },
  "throughput-1kb-100-max" : {
    "name" : "throughput-1kb-100",
    "topics" : 100,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 1024,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "payload/payload-1Kb.data",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 1000000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 2,
    "warmupDurationMinutes" : 1
  },
  "throughput-1kb-500-max" : {
    "name" : "throughput-1kb-500",
    "topics" : 500,
    "partitionsPerTopic" : 1,
    "keyDistributor" : "NO_KEY",
    "messageSize" : 1024,
    "useRandomizedPayloads" : false,
    "randomBytesRatio" : 0.0,
    "randomizedPayloadPoolSize" : 0,
    "payloadFile" : "payload/payload-1Kb.data",
    "subscriptionsPerTopic" : 1,
    "producersPerTopic" : 1,
    "consumerPerSubscription" : 1,
    "producerRate" : 1000000,
    "consumerBacklogSizeGB" : 0,
    "backlogDrainRatio" : 1.0,
    "testDurationMinutes" : 2,
    "warmupDurationMinutes" : 1
  }
}
21:26:11.048 [main] INFO Benchmark - TPC-H arguments: [ null ]
21:26:11.086 [main] INFO InstanceWorkerStats - Instance worker stats initialized.
21:26:11.646 [main] INFO DistributedWorkersEnsemble - Workers list - producers: [http://10.0.0.141:8080]
21:26:11.647 [main] INFO DistributedWorkersEnsemble - Workers list - consumers: http://10.0.0.206:8080,http://10.0.0.174:8080
21:26:11.649 [main] INFO Benchmark - --------------- WORKLOAD : throughput-100b-10 --- DRIVER : Kafka---------------
21:26:12.254 [qtp235162442-24] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
21:26:12.287 [qtp235162442-24] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

21:26:12.341 [qtp235162442-24] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.341 [qtp235162442-24] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.341 [qtp235162442-24] INFO AppInfoParser - Kafka startTimeMs: 1716672372339
21:26:12.353 [main] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
21:26:12.380 [main] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

21:26:12.429 [main] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.429 [main] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.429 [main] INFO AppInfoParser - Kafka startTimeMs: 1716672372428
21:26:12.442 [qtp235162442-29] INFO WorkerHandler - Received create topics request for topics: {
  "numberOfTopics" : 10,
  "numberOfPartitionsPerTopic" : 1
}
21:26:12.690 [qtp235162442-29] INFO LocalWorker - Created 10 topics in 246.712207 ms
21:26:12.701 [main] INFO WorkloadGenerator - Created 10 topics in 266.931096 ms
21:26:12.827 [main] INFO WorkloadGenerator - Created 10 consumers in 113.37653 ms
21:26:12.844 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.847 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.853 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
21:26:12.870 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.870 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.870 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.871 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372870
21:26:12.872 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.874 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-2] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.874 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
21:26:12.878 [kafka-producer-network-thread | producer-1] INFO Metadata - [Producer clientId=producer-1] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.879 [kafka-producer-network-thread | producer-1] INFO TransactionManager - [Producer clientId=producer-1] ProducerId set to 3166 with epoch 0
21:26:12.881 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.881 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.882 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.882 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372881
21:26:12.883 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.885 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-3] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.885 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
21:26:12.887 [kafka-producer-network-thread | producer-2] INFO Metadata - [Producer clientId=producer-2] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.887 [kafka-producer-network-thread | producer-2] INFO TransactionManager - [Producer clientId=producer-2] ProducerId set to 3167 with epoch 0
21:26:12.892 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.892 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.892 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.892 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372892
21:26:12.893 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.894 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-4] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.895 [kafka-producer-network-thread | producer-3] INFO Metadata - [Producer clientId=producer-3] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.895 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-4] Instantiated an idempotent producer.
21:26:12.895 [kafka-producer-network-thread | producer-3] INFO TransactionManager - [Producer clientId=producer-3] ProducerId set to 4168 with epoch 0
21:26:12.900 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.900 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.900 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.901 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372900
21:26:12.902 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.903 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-5] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.903 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-5] Instantiated an idempotent producer.
21:26:12.905 [kafka-producer-network-thread | producer-4] INFO Metadata - [Producer clientId=producer-4] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.906 [kafka-producer-network-thread | producer-4] INFO TransactionManager - [Producer clientId=producer-4] ProducerId set to 4169 with epoch 0
21:26:12.908 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.908 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.908 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.908 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372908
21:26:12.909 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.910 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-6] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.911 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-6] Instantiated an idempotent producer.
21:26:12.911 [kafka-producer-network-thread | producer-5] INFO Metadata - [Producer clientId=producer-5] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.912 [kafka-producer-network-thread | producer-5] INFO TransactionManager - [Producer clientId=producer-5] ProducerId set to 4170 with epoch 0
21:26:12.915 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.915 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.915 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.915 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372915
21:26:12.916 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.918 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-7] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.918 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-7] Instantiated an idempotent producer.
21:26:12.920 [kafka-producer-network-thread | producer-6] INFO Metadata - [Producer clientId=producer-6] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.920 [kafka-producer-network-thread | producer-6] INFO TransactionManager - [Producer clientId=producer-6] ProducerId set to 5166 with epoch 0
21:26:12.922 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.922 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.922 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.922 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372922
21:26:12.923 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.924 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-8] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.924 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-8] Instantiated an idempotent producer.
21:26:12.925 [kafka-producer-network-thread | producer-7] INFO Metadata - [Producer clientId=producer-7] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.925 [kafka-producer-network-thread | producer-7] INFO TransactionManager - [Producer clientId=producer-7] ProducerId set to 3168 with epoch 0
21:26:12.928 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.928 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.928 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.928 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372928
21:26:12.929 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.930 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-9] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.931 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-9] Instantiated an idempotent producer.
21:26:12.931 [kafka-producer-network-thread | producer-8] INFO Metadata - [Producer clientId=producer-8] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.931 [kafka-producer-network-thread | producer-8] INFO TransactionManager - [Producer clientId=producer-8] ProducerId set to 4171 with epoch 0
21:26:12.934 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.934 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.934 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.935 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372934
21:26:12.935 [qtp235162442-28] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:26:12.936 [qtp235162442-28] WARN KafkaProducer - [Producer clientId=producer-10] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:26:12.936 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-10] Instantiated an idempotent producer.
21:26:12.937 [kafka-producer-network-thread | producer-9] INFO Metadata - [Producer clientId=producer-9] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.937 [kafka-producer-network-thread | producer-9] INFO TransactionManager - [Producer clientId=producer-9] ProducerId set to 4172 with epoch 0
21:26:12.940 [qtp235162442-28] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:26:12.940 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:26:12.940 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:26:12.940 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672372940
21:26:12.943 [qtp235162442-28] INFO LocalWorker - Created 10 producers in 108.290499 ms from {
  "topics" : [ "test-topic-0000009-GG0HZQ0", "test-topic-0000007-3qbZ37M", "test-topic-0000003-IQoYRnk", "test-topic-0000005-0IhUFDI", "test-topic-0000004-_xUVux8", "test-topic-0000000-YNcyuyg", "test-topic-0000006-BxtSWbs", "test-topic-0000002-Uh_uqvQ", "test-topic-0000008-NS3OvH0", "test-topic-0000001-5USjOtw" ],
  "producerIndex" : 0,
  "isTpcH" : false
}
21:26:12.944 [kafka-producer-network-thread | producer-10] INFO Metadata - [Producer clientId=producer-10] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:26:12.945 [main] INFO WorkloadGenerator - Created 10 producers in 116.60458 ms
21:26:12.945 [main] INFO WorkloadGenerator - Waiting for consumers to be ready...
21:26:12.945 [kafka-producer-network-thread | producer-10] INFO TransactionManager - [Producer clientId=producer-10] ProducerId set to 3169 with epoch 0
21:26:13.015 [main] INFO WorkloadGenerator - Waiting for topics to be ready -- Sent: 2, Received: 0, Expected: 10
21:26:15.018 [main] INFO WorkloadGenerator - Waiting for topics to be ready -- Sent: 10, Received: 0, Expected: 10
21:26:17.022 [main] INFO WorkloadGenerator - Waiting for topics to be ready -- Sent: 10, Received: 10, Expected: 10
21:26:17.022 [main] INFO WorkloadGenerator - All consumers are ready!
21:26:17.041 [qtp235162442-29] INFO WorkerHandler - Start load publish-rate: 1000000.0 msg/s -- payload-size: 100 -- producer index: 0
21:26:17.066 [main] INFO WorkloadGenerator - ----- Starting warm-up traffic (1m) ------
21:26:27.750 [main] INFO WorkloadGenerator - Pub rate 1006038.0 msg/s / 95.9 MB/s | Pub err     0.0 err/s | Cons rate 1003814.2 msg/s / 95.7 MB/s | Backlog: 22.2 K | Pub Latency (ms) avg: 10.8 - 50%:  9.6 - 99%: 46.1 - 99.9%: 84.8 - Max: 110.7 | Pub Delay Latency (us) avg: 79842.8 - 50%: 29.0 - 99%: 417631.0 - 99.9%: 421263.0 - Max: 422537.0
21:26:38.087 [main] INFO WorkloadGenerator - Pub rate 995164.5 msg/s / 94.9 MB/s | Pub err     0.0 err/s | Cons rate 997490.0 msg/s / 95.1 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 11.1 - 50%:  9.8 - 99%: 40.3 - 99.9%: 77.4 - Max: 98.9 | Pub Delay Latency (us) avg: 77.6 - 50%: 20.0 - 99%: 358.0 - 99.9%: 12085.0 - Max: 36232.0
21:26:48.338 [main] INFO WorkloadGenerator - Pub rate 1000405.6 msg/s / 95.4 MB/s | Pub err     0.0 err/s | Cons rate 1000034.4 msg/s / 95.4 MB/s | Backlog:  1.1 K | Pub Latency (ms) avg: 11.1 - 50%:  9.9 - 99%: 36.8 - 99.9%: 79.1 - Max: 102.8 | Pub Delay Latency (us) avg: 88.2 - 50%: 20.0 - 99%: 1182.0 - 99.9%: 12872.0 - Max: 21482.0
21:26:58.582 [main] INFO WorkloadGenerator - Pub rate 1001081.4 msg/s / 95.5 MB/s | Pub err     0.0 err/s | Cons rate 1001219.1 msg/s / 95.5 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 11.1 - 50%:  9.8 - 99%: 40.6 - 99.9%: 85.4 - Max: 102.0 | Pub Delay Latency (us) avg: 90.9 - 50%: 20.0 - 99%: 763.0 - 99.9%: 12245.0 - Max: 18356.0
21:27:08.816 [main] INFO WorkloadGenerator - Pub rate 998767.3 msg/s / 95.3 MB/s | Pub err     0.0 err/s | Cons rate 998760.0 msg/s / 95.2 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 11.0 - 50%: 10.0 - 99%: 28.9 - 99.9%: 61.3 - Max: 71.7 | Pub Delay Latency (us) avg: 103.0 - 50%: 21.0 - 99%: 1962.0 - 99.9%: 13179.0 - Max: 21463.0
21:27:19.012 [main] INFO WorkloadGenerator - Pub rate 1000066.9 msg/s / 95.4 MB/s | Pub err     0.0 err/s | Cons rate 999912.8 msg/s / 95.4 MB/s | Backlog:  1.4 K | Pub Latency (ms) avg: 11.6 - 50%: 10.1 - 99%: 50.7 - 99.9%: 98.1 - Max: 114.0 | Pub Delay Latency (us) avg: 498.5 - 50%: 21.0 - 99%: 25494.0 - 99.9%: 38978.0 - Max: 40075.0
21:27:19.347 [main] INFO WorkloadGenerator - ----- Aggregated Pub Latency (ms) avg: 11.1 - 50%:  9.9 - 95%: 18.0 - 99%: 40.1 - 99.9%: 82.5 - 99.99%: 102.8 - Max: 114.0 | Pub Delay (us)  avg: 13127.7 - 50%: 21.0 - 95%: 10156.0 - 99%: 400457.0 - 99.9%: 418749.0 - 99.99%: 421565.0 - Max: 422537.0
21:27:19.640 [main] INFO WorkloadGenerator - ----- Starting benchmark traffic (2m)------
21:27:29.878 [main] INFO WorkloadGenerator - Pub rate 1083231.0 msg/s / 103.3 MB/s | Pub err     0.0 err/s | Cons rate 1082168.4 msg/s / 103.2 MB/s | Backlog: 12.0 K | Pub Latency (ms) avg: 11.1 - 50%:  9.9 - 99%: 43.5 - 99.9%: 75.0 - Max: 90.2 | Pub Delay Latency (us) avg: 82.0 - 50%: 20.0 - 99%: 674.0 - 99.9%: 12207.0 - Max: 20273.0
21:27:40.081 [main] INFO WorkloadGenerator - Pub rate 998783.7 msg/s / 95.3 MB/s | Pub err     0.0 err/s | Cons rate 1000039.1 msg/s / 95.4 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 10.9 - 50%:  9.8 - 99%: 35.9 - 99.9%: 70.1 - Max: 87.0 | Pub Delay Latency (us) avg: 84.5 - 50%: 20.0 - 99%: 433.0 - 99.9%: 12105.0 - Max: 20238.0
21:27:50.293 [main] INFO WorkloadGenerator - Pub rate 1000034.0 msg/s / 95.4 MB/s | Pub err     0.0 err/s | Cons rate 1000067.0 msg/s / 95.4 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 10.9 - 50%:  9.9 - 99%: 34.4 - 99.9%: 69.6 - Max: 99.2 | Pub Delay Latency (us) avg: 48.4 - 50%: 20.0 - 99%: 172.0 - 99.9%: 7860.0 - Max: 17677.0
21:28:00.570 [main] INFO WorkloadGenerator - Pub rate 1000626.0 msg/s / 95.4 MB/s | Pub err     0.0 err/s | Cons rate 996944.0 msg/s / 95.1 MB/s | Backlog: 36.9 K | Pub Latency (ms) avg: 11.1 - 50%:  9.8 - 99%: 47.0 - 99.9%: 70.6 - Max: 94.2 | Pub Delay Latency (us) avg: 109.8 - 50%: 21.0 - 99%: 2671.0 - 99.9%: 12504.0 - Max: 63595.0
21:28:10.755 [main] INFO WorkloadGenerator - Pub rate 999552.9 msg/s / 95.3 MB/s | Pub err     0.0 err/s | Cons rate 1003146.3 msg/s / 95.7 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 11.0 - 50%:  9.6 - 99%: 45.6 - 99.9%: 83.1 - Max: 106.6 | Pub Delay Latency (us) avg: 49.8 - 50%: 17.0 - 99%: 151.0 - 99.9%: 6757.0 - Max: 34602.0
21:28:20.993 [main] INFO WorkloadGenerator - Pub rate 999878.5 msg/s / 95.4 MB/s | Pub err     0.0 err/s | Cons rate 999620.0 msg/s / 95.3 MB/s | Backlog:  2.1 K | Pub Latency (ms) avg: 10.8 - 50%:  9.7 - 99%: 32.7 - 99.9%: 68.3 - Max: 88.7 | Pub Delay Latency (us) avg: 54.3 - 50%: 20.0 - 99%: 91.0 - 99.9%: 8941.0 - Max: 20255.0
21:28:31.222 [main] INFO WorkloadGenerator - Pub rate 1001823.5 msg/s / 95.5 MB/s | Pub err     0.0 err/s | Cons rate 1001961.7 msg/s / 95.6 MB/s | Backlog:  0.8 K | Pub Latency (ms) avg: 10.8 - 50%:  9.6 - 99%: 36.2 - 99.9%: 63.2 - Max: 81.0 | Pub Delay Latency (us) avg: 81.1 - 50%: 20.0 - 99%: 754.0 - 99.9%: 11677.0 - Max: 19551.0
21:28:41.427 [main] INFO WorkloadGenerator - Pub rate 998107.4 msg/s / 95.2 MB/s | Pub err     0.0 err/s | Cons rate 998257.4 msg/s / 95.2 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 10.8 - 50%:  9.6 - 99%: 36.7 - 99.9%: 72.0 - Max: 99.6 | Pub Delay Latency (us) avg: 75.3 - 50%: 20.0 - 99%: 520.0 - 99.9%: 11428.0 - Max: 20334.0
21:28:51.632 [main] INFO WorkloadGenerator - Pub rate 999745.0 msg/s / 95.3 MB/s | Pub err     0.0 err/s | Cons rate 999763.7 msg/s / 95.3 MB/s | Backlog:  0.0 K | Pub Latency (ms) avg: 11.0 - 50%:  9.8 - 99%: 33.6 - 99.9%: 66.0 - Max: 86.4 | Pub Delay Latency (us) avg: 89.4 - 50%: 20.0 - 99%: 675.0 - 99.9%: 13312.0 - Max: 26985.0
21:29:01.856 [main] INFO WorkloadGenerator - Pub rate 1000439.4 msg/s / 95.4 MB/s | Pub err     0.0 err/s | Cons rate 1000179.4 msg/s / 95.4 MB/s | Backlog:  1.6 K | Pub Latency (ms) avg: 10.7 - 50%:  9.7 - 99%: 29.2 - 99.9%: 58.7 - Max: 71.9 | Pub Delay Latency (us) avg: 82.4 - 50%: 20.0 - 99%: 534.0 - 99.9%: 11919.0 - Max: 19403.0
21:29:12.088 [main] INFO WorkloadGenerator - Pub rate 999974.7 msg/s / 95.4 MB/s | Pub err     0.0 err/s | Cons rate 1000089.7 msg/s / 95.4 MB/s | Backlog:  0.4 K | Pub Latency (ms) avg: 10.8 - 50%:  9.7 - 99%: 36.2 - 99.9%: 60.8 - Max: 76.7 | Pub Delay Latency (us) avg: 53.2 - 50%: 20.0 - 99%: 111.0 - 99.9%: 10090.0 - Max: 15975.0
21:29:22.308 [main] INFO WorkloadGenerator - Pub rate 999656.8 msg/s / 95.3 MB/s | Pub err     0.0 err/s | Cons rate 999683.2 msg/s / 95.3 MB/s | Backlog:  0.2 K | Pub Latency (ms) avg: 10.8 - 50%:  9.6 - 99%: 33.5 - 99.9%: 71.7 - Max: 91.5 | Pub Delay Latency (us) avg: 70.5 - 50%: 20.0 - 99%: 448.0 - 99.9%: 10913.0 - Max: 20353.0
21:29:22.513 [main] INFO WorkloadGenerator - ----- Aggregated Pub Latency (ms) avg: 10.9 - 50%:  9.7 - 95%: 17.3 - 99%: 37.0 - 99.9%: 70.0 - 99.99%: 88.5 - Max: 106.6 | Pub Delay (us)  avg: 73.1 - 50%: 20.0 - 95%: 62.0 - 99%: 358.0 - 99.9%: 11490.0 - 99.99%: 15141.0 - Max: 63595.0
21:29:22.523 [main] INFO WorkloadGenerator - ----- Completed run. Stopping worker and yielding results ------
21:29:22.693 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.696 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.696 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.696 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.697 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-1 unregistered
21:29:22.697 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.698 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.698 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.699 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.699 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-2 unregistered
21:29:22.699 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.701 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.701 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.701 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.701 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-3 unregistered
21:29:22.701 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.702 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.702 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.703 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.703 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-4 unregistered
21:29:22.703 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.704 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.704 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.704 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.705 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-5 unregistered
21:29:22.705 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.706 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.706 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.706 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.706 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-6 unregistered
21:29:22.706 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.708 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.708 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.708 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.708 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-7 unregistered
21:29:22.708 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.709 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.710 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.710 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.710 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-8 unregistered
21:29:22.710 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.711 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.711 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.711 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.712 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-9 unregistered
21:29:22.712 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.713 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.713 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.713 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.714 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-10 unregistered
21:29:22.714 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.714 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.714 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.714 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.714 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-1 unregistered
21:29:22.714 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.714 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.715 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.715 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.715 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-2 unregistered
21:29:22.715 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.715 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.715 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.715 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.715 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-3 unregistered
21:29:22.715 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.715 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.715 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.716 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.716 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-4 unregistered
21:29:22.716 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.716 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.716 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.716 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.716 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-5 unregistered
21:29:22.716 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.716 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.716 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.716 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.717 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-6 unregistered
21:29:22.717 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.717 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.717 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.717 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.717 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-7 unregistered
21:29:22.717 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.717 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.717 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.717 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.717 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-8 unregistered
21:29:22.718 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.718 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.718 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.718 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.718 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-9 unregistered
21:29:22.718 [qtp235162442-29] INFO KafkaProducer - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:22.718 [qtp235162442-29] INFO Metrics - Metrics scheduler closed
21:29:22.718 [qtp235162442-29] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.718 [qtp235162442-29] INFO Metrics - Metrics reporters closed
21:29:22.718 [qtp235162442-29] INFO AppInfoParser - App info kafka.producer for producer-10 unregistered
21:29:22.719 [kafka-admin-client-thread | adminclient-1] INFO AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
21:29:22.719 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Metrics scheduler closed
21:29:22.719 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:22.719 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Metrics reporters closed
21:29:54.690 [kafka-admin-client-thread | adminclient-1] INFO AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
21:29:54.694 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Metrics scheduler closed
21:29:54.695 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:54.695 [kafka-admin-client-thread | adminclient-1] INFO Metrics - Metrics reporters closed
21:29:55.324 [main] INFO InstanceWorkerStats - Instance worker stats initialized.
21:29:55.333 [main] INFO DistributedWorkersEnsemble - Workers list - producers: [http://10.0.0.141:8080]
21:29:55.333 [main] INFO DistributedWorkersEnsemble - Workers list - consumers: http://10.0.0.206:8080,http://10.0.0.174:8080
21:29:55.334 [main] INFO Benchmark - --------------- WORKLOAD : throughput-100b-100 --- DRIVER : Kafka---------------
21:29:55.653 [qtp235162442-28] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
21:29:55.655 [qtp235162442-28] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

21:29:55.657 [qtp235162442-28] INFO AppInfoParser - Kafka version: 3.6.1
21:29:55.657 [qtp235162442-28] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:55.657 [qtp235162442-28] INFO AppInfoParser - Kafka startTimeMs: 1716672595657
21:29:55.661 [main] INFO LocalWorker - Driver: {
  "name" : "Kafka",
  "driverClass" : "io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver"
}
21:29:55.663 [main] INFO AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 1200000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

21:29:55.670 [main] INFO AppInfoParser - Kafka version: 3.6.1
21:29:55.670 [main] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:55.670 [main] INFO AppInfoParser - Kafka startTimeMs: 1716672595669
21:29:55.672 [qtp235162442-30] INFO WorkerHandler - Received create topics request for topics: {
  "numberOfTopics" : 100,
  "numberOfPartitionsPerTopic" : 1
}
21:29:56.188 [qtp235162442-30] INFO LocalWorker - Created 100 topics in 515.195843 ms
21:29:56.190 [main] INFO WorkloadGenerator - Created 100 topics in 518.784578 ms
21:29:56.730 [main] INFO WorkloadGenerator - Created 100 consumers in 536.654098 ms
21:29:56.739 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.740 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-11] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.740 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-11] Instantiated an idempotent producer.
21:29:56.742 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.742 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.742 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.742 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596742
21:29:56.743 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.744 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-12] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.744 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-12] Instantiated an idempotent producer.
21:29:56.745 [kafka-producer-network-thread | producer-11] INFO Metadata - [Producer clientId=producer-11] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.746 [kafka-producer-network-thread | producer-11] INFO TransactionManager - [Producer clientId=producer-11] ProducerId set to 5167 with epoch 0
21:29:56.746 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.746 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.746 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.746 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596746
21:29:56.747 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.747 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-13] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.748 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-13] Instantiated an idempotent producer.
21:29:56.748 [kafka-producer-network-thread | producer-12] INFO Metadata - [Producer clientId=producer-12] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.748 [kafka-producer-network-thread | producer-12] INFO TransactionManager - [Producer clientId=producer-12] ProducerId set to 3170 with epoch 0
21:29:56.749 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.749 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.750 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.750 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596749
21:29:56.750 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.751 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-14] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.751 [kafka-producer-network-thread | producer-13] INFO Metadata - [Producer clientId=producer-13] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.751 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-14] Instantiated an idempotent producer.
21:29:56.751 [kafka-producer-network-thread | producer-13] INFO TransactionManager - [Producer clientId=producer-13] ProducerId set to 4173 with epoch 0
21:29:56.753 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.753 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.753 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.753 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596753
21:29:56.754 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.755 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-15] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.755 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-15] Instantiated an idempotent producer.
21:29:56.755 [kafka-producer-network-thread | producer-14] INFO Metadata - [Producer clientId=producer-14] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.755 [kafka-producer-network-thread | producer-14] INFO TransactionManager - [Producer clientId=producer-14] ProducerId set to 5168 with epoch 0
21:29:56.756 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.757 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.757 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.757 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596757
21:29:56.757 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.758 [kafka-producer-network-thread | producer-15] INFO Metadata - [Producer clientId=producer-15] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.759 [kafka-producer-network-thread | producer-15] INFO TransactionManager - [Producer clientId=producer-15] ProducerId set to 3171 with epoch 0
21:29:56.759 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-16] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.759 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-16] Instantiated an idempotent producer.
21:29:56.760 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.760 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.760 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.761 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596760
21:29:56.761 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.762 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-17] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.762 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-17] Instantiated an idempotent producer.
21:29:56.762 [kafka-producer-network-thread | producer-16] INFO Metadata - [Producer clientId=producer-16] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.762 [kafka-producer-network-thread | producer-16] INFO TransactionManager - [Producer clientId=producer-16] ProducerId set to 4174 with epoch 0
21:29:56.764 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.764 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.764 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.764 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596764
21:29:56.765 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.765 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-18] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.765 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-18] Instantiated an idempotent producer.
21:29:56.765 [kafka-producer-network-thread | producer-17] INFO Metadata - [Producer clientId=producer-17] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.766 [kafka-producer-network-thread | producer-17] INFO TransactionManager - [Producer clientId=producer-17] ProducerId set to 5169 with epoch 0
21:29:56.767 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.767 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.767 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.767 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596767
21:29:56.768 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.769 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-19] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.769 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-19] Instantiated an idempotent producer.
21:29:56.769 [kafka-producer-network-thread | producer-18] INFO Metadata - [Producer clientId=producer-18] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.769 [kafka-producer-network-thread | producer-18] INFO TransactionManager - [Producer clientId=producer-18] ProducerId set to 4175 with epoch 0
21:29:56.770 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.770 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.771 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.771 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596770
21:29:56.771 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.772 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-20] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.772 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-20] Instantiated an idempotent producer.
21:29:56.772 [kafka-producer-network-thread | producer-19] INFO Metadata - [Producer clientId=producer-19] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.772 [kafka-producer-network-thread | producer-19] INFO TransactionManager - [Producer clientId=producer-19] ProducerId set to 3172 with epoch 0
21:29:56.774 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.774 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.774 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.774 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596774
21:29:56.775 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.775 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-21] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.775 [kafka-producer-network-thread | producer-20] INFO Metadata - [Producer clientId=producer-20] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.775 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-21] Instantiated an idempotent producer.
21:29:56.775 [kafka-producer-network-thread | producer-20] INFO TransactionManager - [Producer clientId=producer-20] ProducerId set to 4176 with epoch 0
21:29:56.777 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.777 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.777 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.777 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596777
21:29:56.778 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.778 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-22] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.779 [kafka-producer-network-thread | producer-21] INFO Metadata - [Producer clientId=producer-21] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.779 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-22] Instantiated an idempotent producer.
21:29:56.779 [kafka-producer-network-thread | producer-21] INFO TransactionManager - [Producer clientId=producer-21] ProducerId set to 3173 with epoch 0
21:29:56.780 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.780 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.780 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.781 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596780
21:29:56.781 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.782 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-23] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.782 [kafka-producer-network-thread | producer-22] INFO Metadata - [Producer clientId=producer-22] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.782 [kafka-producer-network-thread | producer-22] INFO TransactionManager - [Producer clientId=producer-22] ProducerId set to 3174 with epoch 0
21:29:56.782 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-23] Instantiated an idempotent producer.
21:29:56.784 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.784 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.784 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.784 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596784
21:29:56.785 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.785 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-24] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.785 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-24] Instantiated an idempotent producer.
21:29:56.785 [kafka-producer-network-thread | producer-23] INFO Metadata - [Producer clientId=producer-23] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.786 [kafka-producer-network-thread | producer-23] INFO TransactionManager - [Producer clientId=producer-23] ProducerId set to 3175 with epoch 0
21:29:56.787 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.787 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.787 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.787 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596787
21:29:56.788 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-25
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.788 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-25] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.788 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-25] Instantiated an idempotent producer.
21:29:56.789 [kafka-producer-network-thread | producer-24] INFO Metadata - [Producer clientId=producer-24] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.789 [kafka-producer-network-thread | producer-24] INFO TransactionManager - [Producer clientId=producer-24] ProducerId set to 3176 with epoch 0
21:29:56.790 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.790 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.790 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.790 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596790
21:29:56.791 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-26
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.791 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-26] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.791 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-26] Instantiated an idempotent producer.
21:29:56.791 [kafka-producer-network-thread | producer-25] INFO Metadata - [Producer clientId=producer-25] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.792 [kafka-producer-network-thread | producer-25] INFO TransactionManager - [Producer clientId=producer-25] ProducerId set to 3177 with epoch 0
21:29:56.793 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.793 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.793 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.793 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596793
21:29:56.794 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-27
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.794 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-27] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.794 [kafka-producer-network-thread | producer-26] INFO Metadata - [Producer clientId=producer-26] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.795 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-27] Instantiated an idempotent producer.
21:29:56.795 [kafka-producer-network-thread | producer-26] INFO TransactionManager - [Producer clientId=producer-26] ProducerId set to 4177 with epoch 0
21:29:56.796 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.796 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.796 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.796 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596796
21:29:56.797 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-28
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.797 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-28] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.798 [kafka-producer-network-thread | producer-27] INFO Metadata - [Producer clientId=producer-27] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.798 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-28] Instantiated an idempotent producer.
21:29:56.798 [kafka-producer-network-thread | producer-27] INFO TransactionManager - [Producer clientId=producer-27] ProducerId set to 3178 with epoch 0
21:29:56.799 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.799 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.799 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.799 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596799
21:29:56.800 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-29
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.801 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-29] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.801 [kafka-producer-network-thread | producer-28] INFO Metadata - [Producer clientId=producer-28] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.801 [kafka-producer-network-thread | producer-28] INFO TransactionManager - [Producer clientId=producer-28] ProducerId set to 4178 with epoch 0
21:29:56.801 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-29] Instantiated an idempotent producer.
21:29:56.802 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.802 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.802 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.802 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596802
21:29:56.803 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-30
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.803 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-30] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.804 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-30] Instantiated an idempotent producer.
21:29:56.804 [kafka-producer-network-thread | producer-29] INFO Metadata - [Producer clientId=producer-29] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.804 [kafka-producer-network-thread | producer-29] INFO TransactionManager - [Producer clientId=producer-29] ProducerId set to 5170 with epoch 0
21:29:56.805 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.805 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.805 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.805 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596805
21:29:56.806 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-31
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.807 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-31] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.807 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-31] Instantiated an idempotent producer.
21:29:56.807 [kafka-producer-network-thread | producer-30] INFO Metadata - [Producer clientId=producer-30] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.807 [kafka-producer-network-thread | producer-30] INFO TransactionManager - [Producer clientId=producer-30] ProducerId set to 5171 with epoch 0
21:29:56.808 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.808 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.808 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.808 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596808
21:29:56.809 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-32
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.810 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-32] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.810 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-32] Instantiated an idempotent producer.
21:29:56.810 [kafka-producer-network-thread | producer-31] INFO Metadata - [Producer clientId=producer-31] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.810 [kafka-producer-network-thread | producer-31] INFO TransactionManager - [Producer clientId=producer-31] ProducerId set to 4179 with epoch 0
21:29:56.811 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.811 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.811 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.811 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596811
21:29:56.812 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-33
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.813 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-33] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.813 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-33] Instantiated an idempotent producer.
21:29:56.813 [kafka-producer-network-thread | producer-32] INFO Metadata - [Producer clientId=producer-32] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.813 [kafka-producer-network-thread | producer-32] INFO TransactionManager - [Producer clientId=producer-32] ProducerId set to 3179 with epoch 0
21:29:56.814 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.815 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.815 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.815 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596815
21:29:56.815 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-34
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.816 [kafka-producer-network-thread | producer-33] INFO Metadata - [Producer clientId=producer-33] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.816 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-34] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.816 [kafka-producer-network-thread | producer-33] INFO TransactionManager - [Producer clientId=producer-33] ProducerId set to 4180 with epoch 0
21:29:56.816 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-34] Instantiated an idempotent producer.
21:29:56.817 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.818 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.818 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.818 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596817
21:29:56.818 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-35
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.819 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-35] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.819 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-35] Instantiated an idempotent producer.
21:29:56.819 [kafka-producer-network-thread | producer-34] INFO Metadata - [Producer clientId=producer-34] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.819 [kafka-producer-network-thread | producer-34] INFO TransactionManager - [Producer clientId=producer-34] ProducerId set to 5172 with epoch 0
21:29:56.820 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.820 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.820 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.820 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596820
21:29:56.821 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-36
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.822 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-36] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.822 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-36] Instantiated an idempotent producer.
21:29:56.822 [kafka-producer-network-thread | producer-35] INFO Metadata - [Producer clientId=producer-35] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.822 [kafka-producer-network-thread | producer-35] INFO TransactionManager - [Producer clientId=producer-35] ProducerId set to 5173 with epoch 0
21:29:56.823 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.823 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.823 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.824 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596823
21:29:56.824 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-37
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.825 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-37] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.825 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-37] Instantiated an idempotent producer.
21:29:56.825 [kafka-producer-network-thread | producer-36] INFO Metadata - [Producer clientId=producer-36] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.825 [kafka-producer-network-thread | producer-36] INFO TransactionManager - [Producer clientId=producer-36] ProducerId set to 5174 with epoch 0
21:29:56.826 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.826 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.826 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.826 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596826
21:29:56.827 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-38
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.827 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-38] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.828 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-38] Instantiated an idempotent producer.
21:29:56.828 [kafka-producer-network-thread | producer-37] INFO Metadata - [Producer clientId=producer-37] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.828 [kafka-producer-network-thread | producer-37] INFO TransactionManager - [Producer clientId=producer-37] ProducerId set to 5175 with epoch 0
21:29:56.829 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.829 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.829 [qtp235162442-24] INFO KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:56.829 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.829 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596829
21:29:56.830 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-39
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.831 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-39] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.831 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-39] Instantiated an idempotent producer.
21:29:56.831 [kafka-producer-network-thread | producer-38] INFO Metadata - [Producer clientId=producer-38] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.831 [qtp235162442-24] INFO Metrics - Metrics scheduler closed
21:29:56.831 [kafka-producer-network-thread | producer-38] INFO TransactionManager - [Producer clientId=producer-38] ProducerId set to 4181 with epoch 0
21:29:56.831 [qtp235162442-24] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:56.831 [qtp235162442-24] INFO Metrics - Metrics reporters closed
21:29:56.832 [qtp235162442-24] INFO AppInfoParser - App info kafka.producer for producer-11 unregistered
21:29:56.833 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.833 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.833 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.833 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596833
21:29:56.834 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-40
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.834 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-40] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.834 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-40] Instantiated an idempotent producer.
21:29:56.835 [kafka-producer-network-thread | producer-39] INFO Metadata - [Producer clientId=producer-39] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.835 [kafka-producer-network-thread | producer-39] INFO TransactionManager - [Producer clientId=producer-39] ProducerId set to 5176 with epoch 0
21:29:56.832 [qtp235162442-24] ERROR LocalWorker - Error occurred while stopping all local resources.
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:1043) ~[?:?]
	at java.util.ArrayList$Itr.next(ArrayList.java:997) ~[?:?]
	at io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver.close(KafkaBenchmarkDriver.java:145) ~[io.openmessaging.benchmark-driver-kafka-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.LocalWorker.stopAll(LocalWorker.java:593) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.WorkerHandler.handleStopAll(WorkerHandler.java:151) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.javalin.core.JavalinServlet.service(JavalinServlet.kt:61) ~[io.javalin-javalin-1.3.0.jar:?]
	at io.javalin.embeddedserver.jetty.EmbeddedJettyServer$start$httpHandler$1.doHandle(EmbeddedJettyServer.kt:42) ~[io.javalin-javalin-1.3.0.jar:?]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501) ~[org.eclipse.jetty-jetty-servlet-9.4.43.v20210629.jar:9.4.43.v20210629]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:59) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.Server.handle(Server.java:516) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:29:56.839 [qtp235162442-24] WARN ExceptionMapper - Uncaught exception
java.lang.RuntimeException: java.util.ConcurrentModificationException
	at io.openmessaging.benchmark.worker.LocalWorker.stopAll(LocalWorker.java:598) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.WorkerHandler.handleStopAll(WorkerHandler.java:151) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.javalin.core.JavalinServlet.service(JavalinServlet.kt:61) ~[io.javalin-javalin-1.3.0.jar:?]
	at io.javalin.embeddedserver.jetty.EmbeddedJettyServer$start$httpHandler$1.doHandle(EmbeddedJettyServer.kt:42) ~[io.javalin-javalin-1.3.0.jar:?]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501) ~[org.eclipse.jetty-jetty-servlet-9.4.43.v20210629.jar:9.4.43.v20210629]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:59) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.Server.handle(Server.java:516) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.util.ConcurrentModificationException
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:1043) ~[?:?]
	at java.util.ArrayList$Itr.next(ArrayList.java:997) ~[?:?]
	at io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver.close(KafkaBenchmarkDriver.java:145) ~[io.openmessaging.benchmark-driver-kafka-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.LocalWorker.stopAll(LocalWorker.java:593) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	... 28 more
21:29:56.840 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.840 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.840 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.840 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596840
21:29:56.841 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-41
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.841 [AsyncHttpClient-4-2] ERROR HttpWorkerClient - Failed to do HTTP post request to http://10.0.0.141:8080/stop-all -- code: 500
21:29:56.841 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-41] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.842 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-41] Instantiated an idempotent producer.
21:29:56.843 [kafka-producer-network-thread | producer-40] INFO Metadata - [Producer clientId=producer-40] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.843 [kafka-producer-network-thread | producer-40] INFO TransactionManager - [Producer clientId=producer-40] ProducerId set to 5177 with epoch 0
21:29:56.846 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:56.846 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:56.846 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:56.846 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:56.846 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-11 unregistered
21:29:56.846 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:56.847 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.847 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.847 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.847 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596847
21:29:56.848 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:56.848 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-42
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.848 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:56.848 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:56.848 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-12 unregistered
21:29:56.848 [qtp235162442-28] ERROR LocalWorker - Error occurred while stopping all local resources.
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:1043) ~[?:?]
	at java.util.ArrayList$Itr.next(ArrayList.java:997) ~[?:?]
	at io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver.close(KafkaBenchmarkDriver.java:145) ~[io.openmessaging.benchmark-driver-kafka-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.LocalWorker.stopAll(LocalWorker.java:593) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.WorkerHandler.handleStopAll(WorkerHandler.java:151) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.javalin.core.JavalinServlet.service(JavalinServlet.kt:61) ~[io.javalin-javalin-1.3.0.jar:?]
	at io.javalin.embeddedserver.jetty.EmbeddedJettyServer$start$httpHandler$1.doHandle(EmbeddedJettyServer.kt:42) ~[io.javalin-javalin-1.3.0.jar:?]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501) ~[org.eclipse.jetty-jetty-servlet-9.4.43.v20210629.jar:9.4.43.v20210629]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:59) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.Server.handle(Server.java:516) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:29:56.849 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-42] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.849 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-42] Instantiated an idempotent producer.
21:29:56.842 [ForkJoinPool.commonPool-worker-11] ERROR HttpWorkerClient - Exception occurred while stopping all workers
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:56.849 [qtp235162442-28] WARN ExceptionMapper - Uncaught exception
java.lang.RuntimeException: java.util.ConcurrentModificationException
	at io.openmessaging.benchmark.worker.LocalWorker.stopAll(LocalWorker.java:598) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.WorkerHandler.handleStopAll(WorkerHandler.java:151) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.javalin.core.JavalinServlet.service(JavalinServlet.kt:61) ~[io.javalin-javalin-1.3.0.jar:?]
	at io.javalin.embeddedserver.jetty.EmbeddedJettyServer$start$httpHandler$1.doHandle(EmbeddedJettyServer.kt:42) ~[io.javalin-javalin-1.3.0.jar:?]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501) ~[org.eclipse.jetty-jetty-servlet-9.4.43.v20210629.jar:9.4.43.v20210629]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:59) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.Server.handle(Server.java:516) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.util.ConcurrentModificationException
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:1043) ~[?:?]
	at java.util.ArrayList$Itr.next(ArrayList.java:997) ~[?:?]
	at io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver.close(KafkaBenchmarkDriver.java:145) ~[io.openmessaging.benchmark-driver-kafka-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.LocalWorker.stopAll(LocalWorker.java:593) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	... 28 more
21:29:56.851 [AsyncHttpClient-12-1] ERROR HttpWorkerClient - Failed to do HTTP post request to http://10.0.0.141:8080/stop-all -- code: 500
21:29:56.852 [kafka-producer-network-thread | producer-41] INFO Metadata - [Producer clientId=producer-41] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.853 [kafka-producer-network-thread | producer-41] INFO TransactionManager - [Producer clientId=producer-41] ProducerId set to 5178 with epoch 0
21:29:56.852 [ForkJoinPool.commonPool-worker-3] ERROR HttpWorkerClient - Exception occurred while stopping all workers
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:56.862 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.862 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.862 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.862 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596862
21:29:56.862 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-43
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.863 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-43] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.863 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-43] Instantiated an idempotent producer.
21:29:56.864 [kafka-producer-network-thread | producer-42] INFO Metadata - [Producer clientId=producer-42] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.864 [kafka-producer-network-thread | producer-42] INFO TransactionManager - [Producer clientId=producer-42] ProducerId set to 5179 with epoch 0
21:29:56.864 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.864 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.864 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.864 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596864
21:29:56.865 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-44
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.866 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-44] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.866 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-44] Instantiated an idempotent producer.
21:29:56.866 [kafka-producer-network-thread | producer-43] INFO Metadata - [Producer clientId=producer-43] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.867 [kafka-producer-network-thread | producer-43] INFO TransactionManager - [Producer clientId=producer-43] ProducerId set to 5180 with epoch 0
21:29:56.867 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.867 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.867 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.867 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596867
21:29:56.868 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-45
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.868 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-45] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.868 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-45] Instantiated an idempotent producer.
21:29:56.869 [kafka-producer-network-thread | producer-44] INFO Metadata - [Producer clientId=producer-44] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.869 [kafka-producer-network-thread | producer-44] INFO TransactionManager - [Producer clientId=producer-44] ProducerId set to 3180 with epoch 0
21:29:56.870 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.870 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.870 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.870 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596870
21:29:56.870 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-46
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.871 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-46] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.871 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-46] Instantiated an idempotent producer.
21:29:56.872 [kafka-producer-network-thread | producer-45] INFO Metadata - [Producer clientId=producer-45] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.872 [kafka-producer-network-thread | producer-45] INFO TransactionManager - [Producer clientId=producer-45] ProducerId set to 4182 with epoch 0
21:29:56.872 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.872 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.872 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.872 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596872
21:29:56.873 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-47
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.873 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-47] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.874 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-47] Instantiated an idempotent producer.
21:29:56.874 [kafka-producer-network-thread | producer-46] INFO Metadata - [Producer clientId=producer-46] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.874 [kafka-producer-network-thread | producer-46] INFO TransactionManager - [Producer clientId=producer-46] ProducerId set to 4183 with epoch 0
21:29:56.875 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.875 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.875 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.875 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596875
21:29:56.875 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-48
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.876 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-48] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.876 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-48] Instantiated an idempotent producer.
21:29:56.876 [kafka-producer-network-thread | producer-47] INFO Metadata - [Producer clientId=producer-47] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.876 [kafka-producer-network-thread | producer-47] INFO TransactionManager - [Producer clientId=producer-47] ProducerId set to 5181 with epoch 0
21:29:56.877 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.877 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.877 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.877 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596877
21:29:56.878 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-49
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.878 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-49] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.878 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-49] Instantiated an idempotent producer.
21:29:56.879 [kafka-producer-network-thread | producer-48] INFO Metadata - [Producer clientId=producer-48] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.879 [kafka-producer-network-thread | producer-48] INFO TransactionManager - [Producer clientId=producer-48] ProducerId set to 4184 with epoch 0
21:29:56.879 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.880 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.880 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.880 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596880
21:29:56.880 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-50
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.880 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-50] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.881 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-50] Instantiated an idempotent producer.
21:29:56.881 [kafka-producer-network-thread | producer-49] INFO Metadata - [Producer clientId=producer-49] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.881 [kafka-producer-network-thread | producer-49] INFO TransactionManager - [Producer clientId=producer-49] ProducerId set to 4185 with epoch 0
21:29:56.882 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.882 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.882 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.882 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596882
21:29:56.882 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-51
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.883 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-51] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.883 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-51] Instantiated an idempotent producer.
21:29:56.883 [kafka-producer-network-thread | producer-50] INFO Metadata - [Producer clientId=producer-50] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.883 [kafka-producer-network-thread | producer-50] INFO TransactionManager - [Producer clientId=producer-50] ProducerId set to 3181 with epoch 0
21:29:56.884 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.884 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.884 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.884 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596884
21:29:56.885 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-52
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.885 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-52] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.885 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-52] Instantiated an idempotent producer.
21:29:56.886 [kafka-producer-network-thread | producer-51] INFO Metadata - [Producer clientId=producer-51] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.886 [kafka-producer-network-thread | producer-51] INFO TransactionManager - [Producer clientId=producer-51] ProducerId set to 3182 with epoch 0
21:29:56.886 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.886 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.886 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.886 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596886
21:29:56.887 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-53
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.887 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-53] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.887 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-53] Instantiated an idempotent producer.
21:29:56.888 [kafka-producer-network-thread | producer-52] INFO Metadata - [Producer clientId=producer-52] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.888 [kafka-producer-network-thread | producer-52] INFO TransactionManager - [Producer clientId=producer-52] ProducerId set to 4186 with epoch 0
21:29:56.888 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.889 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.889 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.889 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596888
21:29:56.889 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-54
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.889 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-54] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.889 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-54] Instantiated an idempotent producer.
21:29:56.890 [kafka-producer-network-thread | producer-53] INFO Metadata - [Producer clientId=producer-53] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.890 [kafka-producer-network-thread | producer-53] INFO TransactionManager - [Producer clientId=producer-53] ProducerId set to 3183 with epoch 0
21:29:56.891 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.891 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.891 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.891 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596891
21:29:56.891 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-55
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.892 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-55] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.892 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-55] Instantiated an idempotent producer.
21:29:56.892 [kafka-producer-network-thread | producer-54] INFO Metadata - [Producer clientId=producer-54] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.892 [kafka-producer-network-thread | producer-54] INFO TransactionManager - [Producer clientId=producer-54] ProducerId set to 3184 with epoch 0
21:29:56.893 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.893 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.893 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.893 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596893
21:29:56.893 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-56
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.894 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-56] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.894 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-56] Instantiated an idempotent producer.
21:29:56.895 [kafka-producer-network-thread | producer-55] INFO Metadata - [Producer clientId=producer-55] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.895 [kafka-producer-network-thread | producer-55] INFO TransactionManager - [Producer clientId=producer-55] ProducerId set to 3185 with epoch 0
21:29:56.895 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.895 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.895 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.895 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596895
21:29:56.896 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-57
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.896 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-57] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.896 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-57] Instantiated an idempotent producer.
21:29:56.897 [kafka-producer-network-thread | producer-56] INFO Metadata - [Producer clientId=producer-56] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.897 [kafka-producer-network-thread | producer-56] INFO TransactionManager - [Producer clientId=producer-56] ProducerId set to 5182 with epoch 0
21:29:56.897 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.897 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.897 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.897 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596897
21:29:56.898 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-58
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.898 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-58] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.898 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-58] Instantiated an idempotent producer.
21:29:56.899 [kafka-producer-network-thread | producer-57] INFO Metadata - [Producer clientId=producer-57] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.899 [kafka-producer-network-thread | producer-57] INFO TransactionManager - [Producer clientId=producer-57] ProducerId set to 4187 with epoch 0
21:29:56.900 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.900 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.900 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.900 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596900
21:29:56.900 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-59
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.901 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-59] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.901 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-59] Instantiated an idempotent producer.
21:29:56.901 [kafka-producer-network-thread | producer-58] INFO Metadata - [Producer clientId=producer-58] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.901 [kafka-producer-network-thread | producer-58] INFO TransactionManager - [Producer clientId=producer-58] ProducerId set to 4188 with epoch 0
21:29:56.902 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.902 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.902 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.902 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596902
21:29:56.902 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-60
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.903 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-60] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.903 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-60] Instantiated an idempotent producer.
21:29:56.903 [kafka-producer-network-thread | producer-59] INFO Metadata - [Producer clientId=producer-59] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.904 [kafka-producer-network-thread | producer-59] INFO TransactionManager - [Producer clientId=producer-59] ProducerId set to 5183 with epoch 0
21:29:56.904 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.904 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.904 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.904 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596904
21:29:56.904 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-61
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.905 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-61] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.905 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-61] Instantiated an idempotent producer.
21:29:56.906 [kafka-producer-network-thread | producer-60] INFO Metadata - [Producer clientId=producer-60] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.906 [kafka-producer-network-thread | producer-60] INFO TransactionManager - [Producer clientId=producer-60] ProducerId set to 3186 with epoch 0
21:29:56.906 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.906 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.906 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.906 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596906
21:29:56.907 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-62
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.907 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-62] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.907 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-62] Instantiated an idempotent producer.
21:29:56.908 [kafka-producer-network-thread | producer-61] INFO Metadata - [Producer clientId=producer-61] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.908 [kafka-producer-network-thread | producer-61] INFO TransactionManager - [Producer clientId=producer-61] ProducerId set to 3187 with epoch 0
21:29:56.908 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.908 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.908 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.908 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596908
21:29:56.909 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-63
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.909 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-63] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.909 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-63] Instantiated an idempotent producer.
21:29:56.910 [kafka-producer-network-thread | producer-62] INFO Metadata - [Producer clientId=producer-62] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.910 [kafka-producer-network-thread | producer-62] INFO TransactionManager - [Producer clientId=producer-62] ProducerId set to 3188 with epoch 0
21:29:56.911 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.911 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.911 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.911 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596911
21:29:56.912 [AsyncHttpClient-16-1] ERROR HttpWorkerClient - Failed to do HTTP post request to http://10.0.0.206:8080/stop-all -- code: 500
21:29:56.913 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-64
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.913 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-64] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.914 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-64] Instantiated an idempotent producer.
21:29:56.913 [ForkJoinPool.commonPool-worker-13] ERROR HttpWorkerClient - Exception occurred while stopping all workers
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:56.916 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.916 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.916 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.916 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596916
21:29:56.916 [kafka-producer-network-thread | producer-63] INFO Metadata - [Producer clientId=producer-63] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.916 [kafka-producer-network-thread | producer-63] INFO TransactionManager - [Producer clientId=producer-63] ProducerId set to 4189 with epoch 0
21:29:56.916 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-65
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.917 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-65] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.917 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-65] Instantiated an idempotent producer.
21:29:56.918 [kafka-producer-network-thread | producer-64] INFO Metadata - [Producer clientId=producer-64] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.918 [kafka-producer-network-thread | producer-64] INFO TransactionManager - [Producer clientId=producer-64] ProducerId set to 5184 with epoch 0
21:29:56.919 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.919 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.919 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.919 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596919
21:29:56.920 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-66
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.920 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-66] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.920 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-66] Instantiated an idempotent producer.
21:29:56.921 [kafka-producer-network-thread | producer-65] INFO Metadata - [Producer clientId=producer-65] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.921 [kafka-producer-network-thread | producer-65] INFO TransactionManager - [Producer clientId=producer-65] ProducerId set to 5185 with epoch 0
21:29:56.922 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.922 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.922 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.922 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596922
21:29:56.922 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-67
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.923 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-67] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.923 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-67] Instantiated an idempotent producer.
21:29:56.924 [kafka-producer-network-thread | producer-66] INFO Metadata - [Producer clientId=producer-66] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.924 [kafka-producer-network-thread | producer-66] INFO TransactionManager - [Producer clientId=producer-66] ProducerId set to 3189 with epoch 0
21:29:56.925 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.925 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.925 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.925 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596925
21:29:56.925 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-68
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.926 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-68] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.926 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-68] Instantiated an idempotent producer.
21:29:56.927 [kafka-producer-network-thread | producer-67] INFO Metadata - [Producer clientId=producer-67] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.927 [kafka-producer-network-thread | producer-67] INFO TransactionManager - [Producer clientId=producer-67] ProducerId set to 5186 with epoch 0
21:29:56.928 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.928 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.928 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.928 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596928
21:29:56.929 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-69
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.929 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-69] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.929 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-69] Instantiated an idempotent producer.
21:29:56.933 [kafka-producer-network-thread | producer-68] INFO Metadata - [Producer clientId=producer-68] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.933 [kafka-producer-network-thread | producer-68] INFO TransactionManager - [Producer clientId=producer-68] ProducerId set to 4190 with epoch 0
21:29:56.934 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.934 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.934 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.934 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596934
21:29:56.935 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-70
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.935 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-70] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.935 [kafka-producer-network-thread | producer-69] INFO Metadata - [Producer clientId=producer-69] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.935 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-70] Instantiated an idempotent producer.
21:29:56.935 [kafka-producer-network-thread | producer-69] INFO TransactionManager - [Producer clientId=producer-69] ProducerId set to 4191 with epoch 0
21:29:56.937 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.937 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.937 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.937 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596937
21:29:56.937 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-71
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.938 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-71] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.938 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-71] Instantiated an idempotent producer.
21:29:56.938 [kafka-producer-network-thread | producer-70] INFO Metadata - [Producer clientId=producer-70] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.938 [kafka-producer-network-thread | producer-70] INFO TransactionManager - [Producer clientId=producer-70] ProducerId set to 4192 with epoch 0
21:29:56.940 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.940 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.940 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.940 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596940
21:29:56.940 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-72
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.941 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-72] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.941 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-72] Instantiated an idempotent producer.
21:29:56.941 [kafka-producer-network-thread | producer-71] INFO Metadata - [Producer clientId=producer-71] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.942 [kafka-producer-network-thread | producer-71] INFO TransactionManager - [Producer clientId=producer-71] ProducerId set to 5187 with epoch 0
21:29:56.944 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.944 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.944 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.944 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596944
21:29:56.944 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-73
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.945 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-73] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.945 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-73] Instantiated an idempotent producer.
21:29:56.946 [kafka-producer-network-thread | producer-72] INFO Metadata - [Producer clientId=producer-72] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.946 [kafka-producer-network-thread | producer-72] INFO TransactionManager - [Producer clientId=producer-72] ProducerId set to 4193 with epoch 0
21:29:56.947 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.947 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.947 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.947 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596947
21:29:56.947 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-74
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.948 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-74] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.948 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-74] Instantiated an idempotent producer.
21:29:56.948 [kafka-producer-network-thread | producer-73] INFO Metadata - [Producer clientId=producer-73] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.949 [kafka-producer-network-thread | producer-73] INFO TransactionManager - [Producer clientId=producer-73] ProducerId set to 4194 with epoch 0
21:29:56.951 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.951 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.951 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.951 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596951
21:29:56.951 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-75
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.952 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-75] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.952 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-75] Instantiated an idempotent producer.
21:29:56.953 [kafka-producer-network-thread | producer-74] INFO Metadata - [Producer clientId=producer-74] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.953 [kafka-producer-network-thread | producer-74] INFO TransactionManager - [Producer clientId=producer-74] ProducerId set to 3190 with epoch 0
21:29:56.955 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.955 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.955 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.955 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596955
21:29:56.955 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-76
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.956 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-76] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.956 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-76] Instantiated an idempotent producer.
21:29:56.957 [kafka-producer-network-thread | producer-75] INFO Metadata - [Producer clientId=producer-75] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.957 [kafka-producer-network-thread | producer-75] INFO TransactionManager - [Producer clientId=producer-75] ProducerId set to 3191 with epoch 0
21:29:56.958 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.958 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.958 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.958 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596958
21:29:56.958 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-77
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.959 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-77] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.959 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-77] Instantiated an idempotent producer.
21:29:56.959 [kafka-producer-network-thread | producer-76] INFO Metadata - [Producer clientId=producer-76] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.959 [kafka-producer-network-thread | producer-76] INFO TransactionManager - [Producer clientId=producer-76] ProducerId set to 3192 with epoch 0
21:29:56.963 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.963 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.963 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.963 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596963
21:29:56.963 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-78
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.964 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-78] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.964 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-78] Instantiated an idempotent producer.
21:29:56.967 [kafka-producer-network-thread | producer-77] INFO Metadata - [Producer clientId=producer-77] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.967 [kafka-producer-network-thread | producer-77] INFO TransactionManager - [Producer clientId=producer-77] ProducerId set to 4195 with epoch 0
21:29:56.968 [AsyncHttpClient-6-1] ERROR HttpWorkerClient - Failed to do HTTP post request to http://10.0.0.174:8080/stop-all -- code: 500
21:29:56.968 [Thread-1] ERROR HttpWorkerClient - Exception occurred while stopping all workers
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:56.974 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.974 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.974 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.974 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596974
21:29:56.975 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-79
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.976 [kafka-producer-network-thread | producer-78] INFO Metadata - [Producer clientId=producer-78] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.976 [kafka-producer-network-thread | producer-78] INFO TransactionManager - [Producer clientId=producer-78] ProducerId set to 4196 with epoch 0
21:29:56.977 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-79] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.977 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-79] Instantiated an idempotent producer.
21:29:56.978 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.979 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.979 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.979 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596979
21:29:56.979 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-80
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.980 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-80] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.980 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-80] Instantiated an idempotent producer.
21:29:56.981 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.982 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.982 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.982 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596982
21:29:56.982 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-81
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.983 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-81] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.983 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-81] Instantiated an idempotent producer.
21:29:56.985 [kafka-producer-network-thread | producer-80] INFO Metadata - [Producer clientId=producer-80] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.985 [kafka-producer-network-thread | producer-80] INFO TransactionManager - [Producer clientId=producer-80] ProducerId set to 3193 with epoch 0
21:29:56.990 [kafka-producer-network-thread | producer-79] INFO Metadata - [Producer clientId=producer-79] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.990 [kafka-producer-network-thread | producer-79] INFO TransactionManager - [Producer clientId=producer-79] ProducerId set to 3194 with epoch 0
21:29:56.994 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.994 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.994 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.994 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596994
21:29:56.995 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-82
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.995 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-82] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.996 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-82] Instantiated an idempotent producer.
21:29:56.997 [kafka-producer-network-thread | producer-81] INFO Metadata - [Producer clientId=producer-81] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:56.997 [kafka-producer-network-thread | producer-81] INFO TransactionManager - [Producer clientId=producer-81] ProducerId set to 5188 with epoch 0
21:29:56.998 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:56.998 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:56.998 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:56.998 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672596998
21:29:56.998 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-83
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:56.999 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-83] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:56.999 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-83] Instantiated an idempotent producer.
21:29:57.001 [kafka-producer-network-thread | producer-82] INFO Metadata - [Producer clientId=producer-82] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.001 [kafka-producer-network-thread | producer-82] INFO TransactionManager - [Producer clientId=producer-82] ProducerId set to 3195 with epoch 0
21:29:57.002 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.002 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.002 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.002 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597002
21:29:57.002 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-84
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.003 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-84] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.003 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-84] Instantiated an idempotent producer.
21:29:57.004 [kafka-producer-network-thread | producer-83] INFO Metadata - [Producer clientId=producer-83] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.004 [kafka-producer-network-thread | producer-83] INFO TransactionManager - [Producer clientId=producer-83] ProducerId set to 4197 with epoch 0
21:29:57.005 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.005 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.005 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.005 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597005
21:29:57.006 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-85
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.006 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-85] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.006 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-85] Instantiated an idempotent producer.
21:29:57.007 [kafka-producer-network-thread | producer-84] INFO Metadata - [Producer clientId=producer-84] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.007 [kafka-producer-network-thread | producer-84] INFO TransactionManager - [Producer clientId=producer-84] ProducerId set to 3196 with epoch 0
21:29:57.008 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.008 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.008 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.008 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597008
21:29:57.009 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-86
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.009 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-86] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.010 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-86] Instantiated an idempotent producer.
21:29:57.012 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.012 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.012 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.012 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597012
21:29:57.012 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-87
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.013 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-87] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.013 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-87] Instantiated an idempotent producer.
21:29:57.013 [kafka-producer-network-thread | producer-85] INFO Metadata - [Producer clientId=producer-85] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.013 [kafka-producer-network-thread | producer-85] INFO TransactionManager - [Producer clientId=producer-85] ProducerId set to 5189 with epoch 0
21:29:57.014 [kafka-producer-network-thread | producer-86] INFO Metadata - [Producer clientId=producer-86] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.014 [kafka-producer-network-thread | producer-86] INFO TransactionManager - [Producer clientId=producer-86] ProducerId set to 5190 with epoch 0
21:29:57.015 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.015 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.015 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.015 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597015
21:29:57.015 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-88
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.016 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-88] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.016 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-88] Instantiated an idempotent producer.
21:29:57.016 [kafka-producer-network-thread | producer-87] INFO Metadata - [Producer clientId=producer-87] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.016 [kafka-producer-network-thread | producer-87] INFO TransactionManager - [Producer clientId=producer-87] ProducerId set to 4198 with epoch 0
21:29:57.019 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.019 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.019 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.019 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597019
21:29:57.020 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-89
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.020 [kafka-producer-network-thread | producer-88] INFO Metadata - [Producer clientId=producer-88] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.020 [kafka-producer-network-thread | producer-88] INFO TransactionManager - [Producer clientId=producer-88] ProducerId set to 4199 with epoch 0
21:29:57.020 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-89] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.020 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-89] Instantiated an idempotent producer.
21:29:57.022 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.022 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.022 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.022 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597022
21:29:57.022 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-90
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.023 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-90] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.023 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-90] Instantiated an idempotent producer.
21:29:57.024 [kafka-producer-network-thread | producer-89] INFO Metadata - [Producer clientId=producer-89] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.024 [kafka-producer-network-thread | producer-89] INFO TransactionManager - [Producer clientId=producer-89] ProducerId set to 5191 with epoch 0
21:29:57.024 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.025 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.025 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.025 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597025
21:29:57.025 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-91
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.026 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-91] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.026 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-91] Instantiated an idempotent producer.
21:29:57.026 [kafka-producer-network-thread | producer-90] INFO Metadata - [Producer clientId=producer-90] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.026 [kafka-producer-network-thread | producer-90] INFO TransactionManager - [Producer clientId=producer-90] ProducerId set to 3197 with epoch 0
21:29:57.027 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.027 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.027 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.027 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597027
21:29:57.028 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-92
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.028 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-92] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.028 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-92] Instantiated an idempotent producer.
21:29:57.032 [kafka-producer-network-thread | producer-91] INFO Metadata - [Producer clientId=producer-91] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.032 [kafka-producer-network-thread | producer-91] INFO TransactionManager - [Producer clientId=producer-91] ProducerId set to 4200 with epoch 0
21:29:57.033 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.033 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.033 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.033 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597033
21:29:57.033 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-93
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.034 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-93] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.034 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-93] Instantiated an idempotent producer.
21:29:57.034 [kafka-producer-network-thread | producer-92] INFO Metadata - [Producer clientId=producer-92] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.034 [kafka-producer-network-thread | producer-92] INFO TransactionManager - [Producer clientId=producer-92] ProducerId set to 5192 with epoch 0
21:29:57.035 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.035 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.035 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.035 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597035
21:29:57.036 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-94
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.036 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-94] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.036 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-94] Instantiated an idempotent producer.
21:29:57.036 [kafka-producer-network-thread | producer-93] INFO Metadata - [Producer clientId=producer-93] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.037 [kafka-producer-network-thread | producer-93] INFO TransactionManager - [Producer clientId=producer-93] ProducerId set to 4201 with epoch 0
21:29:57.037 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.038 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.038 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.038 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597038
21:29:57.038 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-95
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.038 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-95] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.039 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-95] Instantiated an idempotent producer.
21:29:57.039 [kafka-producer-network-thread | producer-94] INFO Metadata - [Producer clientId=producer-94] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.039 [kafka-producer-network-thread | producer-94] INFO TransactionManager - [Producer clientId=producer-94] ProducerId set to 4202 with epoch 0
21:29:57.040 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.040 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.040 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.040 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597040
21:29:57.040 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-96
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.041 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-96] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.041 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-96] Instantiated an idempotent producer.
21:29:57.042 [kafka-producer-network-thread | producer-95] INFO Metadata - [Producer clientId=producer-95] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.042 [kafka-producer-network-thread | producer-95] INFO TransactionManager - [Producer clientId=producer-95] ProducerId set to 5193 with epoch 0
21:29:57.042 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.043 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.043 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.043 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597043
21:29:57.043 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-97
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.043 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-97] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.044 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-97] Instantiated an idempotent producer.
21:29:57.044 [kafka-producer-network-thread | producer-96] INFO Metadata - [Producer clientId=producer-96] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.044 [kafka-producer-network-thread | producer-96] INFO TransactionManager - [Producer clientId=producer-96] ProducerId set to 3198 with epoch 0
21:29:57.045 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.045 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.045 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.045 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597045
21:29:57.045 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-98
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.047 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-98] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.047 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-98] Instantiated an idempotent producer.
21:29:57.048 [kafka-producer-network-thread | producer-97] INFO Metadata - [Producer clientId=producer-97] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.048 [kafka-producer-network-thread | producer-97] INFO TransactionManager - [Producer clientId=producer-97] ProducerId set to 5194 with epoch 0
21:29:57.048 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.049 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.049 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.049 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597049
21:29:57.049 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-99
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.049 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-99] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.050 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-99] Instantiated an idempotent producer.
21:29:57.050 [kafka-producer-network-thread | producer-98] INFO Metadata - [Producer clientId=producer-98] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.050 [kafka-producer-network-thread | producer-98] INFO TransactionManager - [Producer clientId=producer-98] ProducerId set to 5195 with epoch 0
21:29:57.051 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.051 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.051 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.051 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597051
21:29:57.052 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-100
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.052 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-100] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.052 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-100] Instantiated an idempotent producer.
21:29:57.053 [kafka-producer-network-thread | producer-99] INFO Metadata - [Producer clientId=producer-99] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.053 [kafka-producer-network-thread | producer-99] INFO TransactionManager - [Producer clientId=producer-99] ProducerId set to 3199 with epoch 0
21:29:57.059 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.059 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.059 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.059 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597059
21:29:57.059 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-101
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.060 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-101] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.060 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-101] Instantiated an idempotent producer.
21:29:57.060 [kafka-producer-network-thread | producer-100] INFO Metadata - [Producer clientId=producer-100] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.061 [kafka-producer-network-thread | producer-100] INFO TransactionManager - [Producer clientId=producer-100] ProducerId set to 3200 with epoch 0
21:29:57.062 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.062 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.062 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.062 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597062
21:29:57.062 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-102
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.063 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-102] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.063 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-102] Instantiated an idempotent producer.
21:29:57.063 [kafka-producer-network-thread | producer-101] INFO Metadata - [Producer clientId=producer-101] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.064 [kafka-producer-network-thread | producer-101] INFO TransactionManager - [Producer clientId=producer-101] ProducerId set to 3201 with epoch 0
21:29:57.065 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.065 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.065 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.065 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597065
21:29:57.066 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-103
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.066 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-103] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.066 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-103] Instantiated an idempotent producer.
21:29:57.066 [kafka-producer-network-thread | producer-102] INFO Metadata - [Producer clientId=producer-102] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.067 [kafka-producer-network-thread | producer-102] INFO TransactionManager - [Producer clientId=producer-102] ProducerId set to 3202 with epoch 0
21:29:57.073 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.073 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.073 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.073 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597073
21:29:57.073 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-104
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.074 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-104] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.074 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-104] Instantiated an idempotent producer.
21:29:57.075 [kafka-producer-network-thread | producer-103] INFO Metadata - [Producer clientId=producer-103] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.075 [kafka-producer-network-thread | producer-103] INFO TransactionManager - [Producer clientId=producer-103] ProducerId set to 3203 with epoch 0
21:29:57.076 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.076 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.076 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.076 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597076
21:29:57.077 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-105
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.077 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-105] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.077 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-105] Instantiated an idempotent producer.
21:29:57.078 [kafka-producer-network-thread | producer-104] INFO TransactionManager - [Producer clientId=producer-104] ProducerId set to 3204 with epoch 0
21:29:57.078 [kafka-producer-network-thread | producer-104] INFO Metadata - [Producer clientId=producer-104] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.080 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.080 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.080 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.080 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597080
21:29:57.081 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-106
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.081 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-106] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.081 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-106] Instantiated an idempotent producer.
21:29:57.081 [kafka-producer-network-thread | producer-105] INFO Metadata - [Producer clientId=producer-105] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.081 [kafka-producer-network-thread | producer-105] INFO TransactionManager - [Producer clientId=producer-105] ProducerId set to 5196 with epoch 0
21:29:57.083 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.083 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.083 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.083 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597083
21:29:57.083 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-107
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.084 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-107] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.084 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-107] Instantiated an idempotent producer.
21:29:57.085 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.085 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.085 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.085 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597085
21:29:57.086 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-108
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.086 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-108] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.086 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-108] Instantiated an idempotent producer.
21:29:57.088 [kafka-producer-network-thread | producer-107] INFO Metadata - [Producer clientId=producer-107] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.088 [kafka-producer-network-thread | producer-107] INFO TransactionManager - [Producer clientId=producer-107] ProducerId set to 4203 with epoch 0
21:29:57.089 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.089 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.089 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.089 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597089
21:29:57.089 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-109
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.090 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-109] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.090 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-109] Instantiated an idempotent producer.
21:29:57.090 [kafka-producer-network-thread | producer-108] INFO Metadata - [Producer clientId=producer-108] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.090 [kafka-producer-network-thread | producer-108] INFO TransactionManager - [Producer clientId=producer-108] ProducerId set to 3205 with epoch 0
21:29:57.090 [kafka-producer-network-thread | producer-106] INFO Metadata - [Producer clientId=producer-106] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.091 [kafka-producer-network-thread | producer-106] INFO TransactionManager - [Producer clientId=producer-106] ProducerId set to 4204 with epoch 0
21:29:57.092 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.092 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.092 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.092 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597092
21:29:57.092 [qtp235162442-23] INFO ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1048576
	bootstrap.servers = [10.0.0.49:9092, 10.0.0.150:9092, 10.0.0.216:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-110
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 1200000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

21:29:57.092 [qtp235162442-23] WARN KafkaProducer - [Producer clientId=producer-110] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 1200001.
21:29:57.093 [qtp235162442-23] INFO KafkaProducer - [Producer clientId=producer-110] Instantiated an idempotent producer.
21:29:57.093 [kafka-producer-network-thread | producer-109] INFO Metadata - [Producer clientId=producer-109] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.093 [kafka-producer-network-thread | producer-109] INFO TransactionManager - [Producer clientId=producer-109] ProducerId set to 4205 with epoch 0
21:29:57.094 [qtp235162442-23] INFO ProducerConfig - These configurations '[default.api.timeout.ms]' were supplied but are not used yet.
21:29:57.094 [qtp235162442-23] INFO AppInfoParser - Kafka version: 3.6.1
21:29:57.094 [qtp235162442-23] INFO AppInfoParser - Kafka commitId: 5e3c2b738d253ff5
21:29:57.094 [qtp235162442-23] INFO AppInfoParser - Kafka startTimeMs: 1716672597094
21:29:57.095 [qtp235162442-23] INFO LocalWorker - Created 100 producers in 355.924191 ms from {
  "topics" : [ "test-topic-0000073-WTZVZOU", "test-topic-0000008-_AbIAqk", "test-topic-0000082-ToUIqPc", "test-topic-0000025-mwrk5-g", "test-topic-0000085-X2PVFWA", "test-topic-0000079-Xv9-ujw", "test-topic-0000004-1AUV_jo", "test-topic-0000028-Y9Xi--k", "test-topic-0000045-90BWGMc", "test-topic-0000069-yTMrYIw", "test-topic-0000053-P3lltdU", "test-topic-0000072-BhPsMjA", "test-topic-0000098-JSJX4PY", "test-topic-0000003-VWwKGEM", "test-topic-0000076-9EZs7wk", "test-topic-0000093-p5E-DgQ", "test-topic-0000014-3wlfDWU", "test-topic-0000091-y6nbggQ", "test-topic-0000031-qpyZMks", "test-topic-0000057-XhH713Y", "test-topic-0000041-QVttWo8", "test-topic-0000067-SlD06ac", "test-topic-0000070-uZ9tD58", "test-topic-0000074-cdEtOz4", "test-topic-0000044-mE2Ox4c", "test-topic-0000035-IfQLsds", "test-topic-0000089-mqdMTSM", "test-topic-0000096-VUYgdWs", "test-topic-0000037-Wvvq4_U", "test-topic-0000002-X8Fic0k", "test-topic-0000040-TT1n5LE", "test-topic-0000033-juSkAsA", "test-topic-0000000-EqdRlho", "test-topic-0000081-UsmlHk0", "test-topic-0000013-izklzhE", "test-topic-0000039-wAJQ9MI", "test-topic-0000029-fOqXK3c", "test-topic-0000011-zIolETw", "test-topic-0000023-MxlF9SM", "test-topic-0000042-NVAOqvg", "test-topic-0000065-IWsiGOA", "test-topic-0000034-62-nNjk", "test-topic-0000092-bPg46f0", "test-topic-0000019-I6X_Gow", "test-topic-0000071-2JH_JOU", "test-topic-0000051-NjNj8vY", "test-topic-0000046-ygUE0fk", "test-topic-0000062-dRxmAjw", "test-topic-0000083-Rk2DFLQ", "test-topic-0000059-WlJ1svc", "test-topic-0000064-_V9WjGo", "test-topic-0000012-S0H3cQM", "test-topic-0000026-ZeDGx_I", "test-topic-0000087-MlG30Pk", "test-topic-0000066-whv_prI", "test-topic-0000052-YTqI0qU", "test-topic-0000018-UNYik_Q", "test-topic-0000088-Di3Wy3A", "test-topic-0000015-HkvsDVE", "test-topic-0000060-EHSdsuQ", "test-topic-0000095-UEU0ItM", "test-topic-0000090-Lq7AKI8", "test-topic-0000086-6FtwVn4", "test-topic-0000020-bv-k2qg", "test-topic-0000036-kOuIiMk", "test-topic-0000007-bv6BWhs", "test-topic-0000097-_lGOca8", "test-topic-0000006-LtyJ12I", "test-topic-0000078-eGi2ci8", "test-topic-0000047-80FYLsE", "test-topic-0000099-EUDDdOc", "test-topic-0000056-KapFcJ4", "test-topic-0000017-Wykc6X4", "test-topic-0000050-2cvSFKA", "test-topic-0000061-Ybdz0Uk", "test-topic-0000080-igv5vlI", "test-topic-0000030-0GtDHN8", "test-topic-0000032-_C1G2Q8", "test-topic-0000024-TMv0b2I", "test-topic-0000010-lLXUrkw", "test-topic-0000021-sdW0y6M", "test-topic-0000022-mQNc4Z8", "test-topic-0000077-JByZBUU", "test-topic-0000016-OCXmx4s", "test-topic-0000009-A-qlUjk", "test-topic-0000054-t2CPubU", "test-topic-0000027-toDHO84", "test-topic-0000084-s8QwX7E", "test-topic-0000094-fBaTjFs", "test-topic-0000049-AjAhpx4", "test-topic-0000058-rPy3eeM", "test-topic-0000038-OmzJuTc", "test-topic-0000075-5Ykluh0", "test-topic-0000048-hfREUas", "test-topic-0000001-BHPnfhE", "test-topic-0000055-AOowQcA", "test-topic-0000063-4vO_q3k", "test-topic-0000005-3HeUR5c", "test-topic-0000068-CpDt4EU", "test-topic-0000043-QrfiWMo" ],
  "producerIndex" : 0,
  "isTpcH" : false
}
21:29:57.096 [kafka-producer-network-thread | producer-110] INFO Metadata - [Producer clientId=producer-110] Cluster ID: D6f6WVSvSZiSzVetQWJOyA
21:29:57.096 [kafka-producer-network-thread | producer-110] INFO TransactionManager - [Producer clientId=producer-110] ProducerId set to 5197 with epoch 0
21:29:57.096 [main] INFO WorkloadGenerator - Created 100 producers in 365.490562 ms
21:29:57.096 [main] INFO WorkloadGenerator - Waiting for consumers to be ready...
21:29:57.098 [qtp235162442-26] WARN ExceptionMapper - Uncaught exception
java.lang.IllegalStateException: Cannot perform operation after producer has been closed
	at org.apache.kafka.clients.producer.KafkaProducer.throwIfProducerClosed(KafkaProducer.java:954) ~[org.apache.kafka-kafka-clients-3.6.1.jar:?]
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:976) ~[org.apache.kafka-kafka-clients-3.6.1.jar:?]
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:947) ~[org.apache.kafka-kafka-clients-3.6.1.jar:?]
	at io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkProducer.sendAsync(KafkaBenchmarkProducer.java:52) ~[io.openmessaging.benchmark-driver-kafka-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.LocalWorker.lambda$probeProducers$9(LocalWorker.java:261) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.ArrayList.forEach(ArrayList.java:1541) ~[?:?]
	at io.openmessaging.benchmark.worker.LocalWorker.probeProducers(LocalWorker.java:258) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.openmessaging.benchmark.worker.WorkerHandler.handleProbeProducers(WorkerHandler.java:101) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at io.javalin.core.JavalinServlet.service(JavalinServlet.kt:61) ~[io.javalin-javalin-1.3.0.jar:?]
	at io.javalin.embeddedserver.jetty.EmbeddedJettyServer$start$httpHandler$1.doHandle(EmbeddedJettyServer.kt:42) ~[io.javalin-javalin-1.3.0.jar:?]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501) ~[org.eclipse.jetty-jetty-servlet-9.4.43.v20210629.jar:9.4.43.v20210629]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:59) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.Server.handle(Server.java:516) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388) ~[org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277) [org.eclipse.jetty-jetty-server-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104) [org.eclipse.jetty-jetty-io-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036) [org.eclipse.jetty-jetty-util-9.4.42.v20210604.jar:9.4.42.v20210604]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:29:57.099 [AsyncHttpClient-12-2] ERROR HttpWorkerClient - Failed to do HTTP post request to http://10.0.0.141:8080/probe-producers -- code: 500
21:29:57.100 [main] ERROR HttpWorkerClient - Exception occurred while probing producers
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:57.101 [main] ERROR Benchmark - Failed to run the workload 'throughput-100b-100' for driver 'driver-kafka/kafka-experiment.yaml'
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:57.261 [AsyncHttpClient-14-1] ERROR HttpWorkerClient - Failed to do HTTP post request to http://10.0.0.174:8080/stop-all -- code: 500
21:29:57.261 [AsyncHttpClient-16-1] ERROR HttpWorkerClient - Failed to do HTTP post request to http://10.0.0.206:8080/stop-all -- code: 500
21:29:57.262 [ForkJoinPool.commonPool-worker-3] ERROR HttpWorkerClient - Exception occurred while stopping all workers
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:57.261 [main] ERROR HttpWorkerClient - Exception occurred while stopping all workers
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:319) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:645) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2079) ~[?:?]
	at org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:113) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:142) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.3.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-all-4.1.65.Final.jar:4.1.65.Final]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:128) ~[com.google.guava-guava-29.0-jre.jar:?]
	at io.openmessaging.benchmark.worker.HttpWorkerClient.lambda$sendPost$0(HttpWorkerClient.java:239) ~[io.openmessaging.benchmark-benchmark-framework-0.0.1-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642) ~[?:?]
	... 35 more
21:29:57.295 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.295 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.295 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.295 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.295 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-11 unregistered
21:29:57.295 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.295 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.295 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.295 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.295 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-12 unregistered
21:29:57.295 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.297 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.297 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.297 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.297 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-13 unregistered
21:29:57.297 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.298 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.298 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.298 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.298 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-14 unregistered
21:29:57.298 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.300 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.300 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.300 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.300 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-15 unregistered
21:29:57.300 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.301 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.301 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.301 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.301 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-16 unregistered
21:29:57.301 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.302 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.302 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.302 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.302 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-17 unregistered
21:29:57.302 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.303 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.303 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.303 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.304 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-18 unregistered
21:29:57.304 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.305 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.305 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.305 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.305 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-19 unregistered
21:29:57.305 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.306 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.306 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.306 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.306 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-20 unregistered
21:29:57.306 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.307 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.307 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.307 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.307 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-21 unregistered
21:29:57.307 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.308 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.308 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.308 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.308 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-22 unregistered
21:29:57.308 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.309 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.309 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.309 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.309 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-23 unregistered
21:29:57.309 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.311 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.311 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.311 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.311 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-24 unregistered
21:29:57.311 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.312 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.312 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.312 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.312 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-25 unregistered
21:29:57.312 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-26] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.313 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.313 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.313 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.313 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-26 unregistered
21:29:57.313 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.314 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.314 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.314 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.314 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-27 unregistered
21:29:57.314 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-28] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.315 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.315 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.315 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.315 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-28 unregistered
21:29:57.316 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.317 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.317 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.317 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.317 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-29 unregistered
21:29:57.317 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-30] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.318 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.318 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.318 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.318 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-30 unregistered
21:29:57.318 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-31] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.319 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.319 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.319 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.319 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-31 unregistered
21:29:57.319 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-32] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.321 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.321 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.321 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.321 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-32 unregistered
21:29:57.321 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-33] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.322 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.322 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.322 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.322 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-33 unregistered
21:29:57.322 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-34] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.323 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.323 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.323 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.323 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-34 unregistered
21:29:57.323 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-35] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.324 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.324 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.324 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.324 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-35 unregistered
21:29:57.324 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-36] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.325 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.325 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.325 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.325 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-36 unregistered
21:29:57.325 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-37] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.326 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.326 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.326 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.326 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-37 unregistered
21:29:57.326 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-38] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.327 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.327 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.327 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.327 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-38 unregistered
21:29:57.327 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-39] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.329 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.329 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.329 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.329 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-39 unregistered
21:29:57.329 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-40] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.330 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.330 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.330 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.330 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-40 unregistered
21:29:57.330 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-41] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.331 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.331 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.331 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.331 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-41 unregistered
21:29:57.331 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-42] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.332 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.332 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.332 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.332 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-42 unregistered
21:29:57.332 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-43] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.333 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.333 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.333 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.333 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-43 unregistered
21:29:57.333 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-44] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.334 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.334 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.334 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.334 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-44 unregistered
21:29:57.334 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-45] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.335 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.335 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.335 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.335 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-45 unregistered
21:29:57.335 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-46] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.336 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.336 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.336 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.336 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-46 unregistered
21:29:57.337 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-47] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.337 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.337 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.337 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.337 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-47 unregistered
21:29:57.337 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-48] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.338 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.338 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.339 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.339 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-48 unregistered
21:29:57.339 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-49] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.339 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.340 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.340 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.340 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-49 unregistered
21:29:57.340 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-50] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.341 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.341 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.341 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.341 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-50 unregistered
21:29:57.341 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-51] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.342 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.342 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.342 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.342 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-51 unregistered
21:29:57.342 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-52] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.343 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.343 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.343 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.343 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-52 unregistered
21:29:57.343 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-53] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.344 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.344 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.344 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.344 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-53 unregistered
21:29:57.344 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-54] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.345 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.345 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.345 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.345 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-54 unregistered
21:29:57.345 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-55] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.346 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.346 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.346 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.346 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-55 unregistered
21:29:57.346 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-56] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.347 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.347 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.347 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.347 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-56 unregistered
21:29:57.347 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-57] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.348 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.348 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.349 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.349 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-57 unregistered
21:29:57.349 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-58] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.350 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.350 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.350 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.350 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-58 unregistered
21:29:57.350 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-59] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.351 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.351 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.351 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.351 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-59 unregistered
21:29:57.351 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-60] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.352 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.352 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.352 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.352 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-60 unregistered
21:29:57.352 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-61] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.353 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.353 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.353 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.353 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-61 unregistered
21:29:57.353 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-62] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.354 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.354 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.354 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.354 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-62 unregistered
21:29:57.354 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-63] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.355 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.355 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.355 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.355 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-63 unregistered
21:29:57.355 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-64] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.356 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.356 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.356 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.356 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-64 unregistered
21:29:57.357 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-65] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.357 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.358 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.358 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.358 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-65 unregistered
21:29:57.358 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-66] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.359 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.359 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.359 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.359 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-66 unregistered
21:29:57.359 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-67] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.360 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.360 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.360 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.360 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-67 unregistered
21:29:57.360 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-68] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.361 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.361 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.361 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.361 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-68 unregistered
21:29:57.361 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-69] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.362 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.362 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.362 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.362 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-69 unregistered
21:29:57.362 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-70] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.363 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.363 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.363 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.363 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-70 unregistered
21:29:57.363 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-71] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.364 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.364 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.365 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.365 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-71 unregistered
21:29:57.365 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-72] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.365 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.365 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.365 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.365 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-72 unregistered
21:29:57.365 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-73] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.366 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.366 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.366 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.367 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-73 unregistered
21:29:57.367 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-74] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.368 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.368 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.368 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.368 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-74 unregistered
21:29:57.368 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-75] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.369 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.369 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.369 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.369 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-75 unregistered
21:29:57.369 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-76] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.370 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.370 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.370 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.370 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-76 unregistered
21:29:57.370 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-77] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.371 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.371 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.371 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.371 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-77 unregistered
21:29:57.371 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-78] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.372 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.372 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.372 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.372 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-78 unregistered
21:29:57.372 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-79] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.373 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.373 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.373 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.373 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-79 unregistered
21:29:57.373 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-80] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.375 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.375 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.375 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.375 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-80 unregistered
21:29:57.375 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-81] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.376 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.376 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.376 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.376 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-81 unregistered
21:29:57.376 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-82] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.377 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.377 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.377 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.377 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-82 unregistered
21:29:57.377 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-83] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.378 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.378 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.378 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.378 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-83 unregistered
21:29:57.378 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-84] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.379 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.379 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.379 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.379 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-84 unregistered
21:29:57.379 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-85] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.381 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.381 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.381 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.381 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-85 unregistered
21:29:57.381 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-86] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.382 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.382 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.382 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.382 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-86 unregistered
21:29:57.382 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-87] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.383 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.383 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.383 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.383 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-87 unregistered
21:29:57.383 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-88] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.384 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.384 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.384 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.384 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-88 unregistered
21:29:57.384 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-89] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.385 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.385 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.385 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.385 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-89 unregistered
21:29:57.385 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-90] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.386 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.386 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.386 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.386 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-90 unregistered
21:29:57.386 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-91] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.387 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.387 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.387 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.387 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-91 unregistered
21:29:57.387 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-92] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.388 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.388 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.388 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.388 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-92 unregistered
21:29:57.388 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-93] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.389 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.389 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.389 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.389 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-93 unregistered
21:29:57.389 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-94] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.390 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.390 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.390 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.390 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-94 unregistered
21:29:57.390 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-95] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.391 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.391 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.392 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.392 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-95 unregistered
21:29:57.392 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-96] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.393 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.393 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.393 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.393 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-96 unregistered
21:29:57.393 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-97] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.394 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.394 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.394 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.394 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-97 unregistered
21:29:57.394 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-98] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.395 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.395 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.395 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.395 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-98 unregistered
21:29:57.395 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-99] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.396 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.396 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.396 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.396 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-99 unregistered
21:29:57.396 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-100] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.397 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.397 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.397 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.397 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-100 unregistered
21:29:57.397 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-101] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.398 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.399 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.399 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.399 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-101 unregistered
21:29:57.399 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-102] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.400 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.400 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.400 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.400 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-102 unregistered
21:29:57.400 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-103] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.401 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.401 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.401 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.401 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-103 unregistered
21:29:57.401 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-104] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.402 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.402 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.402 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.402 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-104 unregistered
21:29:57.402 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-105] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.403 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.403 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.403 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.403 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-105 unregistered
21:29:57.403 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-106] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.404 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.404 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.404 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.404 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-106 unregistered
21:29:57.404 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-107] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.405 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.405 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.405 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.405 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-107 unregistered
21:29:57.405 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-108] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.406 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.406 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.406 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.406 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-108 unregistered
21:29:57.406 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-109] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.407 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.407 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.407 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.407 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-109 unregistered
21:29:57.407 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-110] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.407 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.407 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.407 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.407 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-110 unregistered
21:29:57.407 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.407 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.407 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.407 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-11 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-12 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-13 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-14 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-15 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-16 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-17 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-18 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.408 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-19 unregistered
21:29:57.408 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.408 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.408 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-20 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-21 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-22 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-23 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-24 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-25 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-26] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-26 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-27 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-28] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-28 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.409 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.409 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-29 unregistered
21:29:57.409 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-30] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.409 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-30 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-31] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-31 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-32] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-32 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-33] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-33 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-34] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-34 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-35] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-35 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-36] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-36 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-37] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-37 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-38] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.410 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.410 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.410 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-38 unregistered
21:29:57.410 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-39] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-39 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-40] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-40 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-41] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-41 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-42] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-42 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-43] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-43 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-44] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-44 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-45] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-45 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-46] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-46 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-47] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.411 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-47 unregistered
21:29:57.411 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-48] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.411 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.411 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-48 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-49] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-49 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-50] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-50 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-51] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-51 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-52] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-52 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-53] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-53 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-54] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-54 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-55] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-55 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-56] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-56 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-57] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-57 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-58] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.412 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.412 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.412 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-58 unregistered
21:29:57.412 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-59] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-59 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-60] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-60 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-61] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-61 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-62] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-62 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-63] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-63 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-64] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-64 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-65] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-65 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-66] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-66 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-67] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-67 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-68] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.413 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-68 unregistered
21:29:57.413 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-69] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.413 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.413 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-69 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-70] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-70 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-71] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-71 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-72] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-72 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-73] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-73 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-74] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-74 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-75] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-75 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-76] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-76 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-77] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-77 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-78] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.414 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-78 unregistered
21:29:57.414 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-79] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.414 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.414 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-79 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-80] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-80 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-81] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-81 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-82] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-82 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-83] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-83 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-84] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-84 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-85] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-85 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-86] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-86 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-87] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-87 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-88] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.415 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-88 unregistered
21:29:57.415 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-89] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.415 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.415 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-89 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-90] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-90 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-91] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-91 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-92] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-92 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-93] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-93 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-94] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-94 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-95] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-95 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-96] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-96 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-97] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-97 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-98] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.416 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-98 unregistered
21:29:57.416 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-99] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.416 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.416 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-99 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-100] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-100 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-101] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-101 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-102] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-102 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-103] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-103 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-104] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-104 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-105] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-105 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-106] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-106 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-107] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-107 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-108] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-108 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-109] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.417 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.417 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-109 unregistered
21:29:57.417 [qtp235162442-28] INFO KafkaProducer - [Producer clientId=producer-110] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
21:29:57.417 [qtp235162442-28] INFO Metrics - Metrics scheduler closed
21:29:57.418 [qtp235162442-28] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.418 [qtp235162442-28] INFO Metrics - Metrics reporters closed
21:29:57.418 [qtp235162442-28] INFO AppInfoParser - App info kafka.producer for producer-110 unregistered
21:29:57.418 [kafka-admin-client-thread | adminclient-2] INFO AppInfoParser - App info kafka.admin.client for adminclient-2 unregistered
21:29:57.418 [kafka-admin-client-thread | adminclient-2] INFO Metrics - Metrics scheduler closed
21:29:57.418 [kafka-admin-client-thread | adminclient-2] INFO Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
21:29:57.418 [kafka-admin-client-thread | adminclient-2] INFO Metrics - Metrics reporters closed
